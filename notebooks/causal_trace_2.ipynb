{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/causal_trace.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Tracing\n",
    "\n",
    "A demonstration of the double-intervention causal tracing method.\n",
    "\n",
    "The strategy used by causal tracing is to understand important\n",
    "states within a transfomer by doing two interventions simultaneously:\n",
    "\n",
    "1. Corrupt a subset of the input.  In our paper, we corrupt the subject tokens\n",
    "   to frustrate the ability of the transformer to accurately complete factual\n",
    "   prompts about the subject.\n",
    "2. Restore a subset of the internal hidden states.  In our paper, we scan\n",
    "   hidden states at all layers and all tokens, searching for individual states\n",
    "   that carry the necessary information for the transformer to recover its\n",
    "   capability to complete the factual prompt.\n",
    "\n",
    "The traces of decisive states can be shown on a heatmap.  This notebook\n",
    "demonstrates the code for conducting causal traces and creating these heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `experiments.causal_trace` module contains a set of functions for running causal traces.\n",
    "\n",
    "In this notebook, we reproduce, demonstrate and discuss the interesting functions.\n",
    "\n",
    "We begin by importing several utility functions that deal with tokens and transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import defaultdict, Counter\n",
    "from util import nethook\n",
    "from util.globals import DATA_DIR\n",
    "from experiments.causal_trace import (\n",
    "    ModelAndTokenizer,\n",
    "    layername,\n",
    "    guess_subject,\n",
    "    plot_trace_heatmap,\n",
    ")\n",
    "from experiments.causal_trace import (\n",
    "    make_inputs,\n",
    "    decode_tokens,\n",
    "    find_token_range,\n",
    "    predict_token,\n",
    "    predict_from_input,\n",
    "    collect_embedding_std,\n",
    ")\n",
    "from dsets import KnownsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fc6182ee640>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "# from uskg.models.unified.prefixtuning import Model\n",
    "from uskg.models.unified import finetune, prefixtuning\n",
    "from uskg.utils.configue import Configure\n",
    "from uskg.utils.training_arguments import WrappedSeq2SeqTrainingArguments\n",
    "from uskg.seq2seq_construction import spider as s2s_spider\n",
    "from uskg.third_party.spider.preprocess.get_tables import dump_db_json_schema\n",
    "from uskg.third_party.spider import evaluation as sp_eval\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# import stanza\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "\n",
    "from experiments import causal_trace_uskg as ctu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tokenizer_uskg: hkunlp/from_all_T5_large_prefix_spider_with_cell_value2\n",
      "Using tokenizer_fast: t5-large\n",
      "prefix-tuning sequence length is 10.\n"
     ]
    }
   ],
   "source": [
    "mt_uskg = ctu.ModelAndTokenizer_USKG('t5-large-prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('constructor', 'seq2seq_construction.spider'),\n",
       " ('schema_serialization_with_db_content', True),\n",
       " ('target_with_db_id', False)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mt_uskg.task_args.seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.model.pretrain_model.encoder.embed_tokens is mt_uskg.model.pretrain_model.shared, \\\n",
    "mt_uskg.model.pretrain_model.decoder.embed_tokens is mt_uskg.model.pretrain_model.shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.model.preseqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [k for k,v in mt_uskg.model.named_parameters()]\n",
    "# [k for k,v in mt_uskg.model.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    enc_sentences=[\"Translate to German: My name is Wolfgang and I live in Berlin\"],\n",
    "    dec_prompts=[\"Mein Name ist Wolfgang\"],\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ctu.run_model_forward_uskg(mt_uskg.model, **inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(odict_keys(['logits', 'past_key_values', 'encoder_last_hidden_state']),\n",
       " torch.Size([1, 5, 32102]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys(), out['logits'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32102,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = out[\"logits\"][0, -1].detach().cpu().numpy()\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, -1.8642352),\n",
       " (6, -9.727753),\n",
       " (5, -10.966707),\n",
       " (27, -11.037394),\n",
       " (213, -12.864212)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5 = sorted(list(enumerate(logits)), key=lambda p: -p[1])[:5]\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', ',', '.', 'I', 'where']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mt_uskg.tokenizer.decode([p[0]]) for p in top_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spider dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_train_path = '/home/yshao/Projects/SDR-analysis/data/spider/train+ratsql_graph.json'\n",
    "spider_dev_path = '/home/yshao/Projects/SDR-analysis/data/spider/dev+ratsql_graph.json'\n",
    "spider_db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev = ctu.load_raw_dataset(\n",
    "    data_filepath = spider_dev_path,\n",
    "    db_path=spider_db_dir,\n",
    "#     schema_cache=SCHEMA_CACHE\n",
    ")\n",
    "len(raw_spider_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.task_args.dataset.use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_spider_dev = s2s_spider.DevDataset(\n",
    "    args=mt_uskg.task_args,\n",
    "    raw_datasets=raw_spider_dev,\n",
    "    cache_root='../cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What are the names of all European countries with at least 3 manufacturers?',\n",
       " '| car_1 | continents : contid , continent ( europe ) | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.countryname from countries as t1 join continents as t2 on t1.continent = t2.contid join car_makers as t3 on t1.countryid = t3.country where t2.continent = 'europe' group by t1.countryname having count(*) >= 3;\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 130\n",
    "processed_spider_dev[_id]['text_in'], \\\n",
    "processed_spider_dev[_id]['struct_in'], \\\n",
    "processed_spider_dev[_id]['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_enc_sentence = f\"{processed_spider_dev[_id]['text_in']}; structed knowledge: {processed_spider_dev[_id]['struct_in']}\"\n",
    "_toks = mt_uskg.tokenizer.tokenize(_enc_sentence)\n",
    "len(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # _occ_punct = set()\n",
    "\n",
    "# for _id in range(len(processed_spider_dev)):\n",
    "#     ex = processed_spider_dev[_id]\n",
    "# #     _occ_punct.update(set(string.punctuation) & set(ex['seq_out']))\n",
    "#     if '_(' in ex['struct_in']:\n",
    "#         print(_id, ex['question'])\n",
    "#         print(ex['struct_in'])\n",
    "#         print(ex['seq_out'])\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Train set\n",
    "\n",
    "# raw_spider_train = ctu.load_raw_dataset(\n",
    "#     data_filepath = spider_train_path,\n",
    "#     db_path=spider_db_dir,\n",
    "# )\n",
    "# processed_spider_train = s2s_spider.TrainDataset(\n",
    "#     args=mt_uskg.task_args,\n",
    "#     raw_datasets=raw_spider_train,\n",
    "#     cache_root='../cache')\n",
    "# len(processed_spider_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_spider_train[5441]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis sample 1 (ID = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('How many singers do we have?', 'select count(*) from singer')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = processed_spider_dev[0]\n",
    "ex['question'], ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "dec_prompt = 'select count(*) from'\n",
    "\n",
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    enc_sentences=[enc_sentence],\n",
    "    dec_prompts=[dec_prompt],\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('How many singers do we have?; structed knowledge: | concert_singer | stadium : stadium_id, location, name, capacity, highest, lowest, average | singer : singer_id, name, country, song_name, song_release_year, age, is_male | concert : concert_id, concert_name, theme, stadium_id, year | singer_in_concert : concert_id, singer_id</s>',\n",
       " '<pad> select count(*) from')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.decode(inp['input_ids'][0]), mt_uskg.tokenizer.decode(inp['decoder_input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ctu.run_model_forward_uskg(mt_uskg.model, **inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(odict_keys(['logits', 'past_key_values', 'encoder_last_hidden_state']),\n",
       " torch.Size([1, 7, 32102]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys(), out['logits'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32102,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = out[\"logits\"][0, -1].detach().cpu().numpy()\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7634, -5.629301),\n",
       " (6721, -15.1248665),\n",
       " (10159, -17.77869),\n",
       " (2377, -18.263933),\n",
       " (8782, -18.631098)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5 = sorted(list(enumerate(logits)), key=lambda p: -p[1])[:5]\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['singer', 'vocal', 'sing', 'artist', 'singing']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mt_uskg.tokenizer.decode([p[0]]) for p in top_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e_range = ctu.find_token_range(mt_uskg.tokenizer, inp[\"input_ids\"][0], 'singer')\n",
    "# e_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 8), (15, 125))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_range, struct_range = ctu.find_text_struct_in_range(mt_uskg.tokenizer, inp[\"input_ids\"][0])\n",
    "text_range, struct_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('How many singers do we have?; structed knowledge: | concert_singer | stadium : stadium_id, location, name, capacity, highest, lowest, average | singer : singer_id, name, country, song_name, song_release_year, age, is_male | concert : concert_id, concert_name, theme, stadium_id, year | singer_in_concert : concert_id, singer_id</s>',\n",
       " 'How many singers do we have?',\n",
       " '| concert_singer | stadium : stadium_id, location, name, capacity, highest, lowest, average | singer : singer_id, name, country, song_name, song_release_year, age, is_male | concert : concert_id, concert_name, theme, stadium_id, year | singer_in_concert : concert_id, singer_id')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb, te = text_range\n",
    "sb, se = struct_range\n",
    "mt_uskg.tokenizer.decode(inp['input_ids'][0]), \\\n",
    "mt_uskg.tokenizer.decode(inp['input_ids'][0][tb:te]), \\\n",
    "mt_uskg.tokenizer.decode(inp['input_ids'][0][sb:se])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_hidden_flow_uskg(): corrupted input: *How *many *singer *s *do *we *have *? *; * *struct *e *d *knowledge *: *| *concert *_ *s *inger *| *stadium * *: *stadium *_ *i *d * *, *location * *, *name * *, *capacity * *, *highest * *, *lowest * *, *average *| *singer * *: *singer *_ *i *d * *, *name * *, *country * *, *song *_ *name * *, *song *_ *release *_ *year * *, *age * *, *is *_ *male *| *concert * *: *concert *_ *i *d * *, *concert *_ *name * *, *theme * *, *stadium *_ *i *d * *, *year *| *singer *_ *in *_ *conce *r *t * *: *concert *_ *i *d * *, *singer *_ *i *d *</s>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a6ab59e50d4835b614db67be994427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "trace_important_states_uskg.encoder:   0%|          | 0/1512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3493e4be9d4a49a9a8120a648d6df427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "trace_important_states_uskg.decoder:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = ctu.calculate_hidden_flow_uskg(\n",
    "    mt_uskg,\n",
    "    enc_sentence=enc_sentence,\n",
    "    dec_prompt=dec_prompt,\n",
    "    subject='singer',\n",
    "    replace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['scores', 'low_score', 'high_score', 'input_ids', 'input_tokens', 'dec_input_ids', 'dec_input_tokens', 'subject_range', 'answer', 'window', 'correct_prediction', 'kind']),\n",
       " True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys(), result['correct_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2487089356436627e-06"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['low_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ctu.plot_trace_heatmap_t5(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis sample 2 (ID = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What are  the different countries with singers above age 20?',\n",
       " 'select distinct country from singer where age > 20')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 9\n",
    "ex = processed_spider_dev[_id]\n",
    "ex['question'], ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "dec_prompt = \"select distinct country from singer where\"\n",
    "expect = \"age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'| concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_hidden_flow_uskg(): corrupted input: *What *are *the *different *countries *with *singer *s *above *age *20 *? *; * *struct *e *d *knowledge *: *| *concert *_ *s *inger *| *stadium * *: *stadium *_ *i *d * *, *location * *, *name * *, *capacity * *, *highest * *, *lowest * *, *average *| *singer * *: *singer *_ *i *d * *, *name * *, *country * *, *song *_ *name * *, *song *_ *release *_ *year * *, *age * *, *is *_ *male *| *concert * *: *concert *_ *i *d * *, *concert *_ *name * *, *theme * *, *stadium *_ *i *d * *, *year *| *singer *_ *in *_ *conce *r *t * *: *concert *_ *i *d * *, *singer *_ *i *d *</s>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac04e3d082042f2a990247ac1f0c95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "trace_important_states_uskg.encoder:   0%|          | 0/1560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a50b4d88314031b157eb615ed72989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "trace_important_states_uskg.decoder:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = ctu.calculate_hidden_flow_uskg(\n",
    "    mt_uskg,\n",
    "    enc_sentence=enc_sentence,\n",
    "    dec_prompt=dec_prompt,\n",
    "    subject='singer',\n",
    "    replace=True,\n",
    "    expect=expect,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['scores', 'low_score', 'high_score', 'input_ids', 'input_tokens', 'dec_input_ids', 'dec_input_tokens', 'subject_range', 'answer', 'window', 'correct_prediction', 'kind']),\n",
       " True,\n",
       " tensor(1.0000, device='cuda:0'),\n",
       " 0.0005113474908284843)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys(), result['correct_prediction'], result['high_score'], result['low_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctu.plot_trace_heatmap_t5(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis sample 3 (ID = 97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Find the model of the car whose weight is below the average weight.',\n",
       " 'select t1.model from car_names as t1 join cars_data as t2 on t1.makeid = t2.id where t2.weight < (select avg(weight) from cars_data)')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 97\n",
    "ex = processed_spider_dev[_id]\n",
    "ex['question'], ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "dec_prompt = \"select t1.model from car_names as t1 join cars_\"\n",
    "expect = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', -10.943039),\n",
       " ('stat', -21.073414),\n",
       " ('daten', -22.921432),\n",
       " ('re', -23.442766),\n",
       " ('performance', -23.719862)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text_in = ex['text_in']\n",
    "# struct_in = ex['struct_in']\n",
    "\n",
    "# enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "# dec_prompt = \"select t1.model from car_names as t1 join cars_\"\n",
    "# expect = \"data\"\n",
    "\n",
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    enc_sentences=[enc_sentence],\n",
    "    dec_prompts=[dec_prompt],\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "out = ctu.run_model_forward_uskg(mt_uskg.model, **inp)\n",
    "logits = out[\"logits\"][0, -1].detach().cpu().numpy()\n",
    "\n",
    "top_5 = sorted(list(enumerate(logits)), key=lambda p: -p[1])[:5]\n",
    "\n",
    "[(mt_uskg.tokenizer.decode([p[0]]), p[1]) for p in top_5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_hidden_flow_uskg(): corrupted input: *Find *the *model *of *the *car * *whose *weight *is *below *the *average *weight *. *; * *struct *e *d *knowledge *: *| *car *_ *1 *| *continent *s * *: *cont *i *d * *, *continent *| *countries * *: *country *i *d * *, *country *name * *, *continent *| *car *_ *makers * *: * *i *d * *, *maker * *, *full *name * *, *country *| *model *_ *list * *: *model *i *d * *, *maker * *, *model *| *car *_ *name *s * *: *make *i *d * *, *model * *, *make *| *cars *_ *data * *: * *i *d * *, * *mp *g * *, * *cylinder *s * *, * *e *disp *l * *, *horsepower * *, *weight * *, *accelerate * *, *year *</s>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328d97f4b69940a0a2f6058f1a370b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "trace_important_states_uskg.encoder:   0%|          | 0/1668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376e361260d747ea9dd41d81a85207ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "trace_important_states_uskg.decoder:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = ctu.calculate_hidden_flow_uskg(\n",
    "    mt_uskg,\n",
    "    enc_sentence=enc_sentence,\n",
    "    dec_prompt=dec_prompt,\n",
    "    subject=None,\n",
    "    replace=True,\n",
    "    expect=expect,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['scores', 'low_score', 'high_score', 'input_ids', 'input_tokens', 'dec_input_ids', 'dec_input_tokens', 'subject_range', 'answer', 'window', 'correct_prediction', 'kind']),\n",
       " True,\n",
       " tensor(0.9999, device='cuda:0'),\n",
       " 0.0008115010568872094)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys(), result['correct_prediction'], result['high_score'], result['low_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctu.plot_trace_heatmap_t5(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "dec_prompt = \"select t1.model from car_names\"\n",
    "expect = \"as\"  # 't1' -> '_', 't', '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_hidden_flow_uskg(): corrupted input: *Find *the *model *of *the *car * *whose *weight *is *below *the *average *weight *. *; * *struct *e *d *knowledge *: *| *car *_ *1 *| *continent *s * *: *cont *i *d * *, *continent *| *countries * *: *country *i *d * *, *country *name * *, *continent *| *car *_ *makers * *: * *i *d * *, *maker * *, *full *name * *, *country *| *model *_ *list * *: *model *i *d * *, *maker * *, *model *| *car *_ *name *s * *: *make *i *d * *, *model * *, *make *| *cars *_ *data * *: * *i *d * *, * *mp *g * *, * *cylinder *s * *, * *e *disp *l * *, *horsepower * *, *weight * *, *accelerate * *, *year *</s>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa85cbc173a4f46b93d0c489d3ddcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "trace_important_states_uskg.encoder:   0%|          | 0/1668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ca6ec568f14fcd80b325cfe0cdc393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "trace_important_states_uskg.decoder:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = ctu.calculate_hidden_flow_uskg(\n",
    "    mt_uskg,\n",
    "    enc_sentence=enc_sentence,\n",
    "    dec_prompt=dec_prompt,\n",
    "    subject=None,\n",
    "    replace=True,\n",
    "    expect=expect,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['scores', 'low_score', 'high_score', 'input_ids', 'input_tokens', 'dec_input_ids', 'dec_input_tokens', 'subject_range', 'answer', 'window', 'correct_prediction', 'kind']),\n",
       " True,\n",
       " tensor(1.0000, device='cuda:0'),\n",
       " 0.9942196011543274)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys(), result['correct_prediction'], result['high_score'], result['low_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctu.plot_trace_heatmap_t5(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "- merged in create_analysis_sample_dicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = '/home/yshao/Projects/language/language/xsp/data/spider/tables.json'\n",
    "db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmaps = sp_eval.build_foreign_key_map_from_json(table_path)\n",
    "evaluator = sp_eval.Evaluator(db_dir=db_dir, kmaps=kmaps, etype='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctu.evaluate_hardness.evaluator = evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0, 0, 'hard')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "_sql_str = 'select t1.birth_date from people as t1 join poker_player as t2 on t1.people_id = t2.people_id order by t2.earnings asc limit 1'\n",
    "db_name = 'poker_player'\n",
    "schema = evaluator.schemas[db_name]\n",
    "_sql = sp_eval.get_sql(schema, _sql_str)\n",
    "sp_eval.count_component1(_sql), sp_eval.count_component2(_sql), sp_eval.count_others(_sql), \\\n",
    "evaluator.eval_hardness(_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hard'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.evaluate_hardness(_sql_str, db_name, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<uskg.third_party.spider.evaluation.Evaluator at 0x7f4a744a8d90>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.evaluate_hardness.evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_prompt = 'select avg(age), min(age), max(age) from'\n",
    "ctu.detect_node_role(dec_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, ['car_makers', 'cars_data', 'car_names', 'model_list'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_dicts = ctu.create_analysis_sample_dicts(\n",
    "    mt=mt_uskg,\n",
    "    ex=processed_spider_dev[100],\n",
    "    subject_type='table'\n",
    ")\n",
    "len(a_dicts), [d['expect'] for d in a_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'partial'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex = a_dicts[2]\n",
    "ctu.check_table_text_match(a_ex, 'car_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the name of the different car makers who produced a car in 1970?'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['text_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp0: Study the influence of corrupting a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the average, minimum, and maximum age for all French singers?',\n",
       " \"select avg(age), min(age), max(age) from singer where country = 'France'\")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 5\n",
    "ex = processed_spider_dev[_id]\n",
    "ex['question'], ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('select avg(age), min(age), max(age) from singer where', 'country')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "\n",
    "# expect = 'singer'\n",
    "# expect = 'age'\n",
    "expect = 'country'\n",
    "dec_prompt = ctu.make_dec_prompt(ex['seq_out'], expect)\n",
    "\n",
    "ex['enc_sentence'] = enc_sentence\n",
    "ex['dec_prompt'] = dec_prompt\n",
    "ex['expect'] = expect\n",
    "dec_prompt, expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_toks = decode_tokens(mt_uskg.tokenizer, mt_uskg.tokenizer.encode(expect, add_special_tokens=False))\n",
    "ans_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999990463256836, 'country')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence],\n",
    "    [dec_prompt],\n",
    "    answer=expect,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "answer_len = len(mt_uskg.tokenizer.tokenize(expect))\n",
    "with torch.no_grad():\n",
    "    answers_t, base_score = [d[0] for d in ctu.predict_from_input_uskg_multi_token(mt_uskg.model, inp, pred_len=answer_len)]\n",
    "base_score = base_score.min().item()\n",
    "answer = ctu.decode_sentences(mt_uskg.tokenizer, answers_t)\n",
    "base_score, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([684], device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0bf9cb15134342bb9b3c4d40ebd864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Corrupt effect: columns:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15951d5486094c779eaf34568678d9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Corrupt effect: tables:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_d = ctu.token_corruption_influence_uskg(\n",
    "    mt_uskg,\n",
    "#     enc_sentence=enc_sentence,\n",
    "#     dec_prompt=dec_prompt,\n",
    "#     expect=expect,\n",
    "    ex,\n",
    "    replace=True,\n",
    "    use_tqdm=True,\n",
    "    skips=('token',)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['enc_sentence', 'dec_prompt', 'expect', 'base_score', 'answers_t', 'answer', 'res_list'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = result_d['res_list']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[d for d in result if d['corrpt_type'] != 'token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tHow\t0.0037964582443237305\n",
      "1\tmany\t0.0013628602027893066\n",
      "2\tbattle\t0.01413428783416748\n",
      "3\ts\t-0.0008431673049926758\n",
      "4\tdid\t0.052848875522613525\n",
      "5\tnot\t0.09322965145111084\n",
      "6\tlose\t0.002241969108581543\n",
      "7\tany\t0.056729793548583984\n",
      "8\tship\t-0.0024902820587158203\n",
      "9\twith\t0.04180067777633667\n",
      "10\tto\t0.006940901279449463\n",
      "11\tn\t0.07953697443008423\n",
      "12\tnage\t0.0018101334571838379\n",
      "13\t\t0.0008842945098876953\n",
      "14\t'\t0.0007312297821044922\n",
      "15\t225\t-0.002007007598876953\n",
      "16\t'\t0.000843048095703125\n",
      "17\t?\t0.001425027847290039\n",
      "18\t;\t-0.0008304119110107422\n",
      "19\t\t0.0033646225929260254\n",
      "20\tstruct\t0.005487203598022461\n",
      "21\te\t-0.0010203719139099121\n",
      "22\td\t0.0009642243385314941\n",
      "23\tknowledge\t-0.00048089027404785156\n",
      "24\t:\t-0.00015664100646972656\n",
      "25\t|\t0.0022062063217163086\n",
      "26\tbattle\t0.0007958412170410156\n",
      "27\t_\t0.000949561595916748\n",
      "28\tde\t0.002287924289703369\n",
      "29\ta\t0.0008778572082519531\n",
      "30\tth\t0.0004265308380126953\n",
      "31\t|\t0.0012375712394714355\n",
      "32\tbattle\t0.0064389705657958984\n",
      "33\t\t-0.0003082752227783203\n",
      "34\t:\t-0.0015889406204223633\n",
      "35\t\t-0.002041161060333252\n",
      "36\ti\t-0.002639591693878174\n",
      "37\td\t0.0030516386032104492\n",
      "38\t\t0.0008799433708190918\n",
      "39\t,\t0.001226961612701416\n",
      "40\tname\t0.0022575855255126953\n",
      "41\t\t0.0013141632080078125\n",
      "42\t,\t0.0004660487174987793\n",
      "43\tdate\t0.001199960708618164\n",
      "44\t\t0.0036588311195373535\n",
      "45\t,\t0.002676248550415039\n",
      "46\tbulg\t0.00016325712203979492\n",
      "47\tarian\t0.0017170906066894531\n",
      "48\t_\t0.00043189525604248047\n",
      "49\tcommand\t0.017362475395202637\n",
      "50\ter\t0.004083693027496338\n",
      "51\t\t0.003155231475830078\n",
      "52\t,\t0.0028000473976135254\n",
      "53\t\t0.0020836591720581055\n",
      "54\tlatin\t0.0017630457878112793\n",
      "55\t_\t0.0010582804679870605\n",
      "56\tcommand\t0.006787300109863281\n",
      "57\ter\t0.005815982818603516\n",
      "58\t\t0.005763590335845947\n",
      "59\t,\t0.01128298044204712\n",
      "60\tresult\t0.001990079879760742\n",
      "61\t|\t-0.0022734999656677246\n",
      "62\tship\t-0.0031125545501708984\n",
      "63\t\t-0.002832651138305664\n",
      "64\t:\t0.2955291271209717\n",
      "S*65*\tlost\t0.9968710248273283\n",
      "*66*\t_\t0.5390499830245972\n",
      "*67*\tin\t0.8797281607985497\n",
      "68\t_\t0.49318522214889526\n",
      "*69*\tb\t0.8122162520885468\n",
      "*70*\ta\t0.6109114289283752\n",
      "*71*E\tttle\t0.7297702133655548\n",
      "72\t\t-0.0015021562576293945\n",
      "73\t,\t0.023115992546081543\n",
      "74\t\t-0.003117501735687256\n",
      "75\ti\t-0.002889871597290039\n",
      "76\td\t-0.0015906691551208496\n",
      "77\t\t-0.00035506486892700195\n",
      "78\t,\t0.0039408206939697266\n",
      "79\tname\t-0.002143383026123047\n",
      "80\t\t0.0008987188339233398\n",
      "81\t,\t0.006338953971862793\n",
      "82\tto\t0.06164884567260742\n",
      "83\tn\t0.029359042644500732\n",
      "84\tnage\t0.0030454397201538086\n",
      "85\t\t0.005168020725250244\n",
      "86\t,\t0.001688838005065918\n",
      "87\tship\t0.008625507354736328\n",
      "88\t_\t0.005386054515838623\n",
      "89\ttype\t-0.0006664395332336426\n",
      "90\t\t0.009672999382019043\n",
      "91\t,\t0.0002510547637939453\n",
      "92\tlocation\t0.00198209285736084\n",
      "93\t\t0.0018159747123718262\n",
      "94\t,\t0.0002453327178955078\n",
      "95\tdisposition\t0.000460207462310791\n",
      "96\t_\t0.0017185211181640625\n",
      "97\tof\t0.0002980232238769531\n",
      "98\t_\t0.0056972503662109375\n",
      "99\tship\t0.0028567910194396973\n",
      "100\t|\t0.01932370662689209\n",
      "101\tdeath\t0.0008538961410522461\n",
      "102\t\t-0.001347661018371582\n",
      "103\t:\t0.002463400363922119\n",
      "104\tcaused\t-0.0013953447341918945\n",
      "105\t_\t0.0009922981262207031\n",
      "106\tby\t0.005261480808258057\n",
      "107\t_\t0.004453897476196289\n",
      "108\tship\t0.0012708306312561035\n",
      "109\t_\t0.002262592315673828\n",
      "110\ti\t0.00289839506149292\n",
      "111\td\t0.007022380828857422\n",
      "112\t\t-0.0002517104148864746\n",
      "113\t,\t-4.589557647705078e-05\n",
      "114\t\t-0.00299072265625\n",
      "115\ti\t-0.0028443336486816406\n",
      "116\td\t-0.0026192665100097656\n",
      "117\t\t-0.0006656646728515625\n",
      "118\t,\t0.0003933906555175781\n",
      "119\tnote\t-0.00017625093460083008\n",
      "120\t\t0.0006151795387268066\n",
      "121\t,\t5.9485435485839844e-05\n",
      "122\tkilled\t0.0003504753112792969\n",
      "123\t\t-0.0002913475036621094\n",
      "124\t,\t-0.0006744861602783203\n",
      "125\tinjured\t-0.0009760260581970215\n"
     ]
    }
   ],
   "source": [
    "# ID = 503\n",
    "\n",
    "_seq_len = len([d for d in result if d['corrpt_type'] == 'token'])\n",
    "_tags = [[False, False, False] for _ in range(_seq_len)]  # (is_span_start, is_span_end, is_unit)\n",
    "for i, d in enumerate(result):\n",
    "    if d['corrpt_drop'] > 0.5:\n",
    "        s, e = d['corrpt_idx']\n",
    "        if e - s > 1:\n",
    "            _tags[s][0] = True\n",
    "            _tags[e-1][1] = True\n",
    "        else:\n",
    "            _tags[s][2] = True\n",
    "\n",
    "l = []\n",
    "for i in range(_seq_len):\n",
    "    id_str = str(i)\n",
    "    if _tags[i][2]:\n",
    "        id_str = f'*{i}*'\n",
    "    if _tags[i][0]:\n",
    "        id_str = 'S' + id_str\n",
    "    if _tags[i][1]:\n",
    "        id_str = id_str + 'E'\n",
    "    \n",
    "    d = result[i]\n",
    "    l.append(f'{id_str}\\t{d[\"corrpt_token\"]}\\t{d[\"corrpt_drop\"]}')\n",
    "#         l.append(f'{i}\\t{d[\"corrpt_token\"]}\\t{d[\"corrpt_drop\"]}')\n",
    "print('\\n'.join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp3 (moved to py script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_type = 'table'\n",
    "\n",
    "res_dir = '/home/yshao/Projects/rome/results/exp3_relational_nodes_mutual'\n",
    "os.makedirs(res_dir, exist_ok=True)\n",
    "res_path = os.path.join(res_dir, f'exp=3.0_dev_{expect_type}.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1695"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(res_path, 'r') as f:\n",
    "    all_results = [json.loads(l) for l in f]\n",
    "len(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'expect', 'expect_type', 'db_id', 'expect_input_ranges', 'expect_table', 'answer', 'base_score', 'answers_t', 'correct_prediction', 'category', 'res_list', 'ex_id']),\n",
       " dict_keys(['corrpt_type', 'corrpt_idx', 'corrpt_token', 'corrpt_score', 'corrpt_drop']))"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results[0].keys(), all_results[0]['res_list'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One-time patches\n",
    "# # patch 1, for those d without \"correct_prediction\", set it True \n",
    "# # patch 2, for each d, add \"expect_table\" which is table of \"expect\" column \n",
    "# # patch 3, for each d, add ex_id \n",
    "# # patch 4, remove d where db_id = 'orchestra' and expect = 'orchestra' (it is duplicated in struct, should be skipped for now)\n",
    "\n",
    "# in_path = os.path.join(res_dir, 'exp=3.0_dev_column_old.jsonl')\n",
    "# out_path = os.path.join(res_dir, 'exp=3.0_dev_column.jsonl')\n",
    "\n",
    "\n",
    "# with open(in_path, 'r') as f:\n",
    "#     all_results = [json.loads(l) for l in f]\n",
    "\n",
    "# keep_results = []\n",
    "# for d in all_results:\n",
    "#     if (d['db_id'] == 'orchestra') and (d['expect'] == 'orchestra'):\n",
    "#         continue\n",
    "#     keep_results.append(d)\n",
    "\n",
    "# # ex_id = 0\n",
    "# # for d in all_results:\n",
    "# #     d_text_in = d['enc_sentence'].split(ctu.USKG_SPLITTER)[0]\n",
    "# #     while True:\n",
    "# #         spider_ex = processed_spider_dev[ex_id]\n",
    "# #         if spider_ex['text_in'] != d_text_in:\n",
    "# #             ex_id += 1\n",
    "# #         else:\n",
    "# #             break\n",
    "# # #     db_id = spider_ex['db_id']\n",
    "# # #     col2table = db_col2table_cache[db_id]\n",
    "# # #     d['expect_table'] = col2table[d['expect']][0]\n",
    "# #     d['ex_id'] = ex_id\n",
    "\n",
    "# with open(out_path, 'w') as f:\n",
    "#     for d in keep_results:\n",
    "#         f.write(json.dumps(d, indent=None) + '\\n')\n",
    "\n",
    "# # ex_id\n",
    "# len(keep_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('self', 1556),\n",
       " ('self_table', 1556),\n",
       " ('self_col', 7698),\n",
       " ('other_col', 24546),\n",
       " ('other_table', 5593),\n",
       " ('self_col_max', 1474),\n",
       " ('other_col_max', 1556),\n",
       " ('other_table_max', 1556)]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_col2table_cache = dict()   # db_id -> col2table\n",
    "\n",
    "scores_per_rel = {\n",
    "    k: [] \n",
    "    for k in ['self', 'self_table', 'self_col', \n",
    "              'other_col', 'other_table', 'self_col_max', 'other_col_max', 'other_table_max']}\n",
    "n_corr_pred = 0\n",
    "\n",
    "for d in all_results:\n",
    "    if not d['correct_prediction']:\n",
    "        continue\n",
    "        \n",
    "    n_corr_pred += 1\n",
    "    ex_id = d['ex_id']\n",
    "    spider_ex = processed_spider_dev[ex_id]\n",
    "    db_id = spider_ex['db_id']\n",
    "    \n",
    "    # TODO: make this a function: get_col2table(struct_in)\n",
    "    if db_col2table_cache.get(db_id) is None:\n",
    "        struct_in = spider_ex['struct_in']\n",
    "        parsed_struct_in = ctu.parse_struct_in(struct_in)\n",
    "        # parsed_struct_in_cache[db_id] = parsed_struct_in\n",
    "    \n",
    "        col2table = defaultdict(list)\n",
    "        db_id_t, tables = parsed_struct_in\n",
    "        for table_name_t, cols in tables:\n",
    "            for col_name_t, vals in cols:\n",
    "                _, table_name, _ = table_name_t\n",
    "                _, col_name, _ = col_name_t\n",
    "                col2table[col_name].append(table_name)\n",
    "        db_col2table_cache[db_id] = col2table\n",
    "    col2table = db_col2table_cache[db_id]\n",
    "    \n",
    "    expect = d['expect']\n",
    "    tab = d['expect_table']\n",
    "    \n",
    "    corrupt_drop_dict = dict()\n",
    "    \n",
    "    corrupt_drop_dict['self'] = None\n",
    "    corrupt_drop_dict['self_table'] = None\n",
    "    corrupt_drop_dict['self_col'] = []\n",
    "    corrupt_drop_dict['other_col'] = []\n",
    "    corrupt_drop_dict['other_table'] = []\n",
    "    for res in d['res_list']:\n",
    "        _drop = res['corrpt_drop']\n",
    "        _is_other = True\n",
    "        if res['corrpt_token'] == expect:\n",
    "            corrupt_drop_dict['self'] = _drop\n",
    "            _is_other = False\n",
    "            if (res['corrpt_type'] == 'column') and (d['expect_type'] == 'column'):\n",
    "                corrupt_drop_dict['self_col'].append(_drop)\n",
    "        if res['corrpt_token'] == tab:\n",
    "            corrupt_drop_dict['self_table'] = _drop\n",
    "            _is_other = False\n",
    "        if (res['corrpt_type'] == 'column') and (d['expect_type'] == 'table'):\n",
    "            _c = res['corrpt_token']\n",
    "            _t = expect\n",
    "            if _t in col2table[_c]:\n",
    "                # corrupted is a column of expect table \n",
    "                corrupt_drop_dict['self_col'].append(_drop)\n",
    "                # print(_c, _t)\n",
    "                is_other = False\n",
    "        \n",
    "        if not _is_other:\n",
    "            continue    \n",
    "        if res['corrpt_type'] == 'column':\n",
    "            corrupt_drop_dict['other_col'].append(_drop)\n",
    "        elif res['corrpt_type'] == 'table':\n",
    "            corrupt_drop_dict['other_table'].append(_drop)\n",
    "            \n",
    "    # corrupt_drop_dict['self_col_max'] = max(corrupt_drop_dict['self_col']) if corrupt_drop_dict['self_col'] else None\n",
    "    if corrupt_drop_dict['self_col']:\n",
    "        corrupt_drop_dict['self_col_max'] = max(corrupt_drop_dict['self_col'])\n",
    "    corrupt_drop_dict['other_col_max'] = max(corrupt_drop_dict['other_col'])\n",
    "    corrupt_drop_dict['other_table_max'] = max(corrupt_drop_dict['other_table'])\n",
    "    \n",
    "#     scores_per_rel['self'].append(corrupt_drop_dict['self'])\n",
    "#     scores_per_rel['self_table'].append(corrupt_drop_dict['self_table'])\n",
    "#     scores_per_rel['self_col'].extend(corrupt_drop_dict['self_col'])\n",
    "#     scores_per_rel['other_col'].extend(corrupt_drop_dict['other_col'])\n",
    "#     scores_per_rel['other_table'].extend(corrupt_drop_dict['other_table'])\n",
    "#     scores_per_rel['other_col_max'].append(corrupt_drop_dict['other_col_max'])\n",
    "#     scores_per_rel['other_table_max'].append(corrupt_drop_dict['other_table_max'])\n",
    "#     if corrupt_drop_dict['self_col_max'] is not None:\n",
    "#         scores_per_rel['self_col_max'].append(corrupt_drop_dict['self_col_max'])\n",
    "    for k, v in corrupt_drop_dict.items():\n",
    "        scores_per_rel[k].extend(ctu.ensure_list(v))\n",
    "    \n",
    "    d['corrupt_drop_dict'] = corrupt_drop_dict\n",
    "    \n",
    "[(k, len(scores_per_rel[k])) for k in scores_per_rel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('other_col', False),\n",
       " ('other_col_max', False),\n",
       " ('other_table', False),\n",
       " ('other_table_max', False),\n",
       " ('self', False),\n",
       " ('self_col', False),\n",
       " ('self_col_max', False),\n",
       " ('self_table', False)}"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{(k, (None in l)) for k, l in scores_per_rel.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('self', 0.7387205946038705),\n",
       " ('self_table', 0.7387205946038705),\n",
       " ('self_col', 0.014660158918760848),\n",
       " ('other_col', 0.006537220754201795),\n",
       " ('other_table', 0.005284151565397158),\n",
       " ('self_col_max', 0.06904510783421929),\n",
       " ('other_col_max', 0.07476104517248733),\n",
       " ('other_table_max', 0.02584633979267775)]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, np.mean(scores_per_rel[k])) for k in scores_per_rel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# self_table_effective_ids = []\n",
    "\n",
    "# for i, d in enumerate(all_results):\n",
    "#     self_table_drop = d.get('self_table_drop', 0.0)\n",
    "#     if self_table_drop > 0.5:\n",
    "#         self_table_effective_ids.append(i)\n",
    "# len(self_table_effective_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_col_effective_ids = []\n",
    "\n",
    "for i, d in enumerate(all_results):\n",
    "    self_col_drop = d.get('self_col_max_drop', 0.0)\n",
    "    if (self_col_drop is not None) and (self_col_drop > 0.5):\n",
    "        self_col_effective_ids.append(i)\n",
    "len(self_col_effective_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135, 184, 190, 191, 194, 196, 200, 203, 204, 206, 207, 209, 224, 226, 235, 246, 247, 268, 273, 275, 278, 280, 281, 282, 285, 287, 294, 298, 316, 395, 402, 423, 446, 459, 463, 467, 471, 489, 491, 495, 531, 638, 642, 711, 719, 720, 750, 763, 764, 781, 794, 795, 842, 843, 848, 977, 978, 1020, 1022, 1025, 1038, 1039, 1040, 1044, 1061, 1065, 1071, 1118, 1302, 1304, 1308, 1310, 1358, 1359, 1360, 1414, 1416, 1418, 1422, 1424, 1440, 1442, 1443, 1456, 1469, 1474, 1486, 1489, 1499, 1641, 1644, 1667, 1671, 1689, 1690]\n"
     ]
    }
   ],
   "source": [
    "print(self_col_effective_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 select t1.fname, t1.age from student as t1 join has_pet as t2 on t1.stuid = t2.stuid join pets as t3 on t3.petid = t2.petid where t3.pettype = 'dog' and t1.stuid not in (select t1.stuid from student as t1 join has_pet as t2 on t1.stuid = t2.stuid join --> pets\n",
      "184 select t1.model from --> car_names\n",
      "190 select t1.model from car_names as t1 join cars_data as t2 on t1.makeid = t2.id where t2.weight < (select avg(weight) from --> cars_data\n",
      "191 select t1.model from --> car_names\n",
      "194 select distinct t1.maker from car_makers as t1 join model_list as t2 on t1.id = t2.maker join --> car_names\n",
      "196 select distinct t1.maker from car_makers as t1 join model_list as t2 on t1.id = t2.maker join car_names as t3 on t2.model = t3.model join --> cars_data\n",
      "200 select distinct t1.maker from car_makers as t1 join model_list as t2 on t1.id = t2.maker join car_names as t3 on t2.model = t3.model join --> cars_data\n",
      "203 select t2.make, t1.year from --> cars_data\n",
      "204 select t2.make, t1.year from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t1.year = (select min(year) from --> cars_data\n",
      "206 select t2.make, t1.year from --> cars_data\n",
      "207 select t2.make, t1.year from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t1.year = (select min(year) from --> cars_data\n",
      "209 select distinct t1.model from --> model_list\n",
      "224 select count(*), t2.fullname from --> model_list\n",
      "226 select count(*), t2.fullname, t2.id from --> model_list\n",
      "235 select count(*) from --> car_makers\n",
      "246 select maker, model from --> model_list\n",
      "247 select maker, model from --> model_list\n",
      "268 select t1.model from --> car_names\n",
      "273 select avg(t2.edispl) from car_names as t1 join --> cars_data\n",
      "275 select avg(t2.edispl) from car_names as t1 join --> cars_data\n",
      "278 select model from --> car_names\n",
      "280 select count(*) from --> cars_data\n",
      "281 select count(*) from --> cars_data\n",
      "282 select count(*) from --> cars_data\n",
      "285 select count(*) from --> car_makers\n",
      "287 select count(*) from --> car_makers\n",
      "294 select distinct t2.model from car_names as t1 join model_list as t2 on t1.model = t2.model join car_makers as t3 on t2.maker = t3.id join --> cars_data\n",
      "298 select distinct t2.model from car_names as t1 join model_list as t2 on t1.model = t2.model join car_makers as t3 on t2.maker = t3.id join --> cars_data\n",
      "316 select count(*) from --> cars_data\n",
      "395 select count(*) from flights as t1 join --> airports\n",
      "402 select count(*) from flights as t1 join airports as t2 on t1.destairport = t2.airportcode join --> airports\n",
      "423 select count(*) from flights as t1 join --> airports\n",
      "446 select t1.abbreviation, t1.country from --> airlines\n",
      "459 select t1.airline from airlines as t1 join flights as t2 on t1.uid = t2.airline where t2.sourceairport = \"APG\" intersect select t1.airline from airlines as t1 join --> flights\n",
      "463 select t1.airline from airlines as t1 join flights as t2 on t1.uid = t2.airline where t2.sourceairport = \"APG\" intersect select t1.airline from airlines as t1 join --> flights\n",
      "467 select t1.airline from airlines as t1 join flights as t2 on t1.uid = t2.airline where t2.sourceairport = \"CVO\" except select t1.airline from airlines as t1 join --> flights\n",
      "471 select t1.airline from airlines as t1 join flights as t2 on t1.uid = t2.airline where t2.sourceairport = \"CVO\" except select t1.airline from airlines as t1 join --> flights\n",
      "489 select t1.flightno from flights as t1 join --> airports\n",
      "491 select t1.flightno from flights as t1 join --> airports\n",
      "495 select t1.flightno from flights as t1 join --> airports\n",
      "531 select t1.name from employee as t1 join --> evaluation\n",
      "638 select distinct t1.template_type_description from --> ref_template_types\n",
      "642 select t2.template_id from --> ref_template_types\n",
      "711 select t3.name, t2. --> course\n",
      "719 select t3.name from course_arrange as t1 join --> course\n",
      "720 select t3.name from course_arrange as t1 join course as t2 on t1.course_id = t2.course_id join teacher as t3 on t1.teacher_id = t3.teacher_id where t2. --> course\n",
      "750 select name from museum where museum_id not in (select museum_id from --> visit\n",
      "763 select count(*) from visitor where id not in (select t2.visitor_id from museum as t1 join --> visit\n",
      "764 select count(*) from visitor where id not in (select t2.visitor_id from --> museum\n",
      "781 select count(distinct loser_name) from --> matches\n",
      "794 select t1.country_code, t1.first_name from players as t1 join --> matches\n",
      "795 select t1.country_code, t1.first_name from players as t1 join matches as t2 on t1.player_id = t2.winner_id where t2.tourney_name = 'WTA Championships' intersect select t1.country_code, t1.first_name from players as t1 join --> matches\n",
      "842 select count(*), hand from --> players\n",
      "843 select count(*), hand from --> players\n",
      "848 select avg(injured) from --> death\n",
      "977 select distinct t2.semester_id from --> degree_programs\n",
      "978 select distinct t2.semester_id from degree_programs as t1 join student_enrolment as t2 on t1.degree_program_id = t2.degree_program_id where degree_summary_name = 'Master' intersect select distinct t2.semester_id from --> degree_programs\n",
      "1020 select t1.series_name from --> tv_channel\n",
      "1022 select t1.series_name from --> tv_channel\n",
      "1025 select t2.title from tv_channel as t1 join --> cartoon\n",
      "1038 select t1.series_name from --> tv_channel\n",
      "1039 select t1.series_name from tv_channel as t1 join --> tv_series\n",
      "1040 select t1.series_name from --> tv_channel\n",
      "1044 select t2.episode from --> tv_channel\n",
      "1061 select t1.series_name, t1.country from tv_channel as t1 join --> cartoon\n",
      "1065 select t1.series_name, t1.country from tv_channel as t1 join --> cartoon\n",
      "1071 select id from --> tv_channel\n",
      "1118 select t1.name from --> people\n",
      "1302 select countrycode from --> countrylanguage\n",
      "1304 select countrycode from --> countrylanguage\n",
      "1308 select code from country where governmentform != \"Republic\" except select countrycode from --> countrylanguage\n",
      "1310 select code from country where governmentform != \"Republic\" except select countrycode from --> countrylanguage\n",
      "1358 select language, countrycode, max(percentage) from --> countrylanguage\n",
      "1359 select language, countrycode, max(percentage) from --> countrylanguage\n",
      "1360 select count(*), max(percentage) from --> countrylanguage\n",
      "1414 select t2.name, count(*) from --> friend\n",
      "1416 select t2.name, count(*) from --> friend\n",
      "1418 select t2.name from --> friend\n",
      "1422 select t2.name from --> friend\n",
      "1424 select t2.name from --> friend\n",
      "1440 select name from highschooler except select t2.name from --> friend\n",
      "1442 select name from highschooler except select t2.name from friend as t1 join --> highschooler\n",
      "1443 select name from highschooler except select t2.name from --> friend\n",
      "1456 select t2.name from friend as t1 join --> highschooler\n",
      "1469 select t2.name from likes as t1 join --> highschooler\n",
      "1474 select t2.name from --> friend\n",
      "1486 select min(grade) from highschooler where id not in (select t1.student_id from --> friend\n",
      "1489 select min(grade) from highschooler where id not in (select t1.student_id from --> friend\n",
      "1499 select avg(age) from --> dogs\n",
      "1641 select distinct t1.first_name, t3.treatment_type_description from professionals as t1 join treatments as t2 on t1.professional_id = t2.professional_id join --> treatment_types\n",
      "1644 select distinct t1.first_name, t3.treatment_type_description from professionals as t1 join treatments as t2 on t1.professional_id = t2.professional_id join --> treatment_types\n",
      "1667 select t2.title, t1.name from --> singer\n",
      "1671 select distinct t1.name from --> singer\n",
      "1689 select t2.feature_type_name from other_available_features as t1 join --> ref_feature_types\n",
      "1690 select t2.feature_type_name from --> other_available_features\n"
     ]
    }
   ],
   "source": [
    "# Any type of samples make self-table effective? More with JOIN \n",
    "\n",
    "for i in self_col_effective_ids:\n",
    "    res_d = all_results[i]\n",
    "    print(i, res_d['dec_prompt'], '-->', res_d['expect'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_id = 263\n",
    "res_d = all_results[_id]\n",
    "result = res_d['res_list']\n",
    "# _seq_len = max([d['corrpt_idx'][1] - 1 for d in result])\n",
    "# _tags = [[False, False, False] for _ in range(_seq_len)]  # (is_span_start, is_span_end, is_unit)\n",
    "# for i, d in enumerate(result):\n",
    "#     if d['corrpt_drop'] > 0.5:\n",
    "#         s, e = d['corrpt_idx']\n",
    "#         if e - s > 1:\n",
    "#             _tags[s][0] = True\n",
    "#             _tags[e-1][1] = True\n",
    "#         else:\n",
    "#             _tags[s][2] = True\n",
    "\n",
    "# spider_ex = processed_spider_dev[res_d['ex_id']]\n",
    "print(res_d['enc_sentence'])\n",
    "print(res_d['dec_prompt'], '-->', res_d['expect'])\n",
    "print()\n",
    "\n",
    "l = []\n",
    "for d in result:\n",
    "    _prefix = ''\n",
    "    db_id = spider_ex['db_id']\n",
    "    \n",
    "    if d[\"corrpt_type\"] == 'column' and d[\"corrpt_token\"] == res_d['expect']:\n",
    "        _prefix = '**'\n",
    "    elif d[\"corrpt_type\"] == 'table' and d[\"corrpt_token\"] == res_d['expect_table']:\n",
    "        _prefix = '*>'\n",
    "    l.append(f'{_prefix}{d[\"corrpt_type\"]}\\t{d[\"corrpt_token\"]}\\t{d[\"corrpt_drop\"]}')\n",
    "#         l.append(f'{i}\\t{d[\"corrpt_token\"]}\\t{d[\"corrpt_drop\"]}')\n",
    "print('\\n'.join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split by different aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_per_rel_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))      # [asp_k, asp_v, rel] -> scores \n",
    "scores_avg_per_rel_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(float))) # [asp_k, asp_v, rel] -> avg \n",
    "scores_cnt_per_rel_by_aspect = defaultdict(lambda: defaultdict(int))  # [asp_k, asp_v] -> scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in all_results:\n",
    "    if 'corrupt_drop_dict' not in d:\n",
    "        continue\n",
    "    for asp_k, asp_v in d['category'].items():\n",
    "        scores_cnt_per_rel_by_aspect[asp_k][asp_v] += 1\n",
    "        for rel_k, rel_score in d['corrupt_drop_dict'].items():\n",
    "            scores_per_rel_by_aspect[asp_k][asp_v][rel_k].extend(ctu.ensure_list(rel_score))\n",
    "\n",
    "for asp_k, d1 in scores_per_rel_by_aspect.items():\n",
    "    for asp_v, d2 in d1.items():\n",
    "        for rel_k, rel_scores in d2.items():\n",
    "            avg_score = np.mean(rel_scores)\n",
    "            scores_avg_per_rel_by_aspect[asp_k][asp_v][rel_k] = avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asp_k, asp_v, rel_k, rel_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(int,\n",
       "                         {'easy': 252,\n",
       "                          'medium': 587,\n",
       "                          'hard': 304,\n",
       "                          'extra': 413}),\n",
       "             'node_role': defaultdict(int,\n",
       "                         {'from': 1096, 'join': 454, 'select': 4, 'where': 2}),\n",
       "             'text_match': defaultdict(int,\n",
       "                         {'exact': 1051, 'no-match': 362, 'partial': 143})})"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_cnt_per_rel_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_avg_per_rel_by_aspect['overall'] = {k : np.mean(scores_per_rel[k]) for k in scores_per_rel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'easy': defaultdict(float,\n",
       "                                      {'self': 0.7472912214306141,\n",
       "                                       'self_table': 0.7472912214306141,\n",
       "                                       'self_col': 0.006704863611054781,\n",
       "                                       'other_col': 0.003542819434260551,\n",
       "                                       'other_table': 0.0006951859250294705,\n",
       "                                       'self_col_max': 0.03492553007411698,\n",
       "                                       'other_col_max': 0.04604249615180567,\n",
       "                                       'other_table_max': 0.002759737627846854}),\n",
       "                          'medium': defaultdict(float,\n",
       "                                      {'self': 0.7536806764945262,\n",
       "                                       'self_table': 0.7536806764945262,\n",
       "                                       'self_col': 0.014668647569402999,\n",
       "                                       'other_col': 0.006190764230153936,\n",
       "                                       'other_table': 0.007232657767023916,\n",
       "                                       'self_col_max': 0.07108035028740989,\n",
       "                                       'other_col_max': 0.07414310453614381,\n",
       "                                       'other_table_max': 0.027383409445450698}),\n",
       "                          'hard': defaultdict(float,\n",
       "                                      {'self': 0.7049923634367864,\n",
       "                                       'self_table': 0.7049923634367864,\n",
       "                                       'self_col': 0.015369261552687457,\n",
       "                                       'other_col': 0.008406524753415185,\n",
       "                                       'other_table': 0.008671428086692835,\n",
       "                                       'self_col_max': 0.07870387880930893,\n",
       "                                       'other_col_max': 0.08828718277773313,\n",
       "                                       'other_table_max': 0.03771084437175887}),\n",
       "                          'extra': defaultdict(float,\n",
       "                                      {'self': 0.7370547743729726,\n",
       "                                       'self_table': 0.7370547743729726,\n",
       "                                       'self_col': 0.020259730685039667,\n",
       "                                       'other_col': 0.007574473216817512,\n",
       "                                       'other_table': 0.003525253462740021,\n",
       "                                       'self_col_max': 0.08138378584508642,\n",
       "                                       'other_col_max': 0.08320622598302169,\n",
       "                                       'other_table_max': 0.029015236807978004})}),\n",
       "             'node_role': defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'from': defaultdict(float,\n",
       "                                      {'self': 0.7254869823849148,\n",
       "                                       'self_table': 0.7254869823849148,\n",
       "                                       'self_col': 0.010871709422469596,\n",
       "                                       'other_col': 0.005777214751957973,\n",
       "                                       'other_table': 0.0003557960719817481,\n",
       "                                       'self_col_max': 0.06082735427541297,\n",
       "                                       'other_col_max': 0.06858320684165019,\n",
       "                                       'other_table_max': 0.008084235303307864}),\n",
       "                          'join': defaultdict(float,\n",
       "                                      {'self': 0.7804306943152544,\n",
       "                                       'self_table': 0.7804306943152544,\n",
       "                                       'self_col': 0.02878536098760247,\n",
       "                                       'other_col': 0.008560008266278991,\n",
       "                                       'other_table': 0.016765637769464905,\n",
       "                                       'self_col_max': 0.08659601767371967,\n",
       "                                       'other_col_max': 0.09066284013721844,\n",
       "                                       'other_table_max': 0.06906728729757956}),\n",
       "                          'select': defaultdict(float,\n",
       "                                      {'self': -5.677342414855957e-06,\n",
       "                                       'self_table': -5.677342414855957e-06,\n",
       "                                       'self_col': 0.1227640297729522,\n",
       "                                       'other_col': 2.1189451217651365e-06,\n",
       "                                       'other_table': 3.4570693969726562e-06,\n",
       "                                       'self_col_max': 0.24552694195881486,\n",
       "                                       'other_col_max': 1.537799835205078e-05,\n",
       "                                       'other_table_max': 8.493661880493164e-06}),\n",
       "                          'where': defaultdict(float,\n",
       "                                      {'self': 0.0,\n",
       "                                       'self_table': 0.0,\n",
       "                                       'self_col': 0.28420576825737953,\n",
       "                                       'other_col': 4.76837158203125e-08,\n",
       "                                       'other_table': 2.9802322387695312e-08,\n",
       "                                       'self_col_max': 0.5684112086892128,\n",
       "                                       'other_col_max': 3.2782554626464844e-07,\n",
       "                                       'other_table_max': 2.086162567138672e-07})}),\n",
       "             'text_match': defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'exact': defaultdict(float,\n",
       "                                      {'self': 0.6814551912630051,\n",
       "                                       'self_table': 0.6814551912630051,\n",
       "                                       'self_col': 0.006114491289457132,\n",
       "                                       'other_col': 0.0037760017775881364,\n",
       "                                       'other_table': 0.003948899447919946,\n",
       "                                       'self_col_max': 0.030258785731176262,\n",
       "                                       'other_col_max': 0.038011519407552985,\n",
       "                                       'other_table_max': 0.016750586042572284}),\n",
       "                          'no-match': defaultdict(float,\n",
       "                                      {'self': 0.8642342843840075,\n",
       "                                       'self_table': 0.8642342843840075,\n",
       "                                       'self_col': 0.025929739824816826,\n",
       "                                       'other_col': 0.011640732024846341,\n",
       "                                       'other_table': 0.011625078113861032,\n",
       "                                       'self_col_max': 0.13607035554977986,\n",
       "                                       'other_col_max': 0.13442275548478536,\n",
       "                                       'other_table_max': 0.03702914117467664}),\n",
       "                          'partial': defaultdict(float,\n",
       "                                      {'self': 0.8418673303440086,\n",
       "                                       'self_table': 0.8418673303440086,\n",
       "                                       'self_col': 0.06555539837102767,\n",
       "                                       'other_col': 0.0130069065684355,\n",
       "                                       'other_table': 0.002844514125038204,\n",
       "                                       'other_col_max': 0.1938254678710475,\n",
       "                                       'other_table_max': 0.06438803973028084,\n",
       "                                       'self_col_max': 0.22136162598386702})}),\n",
       "             'overall': {'self': 0.7387205946038705,\n",
       "              'self_table': 0.7387205946038705,\n",
       "              'self_col': 0.014660158918760848,\n",
       "              'other_col': 0.006537220754201795,\n",
       "              'other_table': 0.005284151565397158,\n",
       "              'self_col_max': 0.06904510783421929,\n",
       "              'other_col_max': 0.07476104517248733,\n",
       "              'other_table_max': 0.02584633979267775}})"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_avg_per_rel_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': {'easy': {'self': '0.7473',\n",
       "   'self_table': '0.7473',\n",
       "   'self_col': '0.0067',\n",
       "   'other_col': '0.0035',\n",
       "   'other_table': '0.0007',\n",
       "   'self_col_max': '0.0349',\n",
       "   'other_col_max': '0.0460',\n",
       "   'other_table_max': '0.0028',\n",
       "   'n_samples': 252},\n",
       "  'medium': {'self': '0.7537',\n",
       "   'self_table': '0.7537',\n",
       "   'self_col': '0.0147',\n",
       "   'other_col': '0.0062',\n",
       "   'other_table': '0.0072',\n",
       "   'self_col_max': '0.0711',\n",
       "   'other_col_max': '0.0741',\n",
       "   'other_table_max': '0.0274',\n",
       "   'n_samples': 587},\n",
       "  'hard': {'self': '0.7050',\n",
       "   'self_table': '0.7050',\n",
       "   'self_col': '0.0154',\n",
       "   'other_col': '0.0084',\n",
       "   'other_table': '0.0087',\n",
       "   'self_col_max': '0.0787',\n",
       "   'other_col_max': '0.0883',\n",
       "   'other_table_max': '0.0377',\n",
       "   'n_samples': 304},\n",
       "  'extra': {'self': '0.7371',\n",
       "   'self_table': '0.7371',\n",
       "   'self_col': '0.0203',\n",
       "   'other_col': '0.0076',\n",
       "   'other_table': '0.0035',\n",
       "   'self_col_max': '0.0814',\n",
       "   'other_col_max': '0.0832',\n",
       "   'other_table_max': '0.0290',\n",
       "   'n_samples': 413}},\n",
       " 'node_role': {'from': {'self': '0.7255',\n",
       "   'self_table': '0.7255',\n",
       "   'self_col': '0.0109',\n",
       "   'other_col': '0.0058',\n",
       "   'other_table': '0.0004',\n",
       "   'self_col_max': '0.0608',\n",
       "   'other_col_max': '0.0686',\n",
       "   'other_table_max': '0.0081',\n",
       "   'n_samples': 1096},\n",
       "  'join': {'self': '0.7804',\n",
       "   'self_table': '0.7804',\n",
       "   'self_col': '0.0288',\n",
       "   'other_col': '0.0086',\n",
       "   'other_table': '0.0168',\n",
       "   'self_col_max': '0.0866',\n",
       "   'other_col_max': '0.0907',\n",
       "   'other_table_max': '0.0691',\n",
       "   'n_samples': 454},\n",
       "  'select': {'self': '-0.0000',\n",
       "   'self_table': '-0.0000',\n",
       "   'self_col': '0.1228',\n",
       "   'other_col': '0.0000',\n",
       "   'other_table': '0.0000',\n",
       "   'self_col_max': '0.2455',\n",
       "   'other_col_max': '0.0000',\n",
       "   'other_table_max': '0.0000',\n",
       "   'n_samples': 4},\n",
       "  'where': {'self': '0.0000',\n",
       "   'self_table': '0.0000',\n",
       "   'self_col': '0.2842',\n",
       "   'other_col': '0.0000',\n",
       "   'other_table': '0.0000',\n",
       "   'self_col_max': '0.5684',\n",
       "   'other_col_max': '0.0000',\n",
       "   'other_table_max': '0.0000',\n",
       "   'n_samples': 2}},\n",
       " 'text_match': {'exact': {'self': '0.6815',\n",
       "   'self_table': '0.6815',\n",
       "   'self_col': '0.0061',\n",
       "   'other_col': '0.0038',\n",
       "   'other_table': '0.0039',\n",
       "   'self_col_max': '0.0303',\n",
       "   'other_col_max': '0.0380',\n",
       "   'other_table_max': '0.0168',\n",
       "   'n_samples': 1051},\n",
       "  'no-match': {'self': '0.8642',\n",
       "   'self_table': '0.8642',\n",
       "   'self_col': '0.0259',\n",
       "   'other_col': '0.0116',\n",
       "   'other_table': '0.0116',\n",
       "   'self_col_max': '0.1361',\n",
       "   'other_col_max': '0.1344',\n",
       "   'other_table_max': '0.0370',\n",
       "   'n_samples': 362},\n",
       "  'partial': {'self': '0.8419',\n",
       "   'self_table': '0.8419',\n",
       "   'self_col': '0.0656',\n",
       "   'other_col': '0.0130',\n",
       "   'other_table': '0.0028',\n",
       "   'other_col_max': '0.1938',\n",
       "   'other_table_max': '0.0644',\n",
       "   'self_col_max': '0.2214',\n",
       "   'n_samples': 143}},\n",
       " 'overall': {'self': '0.7387',\n",
       "  'self_table': '0.7387',\n",
       "  'self_col': '0.0147',\n",
       "  'other_col': '0.0065',\n",
       "  'other_table': '0.0053',\n",
       "  'self_col_max': '0.0690',\n",
       "  'other_col_max': '0.0748',\n",
       "  'other_table_max': '0.0258',\n",
       "  'n_samples': 1556}}"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump_d = ctu.nested_json_processing(scores_avg_per_rel_by_aspect, func=lambda x: np.format_float_positional(x, precision=4, min_digits=4))\n",
    "\n",
    "for asp_k, d1 in dump_d.items():\n",
    "    if asp_k == 'overall':\n",
    "        d1['n_samples'] = len(scores_per_rel['self'])\n",
    "        continue\n",
    "    for asp_v, d2 in d1.items():\n",
    "        d2['n_samples'] = scores_cnt_per_rel_by_aspect[asp_k][asp_v]\n",
    "        \n",
    "dump_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = '/home/yshao/Projects/rome/results/exp3_relational_nodes_mutual'\n",
    "dump_path = os.path.join(res_dir, f'summ-exp=3.0_dev_{expect_type}.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dump_path, 'w') as f:\n",
    "    json.dump(dump_d, f, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('easy', 252), ('medium', 587), ('hard', 304), ('extra', 413)]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Hardness\n",
    "\n",
    "samples_by_hardness = defaultdict(list)\n",
    "\n",
    "for res_d in all_results:\n",
    "    if not res_d['correct_prediction']:\n",
    "        continue\n",
    "#     hardness = spider_id2hardness[res_d['ex_id']]\n",
    "    hardness = res_d['category']['sql_hardness']\n",
    "    samples_by_hardness[hardness].append(res_d)\n",
    "\n",
    "[(h, len(samples)) for h, samples in samples_by_hardness.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardness: easy (252)\n",
      "self\t0.7473\t\n",
      "self_table\t0.7473\t\n",
      "self_col\t0.0067\t\n",
      "other_col\t0.0035\t\n",
      "other_table\t0.0007\t\n",
      "self_col_max\t0.0349\t\n",
      "other_col_max\t0.0460\t\n",
      "other_table_max\t0.0028\t\n",
      "\n",
      "Hardness: medium (587)\n",
      "self\t0.7537\t\n",
      "self_table\t0.7537\t\n",
      "self_col\t0.0147\t\n",
      "other_col\t0.0062\t\n",
      "other_table\t0.0072\t\n",
      "self_col_max\t0.0711\t\n",
      "other_col_max\t0.0741\t\n",
      "other_table_max\t0.0274\t\n",
      "\n",
      "Hardness: hard (304)\n",
      "self\t0.7050\t\n",
      "self_table\t0.7050\t\n",
      "self_col\t0.0154\t\n",
      "other_col\t0.0084\t\n",
      "other_table\t0.0087\t\n",
      "self_col_max\t0.0787\t\n",
      "other_col_max\t0.0883\t\n",
      "other_table_max\t0.0377\t\n",
      "\n",
      "Hardness: extra (413)\n",
      "self\t0.7371\t\n",
      "self_table\t0.7371\t\n",
      "self_col\t0.0203\t\n",
      "other_col\t0.0076\t\n",
      "other_table\t0.0035\t\n",
      "self_col_max\t0.0814\t\n",
      "other_col_max\t0.0832\t\n",
      "other_table_max\t0.0290\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for h in ['easy', 'medium', 'hard', 'extra']:\n",
    "    samples = samples_by_hardness[h]\n",
    "    print(f'Hardness: {h} ({len(samples)})')\n",
    "    # print('[Example sql]', samples[0]['seq_out'])\n",
    "    \n",
    "    for rel in scores_per_rel.keys():\n",
    "        _rel_k = rel + '_drop'\n",
    "        rel_scores = [x for res_d in samples for x in ctu.ensure_list(res_d[_rel_k]) if x is not None]\n",
    "        avg_score = np.mean(rel_scores, )\n",
    "        print(f'{rel}\\t{avg_score:.4f}\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('from', 1096), ('join', 454), ('select', 4), ('where', 2)]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Node role\n",
    "\n",
    "samples_by_node_role = defaultdict(list)\n",
    "\n",
    "for res_d in all_results:\n",
    "    if not res_d['correct_prediction']:\n",
    "        continue\n",
    "#     col_role_kw = _detect_column_role(res_d['dec_prompt'])\n",
    "    role_kw = res_d['category']['node_role']\n",
    "    samples_by_node_role[role_kw].append(res_d)\n",
    "\n",
    "[(r, len(samples)) for r, samples in samples_by_node_role.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column role: from (1096)\n",
      "self\t0.7255\t\n",
      "self_table\t0.7255\t\n",
      "self_col\t0.0109\t\n",
      "other_col\t0.0058\t\n",
      "other_table\t0.0004\t\n",
      "self_col_max\t0.0608\t\n",
      "other_col_max\t0.0686\t\n",
      "other_table_max\t0.0081\t\n",
      "\n",
      "Column role: join (454)\n",
      "self\t0.7804\t\n",
      "self_table\t0.7804\t\n",
      "self_col\t0.0288\t\n",
      "other_col\t0.0086\t\n",
      "other_table\t0.0168\t\n",
      "self_col_max\t0.0866\t\n",
      "other_col_max\t0.0907\t\n",
      "other_table_max\t0.0691\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r, samples in samples_by_node_role.items():\n",
    "    if len(samples) < 10:\n",
    "        continue\n",
    "    print(f'Column role: {r} ({len(samples)})')\n",
    "    # print('[Example sql]', samples[0]['seq_out'])\n",
    "    \n",
    "    for rel in scores_per_rel.keys():\n",
    "        _rel_k = rel + '_drop'\n",
    "        rel_scores = [x for res_d in samples for x in ctu.ensure_list(res_d[_rel_k]) if x is not None]\n",
    "        avg_score = np.mean(rel_scores)\n",
    "        print(f'{rel}\\t{avg_score:.4f}\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exact', 1051), ('partial', 143), ('no-match', 362)]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Text match \n",
    "\n",
    "samples_by_text_match = {k: [] for k in ['exact', 'partial', 'no-match']}\n",
    "\n",
    "for res_d in all_results:\n",
    "    if not res_d['correct_prediction']:\n",
    "        continue\n",
    "#     spider_ex = processed_spider_dev[res_d['ex_id']]\n",
    "#     text_match = ctu.check_text_match(spider_ex, col=res_d['expect'], tab=res_d['expect_table'])\n",
    "    text_match = res_d['category']['text_match']\n",
    "    samples_by_text_match[text_match].append(res_d)\n",
    "\n",
    "[(m, len(samples)) for m, samples in samples_by_text_match.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-match: exact (1051)\n",
      "self\t0.6815\t\n",
      "self_table\t0.6815\t\n",
      "self_col\t0.0061\t\n",
      "other_col\t0.0038\t\n",
      "other_table\t0.0039\t\n",
      "self_col_max\t0.0303\t\n",
      "other_col_max\t0.0380\t\n",
      "other_table_max\t0.0168\t\n",
      "\n",
      "Text-match: partial (143)\n",
      "self\t0.8419\t\n",
      "self_table\t0.8419\t\n",
      "self_col\t0.0656\t\n",
      "other_col\t0.0130\t\n",
      "other_table\t0.0028\t\n",
      "self_col_max\t0.2214\t\n",
      "other_col_max\t0.1938\t\n",
      "other_table_max\t0.0644\t\n",
      "\n",
      "Text-match: no-match (362)\n",
      "self\t0.8642\t\n",
      "self_table\t0.8642\t\n",
      "self_col\t0.0259\t\n",
      "other_col\t0.0116\t\n",
      "other_table\t0.0116\t\n",
      "self_col_max\t0.1361\t\n",
      "other_col_max\t0.1344\t\n",
      "other_table_max\t0.0370\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m, samples in samples_by_text_match.items():\n",
    "    print(f'Text-match: {m} ({len(samples)})')\n",
    "    # print('[Example sql]', samples[0]['seq_out'])\n",
    "    \n",
    "    for rel in scores_per_rel.keys():\n",
    "        _rel_k = rel + '_drop'\n",
    "        rel_scores = [x for res_d in samples for x in ctu.ensure_list(res_d[_rel_k]) if x is not None]\n",
    "        avg_score = np.mean(rel_scores)\n",
    "        print(f'{rel}\\t{avg_score:.4f}\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-1: column/table corruption\n",
    "- In py script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = 'dev_table_alias_encoder-tmp'\n",
    "\n",
    "res_json_path = f'/home/yshao/Projects/rome/results/exp1_struct_node_restore/{exp_name}.jsonl'\n",
    "with open(res_json_path, 'r') as f:\n",
    "    res_dicts = [json.loads(l) for l in f if l]\n",
    "#     all_str = f.read()\n",
    "# all_str = all_str.replace('{\"ex_id\":', '\\n{\"ex_id\":').strip()\n",
    "# res_dicts = [json.loads(l) for l in all_str.split('\\n')]\n",
    "len(res_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([r for d in res_dicts for r in d['trace_results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_trace_results = []\n",
    "for d in res_dicts:\n",
    "    for r in d['trace_results']:\n",
    "        if r['correct_prediction'] and r['is_good_sample']:\n",
    "            r['ex_id'] = d['ex_id']\n",
    "            good_trace_results.append(r)\n",
    "len(good_trace_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['ex_id', 'trace_results']),\n",
       " dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'expect', 'expect_type', 'db_id', 'expect_input_ranges', 'category', 'low_score', 'high_score', 'input_ids', 'input_tokens', 'dec_input_ids', 'dec_input_tokens', 'subject_range', 'subject_range_individual_indices', 'answer', 'window', 'correct_prediction', 'kind', 'sever_kind', 'scores', 'is_good_sample', 'ex_id']),\n",
       " list)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys(), good_trace_results[0].keys(), type(good_trace_results[0]['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccd9ea85445469dbb43564e8e0af1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['Times New Roman'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['Times New Roman'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['Times New Roman'] not found. Falling back to DejaVu Sans.\n"
     ]
    }
   ],
   "source": [
    "# Generating all plots\n",
    "fig_save_dir = f'/home/yshao/Projects/rome/results/figs/exp1_struct_node_restore/{exp_name}'\n",
    "\n",
    "for i, r in enumerate(tqdm(good_trace_results)):\n",
    "    result = dict(r)\n",
    "\n",
    "    enc_s, dec_s = result['scores']\n",
    "    enc_s = np.array(enc_s)\n",
    "    dec_s = np.array(dec_s)\n",
    "    result['scores'] = [enc_s, dec_s]\n",
    "\n",
    "    ex_id = r['ex_id']\n",
    "    ctu.plot_trace_heatmap_t5(result, savepdf=os.path.join(fig_save_dir, f'{i}-ex_id={ex_id}.pdf'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding special samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57-ex_id=69\n",
      "60-ex_id=70\n",
      "83-ex_id=139\n",
      "87-ex_id=143\n",
      "88-ex_id=144\n",
      "89-ex_id=145\n",
      "91-ex_id=153\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(good_trace_results):\n",
    "    _, dec_s = r['scores']\n",
    "    ## dec_s: (n_toks, n_layers)\n",
    "    non_last_token_s = np.array(dec_s)[:-1]\n",
    "    if (non_last_token_s > 0.5).any():\n",
    "        print(f'{i}-ex_id={r[\"ex_id\"]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-1.1: severing decoder cross-attention\n",
    "- TODO: merge to py script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single sample (ID = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = 2\n",
    "ex = processed_spider_dev[_id]\n",
    "ex['question'], ex['struct_in'], ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "enc_tokenized = mt_uskg.tokenizer(enc_sentence)\n",
    "\n",
    "token_ranges_dict = ctu.find_struct_name_ranges(mt_uskg.tokenizer, enc_tokenized['input_ids'], struct_in)\n",
    "token_ranges_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'name'\n",
    "tok_ranges = token_ranges_dict['col_name_ranges'][col]\n",
    "tok_indices = [i for s, e in tok_ranges for i in range(s, e)]\n",
    "\n",
    "dec_prompt = make_dec_prompt(ex['seq_out'], col)\n",
    "\n",
    "dec_prompt, tok_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ctu.calculate_hidden_flow_uskg(\n",
    "    mt_uskg,\n",
    "    enc_sentence=enc_sentence,\n",
    "    dec_prompt=dec_prompt,\n",
    "    expect=col,\n",
    "    e_range=tok_indices,\n",
    "    enc_token_range=[],    # no analysis\n",
    "    dec_token_range=None,  # full analysis\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    "    sever_kind='self_attn'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no sever\n",
    "ctu.plot_trace_heatmap_t5(result)\n",
    "print([f\"{s:.2f}\" for s in result['scores'][1][-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sever cross_attn\n",
    "ctu.plot_trace_heatmap_t5(result)\n",
    "print([f\"{s:.2f}\" for s in result['scores'][1][-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sever mlp; a bit better than no severing??\n",
    "ctu.plot_trace_heatmap_t5(result)\n",
    "print([f\"{s:.2f}\" for s in result['scores'][1][-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sever self_attn\n",
    "ctu.plot_trace_heatmap_t5(result)\n",
    "print([f\"{s:.2f}\" for s in result['scores'][1][-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['scores'][1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-2: dirty text recovery\n",
    "- Corrupt the text, restore different parts of encoder final output\n",
    "- Idea is to check the existence of contextual understanding (incorporating text info into struct representation)\n",
    "- (In py script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single sample\n",
    "- ID = 2, col = 'name': (name exact match with text)\n",
    "    - none: wrong; text: correct; struct: correct; col: correct\n",
    "- ID = 5, col = 'country': (no exact match, but value match with text (French) )\n",
    "    - none: wrong; text: correct; struct: correct; col: correct\n",
    "- ID = 145, col = 'year': (no exact match, but value match with text (1980) )\n",
    "    - none: wrong; text: correct; struct: correct; col: correct\n",
    "- ID = 7, col = 'song_release_year': (multi-token, and with confusing columns in table (song_name) )\n",
    "    - none: wrong; text: wrong; struct: correct; col: wrong\n",
    "    - hypothesis: need clean struct to avoid confusion\n",
    "- ID = 185, col = 'airportcode': (multi-token, with confusing col (airportname), but have match with text (airport code) )\n",
    "    - none: wrong; text: correct; struct: wrong (2nd token); col: wrong\n",
    "    - differs from hypothesis... clean struct should know sql info about the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('concert_singer',\n",
       " 'Show the stadium name and capacity with most number of concerts in year 2014 or after.',\n",
       " '| concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id',\n",
       " 'select t2.name, t2.capacity from concert as t1 join stadium as t2 on t1.stadium_id = t2.stadium_id where t1.year >= 2014 group by t2.stadium_id order by count(*) desc limit 1')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 24\n",
    "ex = processed_spider_dev[_id]\n",
    "ex['db_id'], ex['question'], ex['struct_in'], ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 17), (24, 134))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "enc_tokenized = mt_uskg.tokenizer(enc_sentence)\n",
    "\n",
    "text_range, struct_range = ctu.find_text_struct_in_range(mt_uskg.tokenizer, enc_tokenized['input_ids'])\n",
    "text_range, struct_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name', 'nationality'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ranges_dict = ctu.find_struct_name_ranges(mt_uskg.tokenizer, enc_tokenized['input_ids'], struct_in)\n",
    "\n",
    "col_name_ranges = token_ranges_dict['col_name_ranges']\n",
    "\n",
    "sql_tokens = ctu.separate_punct(ex['seq_out']).split(' ')\n",
    "\n",
    "sql_cols = set()\n",
    "for t in sql_tokens:\n",
    "    if t in col_name_ranges:\n",
    "        sql_cols.add(t)\n",
    "sql_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 'orchestra', 'orchestra'),\n",
       " [((3, 'conductor', 'conductor'),\n",
       "   [[(5, 'conductor_id', 'conductor_id'), []],\n",
       "    [(7, 'name', 'name'), []],\n",
       "    [(9, 'age', 'age'), []],\n",
       "    [(11, 'nationality', 'nationality ( USA )'), [(13, 'USA', 'USA')]],\n",
       "    [(16, 'year_of_work', 'year_of_work'), []]]),\n",
       "  ((18, 'orchestra', 'orchestra'),\n",
       "   [[(20, 'orchestra_id', 'orchestra_id'), []],\n",
       "    [(22, 'orchestra', 'orchestra'), []],\n",
       "    [(24, 'conductor_id', 'conductor_id'), []],\n",
       "    [(26, 'record_company', 'record_company'), []],\n",
       "    [(28, 'year_of_founded', 'year_of_founded'), []],\n",
       "    [(30, 'major_record_format', 'major_record_format'), []]]),\n",
       "  ((32, 'performance', 'performance'),\n",
       "   [[(34, 'performance_id', 'performance_id'), []],\n",
       "    [(36, 'orchestra_id', 'orchestra_id'), []],\n",
       "    [(38, 'type', 'type'), []],\n",
       "    [(40, 'date', 'date'), []],\n",
       "    [(42, 'official_ratings_(millions)', 'official_ratings_(millions)'), []],\n",
       "    [(44, 'weekly_rank', 'weekly_rank'), []],\n",
       "    [(46, 'share', 'share'), []]]),\n",
       "  ((48, 'show', 'show'),\n",
       "   [[(50, 'show_id', 'show_id'), []],\n",
       "    [(52, 'performance_id', 'performance_id'), []],\n",
       "    [(54, 'if_first_show', 'if_first_show'), []],\n",
       "    [(56, 'result', 'result'), []],\n",
       "    [(58, 'attendance', 'attendance'), []]])])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_struct_in = ctu.parse_struct_in(struct_in)\n",
    "parsed_struct_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('select name from conductor where', 'nationality')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'nationality'\n",
    "# tok_ranges = token_ranges_dict['col_name_ranges'][col]\n",
    "# tok_indices = [i for s, e in tok_ranges for i in range(s, e)]\n",
    "dec_prompt = ctu.make_dec_prompt(ex['seq_out'], col)\n",
    "expect = col\n",
    "dec_prompt, expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nationality', [(45, 51)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_toks = token_ranges_dict['col_name_ranges'][col]\n",
    "col, col_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = ctu.calculate_hidden_flow_uskg(\n",
    "#     mt_uskg,\n",
    "#     enc_sentence=enc_sentence,\n",
    "#     dec_prompt=dec_prompt,\n",
    "#     expect=col,\n",
    "#     e_range=text_range,\n",
    "#     enc_token_range=[],    # no analysis\n",
    "#     dec_token_range=None,  # full analysis\n",
    "#     tokens_to_mix_individual_indices=False,\n",
    "#     replace=True,\n",
    "#     sever_kind=None,\n",
    "# )\n",
    "\n",
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 11,\n",
    "    [dec_prompt] * 11,\n",
    "    answer=expect)\n",
    "\n",
    "encoder_text_last_layer_states = [\n",
    "    (tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "    for tnum in range(*text_range)\n",
    "]\n",
    "\n",
    "encoder_struct_last_layer_states = [\n",
    "    (tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "    for tnum in range(*struct_range)\n",
    "]\n",
    "\n",
    "encoder_col_last_layer_states = [\n",
    "    (tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "    for tnum in col_toks\n",
    "]\n",
    "\n",
    "answer_len = len(mt_uskg.tokenizer.tokenize(expect))\n",
    "answers_t, base_score = [d[0] for d in ctu.predict_from_input_uskg_multi_token(mt_uskg.model, inp, pred_len=answer_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(0.1734, device='cuda:0'), tensor(1.0000, device='cuda:0')],\n",
       " tensor(0.1734, device='cuda:0'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Corrupting text: expect wrong pred \n",
    "\n",
    "all_ans_probs = ctu.trace_with_repatch_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_range,\n",
    "    tokens_to_mix_individual_indices=False,\n",
    "    replace=True,\n",
    ")\n",
    "all_ans_probs, min(all_ans_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(1.0000, device='cuda:0'), tensor(0.9999, device='cuda:0')],\n",
       " tensor(0.9999, device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Restoring text encoding for decoder, but struct encoding are with dirty text encoding \n",
    "\n",
    "all_ans_probs = ctu.trace_with_repatch_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=encoder_text_last_layer_states,\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_range,\n",
    "    tokens_to_mix_individual_indices=False,\n",
    "    replace=True,\n",
    ")\n",
    "all_ans_probs, min(all_ans_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(1.0000, device='cuda:0'), tensor(1., device='cuda:0')],\n",
       " tensor(1.0000, device='cuda:0'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Restoring clean struct encoding but dirty text encoding for decoder\n",
    "## Prediction being correct means encoder final output has \"contextual\" or \"semantic\" understanding of struct_in \n",
    "\n",
    "all_ans_probs = ctu.trace_with_repatch_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=encoder_struct_last_layer_states,\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_range,\n",
    "    tokens_to_mix_individual_indices=False,\n",
    "    replace=True,\n",
    ")\n",
    "all_ans_probs, min(all_ans_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(1.0000, device='cuda:0'), tensor(1.0000, device='cuda:0')],\n",
       " tensor(1.0000, device='cuda:0'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Restoring clean col_name encoding but dirty text encoding for decoder (stricter than above)\n",
    "\n",
    "all_ans_probs = ctu.trace_with_repatch_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=encoder_col_last_layer_states,\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_range,\n",
    "    tokens_to_mix_individual_indices=False,\n",
    "    replace=True,\n",
    ")\n",
    "all_ans_probs, min(all_ans_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(1.0000, device='cuda:0'), tensor(1.0000, device='cuda:0')],\n",
       " tensor(1.0000, device='cuda:0'))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For exp-2.1: mutual corruption\n",
    "# First pass: corrupt text (no restore)\n",
    "# Second pass: corrupt struct, no restore, reset struct output to first pass\n",
    "\n",
    "all_ans_probs = ctu.trace_with_repatch_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=encoder_struct_last_layer_states,\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix_1st_pass=text_range,\n",
    "    tokens_to_mix=struct_range,\n",
    "    tokens_to_mix_individual_indices=False,\n",
    "    replace=True,\n",
    ")\n",
    "all_ans_probs, min(all_ans_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_path = '/home/yshao/Projects/rome/results/exp2_text_struct_interaction/exp=2_dev_table.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_samples[5439]['ex_id'], all_samples[5440]['ex_id'], all_samples[-1]['ex_id'], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5\n",
    "\n",
    "base_scores = []\n",
    "low_scores = []\n",
    "\n",
    "## len = n_good_samples\n",
    "restore_scores_dict = {\n",
    "    'text': [],\n",
    "    'struct': [],\n",
    "    'node': [],\n",
    "    'struct_no_node': [],\n",
    "    'node_corrupt_all': [],\n",
    "    # 2.0.1: cancelled\n",
    "    # 'ctname': [],      # col name + table name (col belongs to) \n",
    "    # 'catname': [],     # col name + all table names \n",
    "    # 'full_table': [],  # full table (col belongs to) \n",
    "    # 'all_col': [],     # all col names (regardless of table)\n",
    "}\n",
    "\n",
    "## len = total_samples\n",
    "mutual_scores_dict = {\n",
    "    f'{text}-{struct}': []\n",
    "    for text in ['clean_t', 'dc_t', 'dirty_t']\n",
    "    for struct in ['clean_s', 'dc_s', 'dirty_s']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1725, (821, 821), 141, 763)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'expect', 'expect_type', 'db_id', 'expect_input_ranges', 'expect_table', 'answer', 'base_score', 'answers_t', 'correct_prediction', 'category', 'mutual_scores', 'low_score', 'is_good_sample']),\n",
       " dict_keys(['clean_t-clean_s', 'clean_t-dc_s', 'clean_t-dirty_s', 'dc_t-clean_s', 'dc_t-dc_s', 'dc_t-dirty_s', 'dirty_t-clean_s', 'dirty_t-dc_s', 'dirty_t-dirty_s']))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys(), d['mutual_scores'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    base_scores.append(d['base_score'])\n",
    "    low_scores.append(d['low_score'])\n",
    "    for k in restore_scores_dict.keys():\n",
    "        restore_scores_dict[k].append(d[f'r_{k}_score'])\n",
    "    for k in mutual_scores_dict.keys():\n",
    "        mutual_scores_dict[k].append(d['mutual_scores'][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(821, 821, 821)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_scores), len(restore_scores_dict['text']), len(mutual_scores_dict['dc_t-dc_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\t0.4472\n",
      "struct\t0.9687\n",
      "node\t0.8675\n",
      "struct_no_node\t0.4292\n",
      "node_corrupt_all\t0.9004\n"
     ]
    }
   ],
   "source": [
    "# results for exp2\n",
    "for k, scores in restore_scores_dict.items():\n",
    "    avg = np.mean(scores)\n",
    "    print(f'{k}\\t{avg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\tavg_gain\tperc_recover\n",
      "base_scores\t0.8885\t1.0000\n",
      "r_text\t0.3452\t0.3727\n",
      "r_struct\t0.8667\t0.9683\n",
      "r_node\t0.7654\t0.8551\n",
      "r_struct_no_node\t0.3272\t0.3666\n",
      "r_node_corrupt_all\t0.7984\t0.8940\n"
     ]
    }
   ],
   "source": [
    "print(f'Score\\tavg_gain\\tperc_recover')\n",
    "for score_label, high_scores in [\n",
    "    ('base_scores', base_scores),\n",
    "    ('r_text', restore_scores_dict['text']),\n",
    "    ('r_struct', restore_scores_dict['struct']),\n",
    "    ('r_node', restore_scores_dict['node']),\n",
    "    ('r_struct_no_node', restore_scores_dict['struct_no_node']),\n",
    "    ('r_node_corrupt_all', restore_scores_dict['node_corrupt_all']),\n",
    "]:\n",
    "    avg_gain = np.mean([h - l for h, l in zip(high_scores, low_scores)])\n",
    "    perc_recover = np.mean([h - l > 0.5 for h, l in zip(high_scores, low_scores)])\n",
    "    print(f'{score_label}\\t{avg_gain:.4f}\\t{perc_recover:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        clean_t dc_t    dirty_t \n",
      "clean_s 0.9906  0.9802  0.9687  \n",
      "dc_s    0.4472  0.3965  0.1020  \n",
      "dirty_s 0.2241  0.1958  0.0015  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# results for exp2.1.1 \n",
    "msg = ' '*8\n",
    "for k_t in ['clean_t', 'dc_t', 'dirty_t']:\n",
    "    msg += f'{k_t:8s}'\n",
    "msg += '\\n'\n",
    "for k_s in ['clean_s', 'dc_s', 'dirty_s']:\n",
    "    msg += f'{k_s:8s}'\n",
    "    for k_t in ['clean_t', 'dc_t', 'dirty_t']:\n",
    "        k = f'{k_t}-{k_s}'\n",
    "        scores = mutual_scores_dict[k]\n",
    "        avg = np.mean(scores)\n",
    "        msg += f'{avg:.4f}  '\n",
    "    msg += '\\n'\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split by hardness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp2 + exp2.1.1 \n",
    "# res_path = '/home/yshao/Projects/rome/results/exp2_text_struct_interaction/exp=2_dev_column.jsonl'\n",
    "\n",
    "# with open(res_path, 'r') as f:\n",
    "#     all_samples = [json.loads(l) for l in f]\n",
    "# len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_samples = []\n",
    "\n",
    "# for i, ex in enumerate(all_samples):\n",
    "#     for d in ex['trace_results']:\n",
    "#         if d['is_good_sample']:\n",
    "#             d['ex_id'] = i\n",
    "#             good_samples.append(d)\n",
    "# len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_by_hardness = defaultdict(list)\n",
    "\n",
    "# for ex in all_samples:\n",
    "#     for d in ex['trace_results']:\n",
    "#         if not d['is_good_sample']:\n",
    "#             continue\n",
    "\n",
    "for d in good_samples:\n",
    "#     sql_str = d['seq_out']\n",
    "#     db_id = d['struct_in'].split('|')[1].strip()    # TODO: add db_id to result during experiment main run \n",
    "#     sql = sp_eval.get_sql(evaluator.schemas[db_id], sql_str)\n",
    "#     hardness = evaluator.eval_hardness(sql)\n",
    "#     hardness = spider_id2hardness[d['ex_id']]\n",
    "    hardness = d['category']['sql_hardness']\n",
    "    samples_by_hardness[hardness].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('easy', 140), ('medium', 307), ('hard', 168), ('extra', 206)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(h, len(samples)) for h, samples in samples_by_hardness.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardness: easy (140)\n",
      "[Example sql] select count(*) from singer\n",
      "Score\tavg_gain\tperc_recover\n",
      "base_score\t0.8812\t1.0000\n",
      "r_text_score\t0.3415\t0.3643\n",
      "r_struct_score\t0.8589\t0.9714\n",
      "r_node_score\t0.6934\t0.7714\n",
      "r_struct_no_node_score\t0.4167\t0.4429\n",
      "r_node_corrupt_all_score\t0.8762\t1.0000\n",
      "\n",
      "Hardness: medium (307)\n",
      "[Example sql] select name, country, age from singer order by age desc\n",
      "Score\tavg_gain\tperc_recover\n",
      "base_score\t0.9013\t1.0000\n",
      "r_text_score\t0.3883\t0.4365\n",
      "r_struct_score\t0.8948\t0.9935\n",
      "r_node_score\t0.8010\t0.8925\n",
      "r_struct_no_node_score\t0.3597\t0.4202\n",
      "r_node_corrupt_all_score\t0.8096\t0.8990\n",
      "\n",
      "Hardness: hard (168)\n",
      "[Example sql] select song_name from singer where age > (select avg(age) from singer)\n",
      "Score\tavg_gain\tperc_recover\n",
      "base_score\t0.8995\t1.0000\n",
      "r_text_score\t0.3341\t0.3750\n",
      "r_struct_score\t0.8428\t0.9286\n",
      "r_node_score\t0.7446\t0.8393\n",
      "r_struct_no_node_score\t0.2623\t0.2798\n",
      "r_node_corrupt_all_score\t0.7794\t0.8690\n",
      "\n",
      "Hardness: extra (206)\n",
      "[Example sql] select t2.name, t2.capacity from concert as t1 join stadium as t2 on t1.stadium_id = t2.stadium_id where t1.year >= 2014 group by t2.stadium_id order by count(*) desc limit 1\n",
      "Score\tavg_gain\tperc_recover\n",
      "base_score\t0.8656\t1.0000\n",
      "r_text_score\t0.2924\t0.2816\n",
      "r_struct_score\t0.8494\t0.9612\n",
      "r_node_score\t0.7783\t0.8689\n",
      "r_struct_no_node_score\t0.2708\t0.3058\n",
      "r_node_corrupt_all_score\t0.7442\t0.8350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for h in ['easy', 'medium', 'hard', 'extra']:\n",
    "    samples = samples_by_hardness[h]\n",
    "    print(f'Hardness: {h} ({len(samples)})')\n",
    "    print('[Example sql]', samples[0]['seq_out'])\n",
    "    print(f'Score\\tavg_gain\\tperc_recover')\n",
    "    \n",
    "    low_scores = [d['low_score'] for d in samples]\n",
    "    for score_label in [\n",
    "        'base_score',\n",
    "        'r_text_score',\n",
    "        'r_struct_score',\n",
    "        'r_node_score',\n",
    "        'r_struct_no_node_score',\n",
    "        'r_node_corrupt_all_score'\n",
    "    ]:\n",
    "        high_scores = [d[score_label] for d in samples]\n",
    "        avg_gain = np.mean([h - l for h, l in zip(high_scores, low_scores)])\n",
    "        perc_recover = np.mean([h - l > 0.5 for h, l in zip(high_scores, low_scores)])\n",
    "        print(f'{score_label}\\t{avg_gain:.4f}\\t{perc_recover:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split by node role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# role_keyword_pattern = r'\\W(select|where|join|group by|having|order by)\\W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _sql_str = samples_by_hardness['extra'][0]['seq_out']\n",
    "# _sql_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.findall(role_keyword_pattern, ' ' + _sql_str + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('from', 533), ('join', 282), ('select', 6)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_node_role = defaultdict(list)\n",
    "\n",
    "for d in good_samples:\n",
    "#     all_kws = re.findall(role_keyword_pattern, ' ' + d['dec_prompt'] + ' ')\n",
    "#     assert len(all_kws) > 0, d['dec_prompt']\n",
    "#     col_role_kw = all_kws[-1]\n",
    "#     col_role_kw = _detect_column_role(d['dec_prompt'])\n",
    "    role_kw = d['category']['node_role']\n",
    "    samples_by_node_role[role_kw].append(d)\n",
    "\n",
    "[(r, len(samples)) for r, samples in samples_by_node_role.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column role: from (533)\n",
      "[Example prompt] select count(*) from\n",
      "Score\tavg_gain\tperc_recover\n",
      "base_score\t0.8889\t1.0000\n",
      "r_text_score\t0.3948\t0.4447\n",
      "r_struct_score\t0.8652\t0.9681\n",
      "r_node_score\t0.7885\t0.8799\n",
      "r_struct_no_node_score\t0.3151\t0.3452\n",
      "r_node_corrupt_all_score\t0.8623\t0.9644\n",
      "\n",
      "Column role: join (282)\n",
      "[Example prompt] select t2.name, t2.capacity from concert as t1 join\n",
      "Score\tavg_gain\tperc_recover\n",
      "base_score\t0.8870\t1.0000\n",
      "r_text_score\t0.2458\t0.2305\n",
      "r_struct_score\t0.8752\t0.9752\n",
      "r_node_score\t0.7379\t0.8262\n",
      "r_struct_no_node_score\t0.3443\t0.4007\n",
      "r_node_corrupt_all_score\t0.6962\t0.7801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in samples_by_node_role.keys():\n",
    "    samples = samples_by_node_role[r]\n",
    "    if len(samples) < 10:\n",
    "        continue\n",
    "    print(f'Column role: {r} ({len(samples)})')\n",
    "    print('[Example prompt]', samples[0]['dec_prompt'])\n",
    "    print(f'Score\\tavg_gain\\tperc_recover')\n",
    "    \n",
    "    low_scores = [d['low_score'] for d in samples]\n",
    "    for score_label in [\n",
    "        'base_score',\n",
    "        'r_text_score',\n",
    "        'r_struct_score',\n",
    "        'r_node_score',\n",
    "        'r_struct_no_node_score',\n",
    "        'r_node_corrupt_all_score'\n",
    "    ]:\n",
    "        high_scores = [d[score_label] for d in samples]\n",
    "        avg_gain = np.mean([h - l for h, l in zip(high_scores, low_scores)])\n",
    "        perc_recover = np.mean([h - l > 0.5 for h, l in zip(high_scores, low_scores)])\n",
    "        print(f'{score_label}\\t{avg_gain:.4f}\\t{perc_recover:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_path = '/home/yshao/Projects/rome/results/exp2_text_struct_interaction/exp=2_dev_column.jsonl'\n",
    "# with open(res_path, 'r') as f:\n",
    "#     all_samples = [json.loads(l) for l in f]\n",
    "# len(all_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split by text match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = good_samples[244]\n",
    "# spider_ex = processed_spider_dev[d['ex_id']]\n",
    "# col = d['expect']\n",
    "# tab = d['table']\n",
    "# d['table'], d['expect'], d['text_in'], ctu.check_text_match(spider_ex, col, tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exact', 551), ('partial', 98), ('no-match', 172)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_text_match = {k: [] for k in ['exact', 'partial', 'no-match']}\n",
    "\n",
    "for d in good_samples:\n",
    "#     spider_ex = processed_spider_dev[d['ex_id']]\n",
    "#     text_match = _check_text_match(spider_ex, d)\n",
    "    text_match = d['category']['text_match']\n",
    "    samples_by_text_match[text_match].append(d)\n",
    "\n",
    "[(m, len(samples)) for m, samples in samples_by_text_match.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text match: exact (551)\n",
      "[Example] How many singers do we have?; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id\n",
      "[Example] select count(*) from *singer*\n",
      "Score\tavg_gain\tperc_recover\n",
      "base_score\t0.8927\t1.0000\n",
      "r_text_score\t0.4673\t0.5245\n",
      "r_struct_score\t0.8768\t0.9800\n",
      "r_node_score\t0.7754\t0.8621\n",
      "r_struct_no_node_score\t0.3959\t0.4410\n",
      "r_node_corrupt_all_score\t0.8129\t0.9129\n",
      "\n",
      "Text match: partial (98)\n",
      "[Example] Show the name and theme for all concerts and the number of singers in each concert.; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id\n",
      "[Example] select t2.concert_name, t2.theme, count(*) from *singer_in_concert*\n",
      "Score\tavg_gain\tperc_recover\n",
      "base_score\t0.8966\t1.0000\n",
      "r_text_score\t0.0700\t0.0408\n",
      "r_struct_score\t0.8741\t0.9592\n",
      "r_node_score\t0.8173\t0.8980\n",
      "r_struct_no_node_score\t0.1588\t0.2041\n",
      "r_node_corrupt_all_score\t0.8866\t0.9592\n",
      "\n",
      "Text match: no-match (172)\n",
      "[Example] What are the locations and names of all stations with capacity between 5000 and 10000?; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id\n",
      "[Example] select location, name from *stadium*\n",
      "Score\tavg_gain\tperc_recover\n",
      "base_score\t0.8708\t1.0000\n",
      "r_text_score\t0.1106\t0.0756\n",
      "r_struct_score\t0.8298\t0.9360\n",
      "r_node_score\t0.7039\t0.8081\n",
      "r_struct_no_node_score\t0.2030\t0.2209\n",
      "r_node_corrupt_all_score\t0.7015\t0.7965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in ['exact', 'partial', 'no-match']:\n",
    "    samples = samples_by_text_match[m]\n",
    "    print(f'Text match: {m} ({len(samples)})')\n",
    "    print('[Example]', samples[0]['enc_sentence'])\n",
    "    print(f\"[Example] {samples[0]['dec_prompt']} *{samples[0]['expect']}*\")\n",
    "    print(f'Score\\tavg_gain\\tperc_recover')\n",
    "    \n",
    "    low_scores = [d['low_score'] for d in samples]\n",
    "    for score_label in [\n",
    "        'base_score',\n",
    "        'r_text_score',\n",
    "        'r_struct_score',\n",
    "        'r_node_score',\n",
    "        'r_struct_no_node_score',\n",
    "        'r_node_corrupt_all_score'\n",
    "    ]:\n",
    "        high_scores = [d[score_label] for d in samples]\n",
    "        avg_gain = np.mean([h - l for h, l in zip(high_scores, low_scores)])\n",
    "        perc_recover = np.mean([h - l > 0.5 for h, l in zip(high_scores, low_scores)])\n",
    "        print(f'{score_label}\\t{avg_gain:.4f}\\t{perc_recover:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = samples_by_text_match['no-match'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What are the names of all European countries with at least 3 manufacturers? The database is as following: | car_1 | continents : contid , continent ( europe ) | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year => select t1.countryname from countries as t1 join continents as t2 on t1.continent = t2.contid join car_makers as t3 on t1.countryid = t3.country where t2.continent = 'europe' group by t1.countryname having count(*) >= 3;\""
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "enc_sentence = f\"{text_in} The database is as following: {struct_in}\"\n",
    "\n",
    "f\"{enc_sentence} => {ex['seq_out']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['ex_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-2.2: dirty text struct restore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1034, 1084)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'column'\n",
    "\n",
    "res_json_path = f'/home/yshao/Projects/rome/results/exp2.2_dirty_text_struct_restore/exp=2.2_dev_{expect_type}.jsonl'\n",
    "\n",
    "with open(res_json_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "\n",
    "good_trace_results = []\n",
    "for ex in all_samples:\n",
    "    for r in ex['trace_results']:\n",
    "        if r['is_good_sample']:\n",
    "            r['ex_id'] = ex['ex_id']\n",
    "            good_trace_results.append(r)\n",
    "    \n",
    "len(all_samples), len(good_trace_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'expect', 'expect_type', 'db_id', 'expect_input_ranges', 'expect_table', 'category', 'low_score', 'high_score', 'input_ids', 'input_tokens', 'dec_input_ids', 'dec_input_tokens', 'subject_range', 'subject_range_individual_indices', 'answer', 'window', 'correct_prediction', 'kind', 'sever_kind', 'scores', 'is_good_sample', 'part', 'ex_id'])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_trace_results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generating all plots\n",
    "# fig_save_dir = f'/home/yshao/Projects/rome/results/figs/exp2.2_dirty_text_struct_restore/exp=2.2_dev_column'\n",
    "\n",
    "# for i, r in enumerate(tqdm(good_trace_results)):\n",
    "#     result = dict(r)\n",
    "\n",
    "#     enc_s, dec_s = result['scores']\n",
    "    \n",
    "#     # enc_s = np.array(enc_s)\n",
    "#     enc_layers_vec = np.array(enc_s[0])\n",
    "#     assert enc_layers_vec.shape == (mt_uskg.num_enc_layers,)\n",
    "#     enc_token_range, = result['enc_token_range']\n",
    "    \n",
    "#     enc_s = np.zeros((len(result['input_tokens']), mt_uskg.num_enc_layers))\n",
    "#     enc_s[enc_token_range] = enc_layers_vec\n",
    "    \n",
    "#     dec_s = np.zeros((len(result['dec_input_tokens']), mt_uskg.num_dec_layers))\n",
    "#     result['scores'] = [enc_s, dec_s]\n",
    "\n",
    "#     ex_id = r['ex_id']\n",
    "#     ctu.plot_trace_heatmap_t5(result, savepdf=os.path.join(fig_save_dir, f'{i}-ex_id={ex_id}.pdf'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check avg per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_per_layer = [[] for _ in range(mt_uskg.num_enc_layers)]\n",
    "\n",
    "for r in good_trace_results:\n",
    "    enc_s, dec_s = r['scores']\n",
    "    for l, s in enumerate(enc_s[0]):\n",
    "        scores_per_layer[l].append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04998245431660366,\n",
       " 0.05325091241746874,\n",
       " 0.05578506940298435,\n",
       " 0.056500998754504546,\n",
       " 0.05632673384162137,\n",
       " 0.060122467615442834,\n",
       " 0.0743413356685932,\n",
       " 0.07793125936657581,\n",
       " 0.1187241473144563,\n",
       " 0.1544875932789873,\n",
       " 0.18513770163235047,\n",
       " 0.21917309280363884,\n",
       " 0.28553838302240797,\n",
       " 0.3615626793599896,\n",
       " 0.3617946804873726,\n",
       " 0.3946494784126291,\n",
       " 0.47267543055045763,\n",
       " 0.44948675620885103,\n",
       " 0.4737027594501244,\n",
       " 0.5257112130350594,\n",
       " 0.5352272429749859,\n",
       " 0.6249380804599364,\n",
       " 0.670510063510466,\n",
       " 0.7290238733215495]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_avg_by_layer = [np.mean(scores) for scores in scores_per_layer]\n",
    "all_avg_by_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer\tAvg. Score\n",
      "0    \t0.0500\n",
      "1    \t0.0533\n",
      "2    \t0.0558\n",
      "3    \t0.0565\n",
      "4    \t0.0563\n",
      "5    \t0.0601\n",
      "6    \t0.0743\n",
      "7    \t0.0779\n",
      "8    \t0.1187\n",
      "9    \t0.1545\n",
      "10   \t0.1851\n",
      "11   \t0.2192\n",
      "12   \t0.2855\n",
      "13   \t0.3616\n",
      "14   \t0.3618\n",
      "15   \t0.3946\n",
      "16   \t0.4727\n",
      "17   \t0.4495\n",
      "18   \t0.4737\n",
      "19   \t0.5257\n",
      "20   \t0.5352\n",
      "21   \t0.6249\n",
      "22   \t0.6705\n",
      "23   \t0.7290\n"
     ]
    }
   ],
   "source": [
    "print('Layer\\tAvg. Score')\n",
    "for l, avg in enumerate(all_avg_by_layer):\n",
    "    print(f'{l:<5d}\\t{avg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f82d35abf70>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(all_avg_by_layer, label='All')\n",
    "ax.set_xlabel('Layer to restore')\n",
    "ax.set_ylabel('Avg. P(correct answer)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  by hardness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('easy', 191), ('medium', 516), ('hard', 216), ('extra', 161)]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {h : [[score], ...]}\n",
    "scores_by_hardness = {hardness : [] for hardness in ['easy', 'medium', 'hard', 'extra']}   \n",
    "\n",
    "for r in good_trace_results:\n",
    "    enc_s, dec_s = r['scores']\n",
    "    scores, = enc_s\n",
    "#     hardness = spider_id2hardness[r['ex_id']]\n",
    "    hardness = r['category']['sql_hardness']\n",
    "    scores_by_hardness[hardness].append(scores)\n",
    "\n",
    "[(h, len(scores)) for h, scores in scores_by_hardness.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy\n",
      "['0.05', '0.05', '0.06', '0.06', '0.06', '0.06', '0.08', '0.09', '0.14', '0.20', '0.24', '0.29', '0.35', '0.41', '0.40', '0.43', '0.49', '0.48', '0.50', '0.54', '0.55', '0.65', '0.71', '0.78']\n",
      "\n",
      "medium\n",
      "['0.05', '0.05', '0.06', '0.06', '0.06', '0.06', '0.07', '0.07', '0.11', '0.14', '0.17', '0.20', '0.27', '0.35', '0.35', '0.38', '0.45', '0.42', '0.45', '0.50', '0.51', '0.60', '0.65', '0.71']\n",
      "\n",
      "hard\n",
      "['0.04', '0.05', '0.05', '0.05', '0.05', '0.05', '0.06', '0.07', '0.11', '0.14', '0.17', '0.21', '0.27', '0.35', '0.37', '0.41', '0.49', '0.47', '0.48', '0.54', '0.54', '0.60', '0.65', '0.71']\n",
      "\n",
      "extra\n",
      "['0.06', '0.06', '0.07', '0.07', '0.07', '0.07', '0.09', '0.10', '0.13', '0.16', '0.19', '0.22', '0.28', '0.35', '0.35', '0.38', '0.50', '0.48', '0.52', '0.58', '0.60', '0.70', '0.72', '0.74']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for h, sample_scores in scores_by_hardness.items():\n",
    "    print(h)\n",
    "    scores_by_layer = zip(*sample_scores)\n",
    "    avg_by_layer = [np.mean(scores) for scores in scores_by_layer]\n",
    "    print([f'{avg:.2f}' for avg in avg_by_layer])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f82d21f8130>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_avg_by_layer, label='All')\n",
    "for h, sample_scores in scores_by_hardness.items():\n",
    "    h_scores_by_layer = zip(*sample_scores)\n",
    "    h_avg_by_layer = [np.mean(scores) for scores in h_scores_by_layer]\n",
    "    ax.plot(h_avg_by_layer, label=h)\n",
    "ax.set_xlabel('Layer to restore')\n",
    "ax.set_ylabel('Avg. P(correct answer)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  by node role "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('select', 642),\n",
       " ('order by', 73),\n",
       " ('where', 267),\n",
       " ('group by', 26),\n",
       " ('join', 62),\n",
       " ('having', 4),\n",
       " ('from', 10)]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {h : [[score], ...]}\n",
    "scores_by_node_role = defaultdict(list)\n",
    "\n",
    "for r in good_trace_results:\n",
    "    enc_s, dec_s = r['scores']\n",
    "    scores, = enc_s\n",
    "#     role = _detect_node_role(' '.join(r['dec_input_tokens']))\n",
    "    role = r['category']['node_role']\n",
    "    scores_by_node_role[role].append(scores)\n",
    "\n",
    "[(r, len(scores)) for r, scores in scores_by_node_role.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select\n",
      "['0.03', '0.03', '0.03', '0.03', '0.03', '0.03', '0.04', '0.04', '0.04', '0.06', '0.07', '0.09', '0.13', '0.18', '0.18', '0.20', '0.28', '0.26', '0.29', '0.35', '0.37', '0.54', '0.62', '0.72']\n",
      "\n",
      "order by\n",
      "['0.05', '0.05', '0.05', '0.05', '0.05', '0.05', '0.06', '0.06', '0.07', '0.09', '0.13', '0.17', '0.29', '0.50', '0.49', '0.59', '0.71', '0.63', '0.65', '0.74', '0.75', '0.76', '0.75', '0.77']\n",
      "\n",
      "where\n",
      "['0.08', '0.09', '0.10', '0.10', '0.10', '0.12', '0.16', '0.17', '0.30', '0.40', '0.47', '0.54', '0.65', '0.75', '0.76', '0.81', '0.89', '0.87', '0.87', '0.91', '0.91', '0.88', '0.88', '0.88']\n",
      "\n",
      "group by\n",
      "['0.15', '0.16', '0.18', '0.18', '0.18', '0.18', '0.20', '0.21', '0.30', '0.40', '0.46', '0.50', '0.65', '0.74', '0.71', '0.77', '0.87', '0.81', '0.85', '0.88', '0.86', '0.80', '0.85', '0.88']\n",
      "\n",
      "join\n",
      "['0.06', '0.06', '0.06', '0.06', '0.06', '0.06', '0.06', '0.06', '0.06', '0.07', '0.07', '0.09', '0.15', '0.22', '0.23', '0.25', '0.33', '0.30', '0.31', '0.33', '0.30', '0.27', '0.26', '0.24']\n",
      "\n",
      "from\n",
      "['0.18', '0.18', '0.18', '0.18', '0.18', '0.18', '0.18', '0.18', '0.19', '0.20', '0.22', '0.22', '0.26', '0.29', '0.28', '0.30', '0.29', '0.28', '0.28', '0.29', '0.27', '0.26', '0.26', '0.24']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r, sample_scores in scores_by_node_role.items():\n",
    "    if len(sample_scores) < 10:\n",
    "        continue\n",
    "    print(r)\n",
    "    scores_by_layer = zip(*sample_scores)\n",
    "    avg_by_layer = [np.mean(scores) for scores in scores_by_layer]\n",
    "    print([f'{avg:.2f}' for avg in avg_by_layer])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f82d217e760>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_avg_by_layer, label='All')\n",
    "for r, sample_scores in scores_by_node_role.items():\n",
    "    if len(sample_scores) < 50:\n",
    "        continue\n",
    "    r_scores_by_layer = zip(*sample_scores)\n",
    "    r_avg_by_layer = [np.mean(scores) for scores in r_scores_by_layer]\n",
    "    ax.plot(r_avg_by_layer, label=r)\n",
    "ax.set_xlabel('Layer to restore')\n",
    "ax.set_ylabel('Avg. P(correct answer)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### by text matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exact', 613), ('partial', 170), ('no-match', 301)]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_by_text_matching = {k: [] for k in ['exact', 'partial', 'no-match']}\n",
    "\n",
    "for r in good_trace_results:\n",
    "#     spider_ex = processed_spider_dev[r['ex_id']]\n",
    "#     col = r['target_node']\n",
    "#     tab = r['target_node_table']\n",
    "#     m = ctu.check_text_match(spider_ex, col, tab)\n",
    "    m = r['category']['text_match']\n",
    "\n",
    "    enc_s, dec_s = r['scores']\n",
    "    scores, = enc_s\n",
    "    scores_by_text_matching[m].append(scores)\n",
    "\n",
    "[(m, len(samples)) for m, samples in scores_by_text_matching.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact\n",
      "['0.05', '0.06', '0.06', '0.06', '0.06', '0.06', '0.08', '0.08', '0.13', '0.17', '0.20', '0.24', '0.29', '0.35', '0.35', '0.38', '0.46', '0.43', '0.45', '0.51', '0.53', '0.63', '0.68', '0.75']\n",
      "\n",
      "partial\n",
      "['0.05', '0.05', '0.05', '0.05', '0.05', '0.05', '0.05', '0.06', '0.07', '0.09', '0.12', '0.14', '0.22', '0.32', '0.32', '0.36', '0.44', '0.44', '0.47', '0.52', '0.52', '0.62', '0.67', '0.73']\n",
      "\n",
      "no-match\n",
      "['0.05', '0.05', '0.05', '0.05', '0.05', '0.06', '0.08', '0.08', '0.13', '0.15', '0.19', '0.23', '0.31', '0.41', '0.41', '0.44', '0.52', '0.50', '0.52', '0.57', '0.56', '0.61', '0.65', '0.70']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r, sample_scores in scores_by_text_matching.items():\n",
    "    if len(sample_scores) < 10:\n",
    "        continue\n",
    "    print(r)\n",
    "    scores_by_layer = zip(*sample_scores)\n",
    "    avg_by_layer = [np.mean(scores) for scores in scores_by_layer]\n",
    "    print([f'{avg:.2f}' for avg in avg_by_layer])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f82d20fc460>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_avg_by_layer, label='All')\n",
    "for m, sample_scores in scores_by_text_matching.items():\n",
    "    if len(sample_scores) < 10:\n",
    "        continue\n",
    "    r_scores_by_layer = zip(*sample_scores)\n",
    "    r_avg_by_layer = [np.mean(scores) for scores in r_scores_by_layer]\n",
    "    ax.plot(r_avg_by_layer, label=m)\n",
    "ax.set_xlabel('Layer to restore')\n",
    "ax.set_ylabel('Avg. P(correct answer)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-3.1: dirty struct context restore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_path = '/home/yshao/Projects/rome/results/exp3.1_dirty_struct_context_restore/exp=3.1_dev_table-tmp.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex_id': 0,\n",
       " 'trace_results': [{'enc_sentence': 'How many singers do we have?; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id',\n",
       "   'seq_out': 'select count(*) from singer',\n",
       "   'dec_prompt': 'select count(*) from',\n",
       "   'expect': 'singer',\n",
       "   'expect_type': 'table',\n",
       "   'db_id': 'concert_singer',\n",
       "   'expect_input_ranges': [[47, 48]],\n",
       "   'expect_table': 'singer',\n",
       "   'answer': 'singer',\n",
       "   'base_score': 0.9999998807907104,\n",
       "   'answers_t': [7634],\n",
       "   'correct_prediction': True,\n",
       "   'category': {'sql_hardness': 'easy',\n",
       "    'node_role': 'from',\n",
       "    'text_match': 'exact'},\n",
       "   'self_ranges': [[46, 50]],\n",
       "   'struct_context_ranges': [[15, 46], [50, 125]],\n",
       "   'trace_scores': {'single_layer_corrupt': {},\n",
       "    'low_layers_restore': {},\n",
       "    'high_layers_restore': {},\n",
       "    'single_layer_restore': {},\n",
       "    'temp1': {}},\n",
       "   'low_score': 1.0,\n",
       "   'is_good_sample': False}]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, (0, 0), 0, 17, 17)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    print(d['enc_sentence'])\n",
    "    print(d['dec_prompt'], '-->', d['expect'])\n",
    "    print(json.dumps(d['trace_scores'], indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in bad_samples:\n",
    "    print(d['enc_sentence'])\n",
    "    print(d['dec_prompt'], '-->', d['expect'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-3.2: dirty struct context compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_path = '/home/yshao/Projects/rome/results/exp3.2_dirty_struct_context_compare/exp=3.2_dev_table.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex_id': 0,\n",
       " 'trace_results': [{'enc_sentence': 'How many singers do we have?; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id',\n",
       "   'seq_out': 'select count(*) from singer',\n",
       "   'dec_prompt': 'select count(*) from',\n",
       "   'expect': 'singer',\n",
       "   'expect_type': 'table',\n",
       "   'db_id': 'concert_singer',\n",
       "   'expect_input_ranges': [[47, 48]],\n",
       "   'expect_table': 'singer',\n",
       "   'answer': 'singer',\n",
       "   'base_score': 0.9999998807907104,\n",
       "   'answers_t': [7634],\n",
       "   'correct_prediction': True,\n",
       "   'category': {'sql_hardness': 'easy',\n",
       "    'node_role': 'from',\n",
       "    'text_match': 'exact'},\n",
       "   'self_ranges': [[46, 50]],\n",
       "   'struct_context_ranges': [[15, 46], [50, 125]],\n",
       "   'scc_score': 1.0,\n",
       "   'scc_answers_t': [7634],\n",
       "   'scc_answer': 'singer',\n",
       "   'scc_correct_prediction': True,\n",
       "   'compare': {'correctness_compare': 'both'}}]}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'both': 1424, 'clean+': 123, 'scc+': 105, 'none': 31})"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctness_compare_counter = Counter([d['compare']['correctness_compare'] for ex in all_samples for d in ex['trace_results']])\n",
    "correctness_compare_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#43: Find the number of concerts happened in the stadium with the highest capacity .; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id\n",
      "SQL: select count(*) from --> concert\n",
      "Clean: stadium\n",
      "SCC: concert\n",
      "COMP: scc+\n",
      "\n",
      "#44: What are the number of concerts that occurred in the stadium with the largest capacity ?; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id\n",
      "SQL: select count(*) from --> concert\n",
      "Clean: stadium\n",
      "SCC: concert\n",
      "COMP: scc+\n",
      "\n",
      "#51: Find number of pets owned by students who are older than 20.; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype , pet_age , weight\n",
      "SQL: select count(*) from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#52: How many pets are owned by students that have an age greater than 20?; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype , pet_age , weight\n",
      "SQL: select count(*) from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#53: Find the number of dog pets that are raised by female students (with sex F).; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype ( dog ) , pet_age , weight\n",
      "SQL: select count(*) from --> student\n",
      "Clean: pets\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#54: How many dog pets are raised by female students?; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype ( dog ) , pet_age , weight\n",
      "SQL: select count(*) from --> student\n",
      "Clean: pets\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#61: Find the major and age of students who do not have a cat pet.; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype ( cat ) , pet_age , weight\n",
      "SQL: select major, age from student where stuid not in (select t1.stuid from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#62: What major is every student who does not own a cat as a pet, and also how old are they?; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype ( cat ) , pet_age , weight\n",
      "SQL: select major, age from student where stuid not in (select t1.stuid from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#63: Find the id of students who do not have a cat pet.; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype ( cat ) , pet_age , weight\n",
      "SQL: select stuid from student except select t1.stuid from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#64: What are the ids of the students who do not own cats as pets?; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype ( cat ) , pet_age , weight\n",
      "SQL: select stuid from student except select t1.stuid from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#65: Find the first name and age of students who have a dog but do not have a cat as a pet.; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype ( dog , cat ) , pet_age , weight\n",
      "SQL: select t1.fname, t1.age from student as t1 join has_pet as t2 on t1.stuid = t2.stuid join pets as t3 on t3.petid = t2.petid where t3.pettype = 'dog' and t1.stuid not in (select t1.stuid from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#66: What is the first name of every student who has a dog but does not have a cat?; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype ( dog , cat ) , pet_age , weight\n",
      "SQL: select t1.fname, t1.age from student as t1 join has_pet as t2 on t1.stuid = t2.stuid join pets as t3 on t3.petid = t2.petid where t3.pettype = 'dog' and t1.stuid not in (select t1.stuid from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#77: Find the id of the pet owned by student whose last name is Smith.; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype , pet_age , weight\n",
      "SQL: select t2.petid from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#78: What is the id of the pet owned by the student whose last name is 'Smith'?; structed knowledge: | pets_1 | student : stuid , lname ( Smith ) , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype , pet_age , weight\n",
      "SQL: select t2.petid from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#79: Find the number of pets for each student who has any pet and student id.; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype , pet_age , weight\n",
      "SQL: select count(*), t1.stuid from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#80: For students who have pets , how many pets does each student have ? list their ids instead of names .; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype , pet_age , weight\n",
      "SQL: select count(*), t1.stuid from --> student\n",
      "Clean: has\n",
      "SCC: student\n",
      "COMP: scc+\n",
      "\n",
      "#113: How many car makers are there in france?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname ( france ) , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year\n",
      "SQL: select count(*) from --> car_makers\n",
      "Clean: countries_makers\n",
      "SCC: car_makers\n",
      "COMP: scc+\n",
      "\n",
      "#115: How many car models are produced in the usa?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname ( usa ) , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year\n",
      "SQL: select count(*) from --> model_list\n",
      "Clean: countries_list\n",
      "SCC: model_list\n",
      "COMP: scc+\n",
      "\n",
      "#116: What is the count of the car models produced in the United States?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year\n",
      "SQL: select count(*) from --> model_list\n",
      "Clean: car_list\n",
      "SCC: model_list\n",
      "COMP: scc+\n",
      "\n",
      "#133: Which model saves the most gasoline? That is to say, have the maximum miles per gallon.; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year\n",
      "SQL: select t1.model from --> car_names\n",
      "Clean: model_names\n",
      "SCC: car_names\n",
      "COMP: scc+\n",
      "\n",
      "#137: What is the average edispl of the cars of model volvo?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( volvo ) , fullname ( Volvo ) , country | model_list : modelid , maker , model ( volvo ) | car_names : makeid , model ( volvo ) , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year\n",
      "SQL: select avg(t2.edispl) from --> car_names\n",
      "Clean: model_names\n",
      "SCC: car_names\n",
      "COMP: scc+\n",
      "\n",
      "#138: What is the average edispl for all volvos?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( volvo ) , fullname ( Volvo ) , country | model_list : modelid , maker , model ( volvo ) | car_names : makeid , model ( volvo ) , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year\n",
      "SQL: select avg(t2.edispl) from --> car_names\n",
      "Clean: car_datas\n",
      "SCC: car_names\n",
      "COMP: scc+\n",
      "\n",
      "#146: In 1980, how many cars were made?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year\n",
      "SQL: select count(*) from --> cars_data\n",
      "Clean: car_data\n",
      "SCC: cars_data\n",
      "COMP: scc+\n",
      "\n",
      "#151: Which distinctive models are produced by maker with the full name General Motors or weighing more than 3500?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname ( General Motors ) , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year\n",
      "SQL: select distinct t2.model from --> car_names\n",
      "Clean: car_makerss\n",
      "SCC: car_names\n",
      "COMP: scc+\n",
      "\n",
      "#152: What are the different models created by either the car maker General Motors or weighed more than 3500?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname ( General Motors ) , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year\n",
      "SQL: select distinct t2.model from --> car_names\n",
      "Clean: car_makerss\n",
      "SCC: car_names\n",
      "COMP: scc+\n",
      "\n",
      "#205: How many flights have destination ATO?; structed knowledge: | flight_2 | airlines : uid , airline , abbreviation , country | airports : city , airportcode ( ATO ) , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airport\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#206: Count the number of flights into ATO.; structed knowledge: | flight_2 | airlines : uid , airline , abbreviation , country | airports : city , airportcode ( ATO ) , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airport\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#207: How many flights depart from City Aberdeen?; structed knowledge: | flight_2 | airlines : uid , airline , abbreviation , country | airports : city ( Aberdeen  ) , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airport\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#209: How many flights arriving in Aberdeen city?; structed knowledge: | flight_2 | airlines : uid , airline , abbreviation , country | airports : city ( Aberdeen  ) , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airport\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#210: Return the number of flights arriving in Aberdeen.; structed knowledge: | flight_2 | airlines : uid , airline , abbreviation , country | airports : city ( Aberdeen  ) , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airport\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#212: How many flights fly from Aberdeen to Ashley?; structed knowledge: | flight_2 | airlines : uid , airline , abbreviation , country | airports : city ( Aberdeen  , Ashley  ) , airportcode , airportname ( Ashley  ) , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airport\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#213: How many flights does airline 'JetBlue Airways' have?; structed knowledge: | flight_2 | airlines : uid , airline ( JetBlue Airways ) , abbreviation ( JetBlue ) , country | airports : city , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airlines\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#214: Give the number of Jetblue Airways flights.; structed knowledge: | flight_2 | airlines : uid , airline ( JetBlue Airways ) , abbreviation ( JetBlue ) , country | airports : city , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airlines\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#217: How many 'United Airlines' flights depart from Airport 'AHD'?; structed knowledge: | flight_2 | airlines : uid , airline ( United Airlines ) , abbreviation , country | airports : city , airportcode ( AHD ) , airportname , country , countryabbrev | flights : airline , flightno , sourceairport (  AHD ) , destairport (  AHD )\n",
      "SQL: select count(*) from --> airlines\n",
      "Clean: flights\n",
      "SCC: airlines\n",
      "COMP: scc+\n",
      "\n",
      "#218: Return the number of United Airlines flights leaving from AHD Airport.; structed knowledge: | flight_2 | airlines : uid , airline ( United Airlines ) , abbreviation , country | airports : city , airportcode ( AHD ) , airportname , country , countryabbrev | flights : airline , flightno , sourceairport (  AHD ) , destairport (  AHD )\n",
      "SQL: select count(*) from --> airlines\n",
      "Clean: flights\n",
      "SCC: airlines\n",
      "COMP: scc+\n",
      "\n",
      "#219: How many United Airlines flights go to City 'Aberdeen'?; structed knowledge: | flight_2 | airlines : uid , airline ( United Airlines ) , abbreviation , country | airports : city ( Aberdeen  ) , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airlines\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#220: Count the number of United Airlines flights that arrive in Aberdeen.; structed knowledge: | flight_2 | airlines : uid , airline ( United Airlines ) , abbreviation , country | airports : city ( Aberdeen  ) , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airlines\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#255: Find the number of flights landing in the city of Aberdeen or Abilene.; structed knowledge: | flight_2 | airlines : uid , airline , abbreviation , country | airports : city ( Aberdeen  , Abilene  ) , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airport\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#256: How many flights land in Aberdeen or Abilene?; structed knowledge: | flight_2 | airlines : uid , airline , abbreviation , country | airports : city ( Aberdeen  , Abilene  ) , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport\n",
      "SQL: select count(*) from --> flights\n",
      "Clean: airport\n",
      "SCC: flights\n",
      "COMP: scc+\n",
      "\n",
      "#307: How many documents are using the template with type code 'PPT'?; structed knowledge: | cre_Doc_Template_Mgt | ref_template_types : template_type_code ( PPT ) , template_type_description | templates : template_id , version_number , template_type_code ( PPT ) , date_effective_from , date_effective_to , template_details | documents : document_id , template_id , document_name , document_description , other_details | paragraphs : paragraph_id , document_id , paragraph_text , other_details\n",
      "SQL: select count(*) from --> documents\n",
      "Clean: templates\n",
      "SCC: documents\n",
      "COMP: scc+\n",
      "\n",
      "#311: What is the id and type code for the template used by the most documents?; structed knowledge: | cre_Doc_Template_Mgt | ref_template_types : template_type_code , template_type_description | templates : template_id , version_number , template_type_code , date_effective_from , date_effective_to , template_details | documents : document_id , template_id , document_name , document_description , other_details | paragraphs : paragraph_id , document_id , paragraph_text , other_details\n",
      "SQL: select t1.template_id, t2.template_type_code from --> documents\n",
      "Clean: templates\n",
      "SCC: documents\n",
      "COMP: scc+\n",
      "\n",
      "#312: Return the id and type code of the template that is used for the greatest number of documents.; structed knowledge: | cre_Doc_Template_Mgt | ref_template_types : template_type_code , template_type_description | templates : template_id , version_number , template_type_code , date_effective_from , date_effective_to , template_details | documents : document_id , template_id , document_name , document_description , other_details | paragraphs : paragraph_id , document_id , paragraph_text , other_details\n",
      "SQL: select t1.template_id, t2.template_type_code from --> documents\n",
      "Clean: templates\n",
      "SCC: documents\n",
      "COMP: scc+\n",
      "\n",
      "#314: What are the template ids of any templates used in more than a single document?; structed knowledge: | cre_Doc_Template_Mgt | ref_template_types : template_type_code , template_type_description | templates : template_id , version_number , template_type_code , date_effective_from , date_effective_to , template_details | documents : document_id , template_id , document_name , document_description , other_details | paragraphs : paragraph_id , document_id , paragraph_text , other_details\n",
      "SQL: select template_id from --> documents\n",
      "Clean: templates\n",
      "SCC: documents\n",
      "COMP: scc+\n",
      "\n",
      "#345: Show all template type codes that are not used by any document.; structed knowledge: | cre_Doc_Template_Mgt | ref_template_types : template_type_code , template_type_description | templates : template_id , version_number , template_type_code , date_effective_from , date_effective_to , template_details | documents : document_id , template_id , document_name , document_description , other_details | paragraphs : paragraph_id , document_id , paragraph_text , other_details\n",
      "SQL: select template_type_code from templates except select template_type_code from --> templates\n",
      "Clean: documents\n",
      "SCC: templates\n",
      "COMP: scc+\n",
      "\n",
      "#346: What are the codes of template types that are not used for any document?; structed knowledge: | cre_Doc_Template_Mgt | ref_template_types : template_type_code , template_type_description | templates : template_id , version_number , template_type_code , date_effective_from , date_effective_to , template_details | documents : document_id , template_id , document_name , document_description , other_details | paragraphs : paragraph_id , document_id , paragraph_text , other_details\n",
      "SQL: select template_type_code from templates except select template_type_code from --> templates\n",
      "Clean: documents\n",
      "SCC: templates\n",
      "COMP: scc+\n",
      "\n",
      "#359: How many paragraphs for the document with name 'Summer Show'?; structed knowledge: | cre_Doc_Template_Mgt | ref_template_types : template_type_code , template_type_description | templates : template_id , version_number , template_type_code , date_effective_from , date_effective_to , template_details | documents : document_id , template_id , document_name ( Summer Show ) , document_description , other_details | paragraphs : paragraph_id , document_id , paragraph_text , other_details\n",
      "SQL: select count(*) from --> paragraphs\n",
      "Clean: documentss\n",
      "SCC: paragraphs\n",
      "COMP: scc+\n",
      "\n",
      "#360: Count the number of paragraphs in the document named 'Summer Show'.; structed knowledge: | cre_Doc_Template_Mgt | ref_template_types : template_type_code , template_type_description | templates : template_id , version_number , template_type_code , date_effective_from , date_effective_to , template_details | documents : document_id , template_id , document_name ( Summer Show ) , document_description , other_details | paragraphs : paragraph_id , document_id , paragraph_text , other_details\n",
      "SQL: select count(*) from --> paragraphs\n",
      "Clean: documentss\n",
      "SCC: paragraphs\n",
      "COMP: scc+\n",
      "\n",
      "#403: Show the name of the teacher for the math course.; structed knowledge: | course_teach | course : course_id , staring_date , course ( Math ) | teacher : teacher_id , name , age , hometown | course_arrange : course_id , teacher_id , grade\n",
      "SQL: select t3.name from --> course_arrange\n",
      "Clean: course asarrange\n",
      "SCC: course_arrange\n",
      "COMP: scc+\n",
      "\n",
      "#404: What are the names of the people who teach math courses?; structed knowledge: | course_teach | course : course_id , staring_date , course ( Math ) | teacher : teacher_id , name , age , hometown | course_arrange : course_id , teacher_id , grade\n",
      "SQL: select t3.name from --> course_arrange\n",
      "Clean: course asarrange\n",
      "SCC: course_arrange\n",
      "COMP: scc+\n",
      "\n",
      "#486: Find the number of left handed winners who participated in the WTA Championships.; structed knowledge: | wta_1 | players : player_id , first_name , last_name , hand , birth_date , country_code | matches : best_of , draw_size , loser_age , loser_entry , loser_hand , loser_ht , loser_id , loser_ioc , loser_name , loser_rank , loser_rank_points , loser_seed , match_num , minutes , round , score , surface , tourney_date , tourney_id , tourney_level , tourney_name ( WTA Championships ) , winner_age , winner_entry , winner_hand , winner_ht , winner_id , winner_ioc , winner_name , winner_rank , winner_rank_points , winner_seed , year | rankings : ranking_date , ranking , player_id , ranking_points , tours\n",
      "SQL: select count(distinct winner_name) from --> matches\n",
      "Clean: players\n",
      "SCC: matches\n",
      "COMP: scc+\n",
      "\n",
      "#542: What is the first, middle, and last name, along with the id and number of enrollments, for the student who enrolled the most in any program?; structed knowledge: | student_transcripts_tracking | addresses : address_id , line_1 , line_2 , line_3 , city , zip_postcode , state_province_county , country , other_address_details | courses : course_id , course_name , course_description , other_details | departments : department_id , department_name , department_description , other_details | degree_programs : degree_program_id , department_id , degree_summary_name , degree_summary_description , other_details | sections : section_id , course_id , section_name , section_description , other_details | semesters : semester_id , semester_name , semester_description , other_details | students : student_id , current_address_id , permanent_address_id , first_name , middle_name , last_name , cell_mobile_number , email_address , ssn , date_first_registered , date_left , other_student_details | student_enrolment : student_enrolment_id , degree_program_id , semester_id , student_id , other_details | student_enrolment_courses : student_course_id , course_id , student_enrolment_id | transcripts : transcript_id , transcript_date , other_details | transcript_contents : student_course_id , transcript_id\n",
      "SQL: select t1.student_id, t1.first_name, t1.middle_name, t1.last_name, count(*), t1.student_id from --> students\n",
      "Clean: student\n",
      "SCC: students\n",
      "COMP: scc+\n",
      "\n",
      "#551: Show the date and id of the transcript with at least 2 course results.; structed knowledge: | student_transcripts_tracking | addresses : address_id , line_1 , line_2 , line_3 , city , zip_postcode , state_province_county , country , other_address_details | courses : course_id , course_name , course_description , other_details | departments : department_id , department_name , department_description , other_details | degree_programs : degree_program_id , department_id , degree_summary_name , degree_summary_description , other_details | sections : section_id , course_id , section_name , section_description , other_details | semesters : semester_id , semester_name , semester_description , other_details | students : student_id , current_address_id , permanent_address_id , first_name , middle_name , last_name , cell_mobile_number , email_address , ssn , date_first_registered , date_left , other_student_details | student_enrolment : student_enrolment_id , degree_program_id , semester_id , student_id , other_details | student_enrolment_courses : student_course_id , course_id , student_enrolment_id | transcripts : transcript_id , transcript_date , other_details | transcript_contents : student_course_id , transcript_id\n",
      "SQL: select t2.transcript_date, t1.transcript_id from --> transcript_contents\n",
      "Clean: transcriptsss\n",
      "SCC: transcript_contents\n",
      "COMP: scc+\n",
      "\n",
      "#552: What is the date and id of the transcript with at least 2 courses listed?; structed knowledge: | student_transcripts_tracking | addresses : address_id , line_1 , line_2 , line_3 , city , zip_postcode , state_province_county , country , other_address_details | courses : course_id , course_name , course_description , other_details | departments : department_id , department_name , department_description , other_details | degree_programs : degree_program_id , department_id , degree_summary_name , degree_summary_description , other_details | sections : section_id , course_id , section_name , section_description , other_details | semesters : semester_id , semester_name , semester_description , other_details | students : student_id , current_address_id , permanent_address_id , first_name , middle_name , last_name , cell_mobile_number , email_address , ssn , date_first_registered , date_left , other_student_details | student_enrolment : student_enrolment_id , degree_program_id , semester_id , student_id , other_details | student_enrolment_courses : student_course_id , course_id , student_enrolment_id | transcripts : transcript_id , transcript_date , other_details | transcript_contents : student_course_id , transcript_id\n",
      "SQL: select t2.transcript_date, t1.transcript_id from --> transcript_contents\n",
      "Clean: transcriptscontents\n",
      "SCC: transcript_contents\n",
      "COMP: scc+\n",
      "\n",
      "#571: How many times at most can a course enrollment result show in different transcripts? Also show the course enrollment id.; structed knowledge: | student_transcripts_tracking | addresses : address_id , line_1 , line_2 , line_3 , city , zip_postcode , state_province_county , country , other_address_details | courses : course_id , course_name , course_description , other_details | departments : department_id , department_name , department_description , other_details | degree_programs : degree_program_id , department_id , degree_summary_name , degree_summary_description , other_details | sections : section_id , course_id , section_name , section_description , other_details | semesters : semester_id , semester_name , semester_description , other_details | students : student_id , current_address_id , permanent_address_id , first_name , middle_name , last_name , cell_mobile_number , email_address , ssn , date_first_registered , date_left , other_student_details | student_enrolment : student_enrolment_id , degree_program_id , semester_id , student_id , other_details | student_enrolment_courses : student_course_id , course_id , student_enrolment_id | transcripts : transcript_id , transcript_date , other_details | transcript_contents : student_course_id , transcript_id\n",
      "SQL: select count(*), student_course_id from --> transcript_contents\n",
      "Clean: student_contents\n",
      "SCC: transcript_contents\n",
      "COMP: scc+\n",
      "\n",
      "#572: What is the maximum number of times that a course shows up in different transcripts and what is that course's enrollment id?; structed knowledge: | student_transcripts_tracking | addresses : address_id , line_1 , line_2 , line_3 , city , zip_postcode , state_province_county , country , other_address_details | courses : course_id , course_name , course_description , other_details | departments : department_id , department_name , department_description , other_details | degree_programs : degree_program_id , department_id , degree_summary_name , degree_summary_description , other_details | sections : section_id , course_id , section_name , section_description , other_details | semesters : semester_id , semester_name , semester_description , other_details | students : student_id , current_address_id , permanent_address_id , first_name , middle_name , last_name , cell_mobile_number , email_address , ssn , date_first_registered , date_left , other_student_details | student_enrolment : student_enrolment_id , degree_program_id , semester_id , student_id , other_details | student_enrolment_courses : student_course_id , course_id , student_enrolment_id | transcripts : transcript_id , transcript_date , other_details | transcript_contents : student_course_id , transcript_id\n",
      "SQL: select count(*), student_course_id from --> transcript_contents\n",
      "Clean: student_contents\n",
      "SCC: transcript_contents\n",
      "COMP: scc+\n",
      "\n",
      "#573: Show the date of the transcript which shows the least number of results, also list the id.; structed knowledge: | student_transcripts_tracking | addresses : address_id , line_1 , line_2 , line_3 , city , zip_postcode , state_province_county , country , other_address_details | courses : course_id , course_name , course_description , other_details | departments : department_id , department_name , department_description , other_details | degree_programs : degree_program_id , department_id , degree_summary_name , degree_summary_description , other_details | sections : section_id , course_id , section_name , section_description , other_details | semesters : semester_id , semester_name , semester_description , other_details | students : student_id , current_address_id , permanent_address_id , first_name , middle_name , last_name , cell_mobile_number , email_address , ssn , date_first_registered , date_left , other_student_details | student_enrolment : student_enrolment_id , degree_program_id , semester_id , student_id , other_details | student_enrolment_courses : student_course_id , course_id , student_enrolment_id | transcripts : transcript_id , transcript_date , other_details | transcript_contents : student_course_id , transcript_id\n",
      "SQL: select t2.transcript_date, t1.transcript_id from --> transcript_contents\n",
      "Clean: transcriptsss\n",
      "SCC: transcript_contents\n",
      "COMP: scc+\n",
      "\n",
      "#574: What is the date and id of the transcript with the least number of results?; structed knowledge: | student_transcripts_tracking | addresses : address_id , line_1 , line_2 , line_3 , city , zip_postcode , state_province_county , country , other_address_details | courses : course_id , course_name , course_description , other_details | departments : department_id , department_name , department_description , other_details | degree_programs : degree_program_id , department_id , degree_summary_name , degree_summary_description , other_details | sections : section_id , course_id , section_name , section_description , other_details | semesters : semester_id , semester_name , semester_description , other_details | students : student_id , current_address_id , permanent_address_id , first_name , middle_name , last_name , cell_mobile_number , email_address , ssn , date_first_registered , date_left , other_student_details | student_enrolment : student_enrolment_id , degree_program_id , semester_id , student_id , other_details | student_enrolment_courses : student_course_id , course_id , student_enrolment_id | transcripts : transcript_id , transcript_date , other_details | transcript_contents : student_course_id , transcript_id\n",
      "SQL: select t2.transcript_date, t1.transcript_id from --> transcript_contents\n",
      "Clean: transcriptsss\n",
      "SCC: transcript_contents\n",
      "COMP: scc+\n",
      "\n",
      "#576: What is the id of the semester that had both Masters and Bachelors students enrolled?; structed knowledge: | student_transcripts_tracking | addresses : address_id , line_1 , line_2 , line_3 , city , zip_postcode , state_province_county , country , other_address_details | courses : course_id , course_name , course_description , other_details | departments : department_id , department_name , department_description , other_details | degree_programs : degree_program_id , department_id , degree_summary_name , degree_summary_description , other_details | sections : section_id , course_id , section_name , section_description , other_details | semesters : semester_id , semester_name , semester_description , other_details | students : student_id , current_address_id , permanent_address_id , first_name , middle_name , last_name , cell_mobile_number , email_address , ssn , date_first_registered , date_left , other_student_details | student_enrolment : student_enrolment_id , degree_program_id , semester_id , student_id , other_details | student_enrolment_courses : student_course_id , course_id , student_enrolment_id | transcripts : transcript_id , transcript_date , other_details | transcript_contents : student_course_id , transcript_id\n",
      "SQL: select distinct t2.semester_id from --> degree_programs\n",
      "Clean: student_programs\n",
      "SCC: degree_programs\n",
      "COMP: scc+\n",
      "\n",
      "#576: What is the id of the semester that had both Masters and Bachelors students enrolled?; structed knowledge: | student_transcripts_tracking | addresses : address_id , line_1 , line_2 , line_3 , city , zip_postcode , state_province_county , country , other_address_details | courses : course_id , course_name , course_description , other_details | departments : department_id , department_name , department_description , other_details | degree_programs : degree_program_id , department_id , degree_summary_name , degree_summary_description , other_details | sections : section_id , course_id , section_name , section_description , other_details | semesters : semester_id , semester_name , semester_description , other_details | students : student_id , current_address_id , permanent_address_id , first_name , middle_name , last_name , cell_mobile_number , email_address , ssn , date_first_registered , date_left , other_student_details | student_enrolment : student_enrolment_id , degree_program_id , semester_id , student_id , other_details | student_enrolment_courses : student_course_id , course_id , student_enrolment_id | transcripts : transcript_id , transcript_date , other_details | transcript_contents : student_course_id , transcript_id\n",
      "SQL: select distinct t2.semester_id from degree_programs as t1 join student_enrolment as t2 on t1.degree_program_id = t2.degree_program_id where degree_summary_name = 'Master' intersect select distinct t2.semester_id from --> degree_programs\n",
      "Clean: student_programs\n",
      "SCC: degree_programs\n",
      "COMP: scc+\n",
      "\n",
      "#612: What is the title of all the cartools that are on the TV Channel with the series name \"Sky Radio\"?; structed knowledge: | tvshow | tv_channel : id , series_name ( Sky Radio ) , country , language , content , pixel_aspect_ratio_par , hight_definition_tv , pay_per_view_ppv , package_option | tv_series : id , episode , air_date , rating , share , 18_49_rating_share , viewers_m , weekly_rank , channel | cartoon : id , title , directed_by , written_by , original_air_date , production_code , channel\n",
      "SQL: select t2.title from --> tv_channel\n",
      "Clean: tv_serie\n",
      "SCC: tv_channel\n",
      "COMP: scc+\n",
      "\n",
      "#690: What are the maximum and minimum values of area codes?; structed knowledge: | voter_1 | area_code_state : area_code , state | contestants : contestant_number , contestant_name | votes : vote_id , phone_number , state , contestant_number , created\n",
      "SQL: select max(area_code), min(area_code) from --> area_code_state\n",
      "Clean: area_code</s>state\n",
      "SCC: area_code_state\n",
      "COMP: scc+\n",
      "\n",
      "#698: What is the area code in which the most voters voted?; structed knowledge: | voter_1 | area_code_state : area_code , state | contestants : contestant_number , contestant_name | votes : vote_id , phone_number , state , contestant_number , created\n",
      "SQL: select t1.area_code from --> area_code_state\n",
      "Clean: votes_code_state\n",
      "SCC: area_code_state\n",
      "COMP: scc+\n",
      "\n",
      "#710: Which region is the city Kabul located in?; structed knowledge: | world_1 | city : id , name ( Kabul ) , countrycode , district , population | sqlite_sequence : name , seq | country : code , name , continent , region , surfacearea , indepyear , population , lifeexpectancy , gnp , gnpold , localname , governmentform , headofstate , capital , code2 | countrylanguage : countrycode , language , isofficial , percentage\n",
      "SQL: select region from --> country\n",
      "Clean: city\n",
      "SCC: country\n",
      "COMP: scc+\n",
      "\n",
      "#711: What region is Kabul in?; structed knowledge: | world_1 | city : id , name ( Kabul ) , countrycode , district , population | sqlite_sequence : name , seq | country : code , name , continent , region , surfacearea , indepyear , population , lifeexpectancy , gnp , gnpold , localname , governmentform , headofstate , capital , code2 | countrylanguage : countrycode , language , isofficial , percentage\n",
      "SQL: select region from --> country\n",
      "Clean: city\n",
      "SCC: country\n",
      "COMP: scc+\n",
      "\n",
      "#890: Show the names of all of the high schooler Kyle's friends.; structed knowledge: | network_1 | highschooler : id , name ( Kyle ) , grade | friend : student_id , friend_id | likes : student_id , liked_id\n",
      "SQL: select t3.name from --> friend\n",
      "Clean: high\n",
      "SCC: friend\n",
      "COMP: scc+\n",
      "\n",
      "#892: How many friends does the high school student Kyle have?; structed knowledge: | network_1 | highschooler : id , name ( Kyle ) , grade | friend : student_id , friend_id | likes : student_id , liked_id\n",
      "SQL: select count(*) from --> friend\n",
      "Clean: high\n",
      "SCC: friend\n",
      "COMP: scc+\n",
      "\n",
      "#893: Count the number of friends Kyle has.; structed knowledge: | network_1 | highschooler : id , name ( Kyle ) , grade | friend : student_id , friend_id | likes : student_id , liked_id\n",
      "SQL: select count(*) from --> friend\n",
      "Clean: high\n",
      "SCC: friend\n",
      "COMP: scc+\n",
      "\n",
      "#894: Show ids of all students who do not have any friends.; structed knowledge: | network_1 | highschooler : id , name , grade | friend : student_id , friend_id | likes : student_id , liked_id\n",
      "SQL: select id from --> highschooler\n",
      "Clean: studentschooler\n",
      "SCC: highschooler\n",
      "COMP: scc+\n",
      "\n",
      "#912: How many likes does Kyle have?; structed knowledge: | network_1 | highschooler : id , name ( Kyle ) , grade | friend : student_id , friend_id | likes : student_id , liked_id\n",
      "SQL: select count(*) from --> likes\n",
      "Clean: highs\n",
      "SCC: likes\n",
      "COMP: scc+\n",
      "\n",
      "#913: Return the number of likes that the high schooler named Kyle has.; structed knowledge: | network_1 | highschooler : id , name ( Kyle ) , grade | friend : student_id , friend_id | likes : student_id , liked_id\n",
      "SQL: select count(*) from --> likes\n",
      "Clean: highs\n",
      "SCC: likes\n",
      "COMP: scc+\n",
      "\n",
      "#930: Which owner owns the most dogs? List the owner id, first name and last name.; structed knowledge: | dog_kennels | breeds : breed_code , breed_name | charges : charge_id , charge_type , charge_amount | sizes : size_code , size_description | treatment_types : treatment_type_code , treatment_type_description | owners : owner_id , first_name , last_name , street , city , state , zip_code , email_address , home_phone , cell_number | dogs : dog_id , owner_id , abandoned_yn , breed_code , size_code , name , age , date_of_birth , gender , weight , date_arrived , date_adopted , date_departed | professionals : professional_id , role_code , first_name , street , city , state , zip_code , last_name , email_address , home_phone , cell_number | treatments : treatment_id , dog_id , professional_id , treatment_type_code , date_of_treatment , cost_of_treatment\n",
      "SQL: select t1.owner_id, t2.first_name, t2.last_name from --> dogs\n",
      "Clean: owners\n",
      "SCC: dogs\n",
      "COMP: scc+\n",
      "\n",
      "#931: Return the owner id, first name and last name of the owner who has the most dogs.; structed knowledge: | dog_kennels | breeds : breed_code , breed_name | charges : charge_id , charge_type , charge_amount | sizes : size_code , size_description | treatment_types : treatment_type_code , treatment_type_description | owners : owner_id , first_name , last_name , street , city , state , zip_code , email_address , home_phone , cell_number | dogs : dog_id , owner_id , abandoned_yn , breed_code , size_code , name , age , date_of_birth , gender , weight , date_arrived , date_adopted , date_departed | professionals : professional_id , role_code , first_name , street , city , state , zip_code , last_name , email_address , home_phone , cell_number | treatments : treatment_id , dog_id , professional_id , treatment_type_code , date_of_treatment , cost_of_treatment\n",
      "SQL: select t1.owner_id, t2.first_name, t2.last_name from --> dogs\n",
      "Clean: owners\n",
      "SCC: dogs\n",
      "COMP: scc+\n",
      "\n",
      "#959: Find the arriving date and the departing date of the dogs that received a treatment.; structed knowledge: | dog_kennels | breeds : breed_code , breed_name | charges : charge_id , charge_type , charge_amount | sizes : size_code , size_description | treatment_types : treatment_type_code , treatment_type_description | owners : owner_id , first_name , last_name , street , city , state , zip_code , email_address , home_phone , cell_number | dogs : dog_id , owner_id , abandoned_yn , breed_code , size_code , name , age , date_of_birth , gender , weight , date_arrived , date_adopted , date_departed | professionals : professional_id , role_code , first_name , street , city , state , zip_code , last_name , email_address , home_phone , cell_number | treatments : treatment_id , dog_id , professional_id , treatment_type_code , date_of_treatment , cost_of_treatment\n",
      "SQL: select distinct t1.date_arrived, t1.date_departed from --> dogs\n",
      "Clean: treatments\n",
      "SCC: dogs\n",
      "COMP: scc+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        _comp = d['compare']['correctness_compare']\n",
    "#         if _comp in {'scc+', 'clean+'}:\n",
    "        if (_comp == 'scc+') and (d['category']['node_role'] != 'join'):\n",
    "            print(f'#{i}:', d['enc_sentence'])\n",
    "            print('SQL:', d['dec_prompt'], '-->', d['expect'])\n",
    "            print('Clean:', d['answer'])\n",
    "            print('SCC:', d['scc_answer'])\n",
    "            print('COMP:', d['compare']['correctness_compare'])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'join': 83, 'from': 40})"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_clean_node_role_cnt = Counter()\n",
    "# TODO: make a larger counter: {comp -> category_k -> category_v -> count}\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        if d['compare']['correctness_compare'] == 'clean+':\n",
    "            _role = d['category']['node_role']\n",
    "            _clean_node_role_cnt[_role] += 1\n",
    "\n",
    "_clean_node_role_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'from': 73, 'join': 32})"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_scc_node_role_cnt = Counter()\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        if d['compare']['correctness_compare'] == 'scc+':\n",
    "            _role = d['category']['node_role']\n",
    "            _scc_node_role_cnt[_role] += 1\n",
    "\n",
    "_scc_node_role_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-4: inspect attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_type = 'column'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp4_inspect_attention/exp=4_dev_{exp_type}_both.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'expect', 'expect_type', 'db_id', 'expect_input_ranges', 'expect_table', 'category', 'answer', 'probs', 'base_score', 'answers_t', 'correct_prediction', 'attentions'])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples[1]['trace_results'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"What are the students' first names who have both cats and dogs as pets?; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype ( dog , cat ) , pet_age , weight\",\n",
       " 'select t1.',\n",
       " 'fname')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = all_samples[6]['trace_results'][0]\n",
    "d['enc_sentence'], d['dec_prompt'], d['expect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'expect', 'expect_type', 'db_id', 'expect_input_ranges', 'expect_table', 'category', 'answer', 'probs', 'base_score', 'answers_t', 'correct_prediction', 'attentions']),\n",
       " dict_keys(['enc', 'cross', 'dec']),\n",
       " dict_keys(['attn', 'head_tokens', 'cand_tokens']))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys(), d['attentions'].keys(), d['attentions']['enc'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _draw_single_plot_2(ax, val_mat, x_labels=None, y_labels=None, title=None):\n",
    "    \"\"\"\n",
    "    X: # heads\n",
    "    Y: cand tokens\n",
    "    Title: head token (together with full expect)\n",
    "    \"\"\"\n",
    "    if isinstance(val_mat, list):\n",
    "        val_mat = numpy.array(val_mat)\n",
    "    h = ax.pcolormesh(\n",
    "        val_mat,\n",
    "        cmap=\"Reds\",\n",
    "        vmax=1.0,\n",
    "        vmin=0.0,\n",
    "    )\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_yticks([0.5 + i for i in range(val_mat.shape[0])])\n",
    "    ax.set_xticks([0.5 + i for i in range(val_mat.shape[1])])\n",
    "    if x_labels is not None:\n",
    "        ax.set_xticklabels(x_labels, fontsize=8)\n",
    "    if y_labels is not None:\n",
    "        ax.set_yticklabels(y_labels, fontsize=8)\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.set_xlabel(f\"# Head\")\n",
    "    ax.set_ylabel(f\"Attention candidate tokens\")\n",
    "    \n",
    "    # cb = plt.colorbar(h)\n",
    "    # divider = make_axes_locatable(ax)\n",
    "    # cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    # cb = fig.colorbar(h, cax=cax)\n",
    "    cb = plt.colorbar(h, ax=ax)\n",
    "\n",
    "#     if xlabel is not None:\n",
    "#         ax.set_xlabel(xlabel)\n",
    "#     elif answer is not None:\n",
    "#         # The following should be cb.ax.set_xlabel, but this is broken in matplotlib 3.5.1.\n",
    "#         cb.ax.set_title(f\"p({str(answer).strip()})\", y=-0.16, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uskg_attention(d, att_part, inspect_layers=None, savepdf=None):\n",
    "    \"\"\"\n",
    "    Assume 16 heads, 24 layers (T5 large config)\n",
    "    \n",
    "    att_part: enc, cross, dec \n",
    "    \"\"\"\n",
    "    \n",
    "    ## encoder self attention \n",
    "    if inspect_layers is None:\n",
    "        inspect_layers = [0, 6, 12, 18, 23]\n",
    "    elif inspect_layers == 'all':\n",
    "        inspect_layers = [i for i in range(24)]\n",
    "    att_dict = d['attentions'][att_part]\n",
    "    \n",
    "    cand_len = len(att_dict['cand_tokens'])\n",
    "    head_len = len(att_dict['head_tokens'])\n",
    "    prompt_tokens = d['attentions']['dec']['cand_tokens']\n",
    "    prompt_len = len(prompt_tokens)\n",
    "\n",
    "    fig_w = len(inspect_layers) * 4 + 2\n",
    "    fig_h = (0.11*cand_len + 1) * head_len + 2\n",
    "    fig, ax_list = plt.subplots(\n",
    "        nrows=head_len,\n",
    "        ncols=len(inspect_layers),\n",
    "        squeeze=False,\n",
    "        figsize=(fig_w, fig_h))\n",
    "\n",
    "    att_mat = ctu.nested_list_processing(att_dict['attn'], func=float)\n",
    "    att_mat = np.array(att_mat)\n",
    "    \n",
    "    for expect_i in range(len(att_dict['head_tokens'])):\n",
    "        for l_id, layer in enumerate(inspect_layers):\n",
    "            val_mat = att_mat[layer, :, expect_i, :]  # layer, all heads, expect tok i -> all toks \n",
    "            val_mat = val_mat.transpose()    # (cand_toks, n_heads)\n",
    "            x_labels = range(val_mat.shape[1])\n",
    "            y_labels = att_dict['cand_tokens']\n",
    "            if att_part == 'enc':\n",
    "                # enc: correct tokens\n",
    "                title_toks = att_dict['head_tokens'][:expect_i] + [f\"*{att_dict['head_tokens'][expect_i]}*\"]\n",
    "            else:\n",
    "                # cross / dec: use gold tokens from dec_prompt for previous steps and predicted token at this step\n",
    "                # (dec_prompt ends with the first (head_len-1) tokens of the target node)\n",
    "                title_toks = prompt_tokens[prompt_len - (head_len-1) : prompt_len - (head_len-1) + expect_i] + [f\"*{att_dict['head_tokens'][expect_i]}*\"]\n",
    "            \n",
    "            title = f\"L{layer}  Head token: {' '.join(title_toks)}\\n\"\n",
    "            \n",
    "            ax = ax_list[expect_i, l_id]\n",
    "            _draw_single_plot_2(ax,\n",
    "                                val_mat=val_mat, \n",
    "                                x_labels=x_labels, \n",
    "                                y_labels=y_labels,\n",
    "                                title=title)\n",
    "            \n",
    "    fig.tight_layout()\n",
    "    if savepdf:\n",
    "        plt.savefig(savepdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savepdf_tmpl = '/home/yshao/Projects/rome/results/figs/exp4_inspect_attention/tmp-6-{}.pdf'\n",
    "# for att_part in ['enc', 'cross', 'dec']:\n",
    "#     plot_uskg_attention(d, att_part, savepdf=savepdf_tmpl.format(att_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f3a2445a1046e5b8f110bacceee316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Run for all! \n",
    "\n",
    "fig_dir  = f'/home/yshao/Projects/rome/results/figs/exp4_inspect_attention/dev_{exp_type}'\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "global_ex_id = 0\n",
    "for ex_id in tqdm(range(len(all_samples))):\n",
    "    for a_ex_id in range(len(all_samples[ex_id]['trace_results'])):\n",
    "        d = all_samples[ex_id]['trace_results'][a_ex_id]\n",
    "        for att_part in ['enc', 'cross', 'dec']:\n",
    "            savepdf_path = os.path.join(fig_dir, f'{global_ex_id}-ex={ex_id}.{a_ex_id}-{att_part}.pdf')\n",
    "            plot_uskg_attention(d, att_part, savepdf=savepdf_path)\n",
    "        # print(f'{global_ex_id}-ex={ex_id}.{a_ex_id}')\n",
    "        global_ex_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 1), (5, 2), (6, 0), (6, 1), (6, 2), (6, 3), (9, 0), (9, 1), (9, 2), (10, 0), (10, 1), (11, 0), (12, 2), (13, 1), (13, 2), (13, 3), (13, 4), (15, 0), (17, 1), (20, 0), (20, 1), (21, 0), (21, 1), (21, 2), (22, 0), (22, 1), (22, 2), (22, 3), (23, 0), (24, 0), (24, 1), (24, 2), (24, 3), (25, 0), (25, 1), (39, 0), (39, 1), (45, 0), (45, 1), (47, 2), (55, 2), (55, 3), (55, 4), (58, 0), (58, 1), (61, 0), (63, 0), (63, 1), (64, 2), (67, 1), (71, 1), (72, 0), (72, 1), (73, 1), (74, 0), (75, 0), (75, 2), (76, 0), (77, 0), (77, 1), (77, 2), (79, 0), (79, 1), (80, 0), (80, 1), (81, 1), (81, 2), (82, 1), (85, 0), (85, 1), (89, 0), (89, 1), (90, 0), (90, 1), (91, 0), (94, 0), (96, 0), (96, 1)]\n"
     ]
    }
   ],
   "source": [
    "_sel_samples = []\n",
    "\n",
    "for ex_id in (range(len(all_samples))):\n",
    "    for a_ex_id in range(len(all_samples[ex_id]['trace_results'])):\n",
    "        d = all_samples[ex_id]['trace_results'][a_ex_id]\n",
    "        if d['category']['text_match'] == 'no-match':\n",
    "            _sel_samples.append((ex_id, a_ex_id))\n",
    "\n",
    "print(_sel_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run for separate samples \n",
    "\n",
    "fig_dir  = f'/home/yshao/Projects/rome/results/figs/exp4_inspect_attention/detail_subset'\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "ex_id = 17\n",
    "a_ex_id = 1\n",
    "d = all_samples[ex_id]['trace_results'][a_ex_id]\n",
    "for att_part in ['enc']:\n",
    "    savepdf_path = os.path.join(fig_dir, f'{exp_type}-ex={ex_id}.{a_ex_id}-{att_part}.pdf')\n",
    "    plot_uskg_attention(d, att_part, inspect_layers='all', savepdf=savepdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp-4.0.1: Prefix attention samples\n",
    "- Check the samples with high attention on a given layer & head & prefix token\n",
    "- Haven't found any insights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 680)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_a_ex = 0\n",
    "total_tok_sample = 0\n",
    "\n",
    "for ex_id in (range(len(all_samples))):\n",
    "    for a_ex_id in range(len(all_samples[ex_id]['trace_results'])):\n",
    "        d = all_samples[ex_id]['trace_results'][a_ex_id]\n",
    "        _expect_len = len([i for s, e in d['expect_input_ranges'] for i in range(s, e)])\n",
    "        \n",
    "        total_a_ex += 1\n",
    "        total_tok_sample += _expect_len\n",
    "\n",
    "total_a_ex, total_tok_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"What are the students' first names who have both cats and dogs as pets?; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype ( dog , cat ) , pet_age , weight\",\n",
       " 'select t1.',\n",
       " 'fname')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = all_samples[6]['trace_results'][0]\n",
    "d['enc_sentence'], d['dec_prompt'], d['expect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[41, 44]], 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_expect_len = len([i for s, e in d['expect_input_ranges'] for i in range(s, e)])\n",
    "d['expect_input_ranges'], _expect_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e8f3eab2c3411087afc827f49d7745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc_prefix_att_samples = defaultdict(list)  # [(l_id, head_id, prefix_id) -> [dict(ex_id, a_ex_id, tok_id, ...)]]\n",
    "\n",
    "for ex_id in tqdm(range(len(all_samples))):\n",
    "    for a_ex_id in range(len(all_samples[ex_id]['trace_results'])):\n",
    "# for ex_id in [6]:\n",
    "#     for a_ex_id in [0]:\n",
    "        d = all_samples[ex_id]['trace_results'][a_ex_id]\n",
    "        \n",
    "        att_mat = ctu.nested_list_processing(d['attentions']['enc']['attn'], func=float)\n",
    "        # att_mat: (n_layers, n_heads, n_expect_toks, n_input_toks)\n",
    "        att_mat = np.array(att_mat)\n",
    "        n_layers, n_heads, n_expect_toks, n_input_toks = att_mat.shape\n",
    "        \n",
    "        # (n_layers, n_heads, expect_toks)\n",
    "#         input_att_positions = np.argmax(att_mat, axis=-1)\n",
    "#         for l_id in range(n_layers):\n",
    "#             for h_id in range(n_heads):\n",
    "#                 for tok_id in range(n_expect_toks):\n",
    "#                     _max_att_p = input_att_positions[l_id, h_id, tok_id]\n",
    "\n",
    "        input_att_positions = np.where(att_mat > 0.5)\n",
    "        for l_id, h_id, tok_id, _max_att_p in zip(*input_att_positions):\n",
    "            if _max_att_p < 10:\n",
    "                # is prefix \n",
    "                enc_prefix_att_samples[(l_id, h_id, _max_att_p)].append({\n",
    "                    'ex_id': ex_id,\n",
    "                    'a_ex_id': a_ex_id,\n",
    "                    'expect_tok_id': tok_id,\n",
    "                    'enc_sentence': d['enc_sentence'],\n",
    "                    'dec_prompt': d['dec_prompt'],\n",
    "                    'expect': d['expect'],\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1873"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc_prefix_att_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_profile_counter = Counter([len(v) for k, v in enc_prefix_att_samples.items()])\n",
    "sorted(len_profile_counter.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 5, 4) 192\n",
      "(18, 6, 2) 145\n",
      "(20, 0, 7) 136\n",
      "(20, 4, 8) 198\n",
      "(23, 7, 0) 125\n",
      "(8, 5, 0) 140\n",
      "(15, 5, 4) 235\n",
      "(17, 1, 9) 220\n",
      "(19, 10, 1) 177\n",
      "(21, 12, 5) 131\n",
      "(3, 4, 8) 126\n",
      "(11, 8, 4) 124\n",
      "(21, 0, 1) 129\n"
     ]
    }
   ],
   "source": [
    "for k, v in enc_prefix_att_samples.items():\n",
    "    if len(v) > 120:\n",
    "        print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc_prefix_att_samples[(23, 7, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.0: dirty attention vector effect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'table_alias'\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_0_dirty_attention_vector_effect/exp=5_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2039, (164, 164), 339, 1536, 1875, 1700)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "#         # TEMP adjustment for column results \n",
    "#         d['low_score'] = d['trace_scores']['high_layers_corrupt'].get(\"0\", 0.0)  # \"0\" is key (for layer 0), 0.0 is default \n",
    "#         if d['base_score'] - d['low_score'] < 0.5:\n",
    "#             d['is_good_sample'] = False\n",
    "#         # END_TEMP\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5, (i, d)\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "n_good_samples + n_too_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in bad_samples if s['correct_prediction']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {k: {str(l): 0 for l in range(24)} for k in good_samples[0]['trace_scores'].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for k, layer_d in d['trace_scores'].items():\n",
    "        for l, s in layer_d.items():\n",
    "            trace_scores_avg[k][l] += s\n",
    "\n",
    "for k, layer_d in trace_scores_avg.items():\n",
    "    for l, s in layer_d.items():\n",
    "        layer_d[l] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'single_layer_corrupt': {'0': 0.9903660492522783,\n",
       "  '1': 0.9912191076886536,\n",
       "  '2': 0.9935591183479863,\n",
       "  '3': 0.992270957420368,\n",
       "  '4': 0.9914841645892107,\n",
       "  '5': 0.9917366726219458,\n",
       "  '6': 0.9921133482318507,\n",
       "  '7': 0.9925546829063113,\n",
       "  '8': 0.9884596560995644,\n",
       "  '9': 0.9895447648250231,\n",
       "  '10': 0.9902057378082583,\n",
       "  '11': 0.9901614527374801,\n",
       "  '12': 0.990823512741675,\n",
       "  '13': 0.9860627002792783,\n",
       "  '14': 0.9887602694836681,\n",
       "  '15': 0.9810846718381661,\n",
       "  '16': 0.9881367732389605,\n",
       "  '17': 0.9841863689749882,\n",
       "  '18': 0.9756313813927958,\n",
       "  '19': 0.9809024711406525,\n",
       "  '20': 0.9875056571127361,\n",
       "  '21': 0.9683756758756376,\n",
       "  '22': 0.9755285080428312,\n",
       "  '23': 0.9610897044773629},\n",
       " 'window_corrupt': {'0': 0.9856137397050513,\n",
       "  '1': 0.9603656087088468,\n",
       "  '2': 0.940690929613998,\n",
       "  '3': 0.9091262590899868,\n",
       "  '4': 0.8477854189319908,\n",
       "  '5': 0.8556997579194107,\n",
       "  '6': 0.9011115334692908,\n",
       "  '7': 0.8826481299545832,\n",
       "  '8': 0.7892982512622857,\n",
       "  '9': 0.7537106214933535,\n",
       "  '10': 0.7961070242648827,\n",
       "  '11': 0.7329492100976266,\n",
       "  '12': 0.6870917433204993,\n",
       "  '13': 0.5920110209480682,\n",
       "  '14': 0.4474441568615098,\n",
       "  '15': 0.5026773975593483,\n",
       "  '16': 0.48399400010475513,\n",
       "  '17': 0.4695331448226715,\n",
       "  '18': 0.33820177436145654,\n",
       "  '19': 0.2612534881279916,\n",
       "  '20': 0.2996589590387087,\n",
       "  '21': 0.35543875684052434,\n",
       "  '22': 0.41262225753912485,\n",
       "  '23': 0.4884939822543031},\n",
       " 'low_layers_corrupt': {'0': 0.9903660492522783,\n",
       "  '1': 0.9893950840593515,\n",
       "  '2': 0.9901690499383723,\n",
       "  '3': 0.9868812642011041,\n",
       "  '4': 0.9856137397050513,\n",
       "  '5': 0.9603656087088468,\n",
       "  '6': 0.940690929613998,\n",
       "  '7': 0.9091262590899868,\n",
       "  '8': 0.8477854189319908,\n",
       "  '9': 0.8556997579194107,\n",
       "  '10': 0.7859926795601169,\n",
       "  '11': 0.6416983220866609,\n",
       "  '12': 0.5395257978296705,\n",
       "  '13': 0.40879002707077267,\n",
       "  '14': 0.33595817855434884,\n",
       "  '15': 0.09959368820603515,\n",
       "  '16': 0.04763294734725666,\n",
       "  '17': 0.03123572578716031,\n",
       "  '18': 0.031000467273661996,\n",
       "  '19': 0.03264906811458622,\n",
       "  '20': 0.023035812484451,\n",
       "  '21': 0.02822654891542626,\n",
       "  '22': 0.025230792773320493,\n",
       "  '23': 0.016081429916385653},\n",
       " 'high_layers_corrupt': {'0': 0.016081429916385653,\n",
       "  '1': 0.02452844109229833,\n",
       "  '2': 0.03720926111893026,\n",
       "  '3': 0.045813631538295194,\n",
       "  '4': 0.04307453347353015,\n",
       "  '5': 0.0929104494776889,\n",
       "  '6': 0.1125388548228262,\n",
       "  '7': 0.12217107763436948,\n",
       "  '8': 0.126763343911802,\n",
       "  '9': 0.13990643752168724,\n",
       "  '10': 0.17445605520165794,\n",
       "  '11': 0.183102610135129,\n",
       "  '12': 0.20917498042519198,\n",
       "  '13': 0.2331477022941476,\n",
       "  '14': 0.2612534881279916,\n",
       "  '15': 0.2996589590387087,\n",
       "  '16': 0.35543875684052434,\n",
       "  '17': 0.41262225753912485,\n",
       "  '18': 0.4884939822543031,\n",
       "  '19': 0.5749512206171478,\n",
       "  '20': 0.6935333043400563,\n",
       "  '21': 0.7675300635249136,\n",
       "  '22': 0.8931439961704867,\n",
       "  '23': 0.9610897044773629}}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects (category)\n",
    "- Still kind of linear, as in exp-2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': 'hard', 'node_role': 'where', 'text_match': 'partial'}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (trace_key, aspect, asp_val, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no trace key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for trace_k, trace_layer_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            for l, s in trace_layer_d.items():\n",
    "                trace_scores_by_aspect[trace_k][aspect][asp_val][l].append(s)\n",
    "\n",
    "for trace_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for asp_v, d3 in d2.items():\n",
    "            for l, s in d3.items():\n",
    "                trace_scores_avg_by_aspect[trace_k][asp_k][asp_v][l] = np.mean(s)\n",
    "                trace_scores_cnt_by_aspect[asp_k][asp_v] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(int,\n",
       "                         {'medium': 400,\n",
       "                          'hard': 155,\n",
       "                          'easy': 142,\n",
       "                          'extra': 170}),\n",
       "             'node_role': defaultdict(int,\n",
       "                         {'where': 268,\n",
       "                          'select': 412,\n",
       "                          'order by': 66,\n",
       "                          'join': 92,\n",
       "                          'group by': 25,\n",
       "                          'having': 4}),\n",
       "             'text_match': defaultdict(int,\n",
       "                         {'no-match': 360, 'partial': 148, 'exact': 359})})"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'medium': defaultdict(float,\n",
       "                                      {'0': 0.04450339804941881,\n",
       "                                       '1': 0.06077712247297951,\n",
       "                                       '2': 0.07443012352337952,\n",
       "                                       '3': 0.09023469504543302,\n",
       "                                       '4': 0.09699239385699884,\n",
       "                                       '5': 0.10533087190160334,\n",
       "                                       '6': 0.11324018190126224,\n",
       "                                       '7': 0.12753861746499676,\n",
       "                                       '8': 0.1393807704540994,\n",
       "                                       '9': 0.13804197824430048,\n",
       "                                       '10': 0.15294395505543915,\n",
       "                                       '11': 0.17548831619147967,\n",
       "                                       '12': 0.20611704002463158,\n",
       "                                       '13': 0.23636694906072322,\n",
       "                                       '14': 0.29587634767917864,\n",
       "                                       '15': 0.3808887699270154,\n",
       "                                       '16': 0.4437984183392939,\n",
       "                                       '17': 0.5342382172815934,\n",
       "                                       '18': 0.6315521794945415,\n",
       "                                       '19': 0.6780092220321201,\n",
       "                                       '20': 0.7662084644481378,\n",
       "                                       '21': 0.831105896880467,\n",
       "                                       '22': 0.8852630641878924,\n",
       "                                       '23': 0.9586180908462848}),\n",
       "                          'hard': defaultdict(float,\n",
       "                                      {'0': 0.03455361058570902,\n",
       "                                       '1': 0.038769763688066186,\n",
       "                                       '2': 0.05304622618395286,\n",
       "                                       '3': 0.06099195531625095,\n",
       "                                       '4': 0.07449673904469327,\n",
       "                                       '5': 0.0956048861333989,\n",
       "                                       '6': 0.10468397340047758,\n",
       "                                       '7': 0.12430167941986388,\n",
       "                                       '8': 0.1215835265327498,\n",
       "                                       '9': 0.1282230159013429,\n",
       "                                       '10': 0.1373001267184783,\n",
       "                                       '11': 0.1641256159161691,\n",
       "                                       '12': 0.18386047097563218,\n",
       "                                       '13': 0.20451159426611654,\n",
       "                                       '14': 0.24915294894946513,\n",
       "                                       '15': 0.3524570965908052,\n",
       "                                       '16': 0.422188344906379,\n",
       "                                       '17': 0.4993379853832708,\n",
       "                                       '18': 0.5791855467458398,\n",
       "                                       '19': 0.6138058197189955,\n",
       "                                       '20': 0.6838699633700208,\n",
       "                                       '21': 0.7148647491328072,\n",
       "                                       '22': 0.8100830610753259,\n",
       "                                       '23': 0.8894980732514899}),\n",
       "                          'easy': defaultdict(float,\n",
       "                                      {'0': 0.03005848018041195,\n",
       "                                       '1': 0.04219464656594679,\n",
       "                                       '2': 0.057874914019115375,\n",
       "                                       '3': 0.07864675486438161,\n",
       "                                       '4': 0.09273316109929924,\n",
       "                                       '5': 0.10805410853763117,\n",
       "                                       '6': 0.11352563735655508,\n",
       "                                       '7': 0.12165510158964213,\n",
       "                                       '8': 0.13740784416990903,\n",
       "                                       '9': 0.13414738839126933,\n",
       "                                       '10': 0.15582113320802798,\n",
       "                                       '11': 0.21002941299509217,\n",
       "                                       '12': 0.24385752964333032,\n",
       "                                       '13': 0.2858107357188441,\n",
       "                                       '14': 0.34726860860489933,\n",
       "                                       '15': 0.44514369683687854,\n",
       "                                       '16': 0.5373986430666786,\n",
       "                                       '17': 0.6635199072638406,\n",
       "                                       '18': 0.7620532554909453,\n",
       "                                       '19': 0.80107748003061,\n",
       "                                       '20': 0.8743366042670753,\n",
       "                                       '21': 0.8958959611257712,\n",
       "                                       '22': 0.9305142608545075,\n",
       "                                       '23': 0.9731056167626045}),\n",
       "                          'extra': defaultdict(float,\n",
       "                                      {'0': 0.0383461887267202,\n",
       "                                       '1': 0.05246996734140824,\n",
       "                                       '2': 0.05877901792759446,\n",
       "                                       '3': 0.06857287739411755,\n",
       "                                       '4': 0.07444842090857497,\n",
       "                                       '5': 0.08556332218441039,\n",
       "                                       '6': 0.09525038251655189,\n",
       "                                       '7': 0.09973740944254574,\n",
       "                                       '8': 0.10576122008444712,\n",
       "                                       '9': 0.11133052887753936,\n",
       "                                       '10': 0.13695679307003164,\n",
       "                                       '11': 0.14698928033996203,\n",
       "                                       '12': 0.15842237107600543,\n",
       "                                       '13': 0.16453033602163872,\n",
       "                                       '14': 0.16533489113459265,\n",
       "                                       '15': 0.21441963858685367,\n",
       "                                       '16': 0.2578422076632982,\n",
       "                                       '17': 0.319455575613476,\n",
       "                                       '18': 0.3751076509929157,\n",
       "                                       '19': 0.4150782882270596,\n",
       "                                       '20': 0.5086698952708301,\n",
       "                                       '21': 0.6014706476247808,\n",
       "                                       '22': 0.7632794372034021,\n",
       "                                       '23': 0.8894416355692288})}),\n",
       "             'node_role': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'where': defaultdict(float,\n",
       "                                      {'0': 0.03735068250656405,\n",
       "                                       '1': 0.0504066667319474,\n",
       "                                       '2': 0.05869338950978911,\n",
       "                                       '3': 0.07334782870979764,\n",
       "                                       '4': 0.08238907885395763,\n",
       "                                       '5': 0.08787769803469905,\n",
       "                                       '6': 0.09374385490621935,\n",
       "                                       '7': 0.11588967461204297,\n",
       "                                       '8': 0.12431852276340787,\n",
       "                                       '9': 0.12147211760905462,\n",
       "                                       '10': 0.1325943258300611,\n",
       "                                       '11': 0.15691991450007414,\n",
       "                                       '12': 0.17223159782534117,\n",
       "                                       '13': 0.20001203150590444,\n",
       "                                       '14': 0.2359035817718071,\n",
       "                                       '15': 0.31299896984239217,\n",
       "                                       '16': 0.3792586420594452,\n",
       "                                       '17': 0.4591312201494018,\n",
       "                                       '18': 0.5672244436076658,\n",
       "                                       '19': 0.6040182590653218,\n",
       "                                       '20': 0.7135178082703048,\n",
       "                                       '21': 0.7744815867782546,\n",
       "                                       '22': 0.8905050863603846,\n",
       "                                       '23': 0.9564813157446238}),\n",
       "                          'select': defaultdict(float,\n",
       "                                      {'0': 0.04613628574855331,\n",
       "                                       '1': 0.05889265531239583,\n",
       "                                       '2': 0.07880160284329678,\n",
       "                                       '3': 0.09384938193324126,\n",
       "                                       '4': 0.10061927927284452,\n",
       "                                       '5': 0.11964982002403102,\n",
       "                                       '6': 0.12806204590652545,\n",
       "                                       '7': 0.13391697966981975,\n",
       "                                       '8': 0.14596512403073833,\n",
       "                                       '9': 0.14839931994022793,\n",
       "                                       '10': 0.17716152344899697,\n",
       "                                       '11': 0.21363705860958287,\n",
       "                                       '12': 0.2519481859850198,\n",
       "                                       '13': 0.28050364721557464,\n",
       "                                       '14': 0.3463794859034164,\n",
       "                                       '15': 0.437864320419842,\n",
       "                                       '16': 0.5113089393163675,\n",
       "                                       '17': 0.6090113062318561,\n",
       "                                       '18': 0.6975226685454177,\n",
       "                                       '19': 0.7411231445636461,\n",
       "                                       '20': 0.8058783486042757,\n",
       "                                       '21': 0.8633589115906516,\n",
       "                                       '22': 0.9070177803613559,\n",
       "                                       '23': 0.9538025432881573}),\n",
       "                          'order by': defaultdict(float,\n",
       "                                      {'0': 0.02048148632405423,\n",
       "                                       '1': 0.030070530128830222,\n",
       "                                       '2': 0.040676572072264536,\n",
       "                                       '3': 0.058329876456180596,\n",
       "                                       '4': 0.08831628569136583,\n",
       "                                       '5': 0.0948305269888546,\n",
       "                                       '6': 0.10251296044460098,\n",
       "                                       '7': 0.11224544709076646,\n",
       "                                       '8': 0.11939277167339322,\n",
       "                                       '9': 0.10290103717056505,\n",
       "                                       '10': 0.09038929996646158,\n",
       "                                       '11': 0.11863935046869198,\n",
       "                                       '12': 0.1285762248591705,\n",
       "                                       '13': 0.15761315240147553,\n",
       "                                       '14': 0.18899257174660586,\n",
       "                                       '15': 0.27640984677605634,\n",
       "                                       '16': 0.35477302622160833,\n",
       "                                       '17': 0.46502185522073414,\n",
       "                                       '18': 0.5413079723489602,\n",
       "                                       '19': 0.5914446285701834,\n",
       "                                       '20': 0.709811152047608,\n",
       "                                       '21': 0.7633530379818546,\n",
       "                                       '22': 0.8465109347609875,\n",
       "                                       '23': 0.9404228771666319}),\n",
       "                          'join': defaultdict(float,\n",
       "                                      {'0': 0.014783172297263952,\n",
       "                                       '1': 0.029005972611884957,\n",
       "                                       '2': 0.03324025412066063,\n",
       "                                       '3': 0.040004019642689286,\n",
       "                                       '4': 0.043403162149221894,\n",
       "                                       '5': 0.049963717065515195,\n",
       "                                       '6': 0.06048216941694149,\n",
       "                                       '7': 0.06984602752679935,\n",
       "                                       '8': 0.0711996941272699,\n",
       "                                       '9': 0.08588293759245388,\n",
       "                                       '10': 0.0968431727987304,\n",
       "                                       '11': 0.08709687983385715,\n",
       "                                       '12': 0.09210847052880874,\n",
       "                                       '13': 0.09418909836555203,\n",
       "                                       '14': 0.08725946030626544,\n",
       "                                       '15': 0.12173285201994251,\n",
       "                                       '16': 0.1452812593374646,\n",
       "                                       '17': 0.1950136185984371,\n",
       "                                       '18': 0.22601037180178304,\n",
       "                                       '19': 0.26831140391521663,\n",
       "                                       '20': 0.3463517377509927,\n",
       "                                       '21': 0.41091485757937046,\n",
       "                                       '22': 0.5267518507836505,\n",
       "                                       '23': 0.7876308917817052}),\n",
       "                          'group by': defaultdict(float,\n",
       "                                      {'0': 0.08850974593784486,\n",
       "                                       '1': 0.11215080016536376,\n",
       "                                       '2': 0.0905514656269861,\n",
       "                                       '3': 0.10060631519952949,\n",
       "                                       '4': 0.11222502297059692,\n",
       "                                       '5': 0.12520582869088684,\n",
       "                                       '6': 0.14434792925632792,\n",
       "                                       '7': 0.17745844418503112,\n",
       "                                       '8': 0.16786224095732905,\n",
       "                                       '9': 0.1868278609846311,\n",
       "                                       '10': 0.17846283252336434,\n",
       "                                       '11': 0.1808184133231407,\n",
       "                                       '12': 0.22235183918295662,\n",
       "                                       '13': 0.25989689813693984,\n",
       "                                       '14': 0.30344554322597106,\n",
       "                                       '15': 0.43133556193264666,\n",
       "                                       '16': 0.44794347776740323,\n",
       "                                       '17': 0.5435542441927828,\n",
       "                                       '18': 0.583055160563672,\n",
       "                                       '19': 0.6296261364012026,\n",
       "                                       '20': 0.6862947089085355,\n",
       "                                       '21': 0.690542561346665,\n",
       "                                       '22': 0.8352431547641754,\n",
       "                                       '23': 0.9148775762319565}),\n",
       "                          'having': defaultdict(float,\n",
       "                                      {'0': 0.0004047230920605216,\n",
       "                                       '1': 0.0004903688616550994,\n",
       "                                       '2': 0.0005631924158251422,\n",
       "                                       '3': 0.0010991139973839381,\n",
       "                                       '4': 0.0013212460972908957,\n",
       "                                       '5': 0.0019957258118665777,\n",
       "                                       '6': 0.0028662336394518206,\n",
       "                                       '7': 0.002466940491103742,\n",
       "                                       '8': 0.0018075163388857618,\n",
       "                                       '9': 0.002008813047723379,\n",
       "                                       '10': 0.0014234772970667109,\n",
       "                                       '11': 0.002643901199917309,\n",
       "                                       '12': 0.00630858785007149,\n",
       "                                       '13': 0.01633591833524406,\n",
       "                                       '14': 0.09257332561537623,\n",
       "                                       '15': 0.534604050219059,\n",
       "                                       '16': 0.7055654525756836,\n",
       "                                       '17': 0.8596431761980057,\n",
       "                                       '18': 0.9708361923694611,\n",
       "                                       '19': 0.9949062466621399,\n",
       "                                       '20': 0.999748557806015,\n",
       "                                       '21': 0.9999157935380936,\n",
       "                                       '22': 0.9999925047159195,\n",
       "                                       '23': 0.9999953806400299})}),\n",
       "             'text_match': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'no-match': defaultdict(float,\n",
       "                                      {'0': 0.017051113758705747,\n",
       "                                       '1': 0.025490219461348614,\n",
       "                                       '2': 0.026743194938571548,\n",
       "                                       '3': 0.03905139655089538,\n",
       "                                       '4': 0.048968046290673424,\n",
       "                                       '5': 0.055132100823933536,\n",
       "                                       '6': 0.06309312713104306,\n",
       "                                       '7': 0.07406403460930557,\n",
       "                                       '8': 0.07864109449684968,\n",
       "                                       '9': 0.08700824954524376,\n",
       "                                       '10': 0.09516840193651824,\n",
       "                                       '11': 0.1090386657341482,\n",
       "                                       '12': 0.13189860360474231,\n",
       "                                       '13': 0.15700029968993726,\n",
       "                                       '14': 0.17521441759051154,\n",
       "                                       '15': 0.23647587441544735,\n",
       "                                       '16': 0.28725266129267757,\n",
       "                                       '17': 0.361238508685739,\n",
       "                                       '18': 0.4485128897806182,\n",
       "                                       '19': 0.49268188295481397,\n",
       "                                       '20': 0.5988861129843794,\n",
       "                                       '21': 0.6468898883668429,\n",
       "                                       '22': 0.7561261551012204,\n",
       "                                       '23': 0.8919028135297897}),\n",
       "                          'partial': defaultdict(float,\n",
       "                                      {'0': 0.03154872117476015,\n",
       "                                       '1': 0.05227143490547942,\n",
       "                                       '2': 0.06253227561216206,\n",
       "                                       '3': 0.06961423418314808,\n",
       "                                       '4': 0.07014214029012558,\n",
       "                                       '5': 0.07133480439575672,\n",
       "                                       '6': 0.07895082477759681,\n",
       "                                       '7': 0.08390120188691985,\n",
       "                                       '8': 0.0926277002437251,\n",
       "                                       '9': 0.10579619159026271,\n",
       "                                       '10': 0.1305311012624908,\n",
       "                                       '11': 0.14820210129381584,\n",
       "                                       '12': 0.16632602971519614,\n",
       "                                       '13': 0.1880615275733734,\n",
       "                                       '14': 0.22037272843389033,\n",
       "                                       '15': 0.30381050507037655,\n",
       "                                       '16': 0.3773977301357556,\n",
       "                                       '17': 0.4518295443662543,\n",
       "                                       '18': 0.5661011324239251,\n",
       "                                       '19': 0.62271271900285,\n",
       "                                       '20': 0.7225596503774918,\n",
       "                                       '21': 0.8225543695309983,\n",
       "                                       '22': 0.8967396785120996,\n",
       "                                       '23': 0.9543833089992404}),\n",
       "                          'exact': defaultdict(float,\n",
       "                                      {'0': 0.0644476697568657,\n",
       "                                       '1': 0.078883134398745,\n",
       "                                       '2': 0.10396255804396713,\n",
       "                                       '3': 0.1225945683078162,\n",
       "                                       '4': 0.1341469612749421,\n",
       "                                       '5': 0.1572018020830738,\n",
       "                                       '6': 0.16556280316368727,\n",
       "                                       '7': 0.1822622868758368,\n",
       "                                       '8': 0.19517933823331998,\n",
       "                                       '9': 0.1840826507841884,\n",
       "                                       '10': 0.2069335089609748,\n",
       "                                       '11': 0.24863320498862576,\n",
       "                                       '12': 0.2796796980718473,\n",
       "                                       '13': 0.3076549982229948,\n",
       "                                       '14': 0.38633973797441534,\n",
       "                                       '15': 0.49179061814207825,\n",
       "                                       '16': 0.5677897528940936,\n",
       "                                       '17': 0.6760537984393564,\n",
       "                                       '18': 0.7496570656606355,\n",
       "                                       '19': 0.7831001163122124,\n",
       "                                       '20': 0.8372564935190215,\n",
       "                                       '21': 0.8860591223988663,\n",
       "                                       '22': 0.9377040146281916,\n",
       "                                       '23': 0.9703949045040158})})})"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg_by_aspect['high_layers_corrupt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.2: attention section removal effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/exp=5.2.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2039, (168, 168), 339, 1532, 1871)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'Show the stadium name and the number of concerts in each stadium.; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id',\n",
       " 'seq_out': 'select t2.name, count(*) from concert as t1 join stadium as t2 on t1.stadium_id = t2.stadium_id group by t1.stadium_id',\n",
       " 'dec_prompt': 'select t2.name, count(*) from concert as t1 join stadium as t2 on',\n",
       " 'expect': 't1.',\n",
       " 'expect_type': 'table_alias',\n",
       " 'db_id': 'concert_singer',\n",
       " 'expect_input_ranges': [[86, 87]],\n",
       " 'answer': 't1.',\n",
       " 'base_score': 0.9999994039535522,\n",
       " 'answers_t': [3, 17, 5411],\n",
       " 'correct_prediction': True,\n",
       " 'category': {'sql_hardness': 'medium',\n",
       "  'node_role': 'join',\n",
       "  'text_match': 'exact'},\n",
       " 'self_ranges': [[85, 89]],\n",
       " 'struct_context_ranges': [[20, 85], [89, 130]],\n",
       " 'low_score': 1.0,\n",
       " 'is_good_sample': False}"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in bad_samples if s['correct_prediction']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            if k == 'window':\n",
    "                for l, s in v.items():\n",
    "                    trace_scores_avg[sect_k][f'{k}-{l}'] += s\n",
    "            else:\n",
    "                s = v\n",
    "                trace_scores_avg[sect_k][k] += s\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prefix': defaultdict(int,\n",
       "             {'window-0': 0.9489428565970489,\n",
       "              'window-1': 0.9459466916464624,\n",
       "              'window-2': 0.9433333320277077,\n",
       "              'window-3': 0.9472156441992238,\n",
       "              'window-4': 0.9404166692069599,\n",
       "              'window-5': 0.9299381505697966,\n",
       "              'window-6': 0.9402093497947568,\n",
       "              'window-7': 0.9222004726706516,\n",
       "              'window-8': 0.9071454543930789,\n",
       "              'window-9': 0.9118640449624287,\n",
       "              'window-10': 0.9221835770128693,\n",
       "              'window-11': 0.9004831596948428,\n",
       "              'window-12': 0.8577846140982556,\n",
       "              'window-13': 0.8031986702844733,\n",
       "              'window-14': 0.6540351511221987,\n",
       "              'window-15': 0.6439282640543488,\n",
       "              'window-16': 0.6082126750435444,\n",
       "              'window-17': 0.6293545918019131,\n",
       "              'window-18': 0.6225930494554526,\n",
       "              'window-19': 0.5357348926681949,\n",
       "              'window-20': 0.5400049815308836,\n",
       "              'window-21': 0.5742439014753382,\n",
       "              'window-22': 0.6134914372819055,\n",
       "              'window-23': 0.6425308727503227,\n",
       "              'first_layer': 0.9484615538801465,\n",
       "              'last_layer': 0.873940426016426,\n",
       "              'all_layers': 0.2498462739990746}),\n",
       " 'text': defaultdict(int,\n",
       "             {'window-0': 0.9483299592421168,\n",
       "              'window-1': 0.9481449570684206,\n",
       "              'window-2': 0.9471475175094037,\n",
       "              'window-3': 0.947731566571054,\n",
       "              'window-4': 0.9471073106286072,\n",
       "              'window-5': 0.943124884473426,\n",
       "              'window-6': 0.9436389080115727,\n",
       "              'window-7': 0.9410505436715626,\n",
       "              'window-8': 0.9376007896803674,\n",
       "              'window-9': 0.9283620816256318,\n",
       "              'window-10': 0.9277275319965113,\n",
       "              'window-11': 0.9183367850879828,\n",
       "              'window-12': 0.8915040346161861,\n",
       "              'window-13': 0.8924364284529085,\n",
       "              'window-14': 0.8754010844824647,\n",
       "              'window-15': 0.845033811380225,\n",
       "              'window-16': 0.8330992775972845,\n",
       "              'window-17': 0.8387327940631838,\n",
       "              'window-18': 0.8575928019141602,\n",
       "              'window-19': 0.8540408059165029,\n",
       "              'window-20': 0.8546403900909354,\n",
       "              'window-21': 0.8630306227534588,\n",
       "              'window-22': 0.8869916050801597,\n",
       "              'window-23': 0.884705040109111,\n",
       "              'first_layer': 0.9480909219100362,\n",
       "              'last_layer': 0.9342825717869259,\n",
       "              'all_layers': 0.7430854112239325}),\n",
       " 'struct': defaultdict(int,\n",
       "             {'window-0': 0.9330211368921612,\n",
       "              'window-1': 0.925167217717639,\n",
       "              'window-2': 0.9171046379155346,\n",
       "              'window-3': 0.9109604747722014,\n",
       "              'window-4': 0.8965552974314916,\n",
       "              'window-5': 0.887033143416158,\n",
       "              'window-6': 0.8812394776198614,\n",
       "              'window-7': 0.8727138553419665,\n",
       "              'window-8': 0.8563397956812488,\n",
       "              'window-9': 0.8567416591034825,\n",
       "              'window-10': 0.8347947371177827,\n",
       "              'window-11': 0.8174125205976457,\n",
       "              'window-12': 0.7293831761840633,\n",
       "              'window-13': 0.7350210454885675,\n",
       "              'window-14': 0.6940035310516566,\n",
       "              'window-15': 0.7166103291891621,\n",
       "              'window-16': 0.6538497578734795,\n",
       "              'window-17': 0.5417029060904315,\n",
       "              'window-18': 0.4846800624715725,\n",
       "              'window-19': 0.4618284298516503,\n",
       "              'window-20': 0.49702530122476546,\n",
       "              'window-21': 0.5346182826122834,\n",
       "              'window-22': 0.5611266578637496,\n",
       "              'window-23': 0.6287162009882322,\n",
       "              'first_layer': 0.9485237477790742,\n",
       "              'last_layer': 0.9440051373981294,\n",
       "              'all_layers': 0.1263078110766962}),\n",
       " 'text+struct': defaultdict(int,\n",
       "             {'window-0': 0.9303059950027437,\n",
       "              'window-1': 0.9213759321275921,\n",
       "              'window-2': 0.9169963143011999,\n",
       "              'window-3': 0.9082610283401751,\n",
       "              'window-4': 0.8913364413102889,\n",
       "              'window-5': 0.8797086697615581,\n",
       "              'window-6': 0.8770869277726715,\n",
       "              'window-7': 0.8677347994733802,\n",
       "              'window-8': 0.8501009499360364,\n",
       "              'window-9': 0.8489185362886063,\n",
       "              'window-10': 0.8256537349756605,\n",
       "              'window-11': 0.7924875653429407,\n",
       "              'window-12': 0.696795406021136,\n",
       "              'window-13': 0.7370464150339244,\n",
       "              'window-14': 0.6731179804442915,\n",
       "              'window-15': 0.6649166234458898,\n",
       "              'window-16': 0.6021134995348997,\n",
       "              'window-17': 0.5336208946814716,\n",
       "              'window-18': 0.4255613379809537,\n",
       "              'window-19': 0.3974970635258469,\n",
       "              'window-20': 0.4292863488735639,\n",
       "              'window-21': 0.46860412693126346,\n",
       "              'window-22': 0.5120090204694979,\n",
       "              'window-23': 0.5779948868095206,\n",
       "              'first_layer': 0.9478886173594565,\n",
       "              'last_layer': 0.9306179909479051,\n",
       "              'all_layers': 0.10694331496035014}),\n",
       " 'all': defaultdict(int,\n",
       "             {'window-0': 0.9218792797709328,\n",
       "              'window-1': 0.9067843803648084,\n",
       "              'window-2': 0.886196761647062,\n",
       "              'window-3': 0.8622249553348714,\n",
       "              'window-4': 0.7920203238414572,\n",
       "              'window-5': 0.7666085660583113,\n",
       "              'window-6': 0.8218252419517176,\n",
       "              'window-7': 0.748052881100541,\n",
       "              'window-8': 0.6640647552311947,\n",
       "              'window-9': 0.575684257388166,\n",
       "              'window-10': 0.6723340421728425,\n",
       "              'window-11': 0.6102487181519635,\n",
       "              'window-12': 0.4542111269063962,\n",
       "              'window-13': 0.3819512575706283,\n",
       "              'window-14': 0.33067812572060606,\n",
       "              'window-15': 0.34381790590862565,\n",
       "              'window-16': 0.3099250872438035,\n",
       "              'window-17': 0.2986727822245017,\n",
       "              'window-18': 0.2639101625516011,\n",
       "              'window-19': 0.26920749726204984,\n",
       "              'window-20': 0.2760014259428476,\n",
       "              'window-21': 0.29113083423643066,\n",
       "              'window-22': 0.3234503123139499,\n",
       "              'window-23': 0.4049646406155,\n",
       "              'first_layer': 0.9509559933628354,\n",
       "              'last_layer': 0.8428448445147729,\n",
       "              'all_layers': 0.06689078736677516}),\n",
       " 'self': defaultdict(int,\n",
       "             {'window-0': 0.9440061026696294,\n",
       "              'window-1': 0.941891116223165,\n",
       "              'window-2': 0.9395173443481326,\n",
       "              'window-3': 0.937020205094346,\n",
       "              'window-4': 0.9339502474204415,\n",
       "              'window-5': 0.9285054395108351,\n",
       "              'window-6': 0.9216379866536174,\n",
       "              'window-7': 0.9156253876696739,\n",
       "              'window-8': 0.9001903304209312,\n",
       "              'window-9': 0.8915841174755423,\n",
       "              'window-10': 0.886963648610704,\n",
       "              'window-11': 0.8692028160204202,\n",
       "              'window-12': 0.8506584558424601,\n",
       "              'window-13': 0.836893450302471,\n",
       "              'window-14': 0.8102450199012743,\n",
       "              'window-15': 0.8039197585329865,\n",
       "              'window-16': 0.806282035836949,\n",
       "              'window-17': 0.8338727065682373,\n",
       "              'window-18': 0.8419563735670592,\n",
       "              'window-19': 0.8306145018696476,\n",
       "              'window-20': 0.8491509281105946,\n",
       "              'window-21': 0.8778289310830587,\n",
       "              'window-22': 0.8901339451712418,\n",
       "              'window-23': 0.9211891535447821,\n",
       "              'first_layer': 0.9488432190957523,\n",
       "              'last_layer': 0.9441031253054029,\n",
       "              'all_layers': 0.5127852745849876})}"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': 'medium', 'node_role': 'where', 'text_match': 'no-match'}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (sect_k, aspect, asp_val, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no sect key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            for k, v in sect_d.items():\n",
    "                if k == 'window':\n",
    "                    for l, s in v.items():\n",
    "                        if not (int(l) % 4 == 3): continue\n",
    "                        layer_k = f'{k}-{l}'\n",
    "                        trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                else:\n",
    "                    layer_k = k\n",
    "                    s = v\n",
    "                    trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                    \n",
    "for sect_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for asp_v, d3 in d2.items():\n",
    "            for layer_k, s in d3.items():\n",
    "                trace_scores_avg_by_aspect[sect_k][asp_k][asp_v][layer_k] = np.mean(s)\n",
    "                trace_scores_cnt_by_aspect[asp_k][asp_v] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sect_k, sect_d in trace_scores_avg_by_aspect.items():\n",
    "    sect_d['overall'] = dict()\n",
    "    for layer_k, s in trace_scores_avg[sect_k].items():\n",
    "        if layer_k.startswith('window'):\n",
    "            # only keep a subset of layers \n",
    "            _, l = layer_k.split('-')\n",
    "            if not (int(l) % 4 == 3): continue\n",
    "        sect_d['overall'][layer_k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(int,\n",
       "                         {'medium': 41, 'extra': 91, 'hard': 36}),\n",
       "             'node_role': defaultdict(int,\n",
       "                         {'select': 106,\n",
       "                          'group by': 11,\n",
       "                          'join': 10,\n",
       "                          'where': 33,\n",
       "                          'order by': 8}),\n",
       "             'text_match': defaultdict(int,\n",
       "                         {'exact': 102, 'partial': 20, 'no-match': 46})})"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'medium': defaultdict(float,\n",
       "                                      {'window-3': 0.9082739389524227,\n",
       "                                       'window-7': 0.887452801371493,\n",
       "                                       'window-11': 0.8704590771983309,\n",
       "                                       'window-15': 0.814035872406349,\n",
       "                                       'window-19': 0.8376667729419905,\n",
       "                                       'window-23': 0.9137709155315306,\n",
       "                                       'first_layer': 0.9348885344295967,\n",
       "                                       'last_layer': 0.9240150756952239,\n",
       "                                       'all_layers': 0.5712719543519531}),\n",
       "                          'extra': defaultdict(float,\n",
       "                                      {'window-3': 0.9550143567087886,\n",
       "                                       'window-7': 0.9282350607298233,\n",
       "                                       'window-11': 0.8604071743781218,\n",
       "                                       'window-15': 0.8018573768120725,\n",
       "                                       'window-19': 0.8184270616699135,\n",
       "                                       'window-23': 0.9181459966514792,\n",
       "                                       'first_layer': 0.9597188214679341,\n",
       "                                       'last_layer': 0.9557495896632855,\n",
       "                                       'all_layers': 0.46335757918164455}),\n",
       "                          'hard': defaultdict(float,\n",
       "                                      {'window-3': 0.924273791619473,\n",
       "                                       'window-7': 0.9158363818294473,\n",
       "                                       'window-11': 0.8900055016080538,\n",
       "                                       'window-15': 0.797611871527301,\n",
       "                                       'window-19': 0.8533898892088069,\n",
       "                                       'window-23': 0.9373301267623901,\n",
       "                                       'first_layer': 0.9372449484136369,\n",
       "                                       'last_layer': 0.9375415080123477,\n",
       "                                       'all_layers': 0.5711176748977272})}),\n",
       "             'node_role': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'select': defaultdict(float,\n",
       "                                      {'window-3': 0.9236957356333733,\n",
       "                                       'window-7': 0.8938878775345829,\n",
       "                                       'window-11': 0.8332420075202431,\n",
       "                                       'window-15': 0.7414834219198898,\n",
       "                                       'window-19': 0.7882326523541915,\n",
       "                                       'window-23': 0.9035243876629843,\n",
       "                                       'first_layer': 0.9383518425923474,\n",
       "                                       'last_layer': 0.9308291915452706,\n",
       "                                       'all_layers': 0.4845998617705508}),\n",
       "                          'group by': defaultdict(float,\n",
       "                                      {'window-3': 0.9678072821010243,\n",
       "                                       'window-7': 0.9491941603747281,\n",
       "                                       'window-11': 0.9153855768117037,\n",
       "                                       'window-15': 0.8670971962538633,\n",
       "                                       'window-19': 0.8263179917227138,\n",
       "                                       'window-23': 0.9079721515828912,\n",
       "                                       'first_layer': 0.9632697972384366,\n",
       "                                       'last_layer': 0.9577989144758745,\n",
       "                                       'all_layers': 0.4781986732374538}),\n",
       "                          'join': defaultdict(float,\n",
       "                                      {'window-3': 0.9109864175319672,\n",
       "                                       'window-7': 0.9059942543506623,\n",
       "                                       'window-11': 0.8452017337083817,\n",
       "                                       'window-15': 0.8454024970531464,\n",
       "                                       'window-19': 0.795573216676712,\n",
       "                                       'window-23': 0.8652617394924164,\n",
       "                                       'first_layer': 0.9106310546398163,\n",
       "                                       'last_layer': 0.911524623632431,\n",
       "                                       'all_layers': 0.36511413999833164}),\n",
       "                          'where': defaultdict(float,\n",
       "                                      {'window-3': 0.9715473157438365,\n",
       "                                       'window-7': 0.967278238047253,\n",
       "                                       'window-11': 0.9534164098176089,\n",
       "                                       'window-15': 0.9282741808530056,\n",
       "                                       'window-19': 0.9395273774862289,\n",
       "                                       'window-23': 0.9857228777625344,\n",
       "                                       'first_layer': 0.988773504892985,\n",
       "                                       'last_layer': 0.9902134284828649,\n",
       "                                       'all_layers': 0.5425375468789063}),\n",
       "                          'order by': defaultdict(float,\n",
       "                                      {'window-3': 0.961355097591877,\n",
       "                                       'window-7': 0.9564612433314323,\n",
       "                                       'window-11': 0.964802511036396,\n",
       "                                       'window-15': 0.979516826570034,\n",
       "                                       'window-19': 0.992617703974247,\n",
       "                                       'window-23': 0.9771283343434334,\n",
       "                                       'first_layer': 0.9510701894760132,\n",
       "                                       'last_layer': 0.9516691640019417,\n",
       "                                       'all_layers': 0.9956593662500381})}),\n",
       "             'text_match': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'exact': defaultdict(float,\n",
       "                                      {'window-3': 0.930828267160584,\n",
       "                                       'window-7': 0.9139545953595171,\n",
       "                                       'window-11': 0.8608404288100371,\n",
       "                                       'window-15': 0.7874770008658529,\n",
       "                                       'window-19': 0.8086922095026239,\n",
       "                                       'window-23': 0.9008364231490037,\n",
       "                                       'first_layer': 0.9363825823746476,\n",
       "                                       'last_layer': 0.9279729764835507,\n",
       "                                       'all_layers': 0.5395138431613079}),\n",
       "                          'partial': defaultdict(float,\n",
       "                                      {'window-3': 0.9168359525501728,\n",
       "                                       'window-7': 0.906278433650732,\n",
       "                                       'window-11': 0.8688275791704655,\n",
       "                                       'window-15': 0.8713949650526047,\n",
       "                                       'window-19': 0.8908746361732482,\n",
       "                                       'window-23': 0.9291423976421356,\n",
       "                                       'first_layer': 0.9375076621770859,\n",
       "                                       'last_layer': 0.9381944984197617,\n",
       "                                       'all_layers': 0.5124790751375258}),\n",
       "                          'no-match': defaultdict(float,\n",
       "                                      {'window-3': 0.9595259164014588,\n",
       "                                       'window-7': 0.923394081061301,\n",
       "                                       'window-11': 0.8879086471608152,\n",
       "                                       'window-15': 0.8110427400907096,\n",
       "                                       'window-19': 0.8530247439427868,\n",
       "                                       'window-23': 0.9628611887278764,\n",
       "                                       'first_layer': 0.9814018296158832,\n",
       "                                       'last_layer': 0.9824389452519624,\n",
       "                                       'all_layers': 0.4536507092407389})}),\n",
       "             'overall': {'window-3': 0.937020205094346,\n",
       "              'window-7': 0.9156253876696739,\n",
       "              'window-11': 0.8692028160204202,\n",
       "              'window-15': 0.8039197585329865,\n",
       "              'window-19': 0.8306145018696476,\n",
       "              'window-23': 0.9211891535447821,\n",
       "              'first_layer': 0.9488432190957523,\n",
       "              'last_layer': 0.9441031253054029,\n",
       "              'all_layers': 0.5127852745849876}})"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg_by_aspect['self']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_d = ctu.nested_json_processing(trace_scores_avg_by_aspect, func=lambda x: np.format_float_positional(x, precision=4, min_digits=4))\n",
    "dump_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/summ-exp=5.2.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(dump_path, 'w') as f:\n",
    "    json.dump(dump_d, f, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (one-time temp patch: +self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect_type = 'table_alias'\n",
    "# orig_res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/exp=5.2_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "# add_res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/exp=5.2.1+self_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "# merge_res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/exp=5.2.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(orig_res_path, 'r') as f:\n",
    "#     orig_all_samples = [json.loads(l) for l in f]\n",
    "# with open(add_res_path, 'r') as f:\n",
    "#     add_all_samples = [json.loads(l) for l in f]\n",
    "\n",
    "# f = open(merge_res_path, 'w')\n",
    "    \n",
    "# for i, (orig_ex, add_ex) in enumerate(zip(orig_all_samples, add_all_samples)):\n",
    "#     assert len(orig_ex['trace_results']) == len(add_ex['trace_results']), i\n",
    "#     # There is randomness in the order of expected node (from set()), thus sorting here \n",
    "#     orig_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     add_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     for j, (orig_d, add_d) in enumerate(zip(orig_ex['trace_results'], add_ex['trace_results'])):\n",
    "#         assert orig_d['is_good_sample'] == add_d['is_good_sample'], (i, j)\n",
    "#         if not orig_d['is_good_sample']:\n",
    "#             continue\n",
    "#         # is good sample: add the \"self\" section \n",
    "#         orig_d['trace_scores']['self'] = add_d['trace_scores']['self']\n",
    "#     f.write(json.dumps(orig_ex, indent=None) + '\\n')\n",
    "    \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.3: attention section mutual removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/exp=5.3_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2039, (310, 310), 339, 1390, 1729, 'good / correct = 310 / 1700')"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            if k == 'window':\n",
    "                for l, s in v.items():\n",
    "                    trace_scores_avg[sect_k][f'{k}-{l}'] += s\n",
    "            else:\n",
    "                s = v\n",
    "                trace_scores_avg[sect_k][k] += s\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t->s': defaultdict(int,\n",
       "             {'window-0': 0.9584533123239394,\n",
       "              'window-1': 0.9585625982813297,\n",
       "              'window-2': 0.9572239906797486,\n",
       "              'window-3': 0.9565488078361076,\n",
       "              'window-4': 0.9544481780590309,\n",
       "              'window-5': 0.9523413726964199,\n",
       "              'window-6': 0.9546188644448956,\n",
       "              'window-7': 0.949646026376755,\n",
       "              'window-8': 0.9446990264038886,\n",
       "              'window-9': 0.9398153698342221,\n",
       "              'window-10': 0.9346097670683277,\n",
       "              'window-11': 0.9314791725843303,\n",
       "              'window-12': 0.928487829896321,\n",
       "              'window-13': 0.92574613804867,\n",
       "              'window-14': 0.9127256331126289,\n",
       "              'window-15': 0.9006218717564065,\n",
       "              'window-16': 0.8837372648945778,\n",
       "              'window-17': 0.8704569905175353,\n",
       "              'window-18': 0.867874284602416,\n",
       "              'window-19': 0.8673523274176784,\n",
       "              'window-20': 0.8748786774184267,\n",
       "              'window-21': 0.8828331615635756,\n",
       "              'window-22': 0.8966843144144018,\n",
       "              'window-23': 0.9013577918932066,\n",
       "              'first_layer': 0.9658372415650276,\n",
       "              'last_layer': 0.9643811215316096,\n",
       "              'all_layers': 0.8101757214465455}),\n",
       " 's->t': defaultdict(int,\n",
       "             {'window-0': 0.9648913190249474,\n",
       "              'window-1': 0.9616089231544925,\n",
       "              'window-2': 0.9592327519289909,\n",
       "              'window-3': 0.9595487597007906,\n",
       "              'window-4': 0.9570326710179928,\n",
       "              'window-5': 0.9476819619025675,\n",
       "              'window-6': 0.9486132403054545,\n",
       "              'window-7': 0.9419246086910847,\n",
       "              'window-8': 0.9260924654336826,\n",
       "              'window-9': 0.9009790493638291,\n",
       "              'window-10': 0.9021270947951023,\n",
       "              'window-11': 0.8830641807284344,\n",
       "              'window-12': 0.8340167299193161,\n",
       "              'window-13': 0.8392247378495312,\n",
       "              'window-14': 0.8288482483226022,\n",
       "              'window-15': 0.7862605988547717,\n",
       "              'window-16': 0.7674817289734184,\n",
       "              'window-17': 0.7792098808401654,\n",
       "              'window-18': 0.7859151408528947,\n",
       "              'window-19': 0.8019068051236476,\n",
       "              'window-20': 0.8016749608698671,\n",
       "              'window-21': 0.8165928385289284,\n",
       "              'window-22': 0.8722172643449759,\n",
       "              'window-23': 0.8678264075365698,\n",
       "              'first_layer': 0.9641844093799591,\n",
       "              'last_layer': 0.9607677277538085,\n",
       "              'all_layers': 0.7051745008948923}),\n",
       " 't<->s': defaultdict(int,\n",
       "             {'window-0': 0.9555607560661531,\n",
       "              'window-1': 0.9532665403860231,\n",
       "              'window-2': 0.9502317754476661,\n",
       "              'window-3': 0.9489624702161358,\n",
       "              'window-4': 0.9454720143966223,\n",
       "              'window-5': 0.9374408281305785,\n",
       "              'window-6': 0.9409685492605222,\n",
       "              'window-7': 0.9313783558911735,\n",
       "              'window-8': 0.9079270579027868,\n",
       "              'window-9': 0.8798939111931758,\n",
       "              'window-10': 0.8769783510654429,\n",
       "              'window-11': 0.8577903556296361,\n",
       "              'window-12': 0.7955655246097703,\n",
       "              'window-13': 0.798363147126023,\n",
       "              'window-14': 0.7761670979476318,\n",
       "              'window-15': 0.7043904766309804,\n",
       "              'window-16': 0.6828711005234231,\n",
       "              'window-17': 0.6957665906085937,\n",
       "              'window-18': 0.7246003023710115,\n",
       "              'window-19': 0.7344408740217311,\n",
       "              'window-20': 0.7384188179634457,\n",
       "              'window-21': 0.7516775293427224,\n",
       "              'window-22': 0.8009847803971221,\n",
       "              'window-23': 0.8035971604174266,\n",
       "              'first_layer': 0.9621726152396971,\n",
       "              'last_layer': 0.953214639281073,\n",
       "              'all_layers': 0.6026919394236252}),\n",
       " 't->p': defaultdict(int,\n",
       "             {'window-0': 0.9521402130684545,\n",
       "              'window-1': 0.944828805570761,\n",
       "              'window-2': 0.9361788957349716,\n",
       "              'window-3': 0.9233777301067793,\n",
       "              'window-4': 0.9147033481013475,\n",
       "              'window-5': 0.891427379084515,\n",
       "              'window-6': 0.8906718786855157,\n",
       "              'window-7': 0.895839275368261,\n",
       "              'window-8': 0.9059656470923895,\n",
       "              'window-9': 0.8831010588227606,\n",
       "              'window-10': 0.8658306236749511,\n",
       "              'window-11': 0.8258571721649285,\n",
       "              'window-12': 0.8083514545126593,\n",
       "              'window-13': 0.7834526095281574,\n",
       "              'window-14': 0.7336139586431374,\n",
       "              'window-15': 0.703574181481691,\n",
       "              'window-16': 0.7137584182738346,\n",
       "              'window-17': 0.6716832254791941,\n",
       "              'window-18': 0.6874306383466883,\n",
       "              'window-19': 0.6724190127260418,\n",
       "              'window-20': 0.6988314868672113,\n",
       "              'window-21': 0.7509898711972475,\n",
       "              'window-22': 0.7727805546157733,\n",
       "              'window-23': 0.7864214728838922,\n",
       "              'first_layer': 0.9644908489719514,\n",
       "              'last_layer': 0.9192956223362877,\n",
       "              'all_layers': 0.46179544038625703}),\n",
       " 's->p': defaultdict(int,\n",
       "             {'window-0': 0.9492758682778766,\n",
       "              'window-1': 0.9344604630098348,\n",
       "              'window-2': 0.9169232565999752,\n",
       "              'window-3': 0.9110336344028193,\n",
       "              'window-4': 0.9009684802036763,\n",
       "              'window-5': 0.8813363922537512,\n",
       "              'window-6': 0.9082525628688839,\n",
       "              'window-7': 0.8678077228981456,\n",
       "              'window-8': 0.8544057465551921,\n",
       "              'window-9': 0.8440379907950868,\n",
       "              'window-10': 0.8537983581100335,\n",
       "              'window-11': 0.8171106661767847,\n",
       "              'window-12': 0.779699763981138,\n",
       "              'window-13': 0.7393419911942671,\n",
       "              'window-14': 0.6544775469066819,\n",
       "              'window-15': 0.6580996689340297,\n",
       "              'window-16': 0.6343545527313116,\n",
       "              'window-17': 0.6101330665227551,\n",
       "              'window-18': 0.6407744963686626,\n",
       "              'window-19': 0.5555136995018054,\n",
       "              'window-20': 0.5690147695252519,\n",
       "              'window-21': 0.613727879975227,\n",
       "              'window-22': 0.6572342029995565,\n",
       "              'window-23': 0.6891952951996041,\n",
       "              'first_layer': 0.9655360242051463,\n",
       "              'last_layer': 0.8882393725040827,\n",
       "              'all_layers': 0.47487770625630144}),\n",
       " 'ts->p': defaultdict(int,\n",
       "             {'window-0': 0.942079095622044,\n",
       "              'window-1': 0.921520860017758,\n",
       "              'window-2': 0.9018808788248157,\n",
       "              'window-3': 0.8819945359356347,\n",
       "              'window-4': 0.8578115954707933,\n",
       "              'window-5': 0.8188423972804697,\n",
       "              'window-6': 0.8383435779682459,\n",
       "              'window-7': 0.819969868529137,\n",
       "              'window-8': 0.8141501933767044,\n",
       "              'window-9': 0.8086636057730228,\n",
       "              'window-10': 0.7923330115167004,\n",
       "              'window-11': 0.7167329719200095,\n",
       "              'window-12': 0.6579563857982024,\n",
       "              'window-13': 0.6243087193903972,\n",
       "              'window-14': 0.5235944140097871,\n",
       "              'window-15': 0.4935097907515707,\n",
       "              'window-16': 0.5286737216806258,\n",
       "              'window-17': 0.4647881504785483,\n",
       "              'window-18': 0.49461747767649067,\n",
       "              'window-19': 0.446433360539249,\n",
       "              'window-20': 0.4555429527314594,\n",
       "              'window-21': 0.49898580071236887,\n",
       "              'window-22': 0.5407411515388377,\n",
       "              'window-23': 0.5628102659435731,\n",
       "              'first_layer': 0.9652568636402007,\n",
       "              'last_layer': 0.8436051612681401,\n",
       "              'all_layers': 0.20252856080077436}),\n",
       " 'all': defaultdict(int,\n",
       "             {'window-0': 0.9300593031519618,\n",
       "              'window-1': 0.9166604958251193,\n",
       "              'window-2': 0.9035464737489218,\n",
       "              'window-3': 0.8786637139979333,\n",
       "              'window-4': 0.8518693547972637,\n",
       "              'window-5': 0.8031324495711379,\n",
       "              'window-6': 0.8196334323006307,\n",
       "              'window-7': 0.7904137435564771,\n",
       "              'window-8': 0.7765864976950965,\n",
       "              'window-9': 0.7331705970303458,\n",
       "              'window-10': 0.7151323473615561,\n",
       "              'window-11': 0.6412972728617434,\n",
       "              'window-12': 0.5590988061589557,\n",
       "              'window-13': 0.5587055851452499,\n",
       "              'window-14': 0.5194102008299096,\n",
       "              'window-15': 0.44744474050189814,\n",
       "              'window-16': 0.4562500296954826,\n",
       "              'window-17': 0.39759619343472846,\n",
       "              'window-18': 0.3872107883607331,\n",
       "              'window-19': 0.35950367969493113,\n",
       "              'window-20': 0.3770566153205677,\n",
       "              'window-21': 0.4163786878116149,\n",
       "              'window-22': 0.46705260091057726,\n",
       "              'window-23': 0.495855626518398,\n",
       "              'first_layer': 0.9602481694471452,\n",
       "              'last_layer': 0.840372418321978,\n",
       "              'all_layers': 0.08561547638135165})}"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': 'medium', 'node_role': 'group by', 'text_match': 'exact'}"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (sect_k, aspect, asp_val, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no sect key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            for k, v in sect_d.items():\n",
    "                if k == 'window':\n",
    "                    for l, s in v.items():\n",
    "                        if not (int(l) % 4 == 3): continue\n",
    "                        layer_k = f'{k}-{l}'\n",
    "                        trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                else:\n",
    "                    layer_k = k\n",
    "                    s = v\n",
    "                    trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                    \n",
    "for sect_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for asp_v, d3 in d2.items():\n",
    "            for layer_k, s in d3.items():\n",
    "                trace_scores_avg_by_aspect[sect_k][asp_k][asp_v][layer_k] = np.mean(s)\n",
    "                trace_scores_cnt_by_aspect[asp_k][asp_v] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sect_k, sect_d in trace_scores_avg_by_aspect.items():\n",
    "    sect_d['overall'] = dict()\n",
    "    for layer_k, s in trace_scores_avg[sect_k].items():\n",
    "        if layer_k.startswith('window'):\n",
    "            # only keep a subset of layers \n",
    "            _, l = layer_k.split('-')\n",
    "            if not (int(l) % 4 == 3): continue\n",
    "        sect_d['overall'][layer_k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(int,\n",
       "                         {'medium': 104, 'extra': 146, 'hard': 58, 'easy': 2}),\n",
       "             'node_role': defaultdict(int,\n",
       "                         {'select': 177,\n",
       "                          'join': 18,\n",
       "                          'where': 77,\n",
       "                          'group by': 28,\n",
       "                          'order by': 10}),\n",
       "             'text_match': defaultdict(int,\n",
       "                         {'exact': 194, 'partial': 25, 'no-match': 91})})"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'medium': defaultdict(float,\n",
       "                                      {'window-3': 0.9646410473550742,\n",
       "                                       'window-7': 0.9592273762234702,\n",
       "                                       'window-11': 0.8648564622632805,\n",
       "                                       'window-15': 0.7494707158662707,\n",
       "                                       'window-19': 0.7635265177381186,\n",
       "                                       'window-23': 0.8410116810835431,\n",
       "                                       'first_layer': 0.9712855274287554,\n",
       "                                       'last_layer': 0.9625990663010341,\n",
       "                                       'all_layers': 0.6317217321109161}),\n",
       "                          'extra': defaultdict(float,\n",
       "                                      {'window-3': 0.9403904235526307,\n",
       "                                       'window-7': 0.910032949611315,\n",
       "                                       'window-11': 0.8466027683413521,\n",
       "                                       'window-15': 0.656961752460007,\n",
       "                                       'window-19': 0.6885160329948347,\n",
       "                                       'window-23': 0.7530157129830385,\n",
       "                                       'first_layer': 0.9597103120121238,\n",
       "                                       'last_layer': 0.9433861998458432,\n",
       "                                       'all_layers': 0.5342269941837767}),\n",
       "                          'hard': defaultdict(float,\n",
       "                                      {'window-3': 0.9406674676414194,\n",
       "                                       'window-7': 0.9328076860000347,\n",
       "                                       'window-11': 0.8683784189152306,\n",
       "                                       'window-15': 0.73275340266038,\n",
       "                                       'window-19': 0.788734572180868,\n",
       "                                       'window-23': 0.8570629745593359,\n",
       "                                       'first_layer': 0.9507263996477785,\n",
       "                                       'last_layer': 0.9595152283536976,\n",
       "                                       'all_layers': 0.7092815142401879}),\n",
       "                          'easy': defaultdict(float,\n",
       "                                      {'window-3': 0.9999909400939941,\n",
       "                                       'window-7': 0.9999933838844299,\n",
       "                                       'window-11': 0.999992847442627,\n",
       "                                       'window-15': 0.9999900460243225,\n",
       "                                       'window-19': 0.999983549118042,\n",
       "                                       'window-23': 0.9999791383743286,\n",
       "                                       'first_layer': 0.9999895691871643,\n",
       "                                       'last_layer': 0.9999834299087524,\n",
       "                                       'all_layers': 0.9999860525131226})}),\n",
       "             'node_role': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'select': defaultdict(float,\n",
       "                                      {'window-3': 0.9320269626917812,\n",
       "                                       'window-7': 0.9031567521482748,\n",
       "                                       'window-11': 0.7940619898784174,\n",
       "                                       'window-15': 0.5808703182161168,\n",
       "                                       'window-19': 0.665805926642754,\n",
       "                                       'window-23': 0.740639602911331,\n",
       "                                       'first_layer': 0.952452946012303,\n",
       "                                       'last_layer': 0.9341854659345864,\n",
       "                                       'all_layers': 0.4817295308745887}),\n",
       "                          'join': defaultdict(float,\n",
       "                                      {'window-3': 0.9051849328809314,\n",
       "                                       'window-7': 0.8957437665926086,\n",
       "                                       'window-11': 0.8539851121604443,\n",
       "                                       'window-15': 0.7847143524171164,\n",
       "                                       'window-19': 0.8193542369020482,\n",
       "                                       'window-23': 0.8604357252932258,\n",
       "                                       'first_layer': 0.9166829867495431,\n",
       "                                       'last_layer': 0.927678085035748,\n",
       "                                       'all_layers': 0.7088218938442878}),\n",
       "                          'where': defaultdict(float,\n",
       "                                      {'window-3': 0.9839571855671994,\n",
       "                                       'window-7': 0.9765433093242637,\n",
       "                                       'window-11': 0.9499132105522765,\n",
       "                                       'window-15': 0.892976931823994,\n",
       "                                       'window-19': 0.8567667324728824,\n",
       "                                       'window-23': 0.9243421771793396,\n",
       "                                       'first_layer': 0.9892158105775908,\n",
       "                                       'last_layer': 0.9958817695642447,\n",
       "                                       'all_layers': 0.8118785694469023}),\n",
       "                          'group by': defaultdict(float,\n",
       "                                      {'window-3': 0.9706567174621991,\n",
       "                                       'window-7': 0.9845245821135384,\n",
       "                                       'window-11': 0.9626450857945851,\n",
       "                                       'window-15': 0.813363004825078,\n",
       "                                       'window-19': 0.7020573334656157,\n",
       "                                       'window-23': 0.770394250035419,\n",
       "                                       'first_layer': 0.9655950825129237,\n",
       "                                       'last_layer': 0.9562071114778519,\n",
       "                                       'all_layers': 0.5911381919088724}),\n",
       "                          'order by': defaultdict(float,\n",
       "                                      {'window-3': 0.9973173201084137,\n",
       "                                       'window-7': 0.9984634280204773,\n",
       "                                       'window-11': 0.9896926403045654,\n",
       "                                       'window-15': 0.9888755202293396,\n",
       "                                       'window-19': 0.9452001929283143,\n",
       "                                       'window-23': 0.97886803150177,\n",
       "                                       'first_layer': 0.9982765793800354,\n",
       "                                       'last_layer': 0.9990809798240662,\n",
       "                                       'all_layers': 0.9743060946464539})}),\n",
       "             'text_match': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'exact': defaultdict(float,\n",
       "                                      {'window-3': 0.9378272546935327,\n",
       "                                       'window-7': 0.9203111943044728,\n",
       "                                       'window-11': 0.8375433864783767,\n",
       "                                       'window-15': 0.6653050039826345,\n",
       "                                       'window-19': 0.6972370064743746,\n",
       "                                       'window-23': 0.768397239837158,\n",
       "                                       'first_layer': 0.9552106580783412,\n",
       "                                       'last_layer': 0.9457904798621984,\n",
       "                                       'all_layers': 0.550703376677269}),\n",
       "                          'partial': defaultdict(float,\n",
       "                                      {'window-3': 0.9169812083244324,\n",
       "                                       'window-7': 0.9102592086791992,\n",
       "                                       'window-11': 0.8215095499914605,\n",
       "                                       'window-15': 0.6897745274563931,\n",
       "                                       'window-19': 0.7503956253338402,\n",
       "                                       'window-23': 0.774462761519244,\n",
       "                                       'first_layer': 0.9153925859928131,\n",
       "                                       'last_layer': 0.8903508186340332,\n",
       "                                       'all_layers': 0.6217923019298541}),\n",
       "                          'no-match': defaultdict(float,\n",
       "                                      {'window-3': 0.981487342289516,\n",
       "                                       'window-7': 0.9607740485078686,\n",
       "                                       'window-11': 0.9109214782263254,\n",
       "                                       'window-15': 0.7917309208413513,\n",
       "                                       'window-19': 0.8093714401907908,\n",
       "                                       'window-23': 0.8866427050880492,\n",
       "                                       'first_layer': 0.9898662462339296,\n",
       "                                       'last_layer': 0.9863122485496185,\n",
       "                                       'all_layers': 0.7082773472273328})}),\n",
       "             'overall': {'window-3': 0.9489624702161358,\n",
       "              'window-7': 0.9313783558911735,\n",
       "              'window-11': 0.8577903556296361,\n",
       "              'window-15': 0.7043904766309804,\n",
       "              'window-19': 0.7344408740217311,\n",
       "              'window-23': 0.8035971604174266,\n",
       "              'first_layer': 0.9621726152396971,\n",
       "              'last_layer': 0.953214639281073,\n",
       "              'all_layers': 0.6026919394236252}})"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg_by_aspect['t<->s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_d = ctu.nested_json_processing(trace_scores_avg_by_aspect, func=lambda x: np.format_float_positional(x, precision=4, min_digits=4))\n",
    "dump_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/summ-exp=5.3_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(dump_path, 'w') as f:\n",
    "    json.dump(dump_d, f, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USKG error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from play_pred()\n",
    "\n",
    "def pred_sql(mt, ex):\n",
    "    text_in = ex['text_in']\n",
    "    struct_in = ex['struct_in']\n",
    "\n",
    "    txt = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "    \n",
    "    tokenized_txt = mt.tokenizer_uskg([txt], max_length=1024, padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    device = mt.model.device\n",
    "    pred = mt.tokenizer_uskg.batch_decode(\n",
    "      mt.model.generate(\n",
    "        torch.tensor(tokenized_txt.data['input_ids'], dtype=int, device=device),\n",
    "        torch.tensor(tokenized_txt.data['attention_mask'], dtype=int, device=device),\n",
    "        num_beams=1, \n",
    "        max_length=256\n",
    "        ), \n",
    "      skip_special_tokens=True \n",
    "    )\n",
    "    return pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from evaluator.evaluate_one()\n",
    "\n",
    "def evaluate_sql(evaluator, db_name, gold, predicted):\n",
    "    schema = evaluator.schemas[db_name]\n",
    "    g_sql = sp_eval.get_sql(schema, gold)\n",
    "    hardness = evaluator.eval_hardness(g_sql)\n",
    "    # self.scores[hardness][\"count\"] += 1\n",
    "    # self.scores[\"all\"][\"count\"] += 1\n",
    "\n",
    "    parse_error = False\n",
    "    try:\n",
    "        p_sql = sp_eval.get_sql(schema, predicted)\n",
    "    except:\n",
    "        # If p_sql is not valid, then we will use an empty sql to evaluate with the correct sql\n",
    "        p_sql = {\n",
    "            \"except\": None,\n",
    "            \"from\": {\"conds\": [], \"table_units\": []},\n",
    "            \"groupBy\": [],\n",
    "            \"having\": [],\n",
    "            \"intersect\": None,\n",
    "            \"limit\": None,\n",
    "            \"orderBy\": [],\n",
    "            \"select\": [False, []],\n",
    "            \"union\": None,\n",
    "            \"where\": [],\n",
    "        }\n",
    "\n",
    "        # TODO fix\n",
    "        parse_error = True\n",
    "\n",
    "    # rebuild sql for value evaluation\n",
    "    kmap = evaluator.kmaps[db_name]\n",
    "    g_valid_col_units = sp_eval.build_valid_col_units(g_sql[\"from\"][\"table_units\"], schema)\n",
    "    g_sql = sp_eval.rebuild_sql_val(g_sql)\n",
    "    g_sql = sp_eval.rebuild_sql_col(g_valid_col_units, g_sql, kmap)\n",
    "    p_valid_col_units = sp_eval.build_valid_col_units(p_sql[\"from\"][\"table_units\"], schema)\n",
    "    p_sql = sp_eval.rebuild_sql_val(p_sql)\n",
    "    p_sql = sp_eval.rebuild_sql_col(p_valid_col_units, p_sql, kmap)\n",
    "    \n",
    "    exec_score = None\n",
    "    partial_scores = None\n",
    "    exact_score = None\n",
    "    if evaluator.etype in [\"all\", \"exec\"]:\n",
    "        exec_score = sp_eval.eval_exec_match(\n",
    "            evaluator.db_paths[db_name], predicted, gold, p_sql, g_sql\n",
    "        )\n",
    "        exec_score = int(exec_score)\n",
    "    if evaluator.etype in [\"all\", \"match\"]:\n",
    "        partial_scores = evaluator.eval_partial_match(p_sql, g_sql)\n",
    "        exact_score = evaluator.eval_exact_match(p_sql, g_sql, partial_scores)\n",
    "        # update_scores_match(self.scores, exact_score, hardness, partial_scores, PARTIAL_TYPES)\n",
    "\n",
    "    return {\n",
    "        \"predicted\": predicted,\n",
    "        \"gold\": gold,\n",
    "        \"predicted_parse_error\": parse_error,\n",
    "        \"hardness\": hardness,\n",
    "        \"exact\": exact_score,\n",
    "        \"partial\": partial_scores,\n",
    "        \"exec\": exec_score,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'\n",
    "\n",
    "def execute_sql(db, sql_str):\n",
    "    db_path = os.path.join(db_dir, db, f'{db}.sqlite')\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(sql_str)\n",
    "        res = cursor.fetchall()\n",
    "    except:\n",
    "        res = 'ERROR'\n",
    "    conn.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out'])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = processed_spider_dev[503]\n",
    "ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('battle_death',\n",
       " \"How many battles did not lose any ship with tonnage '225'?\",\n",
       " \"select count(*) from battle where id not in ( select lost_in_battle from ship where tonnage = '225' );\",\n",
       " 'select count(*) from battle where id not in ( select lost_in_battle from ship where tonnage > 225 )')"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pred_sql(mt_uskg, ex)\n",
    "ex['db_id'], ex['text_in'], ex['seq_out'], pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "txt = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "txt_toks = mt_uskg.tokenizer_uskg.tokenize(txt)\n",
    "len(txt_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"select count(*) from battle where id not in ( select lost_in_battle from ship where tonnage = '225' );\",\n",
       " [(7,)])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_res = execute_sql(ex['db_id'], ex['seq_out'])\n",
    "ex['seq_out'], exec_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('select count(*) from battle where id not in ( select lost_in_battle from ship where tonnage > 225 )',\n",
       " [(3,)])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_res = execute_sql(ex['db_id'], pred)\n",
    "pred, exec_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8,)]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_pred = \"\"\"\n",
    "SELECT COUNT(DISTINCT battle.id) AS num_battles\n",
    "FROM battle\n",
    "LEFT JOIN ship ON battle.id = ship.lost_in_battle\n",
    "WHERE (ship.tonnage != '225' OR ship.tonnage IS NULL)\n",
    "\"\"\"\n",
    "\n",
    "execute_sql(ex['db_id'], chatgpt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res = evaluate_sql(evaluator, db_name=spider_ex['db_id'], gold=spider_ex['seq_out'], predicted=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted': 'select avg(num_of_staff) from museum where open_year  < 2009',\n",
       " 'gold': 'select avg(num_of_staff) from museum where open_year < 2009',\n",
       " 'predicted_parse_error': False,\n",
       " 'hardness': 'easy',\n",
       " 'exact': True,\n",
       " 'partial': {'select': {'acc': 1,\n",
       "   'rec': 1,\n",
       "   'f1': 1,\n",
       "   'label_total': 1,\n",
       "   'pred_total': 1},\n",
       "  'select(no AGG)': {'acc': 1,\n",
       "   'rec': 1,\n",
       "   'f1': 1,\n",
       "   'label_total': 1,\n",
       "   'pred_total': 1},\n",
       "  'where': {'acc': 1, 'rec': 1, 'f1': 1, 'label_total': 1, 'pred_total': 1},\n",
       "  'where(no OP)': {'acc': 1,\n",
       "   'rec': 1,\n",
       "   'f1': 1,\n",
       "   'label_total': 1,\n",
       "   'pred_total': 1},\n",
       "  'group(no Having)': {'acc': 1,\n",
       "   'rec': 1,\n",
       "   'f1': 1,\n",
       "   'label_total': 0,\n",
       "   'pred_total': 0},\n",
       "  'group': {'acc': 1, 'rec': 1, 'f1': 1, 'label_total': 0, 'pred_total': 0},\n",
       "  'order': {'acc': 1, 'rec': 1, 'f1': 1, 'label_total': 0, 'pred_total': 0},\n",
       "  'and/or': {'acc': 1, 'rec': 1, 'f1': 1, 'label_total': 1, 'pred_total': 1},\n",
       "  'IUEN': {'acc': 1, 'rec': 1, 'f1': 1, 'label_total': 0, 'pred_total': 0},\n",
       "  'keywords': {'acc': 1,\n",
       "   'rec': 1,\n",
       "   'f1': 1,\n",
       "   'label_total': 1,\n",
       "   'pred_total': 1}},\n",
       " 'exec': 1}"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab76cae127742adbc790384e85093b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Eval all \n",
    "# TODO: rerun with tokenizer_uskg decoding \n",
    "\n",
    "eval_sql_results = []\n",
    "\n",
    "for ex_id, ex in enumerate(tqdm(processed_spider_dev)):\n",
    "    pred = pred_sql(mt_uskg, ex)\n",
    "    eval_res = evaluate_sql(evaluator, db_name=ex['db_id'], gold=ex['seq_out'], predicted=pred)\n",
    "    eval_sql_results.append(eval_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6692456479690522, 0.6808510638297872)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "avg_exact, avg_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(eval_sql_results):\n",
    "    if d['exact'] and d['exec']:\n",
    "        continue\n",
    "    err_msg = ('A' if not d['exact'] else '') + ('X' if not d['exec'] else '')\n",
    "    ex = processed_spider_dev[i]\n",
    "    print(f'ID = {i}: {err_msg}  ({ex[\"db_id\"]}) {ex[\"text_in\"]}')\n",
    "    print(f'Pred: {d[\"predicted\"]}')\n",
    "    print(f'Gold: {d[\"gold\"]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator.schemas['dog_kennels'].schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc by db_id \n",
    "eval_sql_results_by_db_id = defaultdict(list)\n",
    "\n",
    "for i, d in enumerate(eval_sql_results):\n",
    "    d['ex_id'] = i\n",
    "    ex = processed_spider_dev[i]\n",
    "    db_id = ex['db_id']\n",
    "    eval_sql_results_by_db_id[db_id].append(d)\n",
    "\n",
    "len(eval_sql_results_by_db_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concert_singer\t0.8889\t0.8889\n",
      "pets_1\t0.5714\t0.7381\n",
      "car_1\t0.3478\t0.3913\n",
      "flight_2\t0.7000\t0.7500\n",
      "employee_hire_evaluation\t0.9474\t0.9737\n",
      "cre_Doc_Template_Mgt\t0.8333\t0.9048\n",
      "course_teach\t0.8667\t0.9333\n",
      "museum_visit\t0.7222\t0.8333\n",
      "wta_1\t0.6774\t0.6129\n",
      "battle_death\t0.5000\t0.5000\n",
      "student_transcripts_tracking\t0.6667\t0.6795\n",
      "tvshow\t0.7258\t0.6613\n",
      "poker_player\t0.8750\t0.8750\n",
      "voter_1\t0.6000\t0.6667\n",
      "world_1\t0.5083\t0.4833\n",
      "orchestra\t0.8000\t0.8750\n",
      "network_1\t0.6250\t0.4643\n",
      "dog_kennels\t0.5854\t0.5976\n",
      "singer\t0.8667\t0.8667\n",
      "real_estate_properties\t0.5000\t0.5000\n"
     ]
    }
   ],
   "source": [
    "for db_id, results in eval_sql_results_by_db_id.items():\n",
    "    _avg_exact = np.mean([d['exact'] for d in results])\n",
    "    _avg_exec = np.mean([d['exec'] for d in results])\n",
    "    print(f'{db_id}\\t{_avg_exact:.4f}\\t{_avg_exec:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model intermediate inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k, v in mt_uskg.model.named_parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.t5.configuration_t5.T5Config"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_t5_config = mt_uskg.model.config\n",
    "type(_t5_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-large\",\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"d_ff\": 4096,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 24,\n",
       "  \"num_heads\": 16,\n",
       "  \"num_layers\": 24,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.9.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32102\n",
       "}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_t5_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Attention(\n",
       "  (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "  (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "  (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "  (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_module = uskg.models.prompt.modeling_t5.T5Attention(_t5_config)\n",
    "sa_module.eval()\n",
    "sa_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('q',\n",
       "               Linear(in_features=1024, out_features=1024, bias=False)),\n",
       "              ('k', Linear(in_features=1024, out_features=1024, bias=False)),\n",
       "              ('v', Linear(in_features=1024, out_features=1024, bias=False)),\n",
       "              ('o', Linear(in_features=1024, out_features=1024, bias=False))]),\n",
       " 'is_decoder': False,\n",
       " 'has_relative_attention_bias': False,\n",
       " 'relative_attention_num_buckets': 32,\n",
       " 'd_model': 1024,\n",
       " 'key_value_proj_dim': 64,\n",
       " 'n_heads': 16,\n",
       " 'dropout': 0.1,\n",
       " 'inner_dim': 1024,\n",
       " 'pruned_heads': set(),\n",
       " 'gradient_checkpointing': False}"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_module.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 3\n",
    "seq_len = 10\n",
    "dim = 1024\n",
    "fake_sa_input = torch.zeros(bsz, seq_len, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attn_output, present_key_value_state, position_bias, attn_weights = sa_module(fake_sa_input, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 1024])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_key_value_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16, 10, 10])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 10, 10])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_bias.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_analysis_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_id = 111\n",
    "a_ex_id = 0\n",
    "\n",
    "ex = processed_spider_dev[ex_id]\n",
    "ex['text_in'], \\\n",
    "ex['struct_in'], \\\n",
    "ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp test\n",
    "# ex['seq_out'] = 'select year from cars_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu.create_analysis_sample_dicts(\n",
    "                mt_uskg, ex,\n",
    "                subject_type='column',\n",
    "                remove_struct_duplicate_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'enc_sentence', 'enc_tokenized', 'text_range', 'struct_range', 'struct_node_ranges_dict', 'dec_prompt', 'expect', 'expect_type', 'remove_struct_duplicate_nodes', 'parsed_struct_in', 'col2table', 'token_ranges_dict', 'node_name_ranges', 'expect_input_ranges', 'alias2table', 'self_ranges', 'context_ranges', 'category'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[a_ex_id].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 'cars_data', 't2': 'car_names'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[a_ex_id]['alias2table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.',\n",
       "  'make',\n",
       "  defaultdict(list,\n",
       "              {'contid': [(37, 40)],\n",
       "               'continent': [(42, 43), (56, 57)],\n",
       "               'countryid': [(47, 50)],\n",
       "               'countryname': [(52, 54)],\n",
       "               'id': [(63, 66), (151, 154)],\n",
       "               'maker': [(68, 74), (92, 93)],\n",
       "               'fullname': [(76, 78)],\n",
       "               'country': [(80, 81)],\n",
       "               'modelid': [(87, 90)],\n",
       "               'model': [(95, 101), (113, 119)],\n",
       "               'makeid': [(108, 111)],\n",
       "               'make': [(121, 145)],\n",
       "               'mpg': [(156, 159)],\n",
       "               'cylinders': [(161, 164)],\n",
       "               'edispl': [(166, 170)],\n",
       "               'horsepower': [(172, 173)],\n",
       "               'weight': [(175, 176)],\n",
       "               'accelerate': [(178, 179)],\n",
       "               'year': [(181, 182)]}),\n",
       "  [(121, 145)],\n",
       "  '------',\n",
       "  [(119, 146)],\n",
       "  [(28, 119), (146, 182)],\n",
       "  {'sql_hardness': 'medium', 'node_role': 'where', 'text_match': 'exact'},\n",
       "  '------------'),\n",
       " ('select t1.',\n",
       "  'accelerate',\n",
       "  defaultdict(list,\n",
       "              {'contid': [(37, 40)],\n",
       "               'continent': [(42, 43), (56, 57)],\n",
       "               'countryid': [(47, 50)],\n",
       "               'countryname': [(52, 54)],\n",
       "               'id': [(63, 66), (151, 154)],\n",
       "               'maker': [(68, 74), (92, 93)],\n",
       "               'fullname': [(76, 78)],\n",
       "               'country': [(80, 81)],\n",
       "               'modelid': [(87, 90)],\n",
       "               'model': [(95, 101), (113, 119)],\n",
       "               'makeid': [(108, 111)],\n",
       "               'make': [(121, 145)],\n",
       "               'mpg': [(156, 159)],\n",
       "               'cylinders': [(161, 164)],\n",
       "               'edispl': [(166, 170)],\n",
       "               'horsepower': [(172, 173)],\n",
       "               'weight': [(175, 176)],\n",
       "               'accelerate': [(178, 179)],\n",
       "               'year': [(181, 182)]}),\n",
       "  [(178, 179)],\n",
       "  '------',\n",
       "  [(176, 181)],\n",
       "  [(28, 176), (181, 182)],\n",
       "  {'sql_hardness': 'medium', 'node_role': 'select', 'text_match': 'exact'},\n",
       "  '------------'),\n",
       " ('select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.',\n",
       "  'makeid',\n",
       "  defaultdict(list,\n",
       "              {'contid': [(37, 40)],\n",
       "               'continent': [(42, 43), (56, 57)],\n",
       "               'countryid': [(47, 50)],\n",
       "               'countryname': [(52, 54)],\n",
       "               'id': [(63, 66), (151, 154)],\n",
       "               'maker': [(68, 74), (92, 93)],\n",
       "               'fullname': [(76, 78)],\n",
       "               'country': [(80, 81)],\n",
       "               'modelid': [(87, 90)],\n",
       "               'model': [(95, 101), (113, 119)],\n",
       "               'makeid': [(108, 111)],\n",
       "               'make': [(121, 145)],\n",
       "               'mpg': [(156, 159)],\n",
       "               'cylinders': [(161, 164)],\n",
       "               'edispl': [(166, 170)],\n",
       "               'horsepower': [(172, 173)],\n",
       "               'weight': [(175, 176)],\n",
       "               'accelerate': [(178, 179)],\n",
       "               'year': [(181, 182)]}),\n",
       "  [(108, 111)],\n",
       "  '------',\n",
       "  [(106, 113)],\n",
       "  [(28, 106), (113, 182)],\n",
       "  {'sql_hardness': 'medium', 'node_role': 'join', 'text_match': 'no-match'},\n",
       "  '------------')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(d['dec_prompt'], d['expect'], d['node_name_ranges'], d['expect_input_ranges'], '------',\\\n",
    "  d['self_ranges'], d['context_ranges'],\\\n",
    "  d['category'], '------' * 2) for d in a_ex_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(a_ex_list[a_ex_id])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ctu.add_clean_prediction(mt_uskg, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parse_sql_alias2table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 'table_name', 't2': 'other_table', 't3': 'ttt'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sql = 'SELECT t2.aaa , t3.ccc FROM table_name as t1 JOIN other_table as t2 on table_name.a_a = other_table.b_a JOIN ttt as t3 on other_table.asth = ttt.asth'\n",
    "ctu.parse_sql_alias2table(_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### context_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the name of the different car makers who produced a car in 1970?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'select year from cars_data',\n",
       " 'year')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex = dict(a_ex_list[0])\n",
    "a_ex['text_in'], a_ex['struct_in'], a_ex['seq_out'], a_ex['expect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['alias2table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "# For full context tokens, use [0, L] and [R, -1]\n",
    "# L: node left max end index ; R: node right min start index\n",
    "\n",
    "token_ranges_dict = a_ex['token_ranges_dict']\n",
    "_all_node_range_lists = list(token_ranges_dict['col_name_ranges'].values()) + list(token_ranges_dict['table_name_ranges'].values()) + list(token_ranges_dict['db_id_ranges'].values())\n",
    "_all_node_ranges = [rg\n",
    "                    for rg_list in _all_node_range_lists\n",
    "                    for rg in rg_list]\n",
    "_all_left_endpoint = [s for s, e in _all_node_ranges] + [struct_range[1]]\n",
    "_all_right_endpoint = [e for s, e in _all_node_ranges] + [struct_range[0]]\n",
    "# TODO: pull this part out to the shared function (e.g. create_analysis_sample_dicts)\n",
    "# TODO: test for columns on ends\n",
    "\n",
    "expect_input_ranges = a_ex['expect_input_ranges']    # list of ranges of node-of-interest (code allows dup)\n",
    "# tok_indices = [i for s, e in expect_input_ranges for i in range(s, e)]\n",
    "# expect_input_indices = [i for s, e in expect_input_ranges for i in range(s, e)]\n",
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "# node = a_ex['expect']\n",
    "\n",
    "context_range_endpoints = [struct_range[0]]\n",
    "self_range_endpoints = []       # This is different from `expect_input_ranges`: this includes boundary toks\n",
    "for tok_s, tok_e in expect_input_ranges:\n",
    "    _l = max([e for e in _all_right_endpoint if e <= tok_s])\n",
    "    _r = min([s for s in _all_left_endpoint if s >= tok_e])\n",
    "    context_range_endpoints.extend([_l, _r])\n",
    "    self_range_endpoints.extend([_l, _r])\n",
    "context_range_endpoints.append(struct_range[1])\n",
    "\n",
    "self_ranges = [(self_range_endpoints[i], self_range_endpoints[i+1])\n",
    "                for i in range(0, len(self_range_endpoints), 2)]\n",
    "self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "\n",
    "context_ranges = [(context_range_endpoints[i], context_range_endpoints[i+1])\n",
    "                    for i in range(0, len(context_range_endpoints), 2)]\n",
    "context_ranges = [(s, e) for s, e in context_ranges if e > s]\n",
    "context_tok_indices = corrupt_tok_indices = [i for s, e in context_ranges for i in range(s, e)]\n",
    "\n",
    "text_tok_indices = list(range(*text_range))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(137, 140)], [(24, 137)])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_ranges, context_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_tok_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", year\n"
     ]
    }
   ],
   "source": [
    "for s, e in self_ranges:\n",
    "    _piece = tokenizer.decode(a_ex['enc_tokenized']['input_ids'][s : e])\n",
    "    print(_piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| car_1 | continents : contid, continent | countries : countryid, countryname, continent | car_makers : id, maker, fullname, country | model_list : modelid, maker, model | car_names : makeid, model, make | cars_data : id, mpg, cylinders, edispl, horsepower, weight, accelerate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s, e in context_ranges:\n",
    "    _piece = tokenizer.decode(a_ex['enc_tokenized']['input_ids'][s : e])\n",
    "    print(_piece)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_uskg_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = dict(a_ex_list[a_ex_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the name of the different car makers who produced a car in 1970?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'select distinct t1.maker from car_makers as t1 join model_list as t2 on t1.id = t2.maker join car_names as t3 on t2.model = t3.model join cars_data as t4 on t3.',\n",
       " 'makeid')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_sentence, dec_prompt, expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 11,\n",
    "    [dec_prompt] * 11,\n",
    "    answer=expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = ctu.run_model_forward_uskg(mt_uskg.model, **inp, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, torch.Size([11, 16, 141, 151]))"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers, (bsz, n_heads, seq_len, seq_len + prev_len)\n",
    "len(_out.encoder_attentions), _out.encoder_attentions[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, torch.Size([11, 16, 2, 151]))"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers, (bsz, n_heads, prompt_len, seq_len + prev_len)\n",
    "len(_out.cross_attentions), _out.cross_attentions[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, torch.Size([11, 16, 2, 12]))"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers, (bsz, n_heads, prompt_len, prompt_len + prev_len)\n",
    "len(_out.decoder_attentions), _out.decoder_attentions[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'decoder_attention_mask'])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = dict(a_ex_list[a_ex_id])\n",
    "a_ex = ctu.add_clean_prediction(mt_uskg, a_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'Which city has the most frequent destination airport?; structed knowledge: | flight_2 | airlines : uid , airline , abbreviation , country | airports : city , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport',\n",
       " 'seq_out': 'select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.city order by count(*) desc limit 1',\n",
       " 'dec_prompt': 'select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.',\n",
       " 'expect': 'city',\n",
       " 'expect_type': 'column',\n",
       " 'db_id': 'flight_2',\n",
       " 'expect_input_ranges': [(45, 46)],\n",
       " 'expect_table': 'airports',\n",
       " 'answer': 'city',\n",
       " 'base_score': 0.9983423948287964,\n",
       " 'answers_t': [6726],\n",
       " 'correct_prediction': True,\n",
       " 'category': {'sql_hardness': 'extra',\n",
       "  'node_role': 'group by',\n",
       "  'text_match': 'exact'}}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ctu.make_basic_result_dict(a_ex)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']\n",
    "answer = result['answer']\n",
    "answers_t = result['answers_t']\n",
    "\n",
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 11,\n",
    "    [dec_prompt] * 11,\n",
    "    answer=expect)\n",
    "\n",
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "self_ranges = a_ex['self_ranges']\n",
    "context_ranges = a_ex['context_ranges']\n",
    "\n",
    "self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "context_tok_indices = corrupt_tok_indices = [i for s, e in context_ranges for i in range(s, e)]\n",
    "text_tok_indices = list(range(*text_range))\n",
    "struct_tok_indices = list(range(*struct_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6726], 'city', 0.8450507521629333)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_t, answer, _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8450507521629333"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_to_corrupt = [(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                for tnum in text_tok_indices]\n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=states_to_corrupt,\n",
    "#     tokens_to_mix=corrupt_tok_indices,\n",
    "#     tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9952, device='cuda:0')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pair of identical input to test correctness \n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_patch_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 12))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 23))\n",
    "                    for tnum in struct_tok_indices],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    tokens_to_mix_1st_pass=context_tok_indices,\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9952, device='cuda:0')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_patch_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 12))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 23))\n",
    "                    for tnum in struct_tok_indices],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_corrupt_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                    for tnum in context_tok_indices],\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253002524375916"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test corrupting attention \n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", l, \"self_attn\"))\n",
    "                    for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers)],\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n for n, w in mt_uskg.model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_probs = ctu.run_repatch_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "                    for tnum in self_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "                    for tnum in self_tok_indices],\n",
    "    answer_len=len(answers_t),\n",
    "    tokens_to_mix=corrupt_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32102])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.], device='cuda:0'),\n",
       "indices=tensor([7634], device='cuda:0'))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(vocab_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs[0, 7634]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2642e-25, 1.2223e-15, 7.3942e-18,  ..., 9.1578e-20, 2.6884e-39,\n",
       "         2.8131e-39]], device='cuda:0')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trace - partial edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uskg.models.prompt.modeling_t5 import T5Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-large\",\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"d_ff\": 4096,\n",
       "  \"d_kv\": 4,\n",
       "  \"d_model\": 10,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 24,\n",
       "  \"num_heads\": 3,\n",
       "  \"num_layers\": 24,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.9.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32102\n",
       "}"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_t5_config = copy.deepcopy(mt_uskg.model.config)\n",
    "_t5_config.d_model = 10\n",
    "_t5_config.d_kv = 4\n",
    "_t5_config.num_heads = 3\n",
    "_t5_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Attention(\n",
       "  (q): Linear(in_features=10, out_features=12, bias=False)\n",
       "  (k): Linear(in_features=10, out_features=12, bias=False)\n",
       "  (v): Linear(in_features=10, out_features=12, bias=False)\n",
       "  (o): Linear(in_features=12, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_attn_module = T5Attention(config=_t5_config)\n",
    "test_attn_module.eval()\n",
    "test_attn_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('q.weight', torch.Size([12, 10])),\n",
       " ('k.weight', torch.Size([12, 10])),\n",
       " ('v.weight', torch.Size([12, 10])),\n",
       " ('o.weight', torch.Size([10, 12]))]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v.size()) for k, v in test_attn_module.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'q', 'k', 'v', 'o']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k, v in test_attn_module.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 7, 10]),\n",
       " [('prev_key', torch.Size([1, 3, 2, 4])),\n",
       "  ('prev_value', torch.Size([1, 3, 2, 4])),\n",
       "  ('prev_key_padding_mask', torch.Size([1, 2]))])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_bs = 1\n",
    "_test_seqlen = 7\n",
    "_test_prevlen = 2\n",
    "\n",
    "_test_h = torch.randn(_test_bs, _test_seqlen, _t5_config.d_model)\n",
    "# _test_h[:, 0] = 999.0\n",
    "_test_prefix = {\n",
    "    'prev_key': torch.randn(_test_bs, _t5_config.num_heads, _test_prevlen, _t5_config.d_kv),\n",
    "    'prev_value': torch.randn(_test_bs, _t5_config.num_heads, _test_prevlen, _t5_config.d_kv),\n",
    "    'prev_key_padding_mask': torch.zeros(_test_bs, _test_prevlen).bool()\n",
    "}\n",
    "_test_h.size(), [(k, v.size()) for k, v in _test_prefix.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8561, -0.0552,  0.3845,  1.1441, -1.2765, -0.6869, -0.9646,\n",
       "          -1.0255, -2.3659, -1.7153],\n",
       "         [ 1.0685, -0.1617,  0.8310, -1.7257,  0.3674,  1.7559,  0.5763,\n",
       "          -0.9344,  0.9016,  0.7490],\n",
       "         [-1.1887, -1.0820, -0.5925,  0.7623, -0.6538, -0.0067,  0.5618,\n",
       "           1.3310,  1.2580, -0.6973],\n",
       "         [ 0.2807,  0.0763, -0.3539,  0.9494, -0.1557, -0.7645, -0.2103,\n",
       "          -1.0175, -0.3029, -0.0376],\n",
       "         [ 0.0984,  0.5610, -2.3323,  1.3421, -1.0381, -1.8568, -0.7754,\n",
       "          -1.6037,  0.2501, -1.4155],\n",
       "         [-1.4474, -0.4784,  0.0972, -0.3393,  1.2340,  0.7611, -0.4786,\n",
       "           0.0506, -0.1188,  2.7051],\n",
       "         [ 2.0642, -0.0186, -0.8283,  1.0852,  0.9819, -0.4044,  0.9831,\n",
       "          -0.2723,  0.2037,  1.6401]]])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev_key': tensor([[[[-2.2578,  0.2019,  0.3287,  0.3906],\n",
       "           [-1.2143, -0.7039, -1.0298,  0.1425]],\n",
       " \n",
       "          [[ 0.3967,  1.5168,  0.0967,  1.4454],\n",
       "           [ 0.1648,  0.2483,  1.5992,  1.2469]],\n",
       " \n",
       "          [[ 1.3875,  0.4460, -0.2676, -1.2290],\n",
       "           [ 2.0209,  1.1736,  0.8446,  0.8827]]]]),\n",
       " 'prev_value': tensor([[[[ 0.8351,  1.2052,  1.4187, -0.5358],\n",
       "           [-1.4274,  0.2792,  2.0149,  1.3695]],\n",
       " \n",
       "          [[-0.0379,  1.8999, -0.4236, -0.9176],\n",
       "           [ 1.5794,  1.1735, -0.2925,  2.2855]],\n",
       " \n",
       "          [[ 1.1935,  0.9343, -0.5582,  0.8163],\n",
       "           [-1.3765,  0.4046,  1.0941,  0.4058]]]]),\n",
       " 'prev_key_padding_mask': tensor([[False, False]])}"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_mask = torch.zeros(1, 1, 1, _test_seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000, 0.0000, 0.0555, 0.0865, 0.2123, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0500, 0.0561, 0.2204, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0790, 0.1347, 0.0803, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0948, 0.1212, 0.0706,\n",
      "           0.1012],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1118, 0.1319, 0.1250,\n",
      "           0.1008],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0817, 0.1127, 0.0234,\n",
      "           0.0819],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0367, 0.0975, 0.0078,\n",
      "           0.0355]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.1741, 0.0213, 0.2074, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0401, 0.0697, 0.0557, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0830, 0.1678, 0.0441, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1445, 0.1715, 0.0983,\n",
      "           0.1005],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1214, 0.1210, 0.0850,\n",
      "           0.0888],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1315, 0.1452, 0.0752,\n",
      "           0.0670],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1172, 0.1225, 0.1172,\n",
      "           0.1114]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.3866, 0.1281, 0.0692, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.3021, 0.0799, 0.0819, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0044, 0.0834, 0.0516, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1173, 0.1256, 0.1433,\n",
      "           0.1062],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0604, 0.0699, 0.3354,\n",
      "           0.1616],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0748, 0.0603, 0.0213,\n",
      "           0.0353],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1201, 0.1420, 0.1255,\n",
      "           0.0757]]]])\n"
     ]
    }
   ],
   "source": [
    "_out = test_attn_module.forward(\n",
    "    _test_h,\n",
    "    mask=_test_mask,\n",
    "    prefix=_test_prefix,\n",
    "    output_attentions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0204,  0.0486,  0.0714, -0.0557, -0.0945, -0.0027, -0.0596,\n",
       "            0.0248, -0.0247,  0.0303],\n",
       "          [-0.0654, -0.0173,  0.0765, -0.1045, -0.1099,  0.0203, -0.0408,\n",
       "            0.0300,  0.0083, -0.0148],\n",
       "          [-0.0137,  0.0049,  0.0044, -0.0359,  0.0081,  0.0057,  0.0129,\n",
       "           -0.0376,  0.0170, -0.0377],\n",
       "          [ 0.1034, -0.0840, -0.0698, -0.1175,  0.0347, -0.0655, -0.1709,\n",
       "           -0.0856,  0.2007,  0.0352],\n",
       "          [ 0.1838, -0.0759, -0.0994,  0.0013,  0.1057, -0.0664, -0.1120,\n",
       "           -0.0768,  0.1879,  0.0741],\n",
       "          [ 0.0380, -0.0258, -0.0283, -0.1196,  0.0072, -0.0688, -0.1354,\n",
       "           -0.0494,  0.0998,  0.0076],\n",
       "          [ 0.1094, -0.0947, -0.0463, -0.1175,  0.0394, -0.0643, -0.1509,\n",
       "           -0.0924,  0.1877,  0.0419]]]),\n",
       " None,\n",
       " tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.]]]]),\n",
       " tensor([[[[0.0000, 0.0000, 0.0555, 0.0865, 0.2123, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000],\n",
       "           [0.0000, 0.0000, 0.0500, 0.0561, 0.2204, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000],\n",
       "           [0.0000, 0.0000, 0.0790, 0.1347, 0.0803, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0948, 0.1212, 0.0706,\n",
       "            0.1012],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1118, 0.1319, 0.1250,\n",
       "            0.1008],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0817, 0.1127, 0.0234,\n",
       "            0.0819],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0367, 0.0975, 0.0078,\n",
       "            0.0355]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.1741, 0.0213, 0.2074, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000],\n",
       "           [0.0000, 0.0000, 0.0401, 0.0697, 0.0557, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000],\n",
       "           [0.0000, 0.0000, 0.0830, 0.1678, 0.0441, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1445, 0.1715, 0.0983,\n",
       "            0.1005],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1214, 0.1210, 0.0850,\n",
       "            0.0888],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1315, 0.1452, 0.0752,\n",
       "            0.0670],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1172, 0.1225, 0.1172,\n",
       "            0.1114]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.3866, 0.1281, 0.0692, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000],\n",
       "           [0.0000, 0.0000, 0.3021, 0.0799, 0.0819, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000],\n",
       "           [0.0000, 0.0000, 0.0044, 0.0834, 0.0516, 0.0000, 0.0000, 0.0000,\n",
       "            0.0000],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1173, 0.1256, 0.1433,\n",
       "            0.1062],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0604, 0.0699, 0.3354,\n",
       "            0.1616],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0748, 0.0603, 0.0213,\n",
       "            0.0353],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1201, 0.1420, 0.1255,\n",
       "            0.0757]]]]))"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3544, 0.3264, 0.2939, 0.3878, 0.4695, 0.2997, 0.1775],\n",
       "         [0.4028, 0.1655, 0.2949, 0.5148, 0.4162, 0.4189, 0.4683],\n",
       "         [0.5839, 0.4639, 0.1393, 0.4925, 0.6272, 0.1917, 0.4634]]])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out[3].sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_mask_attention(att, mix_mask):\n",
    "    # token 4,5,6 (in real_seq) not attending to 2 (in full_seq, i.e. 0 in real_seq)\n",
    "    # att: (bs, n_head, real_seq, full_seq)\n",
    "#     att[:, :, 4:, 2] = 0.0\n",
    "\n",
    "    _zero = torch.tensor(0, dtype=att.dtype)\n",
    "    att = torch.where(mix_mask, _zero, att)\n",
    "\n",
    "    print(att)\n",
    "    return att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ True, False,  True, False,  True, False,  True, False,  True],\n",
       "           [False, False, False, False, False, False, False, False, False],\n",
       "           [ True, False,  True, False,  True, False,  True, False,  True],\n",
       "           [False, False, False, False, False, False, False, False, False],\n",
       "           [ True, False,  True, False,  True, False,  True, False,  True],\n",
       "           [False, False, False, False, False, False, False, False, False],\n",
       "           [ True, False,  True, False,  True, False,  True, False,  True]]]]),\n",
       " tensor([[[[ True,  True, False, False, False,  True,  True,  True,  True],\n",
       "           [ True,  True, False, False, False,  True,  True,  True,  True],\n",
       "           [ True,  True, False, False, False,  True,  True,  True,  True],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False]]]]))"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_mask = torch.zeros(1, 1, _test_seqlen, _test_seqlen + _test_prevlen, dtype=bool)\n",
    "mix_mask[:, :, ::2, ::2] = 1\n",
    "\n",
    "mix_mask_2 = torch.zeros(1, 1, _test_seqlen, _test_seqlen + _test_prevlen, dtype=bool)\n",
    "mix_mask_2[:, :, :, :_test_prevlen] = 1\n",
    "mix_mask_2[:, :, 3:, _test_prevlen : _test_prevlen+3] = 1\n",
    "mix_mask_2[:, :, :3, _test_prevlen+3 :] = 1\n",
    "\n",
    "mix_mask, mix_mask_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_mask | mix_mask_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attn_module.ext_attention_weights_fn = lambda att : _test_mask_attention(att, mix_mask_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x7fc33d6065e0>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test_attn_module.ext_attention_weights_fn)\n",
    "print(test_attn_module.ext_attention_logits_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000, 0.0000, 0.0555, 0.0865, 0.2123, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0500, 0.0561, 0.2204, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0790, 0.1347, 0.0803, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0948, 0.1212, 0.0706,\n",
      "           0.1012],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1118, 0.1319, 0.1250,\n",
      "           0.1008],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0817, 0.1127, 0.0234,\n",
      "           0.0819],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0367, 0.0975, 0.0078,\n",
      "           0.0355]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.1741, 0.0213, 0.2074, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0401, 0.0697, 0.0557, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0830, 0.1678, 0.0441, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1445, 0.1715, 0.0983,\n",
      "           0.1005],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1214, 0.1210, 0.0850,\n",
      "           0.0888],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1315, 0.1452, 0.0752,\n",
      "           0.0670],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1172, 0.1225, 0.1172,\n",
      "           0.1114]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.3866, 0.1281, 0.0692, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.3021, 0.0799, 0.0819, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0044, 0.0834, 0.0516, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1173, 0.1256, 0.1433,\n",
      "           0.1062],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0604, 0.0699, 0.3354,\n",
      "           0.1616],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0748, 0.0603, 0.0213,\n",
      "           0.0353],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1201, 0.1420, 0.1255,\n",
      "           0.0757]]]])\n"
     ]
    }
   ],
   "source": [
    "_out = test_attn_module.forward(\n",
    "    _test_h,\n",
    "    mask=_test_mask,\n",
    "    prefix=_test_prefix,\n",
    "    output_attentions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 3.5841e-01,  1.6328e-01,  7.1743e-02,  2.4984e-01,  2.4944e-01,\n",
       "           -7.9626e-02,  2.5015e-01, -9.8734e-02, -9.3451e-02,  5.2444e-03],\n",
       "          [-9.1883e+01,  2.1521e+02, -2.8524e+02,  1.0094e+02, -2.9927e+00,\n",
       "            2.5641e+02,  3.4648e+02,  1.0199e+02, -3.3081e+02, -1.3056e+02],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.4710e+02, -7.0404e+01, -3.3133e+02, -7.1411e+01, -2.9981e+02,\n",
       "            5.3943e+02,  1.4885e+02, -4.5987e+01,  2.1208e+02, -1.7110e+02],\n",
       "          [-3.4616e-01,  3.7414e-01,  3.2157e-03, -5.8465e-02, -2.5078e-01,\n",
       "            1.6366e-01,  2.0201e-01,  1.4041e-01, -3.5337e-01, -2.7156e-01],\n",
       "          [-1.2197e+02,  3.3138e+02, -8.3268e+01,  2.3763e+02,  1.2709e+02,\n",
       "           -8.0540e+01,  2.3006e+02, -1.4939e+01, -3.5100e+02, -1.6698e+02],\n",
       "          [ 5.1168e-02,  4.9174e-02, -2.8867e-02,  1.7413e-02,  3.2348e-02,\n",
       "            1.2258e-02,  2.5395e-02, -6.7132e-02, -2.9934e-02,  3.2184e-02]]]),\n",
       " None,\n",
       " tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0., 0.]]]]),\n",
       " tensor([[[[0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [4.9323e-02, 4.1917e-01, 0.0000e+00, 1.1252e-01, 5.9022e-02,\n",
       "            3.9324e-02, 2.3981e-01, 3.3832e-02, 4.6999e-02],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 4.7931e-02, 0.0000e+00, 4.9362e-02, 0.0000e+00,\n",
       "            6.9398e-02, 0.0000e+00, 4.3324e-02, 0.0000e+00],\n",
       "           [9.9362e-03, 6.5009e-01, 0.0000e+00, 1.2953e-02, 2.8488e-02,\n",
       "            1.5421e-02, 2.4974e-01, 6.8866e-03, 2.6492e-02],\n",
       "           [0.0000e+00, 1.8436e-32, 0.0000e+00, 1.6576e-32, 0.0000e+00,\n",
       "            1.6713e-32, 0.0000e+00, 1.9826e-32, 0.0000e+00]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [7.8132e-02, 4.7242e-02, 2.0166e-33, 2.7596e-01, 1.0767e-01,\n",
       "            1.3207e-01, 6.6257e-02, 1.1049e-01, 1.8217e-01],\n",
       "           [0.0000e+00, 8.5617e-02, 0.0000e+00, 1.8238e-01, 0.0000e+00,\n",
       "            1.1707e-01, 0.0000e+00, 1.2599e-01, 0.0000e+00]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [2.5248e-01, 2.5725e-01, 0.0000e+00, 1.4999e-02, 4.5690e-02,\n",
       "            5.6195e-02, 2.1949e-01, 4.5556e-02, 1.0834e-01],\n",
       "           [0.0000e+00, 4.9981e-02, 0.0000e+00, 5.1408e-01, 0.0000e+00,\n",
       "            4.5185e-02, 0.0000e+00, 1.4453e-01, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]]))"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = dict(a_ex_list[a_ex_id])\n",
    "a_ex = ctu.add_clean_prediction(mt_uskg, a_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'What is the accelerate of the car make amc hornet sportabout (sw)?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'seq_out': \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\",\n",
       " 'dec_prompt': 'select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.',\n",
       " 'expect': 'make',\n",
       " 'expect_type': 'column',\n",
       " 'db_id': 'car_1',\n",
       " 'expect_input_ranges': [(121, 145)],\n",
       " 'expect_table': 'car_names',\n",
       " 'answer': 'make',\n",
       " 'base_score': 0.9998800754547119,\n",
       " 'answers_t': [19509],\n",
       " 'correct_prediction': True,\n",
       " 'category': {'sql_hardness': 'medium',\n",
       "  'node_role': 'where',\n",
       "  'text_match': 'exact'}}"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ctu.make_basic_result_dict(a_ex)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']\n",
    "answer = result['answer']\n",
    "answers_t = result['answers_t']\n",
    "\n",
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 2,\n",
    "    [dec_prompt] * 2,\n",
    "    answer=expect)\n",
    "\n",
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "self_ranges = a_ex['self_ranges']\n",
    "context_ranges = a_ex['context_ranges']\n",
    "\n",
    "self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "context_tok_indices = corrupt_tok_indices = [i for s, e in context_ranges for i in range(s, e)]\n",
    "text_tok_indices = list(range(*text_range))\n",
    "struct_tok_indices = list(range(*struct_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=context_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([19509], 'make', 0.9987825751304626)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_t, answer, _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score = ctu.trace_attention_manip_uskg_multi_token(\n",
    "# _probs = ctu.run_attention_manip_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     answer_len=len(answers_t),\n",
    "    answers_t=answers_t,\n",
    "#     states_to_patch=[],\n",
    "    layers_to_mix=[ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') for l in range(24)],\n",
    "    src_tokens_to_mix=text_tok_indices + struct_tok_indices, # src doesn't have prefix \n",
    "#     src_tokens_to_mix=[-1],\n",
    "    tgt_tokens_to_mix=list(range(10)) + [i + 10 for i in text_tok_indices + struct_tok_indices],  # tgt has prefix \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.6447], device='cuda:0'),\n",
       "indices=tensor([4350], device='cuda:0'))"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_probs.max(dim=-1)\n",
    "# _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name'"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.decode([4350])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctu.layername_uskg(mt_uskg.model, 'encoder', 0, 'self_attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nested_json_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[0.4967141530112327, -0.13826430117118466],\n",
       "   [0.6476885381006925, 1.5230298564080254]],\n",
       "  [[-0.23415337472333597, -0.23413695694918055],\n",
       "   [1.5792128155073915, 0.7674347291529088]]],\n",
       " [[[-0.4694743859349521, 0.5425600435859647],\n",
       "   [-0.46341769281246226, -0.46572975357025687]],\n",
       "  [[0.24196227156603412, -1.913280244657798],\n",
       "   [-1.7249178325130328, -0.5622875292409727]]]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(2,2,2,2).tolist()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctu.nested_list_processing(a, func=lambda x: np.format_float_positional(x, precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [[[[0.4967141530112327, -0.13826430117118466],\n",
       "    [0.6476885381006925, 1.5230298564080254]],\n",
       "   [[-0.23415337472333597, -0.23413695694918055],\n",
       "    [1.5792128155073915, 0.7674347291529088]]],\n",
       "  [[[-0.4694743859349521, 0.5425600435859647],\n",
       "    [-0.46341769281246226, -0.46572975357025687]],\n",
       "   [[0.24196227156603412, -1.913280244657798],\n",
       "    [-1.7249178325130328, -0.5622875292409727]]]],\n",
       " 'a_list': {'a0': [[[0.4967141530112327, -0.13826430117118466],\n",
       "    [0.6476885381006925, 1.5230298564080254]],\n",
       "   [[-0.23415337472333597, -0.23413695694918055],\n",
       "    [1.5792128155073915, 0.7674347291529088]]],\n",
       "  'a1_list': {'a10': [[-0.4694743859349521, 0.5425600435859647],\n",
       "    [-0.46341769281246226, -0.46572975357025687]],\n",
       "   'a11': [[0.24196227156603412, -1.913280244657798],\n",
       "    [-1.7249178325130328, -0.5622875292409727]]}}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {\n",
    "    'a': a,\n",
    "    'a_list': {\n",
    "        'a0': a[0],\n",
    "        'a1_list': {\n",
    "            'a10': a[1][0],\n",
    "            'a11': a[1][1],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [[[['0.5', '-0.14'], ['0.65', '1.52']],\n",
       "   [['-0.23', '-0.23'], ['1.58', '0.77']]],\n",
       "  [[['-0.47', '0.54'], ['-0.46', '-0.47']],\n",
       "   [['0.24', '-1.91'], ['-1.72', '-0.56']]]],\n",
       " 'a_list': {'a0': [[['0.5', '-0.14'], ['0.65', '1.52']],\n",
       "   [['-0.23', '-0.23'], ['1.58', '0.77']]],\n",
       "  'a1_list': {'a10': [['-0.47', '0.54'], ['-0.46', '-0.47']],\n",
       "   'a11': [['0.24', '-1.91'], ['-1.72', '-0.56']]}}}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.nested_json_processing(b, func=lambda x: np.format_float_positional(x, precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = processed_spider_dev[97]\n",
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "dec_prompt = \"select t1.model from\"\n",
    "expect = \"car_names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    enc_sentences=[enc_sentence]*11,\n",
    "    dec_prompts=[dec_prompt]*11,\n",
    "    answer=expect\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', '_', 'name', 's']"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_toks = decode_tokens(mt_uskg.tokenizer, mt_uskg.tokenizer.encode(expect, add_special_tokens=False))\n",
    "ans_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> select t1.model from car_name'"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.decode(inp['decoder_input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['select', '', 't', '1.', 'model', 'from'], 6)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.tokenize(dec_prompt), len(mt_uskg.tokenizer.tokenize(dec_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inp['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = ctu.trace_with_patch_uskg_multi_token(\n",
    "#     mt_uskg.model,\n",
    "#     inp=inp,\n",
    "# #     states_to_patch=[(4, ctu.layername_uskg(mt_uskg.model, 'decoder', 3))],\n",
    "#     states_to_patch=[],\n",
    "# #     answers_t=mt_uskg.tokenizer.encode(expect, add_special_tokens=False),\n",
    "# #     tokens_to_mix=(0, len(inp['input_ids'][0])-1),\n",
    "#     tokens_to_mix=None,\n",
    "#     replace=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.5643, device='cuda:0'),\n",
       " tensor(1.0000, device='cuda:0'),\n",
       " tensor(0.9996, device='cuda:0'),\n",
       " tensor(1.0000, device='cuda:0')]"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 443,  834, 4350,    7], device='cuda:0')"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_len = len(mt_uskg.tokenizer.tokenize(expect))\n",
    "pred_out = ctu.predict_from_input_uskg_multi_token(mt_uskg.model, inp, pred_len=answer_len)\n",
    "pred, p = pred_out\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model', 'car'), ('_', '_'), ('name', 'name'), ('s', 's')]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_toks = decode_tokens(mt_uskg.tokenizer, pred[0])\n",
    "# list(zip(pred_toks, ans_toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('car_1',\n",
       " 'Find the model of the car whose weight is below the average weight.',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'select t1.model from car_names as t1 join cars_data as t2 on t1.makeid = t2.id where t2.weight < (select avg(weight) from cars_data)')"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['db_id'], ex['question'], ex['struct_in'], ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = ctu.trace_with_repatch_uskg_multi_token(\n",
    "    mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[(4, ctu.layername_uskg(mt_uskg.model, 'decoder', 3))],\n",
    "    states_to_unpatch=[(4, ctu.layername_uskg(mt_uskg.model, 'decoder', 4, 'cross_attn'))],\n",
    "    states_to_patch_1st_pass=[(4, ctu.layername_uskg(mt_uskg.model, 'decoder', l)) for l in range(mt_uskg.num_enc_layers)],\n",
    "    answers_t=pred[0],\n",
    "    tokens_to_mix=(10, 20, 30, 40),\n",
    "    tokens_to_mix_1st_pass=(5, 15, 25),\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.5877, device='cuda:0'),\n",
       " tensor(1., device='cuda:0'),\n",
       " tensor(0.9988, device='cuda:0'),\n",
       " tensor(1.0000, device='cuda:0')]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inp = ctu.make_inputs_t5(mt_uskg.tokenizer, [text_in] * 11, [dec_prompt] * 11)\n",
    "# inp = ctu.make_inputs_t5(mt_uskg.tokenizer, [enc_sentence] * 11, [dec_prompt] * 11, answer=expect, device='cpu')\n",
    "# # answer_t, base_score = [d[0] for d in ctu.predict_from_input_uskg(mt_uskg.model, inp)]\n",
    "# # base_score = base_score.item()\n",
    "# # [answer] = ctu.decode_tokens(mt_uskg.tokenizer, [answer_t])\n",
    "# answer_len = 1\n",
    "# if expect is not None:\n",
    "#     answer_len = len(mt_uskg.tokenizer.tokenize(expect))\n",
    "# with torch.no_grad():\n",
    "#     answers_t, base_score = [d[0] for d in ctu.predict_from_input_uskg_multi_token(mt_uskg.model, inp, pred_len=answer_len)]\n",
    "# # base_score = base_score.min().item()\n",
    "# # [answer] = decode_tokens(mt.tokenizer, [answer_t])\n",
    "# answer = ctu.decode_sentences(mt_uskg.tokenizer, answers_t)\n",
    "\n",
    "# expect, answers_t, answer, base_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # e_range = (129, 132)\n",
    "# # e_range = [8, 13, 131]\n",
    "# e_range = list(range(7, 14))\n",
    "\n",
    "# r = ctu.trace_with_patch_uskg(\n",
    "#     mt_uskg.model,\n",
    "#     inp=inp,\n",
    "#     states_to_patch=[], \n",
    "#     answers_t=answer_t, \n",
    "#     tokens_to_mix=e_range,\n",
    "#     tokens_to_mix_individual_indices=True,\n",
    "#     replace=True,\n",
    "# )\n",
    "\n",
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = mt_uskg.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['mar', 'y', ':', 'has', '', 'a', 'little', 'lamb', 'b', 'b'],\n",
       " ['mar', 'y', ':', 'has', '', 'a', 'little', 'lamb', 'b', 'b'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"mary: has a little  lambbb\"\n",
    "s_ = \"mary: has a little lambbb\"\n",
    "tokenizer.tokenize(s), tokenizer.tokenize(s_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3157, 63, 10, 65, 3, 9, 385, 17871, 115, 115, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tokenizer(s)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'mar'),\n",
       " (1, 'y'),\n",
       " (2, ':'),\n",
       " (3, 'has'),\n",
       " (4, ''),\n",
       " (5, 'a'),\n",
       " (6, 'little'),\n",
       " (7, 'lamb'),\n",
       " (8, 'b'),\n",
       " (9, 'b'),\n",
       " (10, '</s>')]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(t.tokens()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenSpan(start=7, end=10)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_to_tokens(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lambbb'"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.decode_sentences(tokenizer, t['input_ids'][7:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"(a(a)a)\".rindex(\")\"), \"(a(a)a)\".index(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['|',\n",
       " 'concert',\n",
       " '_',\n",
       " 's',\n",
       " 'inger',\n",
       " '|',\n",
       " 'singer',\n",
       " '',\n",
       " ':',\n",
       " 'singer',\n",
       " '_',\n",
       " 'i',\n",
       " 'd',\n",
       " '',\n",
       " ',',\n",
       " 'name',\n",
       " '(',\n",
       " 'First',\n",
       " 'Last',\n",
       " '',\n",
       " ')',\n",
       " '',\n",
       " ',',\n",
       " 'country',\n",
       " '(',\n",
       " 'France',\n",
       " '',\n",
       " ',',\n",
       " 'Germany',\n",
       " '',\n",
       " ',',\n",
       " 'United',\n",
       " 'States',\n",
       " '',\n",
       " ')',\n",
       " '',\n",
       " ',',\n",
       " 'song',\n",
       " '_',\n",
       " 'name',\n",
       " '',\n",
       " ',',\n",
       " 'song',\n",
       " '_',\n",
       " 'release',\n",
       " '_',\n",
       " 'year',\n",
       " '',\n",
       " ',',\n",
       " 'age',\n",
       " '',\n",
       " ',',\n",
       " 'is',\n",
       " '_',\n",
       " 'male']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"\"\"| concert_singer | singer : singer_id , name ( First Last ) , country ( France , Germany , United States ) , \\\n",
    "song_name , song_release_year , age , is_male\"\"\"\n",
    "\n",
    "tokenizer.tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test struct_in parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "_struct_in = \"\"\"| concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , \\\n",
    "average | singer : singer_id , name ( First Last ) , country ( France , Germany , United States ) , \\\n",
    "song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , \\\n",
    "stadium_id , year ( 2008 , 2012 , 2022 ) | singer_in_concert : concert_id , singer_id\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((3, 'stadium'),\n",
       "  [[(5, 'stadium_id'), []],\n",
       "   [(7, 'location'), []],\n",
       "   [(9, 'name'), []],\n",
       "   [(11, 'capacity'), []],\n",
       "   [(13, 'highest'), []],\n",
       "   [(15, 'lowest'), []],\n",
       "   [(17, 'average'), []]]),\n",
       " ((19, 'singer'),\n",
       "  [[(21, 'singer_id'), []],\n",
       "   [(23, 'name'), [(25, 'First Last')]],\n",
       "   [(29, 'country'), [(31, 'France'), (33, 'Germany'), (35, 'United States')]],\n",
       "   [(39, 'song_name'), []],\n",
       "   [(41, 'song_release_year'), []],\n",
       "   [(43, 'age'), []],\n",
       "   [(45, 'is_male'), []]]),\n",
       " ((47, 'concert'),\n",
       "  [[(49, 'concert_id'), []],\n",
       "   [(51, 'concert_name'), []],\n",
       "   [(53, 'theme'), []],\n",
       "   [(55, 'stadium_id'), []],\n",
       "   [(57, 'year'), [(59, '2008'), (61, '2012'), (63, '2022')]]]),\n",
       " ((66, 'singer_in_concert'),\n",
       "  [[(68, 'concert_id'), []], [(70, 'singer_id'), []]])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.parse_struct_in(_struct_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "_text_in = text_in\n",
    "\n",
    "enc_sentence = f\"{_text_in}; structed knowledge: {_struct_in}\"\n",
    "enc_tokenized = mt_uskg.tokenizer(enc_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ranges_dict = ctu.find_struct_name_ranges(mt_uskg.tokenizer, enc_tokenized['input_ids'], _struct_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db_id_ranges': defaultdict(list, {'concert_singer': [(25, 29)]}),\n",
       " 'table_name_ranges': defaultdict(list,\n",
       "             {'stadium': [(30, 31)],\n",
       "              'singer': [(56, 57)],\n",
       "              'concert': [(106, 107)],\n",
       "              'singer_in_concert': [(142, 149)]}),\n",
       " 'col_name_ranges': defaultdict(list,\n",
       "             {'stadium_id': [(33, 37), (123, 127)],\n",
       "              'location': [(39, 40)],\n",
       "              'name': [(42, 43), (65, 66)],\n",
       "              'capacity': [(45, 46)],\n",
       "              'highest': [(48, 49)],\n",
       "              'lowest': [(51, 52)],\n",
       "              'average': [(54, 55)],\n",
       "              'singer_id': [(59, 63), (157, 161)],\n",
       "              'country': [(73, 74)],\n",
       "              'song_name': [(87, 90)],\n",
       "              'song_release_year': [(92, 97)],\n",
       "              'age': [(99, 100)],\n",
       "              'is_male': [(102, 105)],\n",
       "              'concert_id': [(109, 113), (151, 155)],\n",
       "              'concert_name': [(115, 118)],\n",
       "              'theme': [(120, 121)],\n",
       "              'year': [(129, 130)]}),\n",
       " 'val_name_ranges': defaultdict(list,\n",
       "             {'First Last': [(67, 69)],\n",
       "              'France': [(75, 76)],\n",
       "              'Germany': [(78, 79)],\n",
       "              'United States': [(81, 83)],\n",
       "              '2008': [(131, 132)],\n",
       "              '2012': [(134, 135)],\n",
       "              '2022': [(137, 139)]})}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ranges_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db_id_ranges\tconcert_singer\tconcert_singer\n",
      "table_name_ranges\tstadium\tstadium\n",
      "table_name_ranges\tsinger\tsinger\n",
      "table_name_ranges\tconcert\tconcert\n",
      "table_name_ranges\tsinger_in_concert\tsinger_in_concert\n",
      "col_name_ranges\tstadium_id\tstadium_id\n",
      "col_name_ranges\tstadium_id\tstadium_id\n",
      "col_name_ranges\tlocation\tlocation\n",
      "col_name_ranges\tname\tname\n",
      "col_name_ranges\tname\tname\n",
      "col_name_ranges\tcapacity\tcapacity\n",
      "col_name_ranges\thighest\thighest\n",
      "col_name_ranges\tlowest\tlowest\n",
      "col_name_ranges\taverage\taverage\n",
      "col_name_ranges\tsinger_id\tsinger_id\n",
      "col_name_ranges\tsinger_id\tsinger_id\n",
      "col_name_ranges\tcountry\tcountry ( France )\n",
      "col_name_ranges\tsong_name\tsong_name\n",
      "col_name_ranges\tsong_release_year\tsong_release_year\n",
      "col_name_ranges\tage\tage\n",
      "col_name_ranges\tis_male\tis_male\n",
      "col_name_ranges\tconcert_id\tconcert_id\n",
      "col_name_ranges\tconcert_id\tconcert_id\n",
      "col_name_ranges\tconcert_name\tconcert_name\n",
      "col_name_ranges\ttheme\ttheme\n",
      "col_name_ranges\tyear\tyear\n",
      "val_name_ranges\tFrance\tFrance\n"
     ]
    }
   ],
   "source": [
    "for d_key, d in token_ranges_dict.items():\n",
    "    for name, ranges in d.items():\n",
    "        for s, e in ranges:\n",
    "            recs_name = ctu.decode_sentences(mt_uskg.tokenizer, enc_tokenized['input_ids'][s:e])\n",
    "            print(f'{d_key}\\t{name}\\t{recs_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: cars \tlemma: car\n",
      "word: data \tlemma: datum\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('cars data')\n",
    "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"id\": 1,\n",
       "  \"text\": \"cars\",\n",
       "  \"lemma\": \"car\",\n",
       "  \"upos\": \"NOUN\",\n",
       "  \"xpos\": \"NNS\",\n",
       "  \"feats\": \"Number=Plur\",\n",
       "  \"start_char\": 0,\n",
       "  \"end_char\": 4\n",
       "}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('cars data')\n",
    "doc.sentences[0].words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# stanza_nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemm_cache = dict()\n",
    "\n",
    "# def _lemmatize(name):\n",
    "# #     toks = []\n",
    "# #     for t in name.split('_'):\n",
    "# #         lemm_t = lemm_cache.get(t, None)\n",
    "# #         if lemm_t is None:\n",
    "# #             _doc = stanza_nlp(t)\n",
    "# #             lemm_t = _doc.sentences[0].words[0].lemma\n",
    "# #             lemm_cache[t] = lemm_t\n",
    "# #         toks.append(lemm_t)\n",
    "# #     return '_'.join(toks)\n",
    "#     _name = ' '.join(name.split('_'))\n",
    "#     _doc = stanza_nlp(_name)\n",
    "#     lemm_name = [w.lemma for sent in _doc.sentences for w in sent.words]\n",
    "#     return lemm_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _lemmatize('ranking_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _check_text_match(spider_ex, result_d):\n",
    "#     col = result_d['expect']\n",
    "#     tab = result_d['table']\n",
    "#     node_name = f'<C>{tab}::{col}'\n",
    "#     nodes = spider_ex['rat_sql_graph']['nodes']\n",
    "    \n",
    "#     if node_name in nodes:\n",
    "#         node_idx = nodes.index(node_name)\n",
    "#     else:\n",
    "#         _col = _lemmatize(col)\n",
    "#         _tab = _lemmatize(tab)\n",
    "#         _node_name = f'<C>{_tab}::{_col}'\n",
    "# #         if col != _col:\n",
    "# #             print(f'* Lemmatize: {node_name} ==> {_node_name}')\n",
    "#         if _node_name in nodes:\n",
    "#             node_idx = nodes.index(_node_name)\n",
    "#         else:\n",
    "#             assert False, ((node_name, _node_name), nodes)\n",
    "    \n",
    "#     rel_matrix = json.loads(spider_ex['rat_sql_graph']['relations'])\n",
    "#     rel_row = rel_matrix[node_idx]\n",
    "    \n",
    "#     if REL2ID['cqCEM'] in rel_row:\n",
    "#         return 'exact'\n",
    "#     elif REL2ID['cqCPM'] in rel_row:\n",
    "#         return 'partial'\n",
    "#     else:\n",
    "#         return 'no-match'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer-fast / uskg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = processed_spider_dev[416]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,  1738,     3,     9,   208,   122,   599,  5525,   834,   858,\n",
       "           834, 26416,    61,    45,  7071,   213,   539,   834,  1201, 32100,\n",
       "          2464,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: add special token (<, <=) to t5-tokenizer \n",
    "# could use uskg tokenizer, but it's not TokenizerFast \n",
    "\n",
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "txt = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "\n",
    "tokenized_txt = mt_uskg.tokenizer([txt], max_length=1024, padding=\"max_length\", truncation=True)\n",
    "\n",
    "device = mt_uskg.model.device\n",
    "_output = mt_uskg.model.generate(\n",
    "    torch.tensor(tokenized_txt.data['input_ids'], dtype=int, device=device),\n",
    "    torch.tensor(tokenized_txt.data['attention_mask'], dtype=int, device=device),\n",
    "    num_beams=1, \n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['select avg(num_of_staff) from museum where open_year 2009']"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.batch_decode(\n",
    "    _output,\n",
    "    skip_special_tokens=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['select avg(num_of_staff) from museum where open_year  < 2009']"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer_uskg.batch_decode(\n",
    "    _output,\n",
    "    skip_special_tokens=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 't', '3.']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.tokenize('t3.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input for chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = processed_spider_dev[503]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many battles did not lose any ship with tonnage '225'?; structed knowledge: | battle_death | battle : id , name , date , bulgarian_commander , latin_commander , result | ship : lost_in_battle , id , name , tonnage , ship_type , location , disposition_of_ship | death : caused_by_ship_id , id , note , killed , injured => select count(*) from battle where id not in ( select lost_in_battle from ship where tonnage = '225' );\n"
     ]
    }
   ],
   "source": [
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "\n",
    "print(f\"{enc_sentence} => {ex['seq_out']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-time patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For exp2: ['trace_results'][.]: ['%col%_score'] -> ['%node%_score']\n",
    "\n",
    "# res_dir = '/home/yshao/Projects/rome/results/exp2_text_struct_interaction/'\n",
    "# in_path = os.path.join(res_dir, 'exp=2_train_column-tmp.jsonl')\n",
    "# out_path = os.path.join(res_dir, 'exp=2_train_column.jsonl')\n",
    "\n",
    "# with open(in_path, 'r') as f:\n",
    "#     all_results = [json.loads(l) for l in f]\n",
    "\n",
    "# for ex_d in all_results:\n",
    "#     for d in ex_d['trace_results']:\n",
    "#         if not d['is_good_sample']:\n",
    "#             continue\n",
    "#         d['r_node_score'] = d['r_col_score']\n",
    "#         d['r_struct_no_node_score'] = d['r_struct_no_col_score']\n",
    "#         d['r_node_corrupt_all_score'] = d['r_col_corrupt_all_score']\n",
    "#         del d['r_col_score']\n",
    "#         del d['r_struct_no_col_score']\n",
    "#         del d['r_col_corrupt_all_score']\n",
    "\n",
    "# all_results.sort(key=lambda d: d['ex_id'])\n",
    "        \n",
    "# with open(out_path, 'w') as f:\n",
    "#     for d in all_results:\n",
    "#         f.write(json.dumps(d, indent=None) + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RE test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_target = ' a b a c aa da a '\n",
    "subject = 'bb'\n",
    "m = re.search(fr'\\W({subject})\\W', dec_target)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<callable_iterator at 0x7f9d8fe45b20>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = re.finditer(fr'\\W({subject})\\W', dec_target)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = list(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exp4 plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uskg_enc_attention(d, savepdf=None):\n",
    "    ## Assume 16 heads, 24 layers (T5 large config)\n",
    "    \n",
    "    ## encoder self attention \n",
    "    inspect_layers = [0, 6, 12, 18, 23]\n",
    "    att_dict = d['attentions']\n",
    "    \n",
    "    cand_len = len(att_dict['enc_cand_tokens'])\n",
    "    head_len = len(att_dict['enc_head_tokens'])\n",
    "\n",
    "    fig_w = 22\n",
    "    fig_h = (0.11*cand_len + 1) * head_len\n",
    "    fig, ax_list = plt.subplots(\n",
    "        nrows=head_len,\n",
    "        ncols=len(inspect_layers),\n",
    "        squeeze=False,\n",
    "        figsize=(fig_w, fig_h))\n",
    "\n",
    "    att_mat = ctu.nested_list_processing(att_dict['enc_attn'], func=float)\n",
    "    att_mat = np.array(att_mat)\n",
    "    \n",
    "    for expect_i in range(len(att_dict['enc_head_tokens'])):\n",
    "        for l_id, layer in enumerate(inspect_layers):\n",
    "            val_mat = att_mat[layer, :, expect_i, :]  # layer, all heads, expect tok i -> all toks \n",
    "            val_mat = val_mat.transpose()    # (cand_toks, n_heads)\n",
    "            x_labels = range(val_mat.shape[1])\n",
    "            y_labels = att_dict['enc_cand_tokens']\n",
    "            title_toks = att_dict['enc_head_tokens'][:expect_i] + [f\"*{att_dict['enc_head_tokens'][expect_i]}*\"]\n",
    "            title = f\"L{layer}  Head token: {' '.join(title_toks)}\\n\"\n",
    "            \n",
    "            ax = ax_list[expect_i, l_id]\n",
    "            _draw_single_plot_2(ax,\n",
    "                                val_mat=val_mat, \n",
    "                                x_labels=x_labels, \n",
    "                                y_labels=y_labels,\n",
    "                                title=title)\n",
    "            \n",
    "    fig.tight_layout()\n",
    "    if savepdf:\n",
    "        plt.savefig(savepdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uskg_cross_attention(d, savepdf=None):\n",
    "    ## Assume 16 heads, 24 layers (T5 large config)\n",
    "    \n",
    "    ## decoder cross attention \n",
    "    inspect_layers = [0, 6, 12, 18, 23]\n",
    "    att_dict = d['attentions']\n",
    "    cand_len = len(att_dict['cross_cand_tokens'])\n",
    "    head_len = len(att_dict['cross_head_tokens'])\n",
    "    prompt_len = len(att_dict['dec_cand_tokens'])\n",
    "\n",
    "    fig_w = 22\n",
    "    fig_h = (0.11*cand_len + 1) * head_len\n",
    "    fig, ax_list = plt.subplots(\n",
    "        nrows=head_len,\n",
    "        ncols=len(inspect_layers),\n",
    "        squeeze=False,\n",
    "        figsize=(fig_w, fig_h))\n",
    "\n",
    "    att_mat = ctu.nested_list_processing(att_dict['cross_attn'], func=float)\n",
    "    att_mat = np.array(att_mat)\n",
    "    \n",
    "    for expect_i in range(head_len):\n",
    "        for l_id, layer in enumerate(inspect_layers):\n",
    "            val_mat = att_mat[layer, :, expect_i, :]  # layer, all heads, expect tok i -> all toks \n",
    "            val_mat = val_mat.transpose()    # (cand_toks, n_heads)\n",
    "            x_labels = range(val_mat.shape[1])\n",
    "            y_labels = att_dict['cross_cand_tokens']\n",
    "            # a small hack to use gold tokens from dec_prompt (dec_cand_tokens) for previous steps and predicted tokens at this step \n",
    "            # dec_prompt ends with the first (head_len-1) tokens of the target node \n",
    "            title_toks = att_dict['dec_cand_tokens'][prompt_len - (head_len-1) : prompt_len - (head_len-1) + expect_i] + [f\"*{att_dict['cross_head_tokens'][expect_i]}*\"]\n",
    "            title = f\"L{layer}  Head token: {' '.join(title_toks)}\\n\"\n",
    "            \n",
    "            ax = ax_list[expect_i, l_id]\n",
    "            _draw_single_plot_2(ax,\n",
    "                                val_mat=val_mat, \n",
    "                                x_labels=x_labels, \n",
    "                                y_labels=y_labels,\n",
    "                                title=title)\n",
    "            \n",
    "    fig.tight_layout()\n",
    "    if savepdf:\n",
    "        plt.savefig(savepdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d['attentions']['dec_cand_tokens'][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepdf_path = '/home/yshao/Projects/rome/results/figs/exp4_inspect_attention/tmp-6-cross.pdf'\n",
    "plot_uskg_cross_attention(d, savepdf=savepdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uskg_dec_attention(d, savepdf=None):\n",
    "    ## Assume 16 heads, 24 layers (T5 large config)\n",
    "    \n",
    "    ## decoder self attention \n",
    "    inspect_layers = [0, 6, 12, 18, 23]\n",
    "    att_dict = d['attentions']\n",
    "    prompt_len = cand_len = len(att_dict['dec_cand_tokens'])\n",
    "    head_len = len(att_dict['dec_head_tokens'])\n",
    "\n",
    "    fig_w = 22\n",
    "    fig_h = (0.11*cand_len + 1) * head_len\n",
    "    fig, ax_list = plt.subplots(\n",
    "        nrows=head_len,\n",
    "        ncols=len(inspect_layers),\n",
    "        squeeze=False,\n",
    "        figsize=(fig_w, fig_h))\n",
    "\n",
    "    att_mat = ctu.nested_list_processing(att_dict['dec_attn'], func=float)\n",
    "    att_mat = np.array(att_mat)\n",
    "    \n",
    "    for expect_i in range(head_len):\n",
    "        for l_id, layer in enumerate(inspect_layers):\n",
    "            val_mat = att_mat[layer, :, expect_i, :]  # layer, all heads, expect tok i -> all toks \n",
    "            val_mat = val_mat.transpose()    # (cand_toks, n_heads)\n",
    "            x_labels = range(val_mat.shape[1])\n",
    "            y_labels = att_dict['dec_cand_tokens']\n",
    "            # a small hack to use gold tokens from dec_prompt (dec_cand_tokens) for previous steps and predicted tokens at this step \n",
    "            # dec_prompt ends with the first (head_len-1) tokens of the target node \n",
    "            title_toks = att_dict['dec_cand_tokens'][prompt_len - (head_len-1) : prompt_len - (head_len-1) + expect_i] + [f\"*{att_dict['dec_head_tokens'][expect_i]}*\"]\n",
    "            title = f\"L{layer}  Head token: {' '.join(title_toks)}\\n\"\n",
    "            \n",
    "            ax = ax_list[expect_i, l_id]\n",
    "            _draw_single_plot_2(ax,\n",
    "                                val_mat=val_mat, \n",
    "                                x_labels=x_labels, \n",
    "                                y_labels=y_labels,\n",
    "                                title=title)\n",
    "            \n",
    "    fig.tight_layout()\n",
    "    if savepdf:\n",
    "        plt.savefig(savepdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepdf_path = '/home/yshao/Projects/rome/results/figs/exp4_inspect_attention/tmp-6-dec.pdf'\n",
    "plot_uskg_dec_attention(d, savepdf=savepdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 16, 1, 141)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(d['attentions']['enc_attn']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 141)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_att_mat = ctu.nested_list_processing(d['attentions']['enc_attn'], float)\n",
    "_att_mat = np.array(_att_mat)[-1, :, 0, :]  # layer 0, all heads, expect tok 0 -> all toks \n",
    "\n",
    "_att_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_len = len(d['attentions']['enc_tgt_tokens'])\n",
    "fig_h = cand_len / 10\n",
    "\n",
    "fig = plt.figure(figsize=(4, fig_h))\n",
    "ax = fig.gca()\n",
    "\n",
    "val_mat = _att_mat.transpose()\n",
    "x_labels = range(val_mat.shape[1])\n",
    "y_labels = d['attentions']['enc_tgt_tokens']\n",
    "title_toks = d['attentions']['enc_src_tokens'][:-1] + [f\"*{d['attentions']['enc_src_tokens'][-1]}*\"]\n",
    "title = ' '.join(title_toks)\n",
    "\n",
    "_draw_single_plot_2(ax,\n",
    "                    val_mat=val_mat, \n",
    "                    x_labels=x_labels, \n",
    "                    y_labels=y_labels,\n",
    "                    title=title,\n",
    "                   )\n",
    "fig.tight_layout()\n",
    "plt.savefig('/home/yshao/Projects/rome/results/figs/exp4_inspect_attention/tmp-1.pdf',\n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_list = plt.subplots(nrows=4, ncols=2)\n",
    "ax_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exp5.2 attention trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(2,3,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "_m = torch.zeros_like(t).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False],\n",
       "          [False, False],\n",
       "          [False, False],\n",
       "          [False, False]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True],\n",
       "          [ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True],\n",
       "          [ True,  True],\n",
       "          [ True,  True]]],\n",
       "\n",
       "\n",
       "        [[[False, False],\n",
       "          [False, False],\n",
       "          [False, False],\n",
       "          [False, False]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True],\n",
       "          [ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True],\n",
       "          [ True,  True],\n",
       "          [ True,  True]]]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_m[:, 1:, None, :] = True\n",
    "_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K/V: (bs, seq_len, m_dim) --[k/v]--> (bs, seq_len, n_head * dim) --[shape]--> (bs, n_head, seq_len, dim)\n",
    "## can corrupt v output on seq_len dimensions with certain seq_indices, giving attention ignoring these indices \n",
    "## can then restore the attention final output for other_seq_indices; no\n",
    "\n",
    "replace=True  # True to replace with instead of add noise\n",
    "noise_fn = lambda x: 0 * x\n",
    "\n",
    "patch_spec = []\n",
    "unpatch_spec = []\n",
    "corrupt_spec = []\n",
    "\n",
    "toks_to_mix = []\n",
    "\n",
    "def patch_rep(x, layer):\n",
    "\n",
    "    # if first_pass or (layer not in patch_spec and layer not in unpatch_spec):\n",
    "    if (layer not in patch_spec) and (layer not in unpatch_spec) and (layer not in corrupt_spec):\n",
    "        return x\n",
    "\n",
    "    h = untuple(x)\n",
    "    if layer in corrupt_spec:\n",
    "        toks_to_mix = corrupt_spec[layer]\n",
    "        if toks_to_mix:\n",
    "            mix_len = len(toks_to_mix)\n",
    "\n",
    "            noise_data = noise_fn(\n",
    "                torch.from_numpy(prng(h.shape[0] - 1, mix_len, h.shape[2]))\n",
    "            ).to(device=h.device, dtype=h.dtype)\n",
    "\n",
    "            if replace:\n",
    "                h[1:, toks_to_mix] = noise_data\n",
    "            else:\n",
    "                h[1:, toks_to_mix] += noise_data\n",
    "\n",
    "    # If this layer is in the patch_spec, restore the uncorrupted hidden state\n",
    "    # for selected tokens.\n",
    "    toks_to_patch = patch_spec.get(layer, [])\n",
    "    toks_to_unpatch = unpatch_spec.get(layer, [])\n",
    "    # if toks_to_patch:\n",
    "    #     print(f'* 2nd pass, layer: {layer}, restoring: {toks_to_patch}')\n",
    "    # if toks_to_unpatch:\n",
    "    #     print(f'* 2nd pass, layer: {layer}, unpatching: {toks_to_unpatch}')\n",
    "\n",
    "    for t in toks_to_patch:\n",
    "        h[1:, t] = h[0, t]\n",
    "    for t in toks_to_unpatch:\n",
    "        NotImplemented\n",
    "        # h[1:, t] = untuple(first_pass_trace[layer].output)[1:, t]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.49671415, -0.1382643 ,  0.64768854],\n",
       "        [ 1.52302986, -0.23415337, -0.23413696],\n",
       "        [ 1.57921282,  0.76743473, -0.46947439]],\n",
       "\n",
       "       [[ 0.54256004, -0.46341769, -0.46572975],\n",
       "        [ 0.24196227, -1.91328024, -1.72491783],\n",
       "        [-0.56228753, -1.01283112,  0.31424733]],\n",
       "\n",
       "       [[-0.90802408, -1.4123037 ,  1.46564877],\n",
       "        [-0.2257763 ,  0.0675282 , -1.42474819],\n",
       "        [-0.54438272,  0.11092259, -1.15099358]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(3,3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 2, 2]), array([1, 2, 1, 0, 2]), array([1, 1, 1, 2, 2]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(a > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 1), (0, 2, 1), (1, 1, 1), (2, 0, 2), (2, 2, 2)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*np.where(a > 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6666666666666667, '1.667')"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/3, np.format_float_positional(5/3, precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Package(s) not found: uskg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip show uskg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': 'uskg',\n",
       " '__doc__': None,\n",
       " '__package__': 'uskg',\n",
       " '__loader__': <_frozen_importlib_external._NamespaceLoader at 0x7f6cc73c6a00>,\n",
       " '__spec__': ModuleSpec(name='uskg', loader=<_frozen_importlib_external._NamespaceLoader object at 0x7f6cc73c6a00>, submodule_search_locations=_NamespacePath(['/home/yshao/Projects/UnifiedSKG/uskg_pip/uskg'])),\n",
       " '__file__': None,\n",
       " '__path__': _NamespacePath(['/home/yshao/Projects/UnifiedSKG/uskg_pip/uskg']),\n",
       " 'models': <module 'uskg.models' from '/home/yshao/Projects/UnifiedSKG/uskg_pip/uskg/models/__init__.py'>,\n",
       " 'utils': <module 'uskg.utils' from '/home/yshao/Projects/UnifiedSKG/uskg_pip/uskg/utils/__init__.py'>,\n",
       " 'seq2seq_construction': <module 'uskg.seq2seq_construction' from '/home/yshao/Projects/UnifiedSKG/uskg_pip/uskg/seq2seq_construction/__init__.py'>,\n",
       " 'third_party': <module 'uskg.third_party' from '/home/yshao/Projects/UnifiedSKG/uskg_pip/uskg/third_party/__init__.py'>}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uskg.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!echo $PYTHONPATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_t_list = [torch.ones(3) * i for i in range(5)]\n",
    "t1 = torch.stack(_t_list, dim=1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.cat([_t.unsqueeze(dim=1) for _t in _t_list], dim=1)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[[0,2], [2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [2., 3.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2sub = t2[[0,2]][:, [2,3]]\n",
    "t2sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[100.,   3.],\n",
       "         [  2.,   3.]]),\n",
       " tensor([[0., 1., 2., 3., 4.],\n",
       "         [0., 1., 2., 3., 4.],\n",
       "         [0., 1., 2., 3., 4.]]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2sub[0, 0] = 100\n",
    "t2sub, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [2., 3.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2s2 = t2[[0,2]]\n",
    "t2s3 = t2s2[:, [2,3]]\n",
    "t2s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0.,    1.,  100.,    3.,    4.],\n",
       "        [   0.,    1.,    2.,    3.,    4.],\n",
       "        [   0.,    1.,    2., -100.,    4.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2s3[0, 0] = 100\n",
    "t2s3[1, 1] = -100\n",
    "t2s2[:, [2,3]] = t2s3\n",
    "t2[[0,2]] = t2s2\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor(0.3000),\n",
       "indices=tensor(2))"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.tensor([0.1, 0.2, 0.3]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.factory.<locals>._f()>,\n",
       " <function __main__.factory.<locals>._f()>,\n",
       " <function __main__.factory.<locals>._f()>,\n",
       " <function __main__.factory.<locals>._f()>,\n",
       " <function __main__.factory.<locals>._f()>]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_funcs = []\n",
    "for i in range(5):\n",
    "    def factory(x):\n",
    "        def _f():\n",
    "            print(x)\n",
    "        return _f\n",
    "    _funcs.append(factory(i))\n",
    "_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for f in _funcs:\n",
    "    f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "706px",
    "left": "30px",
    "top": "220px",
    "width": "259px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

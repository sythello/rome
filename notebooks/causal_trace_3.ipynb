{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/causal_trace.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Tracing\n",
    "\n",
    "A demonstration of the double-intervention causal tracing method.\n",
    "\n",
    "The strategy used by causal tracing is to understand important\n",
    "states within a transfomer by doing two interventions simultaneously:\n",
    "\n",
    "1. Corrupt a subset of the input.  In our paper, we corrupt the subject tokens\n",
    "   to frustrate the ability of the transformer to accurately complete factual\n",
    "   prompts about the subject.\n",
    "2. Restore a subset of the internal hidden states.  In our paper, we scan\n",
    "   hidden states at all layers and all tokens, searching for individual states\n",
    "   that carry the necessary information for the transformer to recover its\n",
    "   capability to complete the factual prompt.\n",
    "\n",
    "The traces of decisive states can be shown on a heatmap.  This notebook\n",
    "demonstrates the code for conducting causal traces and creating these heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `experiments.causal_trace` module contains a set of functions for running causal traces.\n",
    "\n",
    "In this notebook, we reproduce, demonstrate and discuss the interesting functions.\n",
    "\n",
    "We begin by importing several utility functions that deal with tokens and transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import defaultdict, Counter\n",
    "from util import nethook\n",
    "from util.globals import DATA_DIR\n",
    "from experiments.causal_trace import (\n",
    "    ModelAndTokenizer,\n",
    "    layername,\n",
    "    guess_subject,\n",
    "    plot_trace_heatmap,\n",
    ")\n",
    "from experiments.causal_trace import (\n",
    "    make_inputs,\n",
    "    decode_tokens,\n",
    "    find_token_range,\n",
    "    predict_token,\n",
    "    predict_from_input,\n",
    "    collect_embedding_std,\n",
    ")\n",
    "from dsets import KnownsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f83484ca640>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "# from uskg.models.unified.prefixtuning import Model\n",
    "from uskg.models.unified import finetune, prefixtuning\n",
    "from uskg.utils.configue import Configure\n",
    "from uskg.utils.training_arguments import WrappedSeq2SeqTrainingArguments\n",
    "from uskg.seq2seq_construction import spider as s2s_spider\n",
    "from uskg.third_party.spider.preprocess.get_tables import dump_db_json_schema\n",
    "from uskg.third_party.spider import evaluation as sp_eval\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# import stanza\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import ujson\n",
    "import pickle\n",
    "\n",
    "from experiments import causal_trace_uskg as ctu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tokenizer_uskg: hkunlp/from_all_T5_large_prefix_spider_with_cell_value2\n",
      "Using tokenizer_fast: t5-large\n",
      "prefix-tuning sequence length is 10.\n"
     ]
    }
   ],
   "source": [
    "mt_uskg = ctu.ModelAndTokenizer_USKG('t5-large-prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('constructor', 'seq2seq_construction.spider'),\n",
       " ('schema_serialization_with_db_content', True),\n",
       " ('target_with_db_id', False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mt_uskg.task_args.seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.model.pretrain_model.encoder.embed_tokens is mt_uskg.model.pretrain_model.shared, \\\n",
    "mt_uskg.model.pretrain_model.decoder.embed_tokens is mt_uskg.model.pretrain_model.shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.model.preseqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [k for k,v in mt_uskg.model.named_parameters()]\n",
    "[k for k,v in mt_uskg.model.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    enc_sentences=[\"Translate to German: My name is Wolfgang and I live in Berlin\"],\n",
    "    dec_prompts=[\"Mein Name ist Wolfgang\"],\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ctu.run_model_forward_uskg(mt_uskg.model, **inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(odict_keys(['logits', 'past_key_values', 'encoder_last_hidden_state']),\n",
       " torch.Size([1, 5, 32102]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys(), out['logits'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32102,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = out[\"logits\"][0, -1].detach().cpu().numpy()\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, -1.8642352),\n",
       " (6, -9.727753),\n",
       " (5, -10.966707),\n",
       " (27, -11.037394),\n",
       " (213, -12.864212)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5 = sorted(list(enumerate(logits)), key=lambda p: -p[1])[:5]\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', ',', '.', 'I', 'where']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mt_uskg.tokenizer.decode([p[0]]) for p in top_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spider dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_train_path = '/home/yshao/Projects/SDR-analysis/data/spider/train+ratsql_graph.json'\n",
    "spider_dev_path = '/home/yshao/Projects/SDR-analysis/data/spider/dev+ratsql_graph.json'\n",
    "spider_db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev = ctu.load_raw_dataset(\n",
    "    data_filepath = spider_dev_path,\n",
    "    db_path=spider_db_dir,\n",
    "#     schema_cache=SCHEMA_CACHE\n",
    ")\n",
    "len(raw_spider_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.task_args.dataset.use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_spider_dev = s2s_spider.DevDataset(\n",
    "    args=mt_uskg.task_args,\n",
    "    raw_datasets=raw_spider_dev,\n",
    "    cache_root='../cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the average, minimum, and maximum age for all French singers?',\n",
       " '| concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id',\n",
       " \"select avg(age), min(age), max(age) from singer where country = 'France'\")"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 5\n",
    "processed_spider_dev[_id]['text_in'], \\\n",
    "processed_spider_dev[_id]['struct_in'], \\\n",
    "processed_spider_dev[_id]['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_enc_sentence = f\"{processed_spider_dev[_id]['text_in']}; structed knowledge: {processed_spider_dev[_id]['struct_in']}\"\n",
    "_toks = mt_uskg.tokenizer.tokenize(_enc_sentence)\n",
    "len(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # _occ_punct = set()\n",
    "\n",
    "# for _id in range(len(processed_spider_dev)):\n",
    "#     ex = processed_spider_dev[_id]\n",
    "# #     _occ_punct.update(set(string.punctuation) & set(ex['seq_out']))\n",
    "#     if '_(' in ex['struct_in']:\n",
    "#         print(_id, ex['question'])\n",
    "#         print(ex['struct_in'])\n",
    "#         print(ex['seq_out'])\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train set\n",
    "\n",
    "raw_spider_train = ctu.load_raw_dataset(\n",
    "    data_filepath = spider_train_path,\n",
    "    db_path=spider_db_dir,\n",
    ")\n",
    "processed_spider_train = s2s_spider.TrainDataset(\n",
    "    args=mt_uskg.task_args,\n",
    "    raw_datasets=raw_spider_train,\n",
    "    cache_root='../cache')\n",
    "len(processed_spider_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('| assets_maintenance | third_party_companies : company_id , company_type , company_name , company_address , other_company_details | maintenance_contracts : maintenance_contract_id , maintenance_contract_company_id , contract_start_date , contract_end_date , other_contract_details | parts : part_id , part_name , chargeable_yn , chargeable_amount , other_part_details | skills : skill_id , skill_code , skill_description | staff : staff_id , staff_name , gender , other_staff_details | assets : asset_id , maintenance_contract_id , supplier_company_id , asset_details , asset_make , asset_model , asset_acquired_date , asset_disposed_date , other_asset_details | asset_parts : asset_id , part_id | maintenance_engineers : engineer_id , company_id , first_name , last_name , other_details | engineer_skills : engineer_id , skill_id | fault_log : fault_log_entry_id , asset_id , recorded_by_staff_id , fault_log_entry_datetime , fault_description , other_fault_details | engineer_visits : engineer_visit_id , contact_staff_id , engineer_id , fault_log_entry_id , fault_status , visit_start_datetime , visit_end_datetime , other_visit_details | part_faults : part_fault_id , part_id , fault_short_name , fault_description , other_fault_details | fault_log_parts : fault_log_entry_id , part_fault_id , fault_status | skills_required_to_fix : part_fault_id , skill_id',\n",
       " 'What is the description of the type of the company who concluded its contracts most recently?',\n",
       " 'select t1.company_name from third_party_companies as t1 join maintenance_contracts as t2 on t1.company_id = t2.maintenance_contract_company_id join ref_company_types as t3 on t1.company_type_code = t3.company_type_code order by t2.contract_end_date desc limit 1',\n",
       " ['Third_Party_Companies',\n",
       "  'Maintenance_Contracts',\n",
       "  'Parts',\n",
       "  'Skills',\n",
       "  'Staff',\n",
       "  'Assets',\n",
       "  'Asset_Parts',\n",
       "  'Maintenance_Engineers',\n",
       "  'Engineer_Skills',\n",
       "  'Fault_Log',\n",
       "  'Engineer_Visits',\n",
       "  'Part_Faults',\n",
       "  'Fault_Log_Parts',\n",
       "  'Skills_Required_To_Fix'])"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ex = processed_spider_train[3153]\n",
    "_ex['struct_in'], _ex['text_in'], _ex['seq_out'], _ex['db_table_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out'])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mt_uskg.tokenizer.tokenize(processed_spider_train[3086]['struct_in']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "- Aspects-related helpers are merged into create_analysis_sample_dicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp6_ob_by_exp_tok(samples):\n",
    "    # samples: usually `good_samples`\n",
    "    \n",
    "    # Key: (expect_tok, sect_k, layer) -> [scores]\n",
    "    trace_scores_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    trace_scores_avg_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "    trace_scores_cnt_by_exp_tok = defaultdict(int)  # no sect key & layer key \n",
    "\n",
    "    trace_sample_ids_by_exp_tok = defaultdict(list)\n",
    "    \n",
    "    for i, d in enumerate(samples):\n",
    "        expect = d['expect']\n",
    "        trace_sample_ids_by_exp_tok[expect].append(i)\n",
    "        for sect_k, sect_d in d['trace_scores'].items():\n",
    "            for layer_k, v in sect_d.items():\n",
    "                trace_scores_by_exp_tok[expect][sect_k][layer_k].append(v)\n",
    "\n",
    "    for exp_tok, d1 in trace_scores_by_exp_tok.items():\n",
    "        if exp_tok.isnumeric(): continue\n",
    "        for sect_k, d2 in d1.items():\n",
    "            for layer_k, scores in d2.items():\n",
    "                if len(scores) <= 2: continue\n",
    "                trace_scores_avg_by_exp_tok[exp_tok][sect_k][layer_k] = np.mean(scores)\n",
    "                trace_scores_cnt_by_exp_tok[exp_tok] = len(scores)\n",
    "    \n",
    "    return {\n",
    "        'avg': trace_scores_avg_by_exp_tok,\n",
    "        'cnt': trace_scores_cnt_by_exp_tok,\n",
    "        'sample_ids': trace_sample_ids_by_exp_tok,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_2D_dict(d):\n",
    "    out_d = defaultdict(lambda: defaultdict(np.nan))\n",
    "    for k1, d1 in d.items():\n",
    "        for k2, v in d1.items():\n",
    "            out_d[k2][k1] = v\n",
    "    return out_d\n",
    "\n",
    "def format_print_1D_dict(d, sort_by=None, reverse=False, head_col_w=10, col_w=6):\n",
    "    # sort: None, 'key' or 'value'\n",
    "    \n",
    "    item_l = list(d.items())\n",
    "    if sort_by == 'key':\n",
    "        item_l.sort(reverse=reverse)\n",
    "    elif sort_by == 'value':\n",
    "        item_l.sort(key=lambda x: (x[1], x[0]), reverse=reverse)\n",
    "    \n",
    "    decm_w = col_w - 2\n",
    "    \n",
    "    for k, v in item_l:\n",
    "        print(f'{k:<{head_col_w}s}{v:.{decm_w}f}')\n",
    "\n",
    "def format_print_2D_dict(d, \n",
    "                         all_k1=None, \n",
    "                         all_k2=None, \n",
    "                         sort_k1_kwargs=None, \n",
    "                         sort_k2_kwargs=None, \n",
    "                         head_col_w=12, \n",
    "                         col_w=6,\n",
    "                         decm_w=4):\n",
    "    if all_k1 is None:\n",
    "        all_k1 = list(d.keys())\n",
    "        if sort_k1_kwargs is not None:\n",
    "            all_k1.sort(**sort_k1_kwargs)\n",
    "    \n",
    "    if all_k2 is None:\n",
    "        for k1, d1 in d.items():\n",
    "            d1_keys = list(d1.keys())\n",
    "            if all_k2 is None:\n",
    "                all_k2 = d1_keys\n",
    "            else:\n",
    "                if set(d1_keys) != set(all_k2):\n",
    "                    print('Warning:\\n', d1_keys, '\\n', all_k2)\n",
    "            # all_k2.update(list(d1.keys()))\n",
    "        if sort_k2_kwargs is not None:\n",
    "            all_k2.sort(**sort_k2_kwargs)\n",
    "    \n",
    "    print_str = '\\t'.join(['X' * head_col_w] + [f'{k2:<{col_w}s}' for k2 in all_k2]) + '\\n'\n",
    "    \n",
    "    for k1 in all_k1:\n",
    "        d1 = d[k1]\n",
    "        print_str += f'{k1:<{head_col_w}s}'\n",
    "        for k2 in all_k2:\n",
    "            v = d1[k2]\n",
    "            print_str += f'\\t{v:<{col_w}.{decm_w}f}'\n",
    "        print_str += '\\n'\n",
    "    \n",
    "    print(print_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = '/home/yshao/Projects/language/language/xsp/data/spider/tables.json'\n",
    "db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmaps = sp_eval.build_foreign_key_map_from_json(table_path)\n",
    "evaluator = sp_eval.Evaluator(db_dir=db_dir, kmaps=kmaps, etype='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctu.evaluate_hardness.evaluator = evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0, 0, 'hard')"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "_sql_str = 'select t1.birth_date from people as t1 join poker_player as t2 on t1.people_id = t2.people_id order by t2.earnings asc limit 1'\n",
    "db_name = 'poker_player'\n",
    "schema = evaluator.schemas[db_name]\n",
    "_sql = sp_eval.get_sql(schema, _sql_str)\n",
    "sp_eval.count_component1(_sql), sp_eval.count_component2(_sql), sp_eval.count_others(_sql), \\\n",
    "evaluator.eval_hardness(_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hard'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.evaluate_hardness(_sql_str, db_name, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<uskg.third_party.spider.evaluation.Evaluator at 0x7f81c83e1f40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.evaluate_hardness.evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_prompt = 'select avg(age), min(age), max(age) from'\n",
    "ctu.detect_node_role(dec_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dicts = ctu.create_analysis_sample_dicts(\n",
    "    mt=mt_uskg,\n",
    "    ex=processed_spider_dev[100],\n",
    "    subject_type='table'\n",
    ")\n",
    "len(a_dicts), [d['expect'] for d in a_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = a_dicts[2]\n",
    "ctu.check_table_text_match(a_ex, 'car_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex['text_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-2.3: section corruption effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp2.3_section_corruption_effect/exp=2.3.1_dev_{expect_type}-replace=True-noise=0.0.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2039, (1438, 1438), 339, 262, 601, 'good / correct = 1438 / 1700')"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d.get('is_good_sample', True):\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += v\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': defaultdict(int,\n",
       "             {'embed': 0.7823026149835357, 'final_enc': 0.8686982057318997}),\n",
       " 'struct': defaultdict(int,\n",
       "             {'embed': 0.8156400979291917, 'final_enc': 0.8783989991454734}),\n",
       " 'self': defaultdict(int,\n",
       "             {'embed': 0.9009977694993451, 'final_enc': 0.9186035738517472}),\n",
       " 'struct_context': defaultdict(int,\n",
       "             {'embed': 0.8188476237862654, 'final_enc': 0.9366639298185229}),\n",
       " 'other': defaultdict(int,\n",
       "             {'embed': 0.9668801645956868, 'final_enc': 0.9874240734377392}),\n",
       " 'text+other': defaultdict(int,\n",
       "             {'embed': 0.7898215747748188, 'final_enc': 0.8762273743275982}),\n",
       " 'all': defaultdict(int,\n",
       "             {'embed': 0.05134222172979076, 'final_enc': 0.7129756825101383})}"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\tembed \tfinal_enc\n",
      "text        \t0.7823\t0.8687\n",
      "struct      \t0.8156\t0.8784\n",
      "self        \t0.9010\t0.9186\n",
      "struct_context\t0.8188\t0.9367\n",
      "other       \t0.9669\t0.9874\n",
      "text+other  \t0.7898\t0.8762\n",
      "all         \t0.0513\t0.7130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(trace_scores_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-4.1: attention weights distribution for all nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking too much memory...\n",
    "\n",
    "# res_path = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/exp=4.1_train.jsonl'\n",
    "\n",
    "# with open(res_path, 'r') as f:\n",
    "#     all_train_samples = [ujson.loads(l) for l in tqdm(f)]\n",
    "# len(all_train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_path = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/exp=4.1_dev.jsonl'\n",
    "\n",
    "# with open(res_path, 'r') as f:\n",
    "#     all_dev_samples = [ujson.loads(l) for l in tqdm(f)]\n",
    "# len(all_dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _toks = mt_uskg.tokenizer.tokenize(all_samples[100]['trace_results']['enc_sentence'], add_special_tokens=True)\n",
    "# len(_toks), _toks[136:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/exp=4.1_dev.jsonl'\n",
    "samples_N = len(processed_spider_dev)\n",
    "\n",
    "# check one sample (ex)\n",
    "with open(res_path, 'r') as f:\n",
    "    for l in f:\n",
    "        ex = ujson.loads(l)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['ex_id', 'trace_results']),\n",
       " dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'db_id', 'col_self_ranges', 'col_context_ranges', 'tab_self_ranges', 'tab_context_ranges', 'category', 'occ_cols', 'non_occ_cols', 'occ_tabs', 'non_occ_tabs', 'attentions']))"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.keys(), ex['trace_results'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_sentence : How many singers do we have?; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id\n",
      "seq_out : select count(*) from singer\n",
      "dec_prompt : select\n",
      "db_id : concert_singer\n",
      "col_self_ranges : {'location': [[28, 33]], 'capacity': [[34, 39]], 'highest': [[37, 42]], 'lowest': [[40, 45]], 'average': [[43, 47]], 'country': [[57, 62]], 'song_name': [[60, 67]], 'song_release_year': [[65, 74]], 'age': [[72, 77]], 'is_male': [[75, 81]], 'concert_name': [[88, 95]], 'theme': [[93, 98]], 'year': [[102, 106]]}\n",
      "col_context_ranges : {'location': [[15, 28], [33, 125]], 'capacity': [[15, 34], [39, 125]], 'highest': [[15, 37], [42, 125]], 'lowest': [[15, 40], [45, 125]], 'average': [[15, 43], [47, 125]], 'country': [[15, 57], [62, 125]], 'song_name': [[15, 60], [67, 125]], 'song_release_year': [[15, 65], [74, 125]], 'age': [[15, 72], [77, 125]], 'is_male': [[15, 75], [81, 125]], 'concert_name': [[15, 88], [95, 125]], 'theme': [[15, 93], [98, 125]], 'year': [[15, 102], [106, 125]]}\n",
      "tab_self_ranges : {'singer': [[46, 50]], 'stadium': [[20, 24]], 'concert': [[80, 84]], 'singer_in_concert': [[105, 115]]}\n",
      "tab_context_ranges : {'singer': [[15, 46], [50, 125]], 'stadium': [[15, 20], [24, 125]], 'concert': [[15, 80], [84, 125]], 'singer_in_concert': [[15, 105], [115, 125]]}\n",
      "category : {'sql_hardness': 'easy'}\n",
      "occ_cols : []\n",
      "non_occ_cols : ['location', 'capacity', 'highest', 'lowest', 'average', 'country', 'song_name', 'song_release_year', 'age', 'is_male', 'concert_name', 'theme', 'year']\n",
      "occ_tabs : ['singer']\n",
      "non_occ_tabs : ['stadium', 'concert', 'singer_in_concert']\n"
     ]
    }
   ],
   "source": [
    "for k, v in ex['trace_results'].items():\n",
    "    if k != 'attentions':\n",
    "        print(k, ':', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict: {layer -> {head_id -> {occ_type -> {section -> List[att_w]}}}}; list for all samples, all nodes in each occ_type \n",
    "# Perhaps too large...\n",
    "# att_weights_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "att_weights_sum_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "\n",
    "# Dict: {occ_type -> int}\n",
    "att_weights_cnt_dict = defaultdict(int)\n",
    "\n",
    "# Dict: {layer -> {head_id -> {occ_type -> {section -> avg_att_w}}}}; averaged by all samples, all nodes in each occ_type \n",
    "att_weights_avg_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "\n",
    "# Dict: {occ_type -> List[Tuple(ex_id, node_name)]}\n",
    "sample_backtrace_dict = defaultdict(list)\n",
    "\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    for l in tqdm(f, total=samples_N):\n",
    "        ex = ujson.loads(l)\n",
    "        ex_id = ex['ex_id']\n",
    "\n",
    "        if 'err_msg' in ex:\n",
    "            continue\n",
    "\n",
    "        result_d = ex['trace_results']\n",
    "\n",
    "        all_col_atts = result_d['attentions']['col']\n",
    "        all_tab_atts = result_d['attentions']['tab']\n",
    "\n",
    "        for col_occ_type in ['occ_cols', 'non_occ_cols']:\n",
    "            for col in result_d[col_occ_type]:\n",
    "                sect_att_dict = all_col_atts[col]\n",
    "                sample_backtrace_dict[col_occ_type].append((ex_id, col))\n",
    "                att_weights_cnt_dict[col_occ_type] += 1\n",
    "\n",
    "                for sect_k, att_mat in sect_att_dict.items():\n",
    "                    att_mat = np.array(ctu.nested_list_processing(att_mat, func=float))\n",
    "                    n_layers, n_heads = att_mat.shape\n",
    "                    for l in range(n_layers):\n",
    "                        for h in range(n_heads):\n",
    "                            att_w = att_mat[l, h]\n",
    "                            # att_weights_dict[l][h][col_occ_type][sect_k].append(att_w)\n",
    "                            att_weights_sum_dict[l][h][col_occ_type][sect_k] += att_w\n",
    "\n",
    "        for tab_occ_type in ['occ_tabs', 'non_occ_tabs']:\n",
    "            for tab in result_d[tab_occ_type]:\n",
    "                sect_att_dict = all_tab_atts[tab]\n",
    "                sample_backtrace_dict[tab_occ_type].append((ex_id, tab))\n",
    "                att_weights_cnt_dict[tab_occ_type] += 1\n",
    "\n",
    "                for sect_k, att_mat in sect_att_dict.items():\n",
    "                    att_mat = np.array(ctu.nested_list_processing(att_mat, func=float))\n",
    "                    n_layers, n_heads = att_mat.shape\n",
    "                    for l in range(n_layers):\n",
    "                        for h in range(n_heads):\n",
    "                            att_w = att_mat[l, h]\n",
    "                            # att_weights_dict[l][h][tab_occ_type][sect_k].append(att_w)\n",
    "                            att_weights_sum_dict[l][h][tab_occ_type][sect_k] += att_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_id, layer_d in att_weights_sum_dict.items():\n",
    "    for h_id, head_d in layer_d.items():\n",
    "        for occ_type, occ_type_d in head_d.items():\n",
    "            att_w_cnt = att_weights_cnt_dict[occ_type]\n",
    "            for sect_k, att_w_sum in occ_type_d.items():\n",
    "                att_weights_avg_dict[l_id][h_id][occ_type][sect_k] = att_w_sum / att_w_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'non_occ_cols': defaultdict(float,\n",
       "                         {'prefix#0': 0.00506160506160524,\n",
       "                          'prefix#1': 0.018118548118547986,\n",
       "                          'prefix#2': 0.006291042291042455,\n",
       "                          'prefix#3': 0.00046553446553446523,\n",
       "                          'prefix#4': 0.049131535131533094,\n",
       "                          'prefix#5': 0.03181684981684876,\n",
       "                          'prefix#6': 0.01746253746253744,\n",
       "                          'prefix#7': 0.0016443556443556857,\n",
       "                          'prefix#8': 8.52480852480853e-05,\n",
       "                          'prefix#9': 0.016844488844488335,\n",
       "                          'text': 0.016877122877122598,\n",
       "                          'self': 0.30191874791874695,\n",
       "                          'context': 0.5137555777555907,\n",
       "                          'others': 0.014923076923077245}),\n",
       "             'occ_tabs': defaultdict(float,\n",
       "                         {'prefix#0': 0.002228163992869864,\n",
       "                          'prefix#1': 0.004188948306595357,\n",
       "                          'prefix#2': 0.020843731431966855,\n",
       "                          'prefix#3': 0.0,\n",
       "                          'prefix#4': 0.015163398692810463,\n",
       "                          'prefix#5': 0.013083778966131835,\n",
       "                          'prefix#6': 0.029340463458110557,\n",
       "                          'prefix#7': 0.0012240047534165187,\n",
       "                          'prefix#8': 2.9708853238265006e-05,\n",
       "                          'prefix#9': 0.0027450980392156685,\n",
       "                          'text': 0.039869281045751916,\n",
       "                          'self': 0.23393345216874642,\n",
       "                          'context': 0.608401663695777,\n",
       "                          'others': 0.022537136066547933}),\n",
       "             'non_occ_tabs': defaultdict(float,\n",
       "                         {'prefix#0': 0.001651814131126663,\n",
       "                          'prefix#1': 0.0028453214513048724,\n",
       "                          'prefix#2': 0.008739656269891868,\n",
       "                          'prefix#3': 0.0015340547422024197,\n",
       "                          'prefix#4': 0.020782940802036923,\n",
       "                          'prefix#5': 0.010076384468491401,\n",
       "                          'prefix#6': 0.035245066836410155,\n",
       "                          'prefix#7': 0.0009388924252068686,\n",
       "                          'prefix#8': 4.455760661998726e-05,\n",
       "                          'prefix#9': 0.0021101209420750938,\n",
       "                          'text': 0.025620623806492812,\n",
       "                          'self': 0.23067472947167186,\n",
       "                          'context': 0.6346880967536631,\n",
       "                          'others': 0.018771483131763134}),\n",
       "             'occ_cols': defaultdict(float,\n",
       "                         {'prefix#0': 0.004125874125874112,\n",
       "                          'prefix#1': 0.05966533466533466,\n",
       "                          'prefix#2': 0.005469530469530419,\n",
       "                          'prefix#3': 0.00031468531468531474,\n",
       "                          'prefix#4': 0.013956043956043987,\n",
       "                          'prefix#5': 0.04029970029970037,\n",
       "                          'prefix#6': 0.009730269730269688,\n",
       "                          'prefix#7': 0.002407592407592392,\n",
       "                          'prefix#8': 2.9970029970029973e-05,\n",
       "                          'prefix#9': 0.032472527472527414,\n",
       "                          'text': 0.02718281718281724,\n",
       "                          'self': 0.3122077922077948,\n",
       "                          'context': 0.46994505494505523,\n",
       "                          'others': 0.016243756243756572})})"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weights_avg_dict[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dump results \n",
    "- do not rerun unless updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_path = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/exp=4.1_dev_dump.pkl'\n",
    "\n",
    "# dump_d = {\n",
    "#     'att_weights_sum_dict': ctu.nested_json_processing(att_weights_sum_dict, func=lambda x: x),   # defaultdict -> dict \n",
    "#     'att_weights_cnt_dict': ctu.nested_json_processing(att_weights_cnt_dict, func=lambda x: x),\n",
    "#     'att_weights_avg_dict': ctu.nested_json_processing(att_weights_avg_dict, func=lambda x: x),\n",
    "#     'sample_backtrace_dict': ctu.nested_json_processing(sample_backtrace_dict, func=lambda x: x),\n",
    "# }\n",
    "\n",
    "# with open(res_path, 'wb') as f:\n",
    "#     pickle.dump(dump_d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/exp=4.1_train_dump.pkl'\n",
    "\n",
    "with open(res_path, 'rb') as f:\n",
    "    dump_d = pickle.load(f)\n",
    "\n",
    "att_weights_sum_dict = dump_d['att_weights_sum_dict']\n",
    "att_weights_cnt_dict = dump_d['att_weights_cnt_dict']\n",
    "att_weights_avg_dict = dump_d['att_weights_avg_dict']\n",
    "sample_backtrace_dict = dump_d['sample_backtrace_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'occ_cols': {'prefix#0': 0.005590211530485306,\n",
       "  'prefix#1': 0.038914143508916546,\n",
       "  'prefix#2': 0.011377021982580325,\n",
       "  'prefix#3': 0.00034840315221899436,\n",
       "  'prefix#4': 0.021940273745333354,\n",
       "  'prefix#5': 0.04742015761094831,\n",
       "  'prefix#6': 0.01801990875155525,\n",
       "  'prefix#7': 0.0029879717959352893,\n",
       "  'prefix#8': 6.470344255495649e-05,\n",
       "  'prefix#9': 0.028151804230609197,\n",
       "  'text': 0.028184985483199768,\n",
       "  'self': 0.29681045209456924,\n",
       "  'context': 0.4812252177519773,\n",
       "  'others': 0.013333886354210116},\n",
       " 'non_occ_cols': {'prefix#0': 0.007513540287063308,\n",
       "  'prefix#1': 0.014389637238746093,\n",
       "  'prefix#2': 0.007340073865897553,\n",
       "  'prefix#3': 0.0003575927899990462,\n",
       "  'prefix#4': 0.017249625825066686,\n",
       "  'prefix#5': 0.049186182985021795,\n",
       "  'prefix#6': 0.02434915097285215,\n",
       "  'prefix#7': 0.002757480806710441,\n",
       "  'prefix#8': 0.0001255504947723164,\n",
       "  'prefix#9': 0.012217161438983645,\n",
       "  'text': 0.016699938624532496,\n",
       "  'self': 0.29822700304725547,\n",
       "  'context': 0.5328514821633931,\n",
       "  'others': 0.010901357797368526},\n",
       " 'occ_tabs': {'prefix#0': 0.0021486448728695335,\n",
       "  'prefix#1': 0.0034516159076092364,\n",
       "  'prefix#2': 0.02094067244109103,\n",
       "  'prefix#3': 0.0004964142684176185,\n",
       "  'prefix#4': 0.03373381763993547,\n",
       "  'prefix#5': 0.03593182453199076,\n",
       "  'prefix#6': 0.016710440532737007,\n",
       "  'prefix#7': 0.0067858805997952085,\n",
       "  'prefix#8': 3.3528918692372184e-05,\n",
       "  'prefix#9': 0.0014082145850796153,\n",
       "  'text': 0.03873614603706566,\n",
       "  'self': 0.23159914314985575,\n",
       "  'context': 0.579713141473412,\n",
       "  'others': 0.023304461208902994},\n",
       " 'non_occ_tabs': {'prefix#0': 0.002819191572197486,\n",
       "  'prefix#1': 0.004242146646818907,\n",
       "  'prefix#2': 0.011586320088552267,\n",
       "  'prefix#3': 0.00041795488377418594,\n",
       "  'prefix#4': 0.02032940188556706,\n",
       "  'prefix#5': 0.033704339860298076,\n",
       "  'prefix#6': 0.02492843238291243,\n",
       "  'prefix#7': 0.004646742242070457,\n",
       "  'prefix#8': 3.397076224283372e-05,\n",
       "  'prefix#9': 0.0018057941142791563,\n",
       "  'text': 0.022877972441690972,\n",
       "  'self': 0.23016832703537557,\n",
       "  'context': 0.6218714454750076,\n",
       "  'others': 0.014978815985340713}}"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weights_avg_dict[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_types = ['occ_cols', 'non_occ_cols']\n",
    "\n",
    "for l_id in [1, 6, 12, 18, 23]:\n",
    "    # Dict: occ_type -> sect -> List[att_w]; list for all heads \n",
    "    layer_ob_dict = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for h_id in range(len(att_weights_avg_dict[l_id])):\n",
    "        for occ in occ_types:\n",
    "            for sect_k, att_w in att_weights_avg_dict[l_id][h_id][occ].items():\n",
    "                att_w_str = np.format_float_positional(att_w, precision=2, min_digits=2)\n",
    "                layer_ob_dict[occ][sect_k].append(att_w_str)\n",
    "    \n",
    "    print(f'===== Layer {l_id} =====')\n",
    "    for occ in occ_types:\n",
    "        print(occ)\n",
    "        for sect_k, att_w_list in layer_ob_dict[occ].items():\n",
    "            att_w_list_str = \"  \".join(att_w_list)\n",
    "            print(f'{sect_k:<10s}{att_w_list_str}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(att_weights_avg_dict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probing attn - data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res_path = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/exp=4.1_train_dump.pkl'\n",
    "dev_res_path = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/exp=4.1_dev_dump.pkl'\n",
    "\n",
    "with open(train_res_path, 'rb') as f:\n",
    "    train_dump_d = pickle.load(f)\n",
    "\n",
    "with open(dev_res_path, 'rb') as f:\n",
    "    dev_dump_d = pickle.load(f)\n",
    "\n",
    "# att_weights_sum_dict = train_dump_d['att_weights_sum_dict']\n",
    "# att_weights_cnt_dict = train_dump_d['att_weights_cnt_dict']\n",
    "# att_weights_avg_dict = train_dump_d['att_weights_avg_dict']\n",
    "# sample_backtrace_dict = train_dump_d['sample_backtrace_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict: layer -> head -> sect_k -> heuristic diff val \n",
    "heu_diff_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "heu_diff_flat_dict = dict()\n",
    "\n",
    "occ_cls_A = 'occ_cols'\n",
    "occ_cls_B = 'non_occ_cols'\n",
    "\n",
    "def heu_diff_func(a, b):\n",
    "    return (a + 0.1) / (b + 0.1) - (b + 0.1) / (a + 0.1) + a - b\n",
    "\n",
    "# Dict: layer -> head -> occ -> sect_k -> att_w_avg \n",
    "train_att_weights_avg_dict = train_dump_d['att_weights_avg_dict']\n",
    "\n",
    "for l_id, layer_d in train_att_weights_avg_dict.items():\n",
    "    for h_id, head_d in layer_d.items():\n",
    "        for sect_k, _ in head_d[occ_cls_A].items():\n",
    "            vA = train_att_weights_avg_dict[l_id][h_id][occ_cls_A][sect_k]\n",
    "            vB = train_att_weights_avg_dict[l_id][h_id][occ_cls_B][sect_k]\n",
    "            heu_diff = heu_diff_func(vA, vB)\n",
    "            heu_diff_dict[l_id][h_id][sect_k] = heu_diff\n",
    "            heu_diff_flat_dict[f'L{l_id}-H{h_id}-{sect_k}'] = heu_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5376"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heu_diff_flat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_feats_info = []\n",
    "feat_name2tuple = dict()\n",
    "\n",
    "for l_id, layer_d in heu_diff_dict.items():\n",
    "    for h_id, head_d in layer_d.items():\n",
    "        for sect_k, v in head_d.items():\n",
    "            if abs(v) > 2.0:\n",
    "                feat_name = f'L{l_id}-H{h_id}-{sect_k}'\n",
    "                use_feats_info.append((feat_name, v))\n",
    "                feat_name2tuple[feat_name] = (l_id, h_id, sect_k)\n",
    "\n",
    "len(use_feats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_feats_info_dict = {\n",
    "    'feats': [feat for feat, v in use_feats_info],\n",
    "    'feat_vals': use_feats_info,\n",
    "    'feat_name2tuple': feat_name2tuple,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_out_dir = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/probing/{occ_cls_A}-vs-{occ_cls_B}'\n",
    "os.makedirs(probe_out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_feats_info_path = os.path.join(probe_out_dir, 'use_feats.json')\n",
    "\n",
    "# with open(use_feats_info_path, 'w') as f:\n",
    "#     json.dump(use_feats_info_dict, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 99)"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load feats meta info\n",
    "probe_out_dir = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/probing/{occ_cls_A}-vs-{occ_cls_B}'\n",
    "use_feats_info_path = os.path.join(probe_out_dir, 'use_feats.json')\n",
    "\n",
    "with open(use_feats_info_path, 'r') as f:\n",
    "    use_feats_info_dict = json.load(f)\n",
    "\n",
    "feats = use_feats_info_dict['feats']\n",
    "feat_name2tuple = use_feats_info_dict['feat_name2tuple']\n",
    "\n",
    "len(feats), len(feat_name2tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls2id = {\n",
    "    'occ_cols': 0,\n",
    "    'non_occ_cols': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23246505d1a404b9b57ebb55b4dc685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(102599, 102599, 99)"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Collect X and y from raw output (each node is a sample) \n",
    "\n",
    "train_raw_res_path = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/exp=4.1_train.jsonl'\n",
    "samples_N = 7000\n",
    "\n",
    "train_X = []\n",
    "train_y = []\n",
    "\n",
    "with open(train_raw_res_path, 'r') as f:\n",
    "    for l in tqdm(f, total=samples_N):\n",
    "        ex = ujson.loads(l)\n",
    "        ex_id = ex['ex_id']\n",
    "\n",
    "        if 'err_msg' in ex:\n",
    "            continue\n",
    "\n",
    "        result_d = ex['trace_results']\n",
    "\n",
    "        all_col_atts = result_d['attentions']['col']\n",
    "#         all_tab_atts = result_d['attentions']['tab']\n",
    "\n",
    "        for occ_cls, cls_id in cls2id.items():\n",
    "            for col in list(set(result_d[occ_cls])):   # remove duplicates here \n",
    "                sect_att_dict = all_col_atts[col]\n",
    "                feat_vec = []\n",
    "                for feat_name in feats:\n",
    "                    l_id, h_id, sect_k = feat_name2tuple[feat_name]\n",
    "                    feat_val = float(sect_att_dict[sect_k][l_id][h_id])\n",
    "                    feat_vec.append(feat_val)\n",
    "                \n",
    "                train_X.append(feat_vec)\n",
    "                train_y.append(cls_id)\n",
    "\n",
    "len(train_X), len(train_y), len(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save X, y\n",
    "with open(os.path.join(probe_out_dir, 'train_X.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_X, f)\n",
    "with open(os.path.join(probe_out_dir, 'train_y.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf75c6ce8ce48128c8bf7e8c7d4df50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(16640, 16640, 99)"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_raw_res_path = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/exp=4.1_dev.jsonl'\n",
    "samples_N = 1034\n",
    "\n",
    "test_X = []\n",
    "test_y = []\n",
    "\n",
    "with open(dev_raw_res_path, 'r') as f:\n",
    "    for l in tqdm(f, total=samples_N):\n",
    "        ex = ujson.loads(l)\n",
    "        ex_id = ex['ex_id']\n",
    "\n",
    "        if 'err_msg' in ex:\n",
    "            continue\n",
    "\n",
    "        result_d = ex['trace_results']\n",
    "\n",
    "        all_col_atts = result_d['attentions']['col']\n",
    "#         all_tab_atts = result_d['attentions']['tab']\n",
    "\n",
    "        for occ_cls, cls_id in cls2id.items():\n",
    "            for col in list(set(result_d[occ_cls])):   # remove duplicates here \n",
    "                sect_att_dict = all_col_atts[col]\n",
    "                feat_vec = []\n",
    "                for feat_name in feats:\n",
    "                    l_id, h_id, sect_k = feat_name2tuple[feat_name]\n",
    "                    feat_val = float(sect_att_dict[sect_k][l_id][h_id])\n",
    "                    feat_vec.append(feat_val)\n",
    "                \n",
    "                test_X.append(feat_vec)\n",
    "                test_y.append(cls_id)\n",
    "\n",
    "len(test_X), len(test_y), len(test_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save X, y\n",
    "with open(os.path.join(probe_out_dir, 'test_X.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_X, f)\n",
    "with open(os.path.join(probe_out_dir, 'test_y.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78, 0.58, 0.96, 0.89, 0.98, 0.88, 0.52, 0.95, 0.97, 0.83],\n",
       "       [0.92, 0.69, 0.96, 0.83, 0.45, 0.73, 0.65, 0.96, 1.  , 0.36],\n",
       "       [0.63, 0.44, 0.91, 0.82, 0.97, 0.68, 0.52, 0.98, 0.98, 0.74],\n",
       "       [0.04, 0.27, 0.  , 0.87, 0.32, 0.43, 0.47, 0.96, 1.  , 0.17],\n",
       "       [0.64, 0.42, 0.94, 0.91, 0.97, 0.69, 0.34, 0.98, 0.88, 0.48],\n",
       "       [0.  , 0.12, 0.  , 0.17, 0.06, 0.13, 0.19, 0.32, 0.01, 0.04],\n",
       "       [0.63, 0.43, 0.95, 0.89, 0.98, 0.66, 0.4 , 0.98, 0.93, 0.55],\n",
       "       [0.  , 0.12, 0.  , 0.42, 0.07, 0.13, 0.16, 0.19, 0.01, 0.01],\n",
       "       [0.06, 0.15, 0.  , 0.24, 0.17, 0.49, 0.02, 0.12, 0.12, 0.23],\n",
       "       [0.97, 0.3 , 0.48, 0.43, 0.14, 0.44, 0.19, 0.06, 0.84, 0.37]])"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Have duplicates? - no\n",
    "_check_ids = [i for i in range(len(test_y)) if test_y[i] == 0][:10]\n",
    "np.array(test_X)[_check_ids, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probing attn - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(probe_out_dir, 'train_X.pkl'), 'rb') as f:\n",
    "    train_X = pickle.load(f)\n",
    "with open(os.path.join(probe_out_dir, 'train_y.pkl'), 'rb') as f:\n",
    "    train_y = pickle.load(f)\n",
    "with open(os.path.join(probe_out_dir, 'test_X.pkl'), 'rb') as f:\n",
    "    test_X = pickle.load(f)\n",
    "with open(os.path.join(probe_out_dir, 'test_y.pkl'), 'rb') as f:\n",
    "    test_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102599, 102599, 99, 16640, 16640, 99)"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(train_y), len(train_X[0]), \\\n",
    "len(test_X), len(test_y), len(test_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only use a subset of feats? - no improve, as expected... \n",
    "\n",
    "# sub_f_ids = []\n",
    "# for f_i, (feat_name, feat_val) in enumerate(use_feats_info):\n",
    "#     if abs(feat_val) > 4:\n",
    "#         sub_f_ids.append(f_i)\n",
    "\n",
    "# [use_feats_info[i] for i in sub_f_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = [[x[i] for i in sub_f_ids] for x in train_X]\n",
    "# test_X = [[x[i] for i in sub_f_ids] for x in test_X]\n",
    "# np.array(train_X).shape, np.array(test_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_val = 1.0\n",
    "\n",
    "# clf = LogisticRegression(C=1.0)\n",
    "\n",
    "logreg = LogisticRegression(C=C_val, max_iter=1000)\n",
    "scaler = StandardScaler()\n",
    "clf = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('logreg', logreg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('logreg', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('logreg', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(probe_out_dir, f'trained_scale_clf_C={C_val}.pkl'), 'wb') as f:\n",
    "#     pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results(preds, labels, f1_cls):\n",
    "    \"\"\"f1_cls: the class to compute F1 score on\"\"\"\n",
    "    assert len(preds) == len(labels), (len(preds), len(labels))\n",
    "    \n",
    "    N = len(preds)\n",
    "    N_pred = sum([p == f1_cls for p in preds])\n",
    "    N_true = sum([y == f1_cls for y in labels])\n",
    "    N_pred_true = sum([p == y == f1_cls for p, y in zip(preds, labels)])\n",
    "    N_corr = sum([p == y for p, y in zip(preds, labels)])\n",
    "    \n",
    "    Acc = N_corr / N\n",
    "    P = N_pred_true / N_pred\n",
    "    R = N_pred_true / N_true\n",
    "    F1 = (2 * P * R) / (P + R + 1e-9)\n",
    "    \n",
    "    res_dict = {\n",
    "        'Acc': Acc,\n",
    "        'P': P,\n",
    "        'R': R,\n",
    "        'F1': F1,\n",
    "    }\n",
    "    \n",
    "    for k, v in res_dict.items():\n",
    "        print(f'{k}\\t{v:.4f}')\n",
    "    \n",
    "    return res_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09639597,  0.01532772,  0.07832486, -0.15533311, -0.01392892,\n",
       "        -0.22638873, -0.14406257,  0.09896343,  0.13709107, -0.0838726 ,\n",
       "         0.13207204, -0.07925985, -0.03770774, -0.00595991,  0.0758152 ,\n",
       "         0.01066828,  0.07825765,  0.16469661,  0.05137414,  0.31637049,\n",
       "         0.10691322, -0.69427748, -0.03884708,  0.03260927,  0.11772163,\n",
       "         0.34440898, -0.02701317,  0.36173607, -0.095233  , -0.04127651,\n",
       "        -0.02898593, -0.61401068,  0.04967187, -0.02934451,  0.25257069,\n",
       "        -0.69791418, -0.29124649, -0.10762437,  0.33133284,  0.08670616,\n",
       "        -0.35429363,  0.18354341, -0.07732019,  0.43660091,  0.12727427,\n",
       "         0.77473455, -0.00536978, -0.18288719,  0.30296189, -0.02659497,\n",
       "        -0.12644743, -0.28158617,  0.26223986,  0.12994199,  0.2896086 ,\n",
       "         0.51471449, -0.3773104 , -0.1979374 , -0.28664154,  1.07788551,\n",
       "        -0.14624692,  0.58240512,  0.9270052 , -0.55910419,  0.13400262,\n",
       "         0.1038081 ,  1.13520425, -0.05669287,  0.19346016,  0.05870277,\n",
       "        -0.1806054 ,  0.04706873, -0.2204752 ,  0.29898519, -0.07355432,\n",
       "        -0.23707931,  0.05122526,  0.04428308,  0.18836438, -0.12096586,\n",
       "         0.13608583,  0.78143608,  1.11965897, -0.02060306,  0.51115019,\n",
       "         0.15181056, -0.1576159 ,  0.79716531, -0.8445787 ,  0.65486693,\n",
       "         3.7998397 ,  0.75320704,  0.63807172,  0.31170692,  1.73897491,\n",
       "        -0.30871239, -0.6114607 , -0.25354446,  0.10155371]])"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102599, 93170)"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = clf.predict(train_X)\n",
    "len(train_preds), sum(train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc\t0.9829\n",
      "P\t0.9230\n",
      "R\t0.8946\n",
      "F1\t0.9086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Acc': 0.9829335568572793,\n",
       " 'P': 0.9230034998409163,\n",
       " 'R': 0.8946340460526315,\n",
       " 'F1': 0.9085973790480677}"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_results(train_preds, train_y, f1_cls=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16640, 15040)"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = clf.predict(test_X)\n",
    "len(test_preds), sum(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc\t0.9729\n",
      "P\t0.8669\n",
      "R\t0.8535\n",
      "F1\t0.8602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Acc': 0.9728966346153847,\n",
       " 'P': 0.866875,\n",
       " 'R': 0.8535384615384616,\n",
       " 'F1': 0.86015503825972}"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_results(test_preds, test_y, f1_cls=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9728, 1625)"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y) - sum(train_y), len(test_y) - sum(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.0: dirty attention vector effect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'column'\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_0_dirty_attention_vector_effect/exp=5_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2002, (867, 867), 566, 569, 1135, 1436)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "#         # TEMP adjustment for column results \n",
    "#         d['low_score'] = d['trace_scores']['high_layers_corrupt'].get(\"0\", 0.0)  # \"0\" is key (for layer 0), 0.0 is default \n",
    "#         if d['base_score'] - d['low_score'] < 0.5:\n",
    "#             d['is_good_sample'] = False\n",
    "#         # END_TEMP\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5, (i, d)\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "n_good_samples + n_too_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in bad_samples if s['correct_prediction']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {k: {str(l): 0 for l in range(24)} for k in good_samples[0]['trace_scores'].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for k, layer_d in d['trace_scores'].items():\n",
    "        for l, s in layer_d.items():\n",
    "            trace_scores_avg[k][l] += s\n",
    "\n",
    "for k, layer_d in trace_scores_avg.items():\n",
    "    for l, s in layer_d.items():\n",
    "        layer_d[l] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects (category)\n",
    "- Still kind of linear, as in exp-2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': 'hard', 'node_role': 'where', 'text_match': 'partial'}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (trace_key, aspect, asp_val, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no trace key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for trace_k, trace_layer_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            for l, s in trace_layer_d.items():\n",
    "                trace_scores_by_aspect[trace_k][aspect][asp_val][l].append(s)\n",
    "\n",
    "for trace_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for asp_v, d3 in d2.items():\n",
    "            for l, s in d3.items():\n",
    "                trace_scores_avg_by_aspect[trace_k][asp_k][asp_v][l] = np.mean(s)\n",
    "                trace_scores_cnt_by_aspect[asp_k][asp_v] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(int,\n",
       "                         {'medium': 400,\n",
       "                          'hard': 155,\n",
       "                          'easy': 142,\n",
       "                          'extra': 170}),\n",
       "             'node_role': defaultdict(int,\n",
       "                         {'where': 268,\n",
       "                          'select': 412,\n",
       "                          'order by': 66,\n",
       "                          'join': 92,\n",
       "                          'group by': 25,\n",
       "                          'having': 4}),\n",
       "             'text_match': defaultdict(int,\n",
       "                         {'no-match': 360, 'partial': 148, 'exact': 359})})"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg_by_aspect['high_layers_corrupt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.2: attention section removal effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/exp=5.2.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2039, (168, 168), 339, 1532, 1871, 'good / correct = 168 / 1700')"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples),\\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'Show the stadium name and capacity with most number of concerts in year 2014 or after.; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id',\n",
       " 'seq_out': 'select t2.name, t2.capacity from concert as t1 join stadium as t2 on t1.stadium_id = t2.stadium_id where t1.year >= 2014 group by t2.stadium_id order by count(*) desc limit 1',\n",
       " 'dec_prompt': 'select t2.name, t2.capacity from concert as t1 join stadium as t2 on t1.stadium_id = t2.stadium_id where t1.year >= 2014 group by',\n",
       " 'expect': 't2.',\n",
       " 'expect_type': 'table_alias',\n",
       " 'db_id': 'concert_singer',\n",
       " 'expect_input_ranges': [[30, 31]],\n",
       " 'answer': 't1.',\n",
       " 'base_score': 0.9849615097045898,\n",
       " 'answers_t': [3, 17, 5411],\n",
       " 'correct_prediction': False,\n",
       " 'category': {'sql_hardness': 'extra',\n",
       "  'node_role': 'group by',\n",
       "  'text_match': 'exact'},\n",
       " 'self_ranges': [[29, 33]],\n",
       " 'struct_context_ranges': [[24, 29], [33, 134]],\n",
       " 'is_good_sample': False}"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in bad_samples if not s['correct_prediction']][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            if k == 'window':\n",
    "                for l, s in v.items():\n",
    "                    if int(l) % 4 != 3: continue\n",
    "                    trace_scores_avg[sect_k][f'{k}-{l}'] += s\n",
    "            else:\n",
    "                s = v\n",
    "                trace_scores_avg[sect_k][k] += s\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prefix': defaultdict(int,\n",
       "             {'window-3': 0.9472156441992238,\n",
       "              'window-7': 0.9222004726706516,\n",
       "              'window-11': 0.9004831596948428,\n",
       "              'window-15': 0.6439282640543488,\n",
       "              'window-19': 0.5357348926681949,\n",
       "              'window-23': 0.6425308727503227,\n",
       "              'first_layer': 0.9484615538801465,\n",
       "              'last_layer': 0.873940426016426,\n",
       "              'all_layers': 0.2498462739990746}),\n",
       " 'text': defaultdict(int,\n",
       "             {'window-3': 0.947731566571054,\n",
       "              'window-7': 0.9410505436715626,\n",
       "              'window-11': 0.9183367850879828,\n",
       "              'window-15': 0.845033811380225,\n",
       "              'window-19': 0.8540408059165029,\n",
       "              'window-23': 0.884705040109111,\n",
       "              'first_layer': 0.9480909219100362,\n",
       "              'last_layer': 0.9342825717869259,\n",
       "              'all_layers': 0.7430854112239325}),\n",
       " 'struct': defaultdict(int,\n",
       "             {'window-3': 0.9109604747722014,\n",
       "              'window-7': 0.8727138553419665,\n",
       "              'window-11': 0.8174125205976457,\n",
       "              'window-15': 0.7166103291891621,\n",
       "              'window-19': 0.4618284298516503,\n",
       "              'window-23': 0.6287162009882322,\n",
       "              'first_layer': 0.9485237477790742,\n",
       "              'last_layer': 0.9440051373981294,\n",
       "              'all_layers': 0.1263078110766962}),\n",
       " 'text+struct': defaultdict(int,\n",
       "             {'window-3': 0.9082610283401751,\n",
       "              'window-7': 0.8677347994733802,\n",
       "              'window-11': 0.7924875653429407,\n",
       "              'window-15': 0.6649166234458898,\n",
       "              'window-19': 0.3974970635258469,\n",
       "              'window-23': 0.5779948868095206,\n",
       "              'first_layer': 0.9478886173594565,\n",
       "              'last_layer': 0.9306179909479051,\n",
       "              'all_layers': 0.10694331496035014}),\n",
       " 'all': defaultdict(int,\n",
       "             {'window-3': 0.8622249553348714,\n",
       "              'window-7': 0.748052881100541,\n",
       "              'window-11': 0.6102487181519635,\n",
       "              'window-15': 0.34381790590862565,\n",
       "              'window-19': 0.26920749726204984,\n",
       "              'window-23': 0.4049646406155,\n",
       "              'first_layer': 0.9509559933628354,\n",
       "              'last_layer': 0.8428448445147729,\n",
       "              'all_layers': 0.06689078736677516}),\n",
       " 'self': defaultdict(int,\n",
       "             {'window-3': 0.937020205094346,\n",
       "              'window-7': 0.9156253876696739,\n",
       "              'window-11': 0.8692028160204202,\n",
       "              'window-15': 0.8039197585329865,\n",
       "              'window-19': 0.8306145018696476,\n",
       "              'window-23': 0.9211891535447821,\n",
       "              'first_layer': 0.9488432190957523,\n",
       "              'last_layer': 0.9441031253054029,\n",
       "              'all_layers': 0.5127852745849876}),\n",
       " 'struct_context': defaultdict(int,\n",
       "             {'window-3': 0.9341154902109078,\n",
       "              'window-7': 0.9235011088617501,\n",
       "              'window-11': 0.9000720231796593,\n",
       "              'window-15': 0.7935650288540033,\n",
       "              'window-19': 0.49541405827511165,\n",
       "              'window-23': 0.6495562083257114,\n",
       "              'first_layer': 0.9497169314750603,\n",
       "              'last_layer': 0.9476859299909501,\n",
       "              'all_layers': 0.37673979133652175}),\n",
       " 'text+struct_context': defaultdict(int,\n",
       "             {'window-3': 0.9319076965607348,\n",
       "              'window-7': 0.9102340873685622,\n",
       "              'window-11': 0.8765552542309879,\n",
       "              'window-15': 0.7206775633197688,\n",
       "              'window-19': 0.4290926267704324,\n",
       "              'window-23': 0.581062605106692,\n",
       "              'first_layer': 0.9492174081859135,\n",
       "              'last_layer': 0.9347316793920029,\n",
       "              'all_layers': 0.2667736544415247})}"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\twindow-3    \twindow-7    \twindow-11   \twindow-15   \twindow-19   \twindow-23   \tfirst_layer \tlast_layer  \tall_layers  \n",
      "prefix      \t0.9472      \t0.9222      \t0.9005      \t0.6439      \t0.5357      \t0.6425      \t0.9485      \t0.8739      \t0.2498      \n",
      "text        \t0.9477      \t0.9411      \t0.9183      \t0.8450      \t0.8540      \t0.8847      \t0.9481      \t0.9343      \t0.7431      \n",
      "struct      \t0.9110      \t0.8727      \t0.8174      \t0.7166      \t0.4618      \t0.6287      \t0.9485      \t0.9440      \t0.1263      \n",
      "text+struct \t0.9083      \t0.8677      \t0.7925      \t0.6649      \t0.3975      \t0.5780      \t0.9479      \t0.9306      \t0.1069      \n",
      "all         \t0.8622      \t0.7481      \t0.6102      \t0.3438      \t0.2692      \t0.4050      \t0.9510      \t0.8428      \t0.0669      \n",
      "self        \t0.9370      \t0.9156      \t0.8692      \t0.8039      \t0.8306      \t0.9212      \t0.9488      \t0.9441      \t0.5128      \n",
      "struct_context\t0.9341      \t0.9235      \t0.9001      \t0.7936      \t0.4954      \t0.6496      \t0.9497      \t0.9477      \t0.3767      \n",
      "text+struct_context\t0.9319      \t0.9102      \t0.8766      \t0.7207      \t0.4291      \t0.5811      \t0.9492      \t0.9347      \t0.2668      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(trace_scores_avg, col_w=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP patch for node_len category \n",
    "for d in good_samples + bad_samples:\n",
    "    node_len = len(d['answers_t'])\n",
    "    assert len(mt_uskg.tokenizer.tokenize(d['expect'])) == node_len, (d['expect'], node_len)\n",
    "    d['category']['node_len'] = str(node_len) if node_len <= 3 else '4+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': 'medium',\n",
       " 'node_role': 'from',\n",
       " 'text_match': 'exact',\n",
       " 'node_len': '1'}"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (sect_k, aspect, asp_val, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no sect key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            for k, v in sect_d.items():\n",
    "                if k == 'window':\n",
    "                    for l, s in v.items():\n",
    "                        if not (int(l) % 4 == 3): continue\n",
    "                        layer_k = f'{k}-{l}'\n",
    "                        trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                else:\n",
    "                    layer_k = k\n",
    "                    s = v\n",
    "                    trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                    \n",
    "for sect_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for asp_v, d3 in d2.items():\n",
    "            for layer_k, s in d3.items():\n",
    "                trace_scores_avg_by_aspect[sect_k][asp_k][asp_v][layer_k] = np.mean(s)\n",
    "                trace_scores_cnt_by_aspect[asp_k][asp_v] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sect_k, sect_d in trace_scores_avg_by_aspect.items():\n",
    "    sect_d['overall'] = dict()\n",
    "    for layer_k, s in trace_scores_avg[sect_k].items():\n",
    "        if layer_k.startswith('window'):\n",
    "            # only keep a subset of layers \n",
    "            _, l = layer_k.split('-')\n",
    "            if not (int(l) % 4 == 3): continue\n",
    "        sect_d['overall'][layer_k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(int,\n",
       "                         {'medium': 378,\n",
       "                          'hard': 148,\n",
       "                          'easy': 134,\n",
       "                          'extra': 160}),\n",
       "             'node_role': defaultdict(int,\n",
       "                         {'where': 248,\n",
       "                          'select': 393,\n",
       "                          'order by': 63,\n",
       "                          'join': 91,\n",
       "                          'group by': 21,\n",
       "                          'having': 4}),\n",
       "             'text_match': defaultdict(int,\n",
       "                         {'no-match': 345, 'partial': 142, 'exact': 333}),\n",
       "             'node_len': defaultdict(int,\n",
       "                         {'1': 329, '3': 238, '4+': 160, '2': 93})})"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace_scores_avg_by_aspect['self']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_d = ctu.nested_json_processing(trace_scores_avg_by_aspect, func=lambda x: np.format_float_positional(x, precision=4, min_digits=4))\n",
    "# dump_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/summ-exp=5.2.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(dump_path, 'w') as f:\n",
    "    json.dump(dump_d, f, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (one-time temp patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect_type = 'table_alias'\n",
    "# orig_res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/no_structcontext-exp=5.2.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "# add_res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/exp=5.2.1+structcontext_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "# merge_res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/exp=5.2.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(orig_res_path, 'r') as f:\n",
    "#     orig_all_samples = [json.loads(l) for l in f]\n",
    "# with open(add_res_path, 'r') as f:\n",
    "#     add_all_samples = [json.loads(l) for l in f]\n",
    "\n",
    "# f = open(merge_res_path, 'w')\n",
    "    \n",
    "# for i, (orig_ex, add_ex) in enumerate(zip(orig_all_samples, add_all_samples)):\n",
    "#     assert len(orig_ex['trace_results']) == len(add_ex['trace_results']), i\n",
    "#     # There is randomness in the order of expected node (from set()), thus sorting here \n",
    "#     orig_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     add_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     for j, (orig_d, add_d) in enumerate(zip(orig_ex['trace_results'], add_ex['trace_results'])):\n",
    "#         assert orig_d['is_good_sample'] == add_d['is_good_sample'], (i, j)\n",
    "#         if not orig_d['is_good_sample']:\n",
    "#             continue\n",
    "            \n",
    "#         # is good sample: add the new sections \n",
    "#         orig_d['trace_scores']['struct_context'] = add_d['trace_scores']['struct_context']\n",
    "#         orig_d['trace_scores']['text+struct_context'] = add_d['trace_scores']['text+struct_context']\n",
    "        \n",
    "#     f.write(json.dumps(orig_ex, indent=None) + '\\n')\n",
    "    \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single samples observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prefix', 'text', 'struct', 'text+struct', 'all', 'self', 'struct_context', 'text+struct_context'])"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples[0]['trace_scores'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = 0\n",
    "\n",
    "d = good_samples[_id]\n",
    "\n",
    "check_info_d = defaultdict(dict)\n",
    "\n",
    "for sect_k, sect_d in d['trace_scores'].items():\n",
    "    for layer_k, s in sect_d.items():\n",
    "        if layer_k == 'window':\n",
    "            layer_k = 'window-19'\n",
    "            s = s['19']\n",
    "        if s < 0.5:\n",
    "            check_info_d[sect_k][layer_k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text+struct\": {\n",
      "    \"all_layers\": 0.3990614414215088\n",
      "  },\n",
      "  \"all\": {\n",
      "    \"all_layers\": 0.4772564172744751\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(check_info_d, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check \"breaking\" window layer, i.e. those with sudden changes \n",
    "### For now: single layer drop > _th\n",
    "\n",
    "_th = 0.4\n",
    "check_info_l = []\n",
    "for i, d in enumerate(good_samples):\n",
    "#     for sect_k, sect_d in d['trace_scores'].items():\n",
    "    sect_k = 'all'\n",
    "    sect_d = d['trace_scores'][sect_k]\n",
    "    window_d = sect_d['window']\n",
    "    for l in range(1, 24):\n",
    "        if window_d[str(l-1)] - window_d[str(l)] > _th:\n",
    "            _info_d = {\n",
    "                'id': i,\n",
    "                'sect_k': sect_k,\n",
    "                'layer': l,\n",
    "                'last_layer_score': window_d[str(l-1)],\n",
    "                'this_layer_score': window_d[str(l)],\n",
    "            }\n",
    "            check_info_l.append(_info_d)\n",
    "            break\n",
    "len(check_info_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(844, 1207)"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_info_l), len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 10),\n",
       " (2, 25),\n",
       " (3, 31),\n",
       " (4, 81),\n",
       " (5, 24),\n",
       " (6, 3),\n",
       " (7, 15),\n",
       " (8, 87),\n",
       " (9, 69),\n",
       " (10, 19),\n",
       " (11, 38),\n",
       " (12, 36),\n",
       " (13, 70),\n",
       " (14, 101),\n",
       " (15, 27),\n",
       " (16, 31),\n",
       " (17, 31),\n",
       " (18, 79),\n",
       " (19, 67)]"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "break_layer_counter = Counter([_d['layer'] for _d in check_info_l])\n",
    "sorted(break_layer_counter.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info_d in check_info_l:\n",
    "    if info_d['layer'] < 6:\n",
    "        print(info_d)\n",
    "        sample_id = info_d['id']\n",
    "        d = good_samples[sample_id]\n",
    "        print(d['enc_sentence'])\n",
    "        print(d['dec_prompt'], '---->', d['expect'])\n",
    "        print('Categories:', d['category'])\n",
    "        print('--' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_counter_by_aspect = defaultdict(Counter)  # [asp_k, asp_v] -> count \n",
    "sample_counter = Counter()\n",
    "\n",
    "for info_d in check_info_l:\n",
    "    if info_d['layer'] < 6:\n",
    "        sample_id = info_d['id']\n",
    "        d = good_samples[sample_id]\n",
    "        text_match = d['category']['text_match']\n",
    "        node_len = d['category']['node_len']\n",
    "        sample_counter[(text_match, node_len)] += 1\n",
    "        \n",
    "        for asp_k, asp_v in d['category'].items():\n",
    "            sample_counter_by_aspect[asp_k][asp_v] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'sql_hardness': Counter({'medium': 58,\n",
       "                      'hard': 42,\n",
       "                      'extra': 51,\n",
       "                      'easy': 20}),\n",
       "             'node_role': Counter({'from': 105, 'join': 66}),\n",
       "             'text_match': Counter({'partial': 59,\n",
       "                      'no-match': 74,\n",
       "                      'exact': 38}),\n",
       "             'node_len': Counter({'4+': 60, '3': 51, '2': 24, '1': 36})})"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_counter_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('partial', '3'), 30),\n",
       " (('partial', '4+'), 29),\n",
       " (('exact', '1'), 22),\n",
       " (('no-match', '3'), 21),\n",
       " (('no-match', '4+'), 21),\n",
       " (('no-match', '2'), 18),\n",
       " (('no-match', '1'), 14),\n",
       " (('exact', '4+'), 10),\n",
       " (('exact', '2'), 6)]"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_counter_by_aspect = defaultdict(Counter)  # [asp_k, asp_v] -> count \n",
    "sample_counter = Counter()\n",
    "\n",
    "for info_d in check_info_l:\n",
    "    if info_d['layer'] > 18:\n",
    "        sample_id = info_d['id']\n",
    "        d = good_samples[sample_id]\n",
    "        text_match = d['category']['text_match']\n",
    "        node_len = d['category']['node_len']\n",
    "        sample_counter[(text_match, node_len)] += 1\n",
    "        \n",
    "        for asp_k, asp_v in d['category'].items():\n",
    "            sample_counter_by_aspect[asp_k][asp_v] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'sql_hardness': Counter({'hard': 9,\n",
       "                      'medium': 27,\n",
       "                      'easy': 11,\n",
       "                      'extra': 20}),\n",
       "             'node_role': Counter({'join': 21, 'from': 46}),\n",
       "             'text_match': Counter({'exact': 46,\n",
       "                      'no-match': 20,\n",
       "                      'partial': 1}),\n",
       "             'node_len': Counter({'3': 12, '1': 46, '2': 6, '4+': 3})})"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_counter_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('exact', '1'), 38),\n",
       " (('no-match', '3'), 9),\n",
       " (('no-match', '1'), 8),\n",
       " (('exact', '3'), 3),\n",
       " (('no-match', '2'), 3),\n",
       " (('exact', '2'), 3),\n",
       " (('exact', '4+'), 2),\n",
       " (('partial', '4+'), 1)]"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.385318918917694e-12"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _min_p = 1.0\n",
    "\n",
    "# for i, d in enumerate(good_samples):\n",
    "#     sect_k = 'text'\n",
    "#     sect_d = d['trace_scores'][sect_k]\n",
    "#     _min_p = min(_min_p, sect_d['all_layers'])\n",
    "\n",
    "# _min_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 916, 1207, 1207)"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Systematic \n",
    "\n",
    "ob_sect_k = 'all'\n",
    "\n",
    "_th = 0.4\n",
    "\n",
    "check_info_l = []\n",
    "all_layers_eff_cnt = 0  # for this section to observe, how many samples are effective with all_layers\n",
    "window_eff_cnt = 0      # for this section to observe, how many samples are effective with any window \n",
    "\n",
    "for i, d in enumerate(good_samples):\n",
    "#     for sect_k, sect_d in d['trace_scores'].items():\n",
    "    sect_k = ob_sect_k\n",
    "    sect_d = d['trace_scores'][sect_k]\n",
    "    if sect_d['all_layers'] > 0.5:\n",
    "        # not effective\n",
    "        continue\n",
    "    else:\n",
    "        all_layers_eff_cnt += 1\n",
    "        \n",
    "    if min(sect_d['window'].values()) > 0.5:\n",
    "        # not effective\n",
    "        continue\n",
    "    else:\n",
    "        window_eff_cnt += 1\n",
    "        \n",
    "    window_d = sect_d['window']\n",
    "    for l in range(1, 24):\n",
    "        if window_d[str(l-1)] - window_d[str(l)] > _th:\n",
    "            _info_d = {\n",
    "                'id': i,\n",
    "                'sect_k': sect_k,\n",
    "                'layer': l,\n",
    "                'last_layer_score': window_d[str(l-1)],\n",
    "                'this_layer_score': window_d[str(l)],\n",
    "            }\n",
    "            check_info_l.append(_info_d)\n",
    "            break\n",
    "len(check_info_l), window_eff_cnt, all_layers_eff_cnt, len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctg_list = [(tm, nl) for tm in ['exact', 'partial', 'no-match'] for nl in ['1', '2', '3', '4+']]\n",
    "layer_list = [str(l) for l in range(1, 24)]\n",
    "\n",
    "ctg_elem2id = {elem : i for i, elem in enumerate(ctg_list)}\n",
    "layer_elem2id = {elem : i for i, elem in enumerate(layer_list)}\n",
    "\n",
    "cnt_matrix = np.zeros((len(ctg_list), len(layer_list)), int)\n",
    "\n",
    "for info_d in check_info_l:\n",
    "    sample_id = info_d['id']\n",
    "    d = good_samples[sample_id]\n",
    "    text_match = d['category']['text_match']\n",
    "    node_len = d['category']['node_len']\n",
    "    _ctg = (text_match, node_len)\n",
    "    _layer = str(info_d['layer'])\n",
    "    \n",
    "    _ctg_idx = ctg_elem2id[_ctg]\n",
    "    _layer_idx = layer_elem2id[_layer]\n",
    "    cnt_matrix[_ctg_idx, _layer_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Display the matrix using imshow\n",
    "im = ax.imshow(cnt_matrix, cmap='Blues')\n",
    "\n",
    "# Set the tick labels for the first and second dimensions\n",
    "ax.set_xticks(np.arange(len(layer_list)))\n",
    "ax.set_yticks(np.arange(len(ctg_list)))\n",
    "\n",
    "# Set the tick labels using the ctg_list and layer_list\n",
    "ax.set_xticklabels(layer_list)\n",
    "ax.set_yticklabels(ctg_list)\n",
    "\n",
    "ax.set_title(f'Section: {ob_sect_k}\\n')\n",
    "\n",
    "# Rotate the x-axis tick labels if needed\n",
    "# plt.xticks(rotation=90)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax, shrink=0.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Display the matrix using imshow\n",
    "im = ax.imshow(cnt_matrix, cmap='Blues')\n",
    "\n",
    "# Set the tick labels for the first and second dimensions\n",
    "ax.set_xticks(np.arange(len(layer_list)))\n",
    "ax.set_yticks(np.arange(len(ctg_list)))\n",
    "\n",
    "# Set the tick labels using the ctg_list and layer_list\n",
    "ax.set_xticklabels(layer_list)\n",
    "ax.set_yticklabels(ctg_list)\n",
    "\n",
    "ax.set_title(f'Section: {ob_sect_k}\\n')\n",
    "\n",
    "# Rotate the x-axis tick labels if needed\n",
    "# plt.xticks(rotation=90)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax, shrink=0.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.3: attention section mutual removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'column'\n",
    "\n",
    "# res_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/exp=5.3.2_dev_{expect_type}-attn_crpt=logits.jsonl'\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/exp=5.3.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2002,\n",
       " (1165, 1165),\n",
       " (566, 566),\n",
       " (271, 271),\n",
       " 837,\n",
       " 'good / correct = 1165 / 1436')"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "# bad_samples = []\n",
    "too_hard_samples = []\n",
    "too_easy_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            too_hard_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            too_easy_samples.append(d)\n",
    "\n",
    "bad_samples = too_hard_samples + too_easy_samples\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), \\\n",
    "(n_too_hard, len(too_hard_samples)), (n_too_easy, len(too_easy_samples)), \\\n",
    "len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            if k == 'window':\n",
    "                for l, s in v.items():\n",
    "                    trace_scores_avg[sect_k][f'{k}-{l}'] += s\n",
    "            else:\n",
    "                s = v\n",
    "                trace_scores_avg[sect_k][k] += s\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_print_2D_dict(trace_scores_avg, col_w=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': 'medium', 'node_role': 'where', 'text_match': 'no-match'}"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP patch for node_len category \n",
    "# for d in good_samples + bad_samples:\n",
    "#     node_len = len(d['answers_t'])\n",
    "#     assert len(mt_uskg.tokenizer.tokenize(d['expect'])) == node_len, (d['expect'], node_len)\n",
    "#     d['category']['node_len'] = str(node_len) if node_len <= 3 else '4+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': 'medium',\n",
       " 'node_role': 'group by',\n",
       " 'text_match': 'exact',\n",
       " 'node_len': '3'}"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (sect_k, aspect, asp_val, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no sect key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            for k, v in sect_d.items():\n",
    "                if k == 'window':\n",
    "                    for l, s in v.items():\n",
    "                        if not (int(l) % 4 == 3): continue\n",
    "                        layer_k = f'{k}-{l}'\n",
    "                        trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                else:\n",
    "                    layer_k = k\n",
    "                    s = v\n",
    "                    trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                    \n",
    "for sect_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for asp_v, d3 in d2.items():\n",
    "            for layer_k, s in d3.items():\n",
    "                trace_scores_avg_by_aspect[sect_k][asp_k][asp_v][layer_k] = np.mean(s)\n",
    "                trace_scores_cnt_by_aspect[asp_k][asp_v] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sect_k, sect_d in trace_scores_avg_by_aspect.items():\n",
    "    sect_d['overall'] = dict()\n",
    "    for layer_k, s in trace_scores_avg[sect_k].items():\n",
    "        if layer_k.startswith('window'):\n",
    "            # only keep a subset of layers \n",
    "            _, l = layer_k.split('-')\n",
    "            if not (int(l) % 4 == 3): continue\n",
    "        sect_d['overall'][layer_k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(int,\n",
       "                         {'medium': 123, 'extra': 175, 'hard': 64, 'easy': 2}),\n",
       "             'node_role': defaultdict(int,\n",
       "                         {'select': 191,\n",
       "                          'group by': 33,\n",
       "                          'join': 12,\n",
       "                          'where': 111,\n",
       "                          'order by': 17}),\n",
       "             'text_match': defaultdict(int,\n",
       "                         {'exact': 230, 'partial': 28, 'no-match': 106}),\n",
       "             'node_len': defaultdict(int, {'3': 364})})"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace_scores_avg_by_aspect['c->p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_d = ctu.nested_json_processing(trace_scores_avg_by_aspect, func=lambda x: np.format_float_positional(x, precision=4, min_digits=4))\n",
    "# dump_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/summ-exp=5.3.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "# with open(dump_path, 'w') as f:\n",
    "#     json.dump(dump_d, f, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Good / correct ratio per class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asp_k -> asp_v -> {'good', 'too_easy', 'all_correct', 'ratio'}\n",
    "good_correct_stats = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "for d in good_samples:\n",
    "    for asp_k, asp_v in d['category'].items():\n",
    "        good_correct_stats[asp_k][asp_v]['good'] += 1\n",
    "        good_correct_stats[asp_k][asp_v]['all_correct'] += 1\n",
    "\n",
    "for d in too_easy_samples:\n",
    "    for asp_k, asp_v in d['category'].items():\n",
    "        good_correct_stats[asp_k][asp_v]['too_easy'] += 1\n",
    "        good_correct_stats[asp_k][asp_v]['all_correct'] += 1\n",
    "        \n",
    "for asp_k, d1 in good_correct_stats.items():\n",
    "    for asp_v, asp_d in d1.items():\n",
    "        asp_d['ratio'] = asp_d['good'] / asp_d['all_correct']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'exact': defaultdict(int,\n",
       "                         {'good': 609,\n",
       "                          'all_correct': 791,\n",
       "                          'too_easy': 182,\n",
       "                          'ratio': 0.7699115044247787}),\n",
       "             'no-match': defaultdict(int,\n",
       "                         {'good': 360,\n",
       "                          'all_correct': 443,\n",
       "                          'too_easy': 83,\n",
       "                          'ratio': 0.8126410835214447}),\n",
       "             'partial': defaultdict(int,\n",
       "                         {'good': 196,\n",
       "                          'all_correct': 202,\n",
       "                          'too_easy': 6,\n",
       "                          'ratio': 0.9702970297029703})})"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_correct_stats['text_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\tgood  \tall_correct\ttoo_easy\tratio \n",
      "exact       \t609.0000\t791.0000\t182.0000\t0.7699\n",
      "no-match    \t360.0000\t443.0000\t83.0000\t0.8126\n",
      "partial     \t196.0000\t202.0000\t6.0000\t0.9703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(good_correct_stats['text_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['t->s', 's->t', 't<->s', 't->p', 's->p', 'ts->p', 't->t', 's->s', 's->c', 'c->s', 'c->c', 'c->p', 'all'])"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/summ-exp=5.3.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(dump_path, 'r') as f:\n",
    "    dump_d = json.load(f)\n",
    "\n",
    "dump_d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asp_k -> asp_v -> sect_k -> layer_k -> val\n",
    "results_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "\n",
    "for sect_k, sect_d in dump_d.items():\n",
    "    for asp_k, d1 in sect_d.items():\n",
    "        if asp_k == 'overall':\n",
    "            continue\n",
    "        for asp_v, asp_d in d1.items():\n",
    "            for layer_k in ['window-7', 'window-19', 'all_layers']:\n",
    "                v = float(asp_d[layer_k])\n",
    "                results_by_aspect[asp_k][asp_v][sect_k][layer_k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp_k = 'text_match'\n",
    "\n",
    "for asp_v, asp_d in results_by_aspect[asp_k].items():\n",
    "    print(f'{asp_k} = {asp_v}')\n",
    "    format_print_2D_dict(asp_d, col_w=10)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (one-time temp patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect_type = 'table_alias'\n",
    "# orig_res_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/no_c2p_exp=5.3.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "# add_res_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/exp=5.3.1+c2p_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "# merge_res_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/exp=5.3.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(orig_res_path, 'r') as f:\n",
    "#     orig_all_samples = [json.loads(l) for l in f]\n",
    "# with open(add_res_path, 'r') as f:\n",
    "#     add_all_samples = [json.loads(l) for l in f]\n",
    "\n",
    "# f = open(merge_res_path, 'w')\n",
    "    \n",
    "# for i, (orig_ex, add_ex) in enumerate(zip(orig_all_samples, add_all_samples)):\n",
    "#     assert len(orig_ex['trace_results']) == len(add_ex['trace_results']), i\n",
    "#     # There is randomness in the order of expected node (from set()), thus sorting here \n",
    "#     orig_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     add_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     for j, (orig_d, add_d) in enumerate(zip(orig_ex['trace_results'], add_ex['trace_results'])):\n",
    "#         assert orig_d['is_good_sample'] == add_d['is_good_sample'], (i, j)\n",
    "#         if not orig_d['is_good_sample']:\n",
    "#             continue\n",
    "            \n",
    "#         # is good sample: add the new sections \n",
    "#         orig_d['trace_scores']['c->p'] = add_d['trace_scores']['c->p']\n",
    "        \n",
    "#         # put all at end in the dict \n",
    "#         _t = orig_d['trace_scores']['all']\n",
    "#         del orig_d['trace_scores']['all']\n",
    "#         orig_d['trace_scores']['all'] = _t\n",
    "        \n",
    "#     f.write(json.dumps(orig_ex, indent=None) + '\\n')\n",
    "    \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.4: attention section mutual removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'column'\n",
    "\n",
    "# res_path = f'/home/yshao/Projects/rome/results/exp5_4_decoder_cross_attention_removal/exp=5.4.1_dev_{expect_type}-attn_crpt=logits.jsonl'\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_4_decoder_cross_attention_removal/exp=5.4_dev_{expect_type}-attn_crpt=weights.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2002,\n",
       " (1266, 1266),\n",
       " (566, 566),\n",
       " (170, 170),\n",
       " 736,\n",
       " 'good / correct = 1266 / 1436')"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "# bad_samples = []\n",
    "too_hard_samples = []\n",
    "too_easy_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            too_hard_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            too_easy_samples.append(d)\n",
    "\n",
    "bad_samples = too_hard_samples + too_easy_samples\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), \\\n",
    "(n_too_hard, len(too_hard_samples)), (n_too_easy, len(too_easy_samples)), \\\n",
    "len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict[sect_k, Dict[layer_k, s]]\n",
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, s in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += s\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': defaultdict(int,\n",
       "             {'low_layers': 0.5242457950745857,\n",
       "              'mid_layers': 0.6081488858922526,\n",
       "              'high_layers': 0.04873052586141602,\n",
       "              'all_layers': 0.014953504248225972}),\n",
       " 'ans->t': defaultdict(int,\n",
       "             {'low_layers': 0.9694846544320876,\n",
       "              'mid_layers': 0.9548988270596958,\n",
       "              'high_layers': 0.9813394950611222,\n",
       "              'all_layers': 0.9361464705256212}),\n",
       " 'all->t': defaultdict(int,\n",
       "             {'low_layers': 0.9533332388484522,\n",
       "              'mid_layers': 0.9325720264446838,\n",
       "              'high_layers': 0.9790280977666627,\n",
       "              'all_layers': 0.8936582017384058}),\n",
       " 'ans->s': defaultdict(int,\n",
       "             {'low_layers': 0.8826992521290236,\n",
       "              'mid_layers': 0.8524766282742821,\n",
       "              'high_layers': 0.26891499033840577,\n",
       "              'all_layers': 0.19515848414907608}),\n",
       " 'all->s': defaultdict(int,\n",
       "             {'low_layers': 0.8577877470518337,\n",
       "              'mid_layers': 0.8521567077018459,\n",
       "              'high_layers': 0.2714948349661608,\n",
       "              'all_layers': 0.23313721652266875}),\n",
       " 'ans->p': defaultdict(int,\n",
       "             {'low_layers': 0.9355397474524847,\n",
       "              'mid_layers': 0.9386022137983288,\n",
       "              'high_layers': 0.9787994267221829,\n",
       "              'all_layers': 0.9208982761405902}),\n",
       " 'all->p': defaultdict(int,\n",
       "             {'low_layers': 0.9161497496929711,\n",
       "              'mid_layers': 0.9358495949407368,\n",
       "              'high_layers': 0.977996521841258,\n",
       "              'all_layers': 0.8995113927032365}),\n",
       " 'ans->o': defaultdict(int,\n",
       "             {'low_layers': 0.9886594344089381,\n",
       "              'mid_layers': 0.9879005722242509,\n",
       "              'high_layers': 0.9872499290694841,\n",
       "              'all_layers': 0.9862655090023933}),\n",
       " 'all->o': defaultdict(int,\n",
       "             {'low_layers': 0.9871641860283193,\n",
       "              'mid_layers': 0.9875362204714409,\n",
       "              'high_layers': 0.9873051024961622,\n",
       "              'all_layers': 0.9848773025305821}),\n",
       " 'ans->t+o': defaultdict(int,\n",
       "             {'low_layers': 0.9694594338336873,\n",
       "              'mid_layers': 0.954972941465313,\n",
       "              'high_layers': 0.9797265676970422,\n",
       "              'all_layers': 0.9331099489290341}),\n",
       " 'all->t+o': defaultdict(int,\n",
       "             {'low_layers': 0.952374637890774,\n",
       "              'mid_layers': 0.9329709502503787,\n",
       "              'high_layers': 0.9772559199509444,\n",
       "              'all_layers': 0.8889419137114355}),\n",
       " 'ans->c': defaultdict(int,\n",
       "             {'low_layers': 0.978405858932937,\n",
       "              'mid_layers': 0.9916373812836281,\n",
       "              'high_layers': 0.9854104019292877,\n",
       "              'all_layers': 0.9731142791841306}),\n",
       " 'all->c': defaultdict(int,\n",
       "             {'low_layers': 0.9341740729860604,\n",
       "              'mid_layers': 0.9845395296075047,\n",
       "              'high_layers': 0.984905762776299,\n",
       "              'all_layers': 0.9352233958441996}),\n",
       " 'ans->self': defaultdict(int,\n",
       "             {'low_layers': 0.9447841336468175,\n",
       "              'mid_layers': 0.8506365664131339,\n",
       "              'high_layers': 0.3046866458450536,\n",
       "              'all_layers': 0.2560135196378865}),\n",
       " 'all->self': defaultdict(int,\n",
       "             {'low_layers': 0.9438821171109629,\n",
       "              'mid_layers': 0.8527847244332564,\n",
       "              'high_layers': 0.30930030257587354,\n",
       "              'all_layers': 0.30134236523114305})}"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all     \t0.5242\t0.6081\t0.0487\t0.0150\n",
      "all->t  \t0.9533\t0.9326\t0.9790\t0.8937\n",
      "all->s  \t0.8578\t0.8522\t0.2715\t0.2331\n",
      "all->p  \t0.9161\t0.9358\t0.9780\t0.8995\n",
      "all->o  \t0.9872\t0.9875\t0.9873\t0.9849\n",
      "all->t+o\t0.9524\t0.9330\t0.9773\t0.8889\n",
      "all->c  \t0.9342\t0.9845\t0.9849\t0.9352\n",
      "all->self\t0.9439\t0.8528\t0.3093\t0.3013\n"
     ]
    }
   ],
   "source": [
    "layers_keys = ['low_layers', 'mid_layers', 'high_layers', 'all_layers']\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    # Now unify and use `all` for analysis \n",
    "    if sect_k.startswith('ans->'):\n",
    "        continue\n",
    "    print_l = f'{sect_k:<8s}'\n",
    "    for k in layers_keys:\n",
    "        s = sect_d[k]\n",
    "        print_l += f'\\t{s:.4f}'\n",
    "    print(print_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (sect_k, aspect, asp_val, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no sect key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            for k, v in sect_d.items():\n",
    "#                 if k == 'window':\n",
    "#                     for l, s in v.items():\n",
    "#                         if not (int(l) % 4 == 3): continue\n",
    "#                         layer_k = f'{k}-{l}'\n",
    "#                         trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "#                 else:\n",
    "                layer_k = k\n",
    "                s = v\n",
    "                trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                    \n",
    "for sect_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for asp_v, d3 in d2.items():\n",
    "            for layer_k, s in d3.items():\n",
    "                trace_scores_avg_by_aspect[sect_k][asp_k][asp_v][layer_k] = np.mean(s)\n",
    "                trace_scores_cnt_by_aspect[asp_k][asp_v] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sect_k, sect_d in trace_scores_avg_by_aspect.items():\n",
    "#     sect_d['overall'] = dict()\n",
    "#     for layer_k, s in trace_scores_avg[sect_k].items():\n",
    "#         if layer_k.startswith('window'):\n",
    "#             # only keep a subset of layers \n",
    "#             _, l = layer_k.split('-')\n",
    "#             if not (int(l) % 4 == 3): continue\n",
    "#         sect_d['overall'][layer_k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(int,\n",
       "                         {'medium': 586,\n",
       "                          'easy': 229,\n",
       "                          'hard': 240,\n",
       "                          'extra': 211}),\n",
       "             'node_role': defaultdict(int,\n",
       "                         {'select': 630,\n",
       "                          'order by': 82,\n",
       "                          'where': 381,\n",
       "                          'group by': 82,\n",
       "                          'join': 85,\n",
       "                          'having': 6}),\n",
       "             'text_match': defaultdict(int,\n",
       "                         {'exact': 653, 'no-match': 419, 'partial': 194}),\n",
       "             'node_len': defaultdict(int,\n",
       "                         {'1': 578, '3': 369, '4+': 203, '2': 116})})"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'medium': defaultdict(float,\n",
       "                                      {'low_layers': 0.9511169016978063,\n",
       "                                       'mid_layers': 0.9341550427679274,\n",
       "                                       'high_layers': 0.9850538173801341,\n",
       "                                       'all_layers': 0.8932898050521948}),\n",
       "                          'easy': defaultdict(float,\n",
       "                                      {'low_layers': 0.9820877028289339,\n",
       "                                       'mid_layers': 0.964199215542708,\n",
       "                                       'high_layers': 0.9875165987896452,\n",
       "                                       'all_layers': 0.9503825834782225}),\n",
       "                          'hard': defaultdict(float,\n",
       "                                      {'low_layers': 0.9362867399049416,\n",
       "                                       'mid_layers': 0.8923666021491637,\n",
       "                                       'high_layers': 0.9717760789351207,\n",
       "                                       'all_layers': 0.8278912561142061}),\n",
       "                          'extra': defaultdict(float,\n",
       "                                      {'low_layers': 0.9476704950815845,\n",
       "                                       'mid_layers': 0.9395816376392643,\n",
       "                                       'high_layers': 0.9613292640785718,\n",
       "                                       'all_layers': 0.9079239078498246})}),\n",
       "             'node_role': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'select': defaultdict(float,\n",
       "                                      {'low_layers': 0.9331123405422682,\n",
       "                                       'mid_layers': 0.9043954632903924,\n",
       "                                       'high_layers': 0.976370068555901,\n",
       "                                       'all_layers': 0.839600058655169}),\n",
       "                          'order by': defaultdict(float,\n",
       "                                      {'low_layers': 0.9873206808072764,\n",
       "                                       'mid_layers': 0.959375623389461,\n",
       "                                       'high_layers': 0.9928992819495317,\n",
       "                                       'all_layers': 0.9302111095763039}),\n",
       "                          'where': defaultdict(float,\n",
       "                                      {'low_layers': 0.979118972852963,\n",
       "                                       'mid_layers': 0.9656939626985541,\n",
       "                                       'high_layers': 0.9888393244749788,\n",
       "                                       'all_layers': 0.9565494025272459}),\n",
       "                          'group by': defaultdict(float,\n",
       "                                      {'low_layers': 0.9783710433942515,\n",
       "                                       'mid_layers': 0.963403786861951,\n",
       "                                       'high_layers': 0.9792797524572873,\n",
       "                                       'all_layers': 0.9519493787674724}),\n",
       "                          'join': defaultdict(float,\n",
       "                                      {'low_layers': 0.9273902212872225,\n",
       "                                       'mid_layers': 0.9325856594478383,\n",
       "                                       'high_layers': 0.9396470609833213,\n",
       "                                       'all_layers': 0.9328797982019537}),\n",
       "                          'having': defaultdict(float,\n",
       "                                      {'low_layers': 0.999981164932251,\n",
       "                                       'mid_layers': 0.9999918540318807,\n",
       "                                       'high_layers': 0.999994158744812,\n",
       "                                       'all_layers': 0.7243301989714558})}),\n",
       "             'text_match': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'exact': defaultdict(float,\n",
       "                                      {'low_layers': 0.9465288178046544,\n",
       "                                       'mid_layers': 0.9244442918735252,\n",
       "                                       'high_layers': 0.9811988866438147,\n",
       "                                       'all_layers': 0.8796124633098868}),\n",
       "                          'no-match': defaultdict(float,\n",
       "                                      {'low_layers': 0.9629654628396064,\n",
       "                                       'mid_layers': 0.9461569835374833,\n",
       "                                       'high_layers': 0.9749230568808157,\n",
       "                                       'all_layers': 0.9221393225387274}),\n",
       "                          'partial': defaultdict(float,\n",
       "                                      {'low_layers': 0.9554331619892072,\n",
       "                                       'mid_layers': 0.9305891071306811,\n",
       "                                       'high_layers': 0.9805873090779491,\n",
       "                                       'all_layers': 0.8794225191532917})}),\n",
       "             'node_len': defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'1': defaultdict(float,\n",
       "                                      {'low_layers': 0.9557251531735944,\n",
       "                                       'mid_layers': 0.9231901874511425,\n",
       "                                       'high_layers': 0.9793981519198377,\n",
       "                                       'all_layers': 0.8923402625968458}),\n",
       "                          '3': defaultdict(float,\n",
       "                                      {'low_layers': 0.9473831350538322,\n",
       "                                       'mid_layers': 0.9515573373983441,\n",
       "                                       'high_layers': 0.9782324699159453,\n",
       "                                       'all_layers': 0.9114464892878921}),\n",
       "                          '4+': defaultdict(float,\n",
       "                                      {'low_layers': 0.9552230558409193,\n",
       "                                       'mid_layers': 0.9117674455978414,\n",
       "                                       'high_layers': 0.9750042367666923,\n",
       "                                       'all_layers': 0.8463479260618555}),\n",
       "                          '2': defaultdict(float,\n",
       "                                      {'low_layers': 0.9570352127347617,\n",
       "                                       'mid_layers': 0.9553345532401597,\n",
       "                                       'high_layers': 0.9867568836233314,\n",
       "                                       'all_layers': 0.9264330007073771})})})"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg_by_aspect['all->t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_d = ctu.nested_json_processing(trace_scores_avg_by_aspect, func=lambda x: np.format_float_positional(x, precision=4, min_digits=4))\n",
    "# dump_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = f'/home/yshao/Projects/rome/results/exp5_4_decoder_cross_attention_removal/summ-exp=5.4_dev_{expect_type}-attn_crpt=weights.jsonl'\n",
    "\n",
    "with open(dump_path, 'w') as f:\n",
    "    json.dump(dump_d, f, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Good / correct ratio per class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asp_k -> asp_v -> {'good', 'too_easy', 'all_correct', 'ratio'}\n",
    "good_correct_stats = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "for d in good_samples:\n",
    "    for asp_k, asp_v in d['category'].items():\n",
    "        good_correct_stats[asp_k][asp_v]['good'] += 1\n",
    "        good_correct_stats[asp_k][asp_v]['all_correct'] += 1\n",
    "\n",
    "for d in too_easy_samples:\n",
    "    for asp_k, asp_v in d['category'].items():\n",
    "        good_correct_stats[asp_k][asp_v]['too_easy'] += 1\n",
    "        good_correct_stats[asp_k][asp_v]['all_correct'] += 1\n",
    "        \n",
    "for asp_k, d1 in good_correct_stats.items():\n",
    "    for asp_v, asp_d in d1.items():\n",
    "        asp_d['ratio'] = asp_d['good'] / asp_d['all_correct']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'exact': defaultdict(int,\n",
       "                         {'good': 653,\n",
       "                          'all_correct': 791,\n",
       "                          'too_easy': 138,\n",
       "                          'ratio': 0.8255372945638433}),\n",
       "             'no-match': defaultdict(int,\n",
       "                         {'good': 419,\n",
       "                          'all_correct': 443,\n",
       "                          'too_easy': 24,\n",
       "                          'ratio': 0.945823927765237}),\n",
       "             'partial': defaultdict(int,\n",
       "                         {'good': 194,\n",
       "                          'all_correct': 202,\n",
       "                          'too_easy': 8,\n",
       "                          'ratio': 0.9603960396039604})})"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_correct_stats['text_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\tgood  \tall_correct\ttoo_easy\tratio \n",
      "exact       \t653.0000\t791.0000\t138.0000\t0.8255\n",
      "no-match    \t419.0000\t443.0000\t24.0000\t0.9458\n",
      "partial     \t194.0000\t202.0000\t8.0000\t0.9604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(good_correct_stats['text_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all', 'ans->t', 'all->t', 'ans->s', 'all->s', 'ans->p', 'all->p', 'ans->o', 'all->o', 'ans->t+o', 'all->t+o', 'ans->c', 'all->c', 'ans->self', 'all->self'])"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump_path = f'/home/yshao/Projects/rome/results/exp5_4_decoder_cross_attention_removal/summ-exp=5.4_dev_{expect_type}-attn_crpt=weights.jsonl'\n",
    "\n",
    "with open(dump_path, 'r') as f:\n",
    "    dump_d = json.load(f)\n",
    "\n",
    "dump_d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asp_k -> asp_v -> sect_k -> layer_k -> val\n",
    "results_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "\n",
    "for sect_k, sect_d in dump_d.items():\n",
    "    if sect_k.startswith('ans->'):\n",
    "        continue\n",
    "        \n",
    "    for asp_k, d1 in sect_d.items():\n",
    "        if asp_k == 'overall':\n",
    "            continue\n",
    "        for asp_v, asp_d in d1.items():\n",
    "            for layer_k in asp_d.keys():\n",
    "                v = float(asp_d[layer_k])\n",
    "                results_by_aspect[asp_k][asp_v][sect_k][layer_k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_match = exact\n",
      "XXXXXXXXXXXX\tlow_layers\tmid_layers\thigh_layers\tall_layers\n",
      "all         \t0.6579    \t0.6245    \t0.0514    \t0.0160    \n",
      "all->t      \t0.9465    \t0.9244    \t0.9812    \t0.8796    \n",
      "all->s      \t0.9685    \t0.9386    \t0.4133    \t0.3229    \n",
      "all->p      \t0.9769    \t0.9584    \t0.9874    \t0.9565    \n",
      "all->o      \t0.9933    \t0.9929    \t0.9930    \t0.9913    \n",
      "all->t+o    \t0.9449    \t0.9254    \t0.9798    \t0.8760    \n",
      "all->c      \t0.9684    \t0.9889    \t0.9908    \t0.9527    \n",
      "all->self   \t0.9910    \t0.9589    \t0.4292    \t0.4146    \n",
      "\n",
      "\n",
      "text_match = no-match\n",
      "XXXXXXXXXXXX\tlow_layers\tmid_layers\thigh_layers\tall_layers\n",
      "all         \t0.3726    \t0.6184    \t0.0540    \t0.0139    \n",
      "all->t      \t0.9630    \t0.9462    \t0.9749    \t0.9221    \n",
      "all->s      \t0.7303    \t0.7756    \t0.1491    \t0.1614    \n",
      "all->p      \t0.8113    \t0.9099    \t0.9656    \t0.7972    \n",
      "all->o      \t0.9759    \t0.9774    \t0.9764    \t0.9729    \n",
      "all->t+o    \t0.9620    \t0.9455    \t0.9718    \t0.9137    \n",
      "all->c      \t0.8764    \t0.9808    \t0.9897    \t0.9343    \n",
      "all->self   \t0.8937    \t0.7265    \t0.1475    \t0.1669    \n",
      "\n",
      "\n",
      "text_match = partial\n",
      "XXXXXXXXXXXX\tlow_layers\tmid_layers\thigh_layers\tall_layers\n",
      "all         \t0.4019    \t0.5308    \t0.0283    \t0.0138    \n",
      "all->t      \t0.9554    \t0.9306    \t0.9806    \t0.8794    \n",
      "all->s      \t0.7607    \t0.7266    \t0.0584    \t0.0858    \n",
      "all->p      \t0.9382    \t0.9160    \t0.9729    \t0.9286    \n",
      "all->o      \t0.9909    \t0.9912    \t0.9917    \t0.9892    \n",
      "all->t+o    \t0.9568    \t0.9316    \t0.9804    \t0.8793    \n",
      "all->c      \t0.9438    \t0.9780    \t0.9548    \t0.8786    \n",
      "all->self   \t0.8936    \t0.7685    \t0.2553    \t0.2105    \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "asp_k = 'text_match'\n",
    "\n",
    "for asp_v, asp_d in results_by_aspect[asp_k].items():\n",
    "    print(f'{asp_k} = {asp_v}')\n",
    "    format_print_2D_dict(asp_d, col_w=10)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.5: both part attention removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_5_both_part_attention_removal/exp=5.5.1_dev_{expect_type}-attn_crpt=logits.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2039, (1631, 1631), 339, 69, 408, 'good / correct = 1631 / 1700')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            if k == 'window':\n",
    "                for l, s in v.items():\n",
    "                    trace_scores_avg[sect_k][f'{k}-{l}'] += s\n",
    "            else:\n",
    "                s = v\n",
    "                trace_scores_avg[sect_k][k] += s\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s->t&all->t': defaultdict(int,\n",
       "             {'E-all&D-all': 0.810587916234049,\n",
       "              'E-all&D-low': 0.8383651262275511,\n",
       "              'E-low&D-all': 0.8902601872852249})}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-all&D-all    0.8106\n",
      "E-all&D-low    0.8384\n",
      "E-low&D-all    0.8903\n"
     ]
    }
   ],
   "source": [
    "format_print_1D_dict(trace_scores_avg['s->t&all->t'], head_col_w=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (sect_k, asp_k, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no sect key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            asp_k = f'{aspect}={asp_val}'\n",
    "            for k, v in sect_d.items():\n",
    "                layer_k = k\n",
    "                s = v\n",
    "                trace_scores_by_aspect[sect_k][asp_k][layer_k].append(s)\n",
    "                    \n",
    "for sect_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for layer_k, s in d2.items():\n",
    "            trace_scores_avg_by_aspect[sect_k][asp_k][layer_k] = np.mean(s)\n",
    "            trace_scores_cnt_by_aspect[asp_k] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sect_k, sect_d in trace_scores_avg_by_aspect.items():\n",
    "#     sect_d['overall'] = dict()\n",
    "#     for layer_k, s in trace_scores_avg[sect_k].items():\n",
    "#         if layer_k.startswith('window'):\n",
    "#             # only keep a subset of layers \n",
    "#             _, l = layer_k.split('-')\n",
    "#             if not (int(l) % 4 == 3): continue\n",
    "#         sect_d['overall'][layer_k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('node_len=1', 578),\n",
       " ('node_len=2', 116),\n",
       " ('node_len=3', 369),\n",
       " ('node_len=4+', 203),\n",
       " ('node_role=group by', 82),\n",
       " ('node_role=having', 6),\n",
       " ('node_role=join', 85),\n",
       " ('node_role=order by', 82),\n",
       " ('node_role=select', 630),\n",
       " ('node_role=where', 381),\n",
       " ('sql_hardness=easy', 229),\n",
       " ('sql_hardness=extra', 211),\n",
       " ('sql_hardness=hard', 240),\n",
       " ('sql_hardness=medium', 586),\n",
       " ('text_match=exact', 653),\n",
       " ('text_match=no-match', 419),\n",
       " ('text_match=partial', 194)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(trace_scores_cnt_by_aspect.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'easy': defaultdict(float,\n",
       "             {'E-all&D-all': 0.6952432668401013,\n",
       "              'E-all&D-low': 0.9067031433060689,\n",
       "              'E-low&D-all': 0.9375170493903875}),\n",
       " 'medium': defaultdict(float,\n",
       "             {'E-all&D-all': 0.556048543710707,\n",
       "              'E-all&D-low': 0.8054229393484426,\n",
       "              'E-low&D-all': 0.8955880533978087}),\n",
       " 'hard': defaultdict(float,\n",
       "             {'E-all&D-all': 0.5484870432557414,\n",
       "              'E-all&D-low': 0.8360452807140587,\n",
       "              'E-low&D-all': 0.8290000068771377}),\n",
       " 'extra': defaultdict(float,\n",
       "             {'E-all&D-all': 0.6368124696327836,\n",
       "              'E-all&D-low': 0.8165238064917822,\n",
       "              'E-low&D-all': 0.8967893739510424})}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: trace_scores_avg_by_aspect['s->t&all->t'][f'sql_hardness={k}'] for k in ['easy', 'medium', 'hard', 'extra']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': defaultdict(float,\n",
       "             {'E-all&D-all': 0.5947468875597053,\n",
       "              'E-all&D-low': 0.8776616909043937,\n",
       "              'E-low&D-all': 0.8787339264019262}),\n",
       " 'partial': defaultdict(float,\n",
       "             {'E-all&D-all': 0.49977204983319107,\n",
       "              'E-all&D-low': 0.8079702937117633,\n",
       "              'E-low&D-all': 0.8836331785910234}),\n",
       " 'no-match': defaultdict(float,\n",
       "             {'E-all&D-all': 0.6342099784024492,\n",
       "              'E-all&D-low': 0.7701454216605397,\n",
       "              'E-low&D-all': 0.9127696242686905})}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: trace_scores_avg_by_aspect['s->t&all->t'][f'text_match={k}'] for k in ['exact', 'partial', 'no-match']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_ids = []\n",
    "for i, d in enumerate(good_samples):\n",
    "    if d['category']['text_match'] == 'exact':\n",
    "        continue\n",
    "    # here: no exact text match \n",
    "    if d['trace_scores']['s->t&all->t']['E-all&D-all'] < 0.5:\n",
    "        continue\n",
    "    # here: corrupted pred is correct \n",
    "    ob_ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 [9, 77, 96, 116, 138, 150, 177, 200, 228, 255, 282, 297, 375, 386, 439, 487, 530, 584, 604, 635, 673, 755, 849, 874, 892, 911, 926, 962, 986, 1003, 1019, 1039, 1082, 1108, 1156, 1211]\n"
     ]
    }
   ],
   "source": [
    "print(len(ob_ids), ob_ids[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'What is the average, minimum, and maximum age of all singers from France?; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country ( France ) , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id',\n",
       " 'seq_out': \"select avg(age), min(age), max(age) from singer where country = 'France'\",\n",
       " 'dec_prompt': 'select avg(age), min(age), max(age) from singer where',\n",
       " 'expect': 'country',\n",
       " 'expect_type': 'column',\n",
       " 'db_id': 'concert_singer',\n",
       " 'expect_input_ranges': [[68, 73]],\n",
       " 'self_ranges': [[66, 75]],\n",
       " 'expect_table': 'singer',\n",
       " 'answer': 'country',\n",
       " 'base_score': 0.9999995231628418,\n",
       " 'answers_t': [684],\n",
       " 'correct_prediction': True,\n",
       " 'category': {'sql_hardness': 'medium',\n",
       "  'node_role': 'where',\n",
       "  'text_match': 'no-match',\n",
       "  'node_len': '1'},\n",
       " 'corrupted_answers_t': [2306],\n",
       " 'corrupted_answer': 'album',\n",
       " 'low_score': 5.606463673757389e-06,\n",
       " 'is_good_sample': True,\n",
       " 'trace_scores': {'s->t&all->t': {'E-all&D-all': 0.9999951124191284,\n",
       "   'E-all&D-low': 0.9999991655349731,\n",
       "   'E-low&D-all': 0.9999998807907104}},\n",
       " 'ex_id': 4}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-6.0: corruption effect - syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp6_0_encoding_corruption_effect_syntax/exp=6.0_dev.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10233, (2261, 2261), 1623, 6349, 7972, 'good / correct = 2261 / 8610')"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d.get('is_good_sample', True):\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += v\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': defaultdict(int,\n",
       "             {'embed': 0.2704069729491695, 'final_enc': 0.43288231847139375}),\n",
       " 'struct': defaultdict(int,\n",
       "             {'embed': 0.8434888537914244, 'final_enc': 0.7056294551667914}),\n",
       " 'columns': defaultdict(int,\n",
       "             {'embed': 0.8977011346416999, 'final_enc': 0.9094602057515592}),\n",
       " 'tables': defaultdict(int,\n",
       "             {'embed': 0.9401333304200568, 'final_enc': 0.9652279544981762}),\n",
       " 'all': defaultdict(int,\n",
       "             {'embed': 0.04223158108438767, 'final_enc': 0.14583704401879738})}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\tembed \tfinal_enc\n",
      "text        \t0.2704\t0.4329\n",
      "struct      \t0.8435\t0.7056\n",
      "columns     \t0.8977\t0.9095\n",
      "tables      \t0.9401\t0.9652\n",
      "all         \t0.0422\t0.1458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(trace_scores_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corruption overall effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict[str, int]: expect_tok -> num of effective / not effective corruptions (all)\n",
    "eff_counter = Counter()\n",
    "neff_counter = Counter()\n",
    "\n",
    "for d in good_samples:\n",
    "    eff_counter[d['expect']] += 1\n",
    "for d in bad_samples:\n",
    "    if d['correct_prediction']:\n",
    "        # \"too easy\", corruption not effective \n",
    "        neff_counter[d['expect']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_rate_d = dict()\n",
    "\n",
    "for k in list(set(eff_counter.keys()) | set(neff_counter.keys())):\n",
    "    eff_c = eff_counter[k]\n",
    "    neff_c = neff_counter[k]\n",
    "    eff_r = 1.0 * eff_c / (eff_c + neff_c)\n",
    "    eff_rate_d[k] = eff_r\n",
    "    # print(f'{k:<10s}{eff_c:5d} /{eff_c + neff_c:5d} = {eff_r:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!=\t20\t20\t1.0000\n",
      "or\t34\t34\t1.0000\n",
      "between\t6\t6\t1.0000\n",
      "intersect\t34\t34\t1.0000\n",
      "union\t6\t6\t1.0000\n",
      "asc\t19\t19\t1.0000\n",
      "min\t18\t18\t1.0000\n",
      "avg\t65\t65\t1.0000\n",
      "max\t30\t30\t1.0000\n",
      "except\t21\t21\t1.0000\n",
      "like\t12\t12\t1.0000\n",
      "having\t80\t81\t0.9877\n",
      "distinct\t25\t26\t0.9615\n",
      "sum\t21\t22\t0.9545\n",
      "where\t484\t516\t0.9380\n",
      "not\t42\t46\t0.9130\n",
      "group\t225\t265\t0.8491\n",
      "and\t31\t39\t0.7949\n",
      "count\t267\t406\t0.6576\n",
      "order\t142\t221\t0.6425\n",
      ">\t61\t101\t0.6040\n",
      ")\t11\t23\t0.4783\n",
      "=\t191\t968\t0.1973\n",
      "as\t93\t952\t0.0977\n",
      "desc\t16\t164\t0.0976\n",
      "in\t4\t50\t0.0800\n",
      "join\t39\t496\t0.0786\n",
      "from\t49\t1196\t0.0410\n",
      "limit\t6\t177\t0.0339\n",
      ">=\t1\t30\t0.0333\n",
      "(\t22\t675\t0.0326\n",
      "select\t0\t88\t0.0000\n",
      "on\t0\t516\t0.0000\n",
      "by\t0\t516\t0.0000\n",
      "*\t0\t381\t0.0000\n"
     ]
    }
   ],
   "source": [
    "for k, eff_r in sorted(eff_rate_d.items(), key=lambda x: x[1], reverse=True):\n",
    "    eff_c = eff_counter[k]\n",
    "    neff_c = neff_counter[k]\n",
    "    all_c = eff_c + neff_c\n",
    "    if all_c <= 2: continue\n",
    "    if k.isnumeric(): continue\n",
    "#     print(f'{k:<10s}{eff_c:5d} /{all_c:5d} = {eff_r:.4f}')\n",
    "    print(f'{k}\\t{eff_c}\\t{all_c}\\t{eff_r:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by expect syntax token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (expect_tok, sect_k, layer) -> [scores]\n",
    "trace_scores_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "trace_scores_avg_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "trace_scores_cnt_by_exp_tok = defaultdict(int)  # no sect key & layer key \n",
    "\n",
    "trace_sample_ids_by_exp_tok = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(good_samples):\n",
    "    expect = d['expect']\n",
    "    trace_sample_ids_by_exp_tok[expect].append(i)\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for layer_k, v in sect_d.items():\n",
    "            trace_scores_by_exp_tok[expect][sect_k][layer_k].append(v)\n",
    "\n",
    "for exp_tok, d1 in trace_scores_by_exp_tok.items():\n",
    "    if exp_tok.isnumeric(): continue\n",
    "    for sect_k, d2 in d1.items():\n",
    "        for layer_k, scores in d2.items():\n",
    "            if len(scores) <= 2: continue\n",
    "            trace_scores_avg_by_exp_tok[exp_tok][sect_k][layer_k] = np.mean(scores)\n",
    "            trace_scores_cnt_by_exp_tok[exp_tok] = len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'count': 267,\n",
       "             'order': 142,\n",
       "             'avg': 65,\n",
       "             'min': 18,\n",
       "             'max': 30,\n",
       "             'where': 484,\n",
       "             'distinct': 25,\n",
       "             '>': 61,\n",
       "             'group': 225,\n",
       "             '(': 22,\n",
       "             'between': 6,\n",
       "             'from': 49,\n",
       "             'desc': 16,\n",
       "             'or': 34,\n",
       "             'not': 42,\n",
       "             'intersect': 34,\n",
       "             'except': 21,\n",
       "             'as': 93,\n",
       "             'join': 39,\n",
       "             'like': 12,\n",
       "             'and': 31,\n",
       "             '=': 191,\n",
       "             'having': 80,\n",
       "             '!=': 20,\n",
       "             'union': 6,\n",
       "             'limit': 6,\n",
       "             'sum': 21,\n",
       "             'asc': 19,\n",
       "             ')': 11,\n",
       "             'in': 4})"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_exp_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'text': defaultdict(float,\n",
       "                         {'embed': 0.07181598544092065,\n",
       "                          'final_enc': 0.08561127370659098}),\n",
       "             'struct': defaultdict(float,\n",
       "                         {'embed': 0.9997616432579269,\n",
       "                          'final_enc': 0.9906901482785686}),\n",
       "             'columns': defaultdict(float,\n",
       "                         {'embed': 0.9989915059300397,\n",
       "                          'final_enc': 0.9982228384035804}),\n",
       "             'tables': defaultdict(float,\n",
       "                         {'embed': 0.9940267473124387,\n",
       "                          'final_enc': 0.9992919242783879}),\n",
       "             'all': defaultdict(float,\n",
       "                         {'embed': 0.022402080392785025,\n",
       "                          'final_enc': 0.07584266595464821})})"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg_by_exp_tok['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "sect_k = 'struct'\n",
    "layer_k = 'final_enc'\n",
    "scores_d = dict()\n",
    "\n",
    "for exp_tok, d1 in trace_scores_avg_by_exp_tok.items():\n",
    "    s = d1[sect_k][layer_k]\n",
    "    scores_d[exp_tok] = s\n",
    "    # print(f'{exp_tok:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min       0.9988\n",
      "sum       0.9949\n",
      "distinct  0.9942\n",
      "count     0.9907\n",
      "avg       0.9820\n",
      "like      0.9440\n",
      ">         0.9256\n",
      "max       0.9167\n",
      "between   0.9151\n",
      "having    0.8882\n",
      "and       0.8846\n",
      "or        0.8764\n",
      "intersect 0.8033\n",
      "union     0.7311\n",
      "!=        0.7206\n",
      "asc       0.7038\n",
      "(         0.7033\n",
      "order     0.6748\n",
      "where     0.6481\n",
      "limit     0.6085\n",
      "except    0.6078\n",
      "desc      0.5801\n",
      "=         0.5578\n",
      "from      0.5052\n",
      "group     0.4578\n",
      ")         0.4223\n",
      "not       0.4213\n",
      "as        0.3979\n",
      "in        0.2511\n",
      "join      0.1060\n"
     ]
    }
   ],
   "source": [
    "for k, s in sorted(scores_d.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{k:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from      0.8645\n",
      "as        0.8363\n",
      "=         0.8272\n",
      "in        0.7407\n",
      ")         0.7101\n",
      "desc      0.4644\n",
      "where     0.3572\n",
      ">         0.3472\n",
      "join      0.3131\n",
      "not       0.2707\n",
      "and       0.2300\n",
      "having    0.1737\n",
      "min       0.1698\n",
      "(         0.1657\n",
      "like      0.1639\n",
      "union     0.1435\n",
      "order     0.1126\n",
      "group     0.1046\n",
      "asc       0.0877\n",
      "count     0.0718\n",
      "avg       0.0311\n",
      "or        0.0211\n",
      "except    0.0106\n",
      "distinct  0.0097\n",
      "max       0.0073\n",
      "sum       0.0017\n",
      "intersect 0.0005\n",
      "!=        0.0000\n",
      "between   0.0000\n",
      "limit     0.0000\n"
     ]
    }
   ],
   "source": [
    "sect_k = 'text'\n",
    "layer_k = 'embed'\n",
    "scores_d = dict()\n",
    "\n",
    "for exp_tok, d1 in trace_scores_avg_by_exp_tok.items():\n",
    "    s = d1[sect_k][layer_k]\n",
    "    scores_d[exp_tok] = s\n",
    "    # print(f'{exp_tok:<10s}{s:.4f}')\n",
    "\n",
    "for k, s in sorted(scores_d.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{k:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrupted answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict[str, Dict[str, int]]: exp_tok -> c_ans, cnt\n",
    "confusion_counter = defaultdict(Counter)\n",
    "\n",
    "for d in good_samples:\n",
    "    exp_tok = d['expect']\n",
    "    c_ans = d['corrupted_answer']\n",
    "    if exp_tok.isnumeric():\n",
    "        exp_tok = 'NUM'\n",
    "    if c_ans.isnumeric():\n",
    "        c_ans = 'NUM'\n",
    "    confusion_counter[exp_tok][c_ans] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'count': Counter({'*': 182, '': 64, 'sum': 19, 'count': 2}),\n",
       "             'order': Counter({'</s>': 96,\n",
       "                      'join': 12,\n",
       "                      ')': 2,\n",
       "                      'where': 9,\n",
       "                      'NUM': 5,\n",
       "                      'order': 3,\n",
       "                      'union': 2,\n",
       "                      'and': 2,\n",
       "                      'select': 4,\n",
       "                      's': 6,\n",
       "                      '_': 1}),\n",
       "             'avg': Counter({'*tvg': 43,\n",
       "                      'maxtvg': 8,\n",
       "                      'maxavg': 2,\n",
       "                      'tvg': 6,\n",
       "                      'mintvg': 2,\n",
       "                      'counttvg': 4}),\n",
       "             'min': Counter({'': 9, 'max': 5, '*': 4}),\n",
       "             'max': Counter({'': 13, '*': 16, 'min': 1}),\n",
       "             'where': Counter({'group': 19,\n",
       "                      'except': 2,\n",
       "                      '</s>': 239,\n",
       "                      'order': 114,\n",
       "                      'where': 9,\n",
       "                      ')': 16,\n",
       "                      ';': 5,\n",
       "                      'join': 36,\n",
       "                      'in': 3,\n",
       "                      'union': 2,\n",
       "                      'r': 3,\n",
       "                      '.': 5,\n",
       "                      'as': 17,\n",
       "                      'select': 2,\n",
       "                      '': 1,\n",
       "                      'class': 1,\n",
       "                      's': 10}),\n",
       "             'distinct': Counter({'*': 25}),\n",
       "             '>': Counter({'=': 55, 'in': 2, '</s>': 1, 'not': 1, 'des': 2}),\n",
       "             'NUM': Counter({'=': 70,\n",
       "                      't': 2,\n",
       "                      'NUM': 55,\n",
       "                      '\"': 22,\n",
       "                      '': 12,\n",
       "                      '(': 2,\n",
       "                      '=000': 6,\n",
       "                      ' and': 3,\n",
       "                      '=</s>': 4,\n",
       "                      '= join': 1,\n",
       "                      '3-': 1,\n",
       "                      '3%': 1,\n",
       "                      '%': 2,\n",
       "                      ')': 2,\n",
       "                      '</s>': 2}),\n",
       "             'group': Counter({'join': 21,\n",
       "                      '</s>': 98,\n",
       "                      'order': 29,\n",
       "                      'as': 16,\n",
       "                      'where': 25,\n",
       "                      'group': 3,\n",
       "                      'air': 5,\n",
       "                      '.': 4,\n",
       "                      'r': 1,\n",
       "                      'in': 2,\n",
       "                      'NUM': 2,\n",
       "                      'from': 2,\n",
       "                      'form': 2,\n",
       "                      'union': 4,\n",
       "                      's': 2,\n",
       "                      'express': 2,\n",
       "                      'l': 1,\n",
       "                      ';': 2,\n",
       "                      '=': 2,\n",
       "                      'and': 2}),\n",
       "             '(': Counter({'=': 11, '': 5, 'NUM': 6}),\n",
       "             'between': Counter({'>': 4, '=': 2}),\n",
       "             'from': Counter({'(': 1,\n",
       "                      'a': 2,\n",
       "                      '': 5,\n",
       "                      ')': 5,\n",
       "                      'ious': 2,\n",
       "                      ';': 1,\n",
       "                      'from': 2,\n",
       "                      'up': 2,\n",
       "                      'i': 2,\n",
       "                      'air': 1,\n",
       "                      'de': 8,\n",
       "                      'le': 2,\n",
       "                      'group': 2,\n",
       "                      '=': 2,\n",
       "                      '-': 2,\n",
       "                      ',': 2,\n",
       "                      'al': 4,\n",
       "                      'ture': 2,\n",
       "                      'call': 2}),\n",
       "             'desc': Counter({'desc': 3,\n",
       "                      'c': 2,\n",
       "                      'sc': 1,\n",
       "                      'ec': 2,\n",
       "                      '</s>c': 4,\n",
       "                      ',c': 1,\n",
       "                      'fromc': 2,\n",
       "                      'limitc': 1}),\n",
       "             'or': Counter({'</s>': 28, 'NUM': 2, 'order': 2, 'and': 2}),\n",
       "             '>=': Counter({'= 60': 1}),\n",
       "             'not': Counter({'=': 40, '': 2}),\n",
       "             'intersect': Counter({'and': 3,\n",
       "                      '</s>': 22,\n",
       "                      '-': 1,\n",
       "                      '-04': 4,\n",
       "                      'order': 4}),\n",
       "             'except': Counter({'order': 10, 'join': 4, '</s>': 7}),\n",
       "             'as': Counter({'_': 2,\n",
       "                      'i': 8,\n",
       "                      'order': 6,\n",
       "                      '</s>': 23,\n",
       "                      'er': 21,\n",
       "                      're': 1,\n",
       "                      'base': 6,\n",
       "                      'join': 7,\n",
       "                      'as': 3,\n",
       "                      ';': 2,\n",
       "                      'ment': 12,\n",
       "                      'in': 2}),\n",
       "             'join': Counter({'</s>': 32,\n",
       "                      ')': 2,\n",
       "                      'where': 1,\n",
       "                      'y': 2,\n",
       "                      'order': 1,\n",
       "                      'join': 1}),\n",
       "             'like': Counter({'=': 8, 'not': 1, 'in': 2, '': 1}),\n",
       "             'and': Counter({'</s>': 29, 'group': 2}),\n",
       "             '=': Counter({'a': 2,\n",
       "                      '</s>': 11,\n",
       "                      'y': 4,\n",
       "                      'ance': 4,\n",
       "                      '_': 5,\n",
       "                      'up': 2,\n",
       "                      'al': 2,\n",
       "                      'not': 39,\n",
       "                      'in': 34,\n",
       "                      '': 33,\n",
       "                      '.': 1,\n",
       "                      'd': 2,\n",
       "                      '=': 8,\n",
       "                      ';': 1,\n",
       "                      '>': 4,\n",
       "                      '\"': 9,\n",
       "                      's': 19,\n",
       "                      'ment': 1,\n",
       "                      'language': 4,\n",
       "                      'foreign': 3,\n",
       "                      '*': 1,\n",
       "                      'c': 2}),\n",
       "             'having': Counter({'</s>': 47, 'order': 31, 'a': 2}),\n",
       "             '!=': Counter({'=!=': 16, 'in!=': 2, '=t=': 1, '!=': 1}),\n",
       "             'union': Counter({'NUM': 2, '</s>': 2, 'as': 2}),\n",
       "             'limit': Counter({'des': 6}),\n",
       "             'sum': Counter({'*': 12, 'count': 5, '': 4}),\n",
       "             'asc': Counter({'desc': 17, '</s>c': 2}),\n",
       "             ')': Counter({'group)': 2, ')': 1, 't': 4, '))': 2, ');': 2}),\n",
       "             ',': Counter({'joint': 1}),\n",
       "             'in': Counter({'=': 4})})"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case study\n",
    "- Now only for the low-score setting (all-layer, embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the average, minimum, and maximum age of all singers from France?\n",
      "select avg(age), min(age), -->  (max)\n",
      "\n",
      "What is the average, minimum, and maximum age for all French singers?\n",
      "select avg(age), min(age), -->  (max)\n",
      "\n",
      "What is the maximum capacity and the average of all stadiums ?\n",
      "select --> * (max)\n",
      "\n",
      "What is the average and maximum capacities for all stadiums ?\n",
      "select avg(capacity), -->  (max)\n",
      "\n",
      "Find the maximum weight for each type of pet. List the maximum weight and pet type.\n",
      "select --> * (max)\n",
      "\n",
      "List the maximum weight and type for each type of pet.\n",
      "select --> * (max)\n",
      "\n",
      "Find the average and maximum age for each type of pet.\n",
      "select avg(pet_age), -->  (max)\n",
      "\n",
      "What is the average and maximum age for each pet type?\n",
      "select avg(pet_age), -->  (max)\n",
      "\n",
      "What is the maximum accelerate for different number of cylinders?\n",
      "select --> * (max)\n",
      "\n",
      "What is the maximum accelerate for all the different cylinders?\n",
      "select --> * (max)\n",
      "\n",
      "What is the maximum miles per gallon of the car with 8 cylinders or produced before 1980 ?\n",
      "select --> * (max)\n",
      "\n",
      "What is the maximum mpg of the cars that had 8 cylinders or that were produced before 1980 ?\n",
      "select --> * (max)\n",
      "\n",
      "find the minimum and maximum number of products of all stores.\n",
      "select min(number_products), -->  (max)\n",
      "\n",
      "What are the minimum and maximum number of products across all the shops?\n",
      "select min(number_products), -->  (max)\n",
      "\n",
      "What are the average and maximum number of tickets bought in all visits?\n",
      "select avg(num_of_ticket), -->  (max)\n",
      "\n",
      "What is maximum and minimum death toll caused each time?\n",
      "select --> * (max)\n",
      "\n",
      "What is the maximum and minimum share for the TV series?\n",
      "select --> * (max)\n",
      "\n",
      "What is the maximum number of final tables made among poker players with earnings less than 200000?\n",
      "select --> * (max)\n",
      "\n",
      "Return the maximum final tables made across all poker players who have earnings below 200000.\n",
      "select --> * (max)\n",
      "\n",
      "What are the maximum and minimum values of area codes?\n",
      "select --> * (max)\n",
      "\n",
      "What is the total population and maximum GNP in Asia?\n",
      "select sum(population), -->  (max)\n",
      "\n",
      "Which Asian countries have a population that is larger than any country in Africa?\n",
      "select name from country where continent = \"Asia\" and population > (select --> min (max)\n",
      "\n",
      "What is the language spoken by the largest percentage of people in each country?\n",
      "select language, countrycode, -->  (max)\n",
      "\n",
      "What are the country codes of the different countries, and what are the languages spoken by the greatest percentage of people for each?\n",
      "select language, countrycode, -->  (max)\n",
      "\n",
      "What are the maximum and minimum share of performances whose type is not \"Live final\".\n",
      "select --> * (max)\n",
      "\n",
      "Return the maximum and minimum shares for performances that do not have the type \"Live final\".\n",
      "select --> * (max)\n",
      "\n",
      "What is the age of the oldest dog?\n",
      "select --> * (max)\n",
      "\n",
      "Tell me the age of the oldest dog.\n",
      "select --> * (max)\n",
      "\n",
      "Show different citizenships and the maximum net worth of singers of each citizenship.\n",
      "select citizenship, -->  (max)\n",
      "\n",
      "For each citizenship, what is the maximum net worth?\n",
      "select citizenship, -->  (max)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in trace_sample_ids_by_exp_tok['max']:\n",
    "    d = good_samples[idx]\n",
    "    _text = d['enc_sentence'].split(';')[0]\n",
    "    print(f\"{_text}\\n{d['dec_prompt']} --> {d['corrupted_answer']} ({d['expect']})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-6.1: attention corruption effect - syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp6_1_attention_corruption_effect_syntax/exp=6.1.1_dev-attn_crpt=logits.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10233, (2375, 2375), 1623, 6235, 7858, 'good / correct = 2375 / 8610')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d.get('is_good_sample', True):\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_samples[0]['trace_scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += v\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t->s': defaultdict(int,\n",
       "             {'low_layers': 0.9873034850396216,\n",
       "              'high_layers': 0.9794485656297967,\n",
       "              'all_layers': 0.9705235183159128}),\n",
       " 's->t': defaultdict(int,\n",
       "             {'low_layers': 0.9914981258135093,\n",
       "              'high_layers': 0.9701850305394514,\n",
       "              'all_layers': 0.9438354478774255}),\n",
       " 't<->s': defaultdict(int,\n",
       "             {'low_layers': 0.9846226840465281,\n",
       "              'high_layers': 0.9617710263219753,\n",
       "              'all_layers': 0.9230146904192555}),\n",
       " 't->p': defaultdict(int,\n",
       "             {'low_layers': 0.9806906042866831,\n",
       "              'high_layers': 0.889322833697198,\n",
       "              'all_layers': 0.8364523902912913}),\n",
       " 's->p': defaultdict(int,\n",
       "             {'low_layers': 0.9860267275776025,\n",
       "              'high_layers': 0.9480603549151314,\n",
       "              'all_layers': 0.9385463390567251}),\n",
       " 'ts->p': defaultdict(int,\n",
       "             {'low_layers': 0.9725087593267217,\n",
       "              'high_layers': 0.7826832817374065,\n",
       "              'all_layers': 0.6455722338362194}),\n",
       " 't->t': defaultdict(int,\n",
       "             {'low_layers': 0.9536315989037909,\n",
       "              'high_layers': 0.9105434243858079,\n",
       "              'all_layers': 0.7346053336587007}),\n",
       " 's->s': defaultdict(int,\n",
       "             {'low_layers': 0.8818130838352181,\n",
       "              'high_layers': 0.9008996876131293,\n",
       "              'all_layers': 0.8485663077117429}),\n",
       " 'all': defaultdict(int,\n",
       "             {'low_layers': 0.6232894862470176,\n",
       "              'high_layers': 0.23267148181337774,\n",
       "              'all_layers': 0.034856813143760025})}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t->s    \t0.9873\t0.9794\t0.9705\n",
      "s->t    \t0.9915\t0.9702\t0.9438\n",
      "t<->s   \t0.9846\t0.9618\t0.9230\n",
      "t->p    \t0.9807\t0.8893\t0.8365\n",
      "s->p    \t0.9860\t0.9481\t0.9385\n",
      "ts->p   \t0.9725\t0.7827\t0.6456\n",
      "t->t    \t0.9536\t0.9105\t0.7346\n",
      "s->s    \t0.8818\t0.9009\t0.8486\n",
      "all     \t0.6233\t0.2327\t0.0349\n"
     ]
    }
   ],
   "source": [
    "layers_keys = ['low_layers', 'high_layers', 'all_layers']\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    print_l = f'{sect_k:<8s}'\n",
    "    for k in layers_keys:\n",
    "        s = sect_d[k]\n",
    "        print_l += f'\\t{s:.4f}'\n",
    "    print(print_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corruption overall effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict[str, int]: expect_tok -> num of effective / not effective corruptions (all)\n",
    "eff_counter = Counter()\n",
    "neff_counter = Counter()\n",
    "\n",
    "for d in good_samples:\n",
    "    eff_counter[d['expect']] += 1\n",
    "for d in bad_samples:\n",
    "    if d['correct_prediction']:\n",
    "        # \"too easy\", corruption not effective \n",
    "        neff_counter[d['expect']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_rate_d = dict()\n",
    "\n",
    "for k in list(set(eff_counter.keys()) | set(neff_counter.keys())):\n",
    "    eff_c = eff_counter[k]\n",
    "    neff_c = neff_counter[k]\n",
    "    eff_r = 1.0 * eff_c / (eff_c + neff_c)\n",
    "    eff_rate_d[k] = eff_r\n",
    "    # print(f'{k:<10s}{eff_c:5d} /{eff_c + neff_c:5d} = {eff_r:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union\t6\t6\t1.0000\n",
      "!=\t20\t20\t1.0000\n",
      "like\t12\t12\t1.0000\n",
      "or\t34\t34\t1.0000\n",
      "asc\t19\t19\t1.0000\n",
      "distinct\t26\t26\t1.0000\n",
      "between\t6\t6\t1.0000\n",
      "except\t21\t21\t1.0000\n",
      "intersect\t34\t34\t1.0000\n",
      "not\t45\t46\t0.9783\n",
      "avg\t63\t65\t0.9692\n",
      "max\t29\t30\t0.9667\n",
      "having\t77\t81\t0.9506\n",
      "group\t241\t265\t0.9094\n",
      "sum\t20\t22\t0.9091\n",
      "order\t197\t221\t0.8914\n",
      "min\t14\t18\t0.7778\n",
      "and\t29\t39\t0.7436\n",
      "count\t294\t406\t0.7241\n",
      "where\t350\t516\t0.6783\n",
      ">\t68\t101\t0.6733\n",
      ")\t13\t23\t0.5652\n",
      "desc\t82\t164\t0.5000\n",
      ">=\t11\t30\t0.3667\n",
      "from\t263\t1196\t0.2199\n",
      "in\t8\t50\t0.1600\n",
      "limit\t26\t177\t0.1469\n",
      "(\t98\t675\t0.1452\n",
      "=\t128\t968\t0.1322\n",
      "join\t44\t496\t0.0887\n",
      "as\t52\t952\t0.0546\n",
      "*\t10\t381\t0.0262\n",
      "by\t0\t516\t0.0000\n",
      "on\t0\t516\t0.0000\n",
      "select\t0\t88\t0.0000\n"
     ]
    }
   ],
   "source": [
    "for k, eff_r in sorted(eff_rate_d.items(), key=lambda x: x[1], reverse=True):\n",
    "    eff_c = eff_counter[k]\n",
    "    neff_c = neff_counter[k]\n",
    "    all_c = eff_c + neff_c\n",
    "    if all_c <= 2: continue\n",
    "    if k.isnumeric(): continue\n",
    "#     print(f'{k:<10s}{eff_c:5d} /{all_c:5d} = {eff_r:.4f}')\n",
    "    print(f'{k}\\t{eff_c}\\t{all_c}\\t{eff_r:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by expect syntax token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (expect_tok, sect_k, layer) -> [scores]\n",
    "trace_scores_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "trace_scores_avg_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "trace_scores_cnt_by_exp_tok = defaultdict(int)  # no sect key & layer key \n",
    "\n",
    "trace_sample_ids_by_exp_tok = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(good_samples):\n",
    "    expect = d['expect']\n",
    "    trace_sample_ids_by_exp_tok[expect].append(i)\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for layer_k, v in sect_d.items():\n",
    "            trace_scores_by_exp_tok[expect][sect_k][layer_k].append(v)\n",
    "\n",
    "for exp_tok, d1 in trace_scores_by_exp_tok.items():\n",
    "    if exp_tok.isnumeric(): continue\n",
    "    for sect_k, d2 in d1.items():\n",
    "        for layer_k, scores in d2.items():\n",
    "            if len(scores) <= 2: continue\n",
    "            trace_scores_avg_by_exp_tok[exp_tok][sect_k][layer_k] = np.mean(scores)\n",
    "            trace_scores_cnt_by_exp_tok[exp_tok] = len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'count': 294,\n",
       "             'order': 197,\n",
       "             'desc': 82,\n",
       "             'avg': 63,\n",
       "             'min': 14,\n",
       "             'max': 29,\n",
       "             'where': 350,\n",
       "             '=': 128,\n",
       "             'distinct': 26,\n",
       "             'from': 263,\n",
       "             '>': 68,\n",
       "             'group': 241,\n",
       "             '(': 98,\n",
       "             'between': 6,\n",
       "             'limit': 26,\n",
       "             'or': 34,\n",
       "             '>=': 11,\n",
       "             'not': 45,\n",
       "             'intersect': 34,\n",
       "             'except': 21,\n",
       "             'as': 52,\n",
       "             'join': 44,\n",
       "             'like': 12,\n",
       "             'and': 29,\n",
       "             'in': 8,\n",
       "             'having': 77,\n",
       "             '!=': 20,\n",
       "             '*': 10,\n",
       "             'union': 6,\n",
       "             'sum': 20,\n",
       "             'asc': 19,\n",
       "             ')': 13})"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_exp_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'t->s': defaultdict(float,\n",
       "                         {'low_layers': 0.9978861685107354,\n",
       "                          'high_layers': 0.9932368714425738,\n",
       "                          'all_layers': 0.9911034725571596}),\n",
       "             's->t': defaultdict(float,\n",
       "                         {'low_layers': 0.9994523721892817,\n",
       "                          'high_layers': 0.9979493310865091,\n",
       "                          'all_layers': 0.997748848329596}),\n",
       "             't<->s': defaultdict(float,\n",
       "                         {'low_layers': 0.998062480874613,\n",
       "                          'high_layers': 0.995554579890707,\n",
       "                          'all_layers': 0.9959644333643167}),\n",
       "             't->p': defaultdict(float,\n",
       "                         {'low_layers': 0.9941589293855347,\n",
       "                          'high_layers': 0.9844484830047099,\n",
       "                          'all_layers': 0.9640641826280487}),\n",
       "             's->p': defaultdict(float,\n",
       "                         {'low_layers': 0.9997543060049718,\n",
       "                          'high_layers': 0.9865310551390487,\n",
       "                          'all_layers': 0.9850442271527587}),\n",
       "             'ts->p': defaultdict(float,\n",
       "                         {'low_layers': 0.992053749685993,\n",
       "                          'high_layers': 0.9076947870914203,\n",
       "                          'all_layers': 0.7469466893840571}),\n",
       "             't->t': defaultdict(float,\n",
       "                         {'low_layers': 0.95961485076646,\n",
       "                          'high_layers': 0.9813218236079703,\n",
       "                          'all_layers': 0.8608877147373191}),\n",
       "             's->s': defaultdict(float,\n",
       "                         {'low_layers': 0.9938991388657068,\n",
       "                          'high_layers': 0.9873157823699856,\n",
       "                          'all_layers': 0.8691012370157356}),\n",
       "             'all': defaultdict(float,\n",
       "                         {'low_layers': 0.7315069800832695,\n",
       "                          'high_layers': 0.6354717421335181,\n",
       "                          'all_layers': 0.02197208333187588})})"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg_by_exp_tok['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "sect_k = 't<->s'\n",
    "layer_k = 'all_layers'\n",
    "scores_d = dict()\n",
    "\n",
    "for exp_tok, d1 in trace_scores_avg_by_exp_tok.items():\n",
    "    s = d1[sect_k][layer_k]\n",
    "    scores_d[exp_tok] = s\n",
    "    # print(f'{exp_tok:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">=        1.0000\n",
      ">         1.0000\n",
      "like      1.0000\n",
      "*         1.0000\n",
      "min       1.0000\n",
      "between   1.0000\n",
      "in        0.9992\n",
      "avg       0.9972\n",
      "count     0.9960\n",
      "(         0.9946\n",
      "desc      0.9942\n",
      "having    0.9894\n",
      "order     0.9826\n",
      "!=        0.9825\n",
      "=         0.9786\n",
      "group     0.9771\n",
      "max       0.9741\n",
      ")         0.9716\n",
      "where     0.9702\n",
      "limit     0.9684\n",
      "from      0.9671\n",
      "or        0.9582\n",
      "intersect 0.9522\n",
      "asc       0.9437\n",
      "except    0.9415\n",
      "not       0.9360\n",
      "sum       0.8969\n",
      "as        0.8349\n",
      "distinct  0.8284\n",
      "union     0.8037\n",
      "and       0.6727\n",
      "join      0.4976\n"
     ]
    }
   ],
   "source": [
    "for k, s in sorted(scores_d.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{k:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exp_toks = sorted(list(trace_scores_cnt_by_exp_tok.keys()))\n",
    "all_sections = list(good_samples[0]['trace_scores'].keys())\n",
    "\n",
    "print_str = '\\t'.join(['Syntax-tok'] + all_sections + ['Eff_cnt', 'All_cnt', 'Eff_rate']) + '\\n'\n",
    "\n",
    "for exp_tok in all_exp_toks:\n",
    "    print_str += f'{exp_tok:<10s}'\n",
    "    for sect_k in all_sections:\n",
    "        s = trace_scores_avg_by_exp_tok[exp_tok][sect_k]['all_layers']\n",
    "        print_str += f'\\t{s:.4f}'\n",
    "    eff_c = eff_counter[exp_tok]\n",
    "    neff_c = neff_counter[exp_tok]\n",
    "    all_c = eff_c + neff_c\n",
    "    eff_r = eff_rate_d[exp_tok]\n",
    "    print_str += f'\\t{eff_c:<7d}\\t{all_c:<7d}\\t{eff_r:.4f}'\n",
    "    print_str += '\\n'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntax-tok\tt->s\ts->t\tt<->s\tt->p\ts->p\tts->p\tt->t\ts->s\tall\tEff_cnt\tAll_cnt\tEff_rate\n",
      "!=        \t0.9984\t0.9995\t0.9825\t0.8485\t0.9998\t0.9070\t0.3025\t0.9193\t0.0284\t20     \t20     \t1.0000\n",
      "(         \t0.9999\t0.9794\t0.9946\t0.9719\t0.9795\t0.9685\t0.8983\t0.9467\t0.1856\t98     \t675    \t0.1452\n",
      ")         \t0.9257\t0.9926\t0.9716\t0.9914\t0.9074\t0.8420\t0.9244\t0.4715\t0.1108\t13     \t23     \t0.5652\n",
      "*         \t1.0000\t0.9999\t1.0000\t0.9997\t0.9999\t0.9998\t0.9999\t0.9982\t0.1802\t10     \t381    \t0.0262\n",
      "=         \t0.9784\t0.9923\t0.9786\t0.9378\t0.8940\t0.7439\t0.9466\t0.5933\t0.1149\t128    \t968    \t0.1322\n",
      ">         \t1.0000\t1.0000\t1.0000\t0.9509\t0.9990\t0.9652\t0.8193\t0.9845\t0.0219\t68     \t101    \t0.6733\n",
      ">=        \t1.0000\t1.0000\t1.0000\t0.9151\t1.0000\t0.9048\t0.2593\t0.9964\t0.1703\t11     \t30     \t0.3667\n",
      "and       \t0.7931\t0.8981\t0.6727\t0.4962\t0.8409\t0.3468\t0.3603\t0.6749\t0.0554\t29     \t39     \t0.7436\n",
      "as        \t0.9212\t0.8936\t0.8349\t0.7992\t0.5034\t0.3457\t0.8478\t0.3288\t0.1002\t52     \t952    \t0.0546\n",
      "asc       \t0.9723\t0.9096\t0.9437\t0.4939\t0.8596\t0.3612\t0.6133\t0.6725\t0.0408\t19     \t19     \t1.0000\n",
      "avg       \t0.9996\t0.9940\t0.9972\t0.7660\t0.9996\t0.3619\t0.7743\t0.9513\t0.0360\t63     \t65     \t0.9692\n",
      "between   \t0.9999\t0.9999\t1.0000\t0.7788\t0.9999\t0.3407\t0.0009\t0.9999\t0.0000\t6      \t6      \t1.0000\n",
      "count     \t0.9911\t0.9977\t0.9960\t0.9641\t0.9850\t0.7469\t0.8609\t0.8691\t0.0220\t294    \t406    \t0.7241\n",
      "desc      \t0.9939\t0.9992\t0.9942\t0.9198\t0.9191\t0.7296\t0.9044\t0.6997\t0.1144\t82     \t164    \t0.5000\n",
      "distinct  \t0.8663\t0.8651\t0.8284\t0.6270\t0.9118\t0.4787\t0.6194\t0.7636\t0.0014\t26     \t26     \t1.0000\n",
      "except    \t0.9517\t0.9847\t0.9415\t0.6213\t0.9311\t0.0783\t0.4062\t0.7137\t0.0002\t21     \t21     \t1.0000\n",
      "from      \t0.9924\t0.9703\t0.9671\t0.9781\t0.9519\t0.6276\t0.8407\t0.5194\t0.1384\t263    \t1196   \t0.2199\n",
      "group     \t0.9895\t0.9925\t0.9771\t0.8332\t0.9838\t0.5694\t0.9167\t0.7823\t0.0282\t241    \t265    \t0.9094\n",
      "having    \t0.9978\t0.9924\t0.9894\t0.5962\t0.9993\t0.3893\t0.8985\t0.9348\t0.0262\t77     \t81     \t0.9506\n",
      "in        \t0.9973\t0.9995\t0.9992\t0.9995\t0.9253\t0.5859\t0.7717\t0.3267\t0.1096\t8      \t50     \t0.1600\n",
      "intersect \t0.9649\t0.9938\t0.9522\t0.2385\t0.9592\t0.0575\t0.4348\t0.8243\t0.0001\t34     \t34     \t1.0000\n",
      "join      \t0.9099\t0.6489\t0.4976\t0.7286\t0.3030\t0.1984\t0.7286\t0.1891\t0.0158\t44     \t496    \t0.0887\n",
      "like      \t1.0000\t1.0000\t1.0000\t0.9997\t0.9997\t0.8233\t0.2700\t0.8809\t0.0062\t12     \t12     \t1.0000\n",
      "limit     \t0.9932\t0.9854\t0.9684\t0.8400\t0.9992\t0.7895\t0.8076\t0.7534\t0.1531\t26     \t177    \t0.1469\n",
      "max       \t0.8483\t0.9925\t0.9741\t0.8141\t0.9458\t0.4659\t0.5214\t0.9008\t0.0633\t29     \t30     \t0.9667\n",
      "min       \t0.9962\t1.0000\t1.0000\t0.9906\t0.9993\t0.9377\t0.7412\t0.9999\t0.0450\t14     \t18     \t0.7778\n",
      "not       \t0.9884\t0.9515\t0.9360\t0.9510\t0.9067\t0.6624\t0.8928\t0.7208\t0.0117\t45     \t46     \t0.9783\n",
      "or        \t0.9788\t0.9728\t0.9582\t0.7773\t0.9856\t0.9181\t0.4193\t0.9718\t0.0311\t34     \t34     \t1.0000\n",
      "order     \t0.9964\t0.9891\t0.9826\t0.7079\t0.9802\t0.4836\t0.8542\t0.8393\t0.0680\t197    \t221    \t0.8914\n",
      "sum       \t0.9054\t0.9988\t0.8969\t0.8431\t0.9998\t0.6812\t0.4672\t0.9511\t0.0119\t20     \t22     \t0.9091\n",
      "union     \t0.9990\t0.8977\t0.8037\t0.2034\t0.7390\t0.3218\t0.0174\t0.7111\t0.0001\t6      \t6      \t1.0000\n",
      "where     \t0.9820\t0.9900\t0.9702\t0.9035\t0.9576\t0.7533\t0.8924\t0.7699\t0.0858\t350    \t516    \t0.6783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(print_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', '!', '=']\n",
      "['▁(']\n",
      "['▁', ')']\n",
      "['▁*']\n",
      "['▁=']\n",
      "['▁>']\n",
      "['▁>', '=']\n",
      "['▁and']\n",
      "['▁as']\n",
      "['▁as', 'c']\n",
      "['▁', 'a', 'v', 'g']\n",
      "['▁between']\n",
      "['▁count']\n",
      "['▁des', 'c']\n",
      "['▁distinct']\n",
      "['▁except']\n",
      "['▁from']\n",
      "['▁group']\n",
      "['▁having']\n",
      "['▁in']\n",
      "['▁intersect']\n",
      "['▁join']\n",
      "['▁like']\n",
      "['▁limit']\n",
      "['▁max']\n",
      "['▁min']\n",
      "['▁not']\n",
      "['▁or']\n",
      "['▁order']\n",
      "['▁sum']\n",
      "['▁union']\n",
      "['▁where']\n"
     ]
    }
   ],
   "source": [
    "# Issue checking: multi-token \n",
    "for exp_tok in all_exp_toks:\n",
    "    print(mt_uskg.tokenizer.tokenize(exp_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-6.2: dec cross attention corruption effect - syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp6_2_decoder_cross_attention_corruption_syntax/exp=6.2.1_dev-attn_crpt=logits.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10233, (5731, 5731), 1623, 2879, 4502, 'good / correct = 5731 / 8610')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d.get('is_good_sample', True):\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_samples[0]['trace_scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += v\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': defaultdict(int,\n",
       "             {'q1_layers': 0.8251662824628329,\n",
       "              'q2_layers': 0.9568811011561555,\n",
       "              'q3_layers': 0.9585451913219025,\n",
       "              'q4_layers': 0.9586033384734522,\n",
       "              'low_layers': 0.5032536523294612,\n",
       "              'mid_layers': 0.7412946459743097,\n",
       "              'high_layers': 0.7327423463639,\n",
       "              'all_layers': 0.057349480442763175}),\n",
       " 'ans->t': defaultdict(int,\n",
       "             {'q1_layers': 0.9954168156351754,\n",
       "              'q2_layers': 0.9905822788459185,\n",
       "              'q3_layers': 0.9671664178380461,\n",
       "              'q4_layers': 0.9757743479523219,\n",
       "              'low_layers': 0.9790280398693059,\n",
       "              'mid_layers': 0.8837345000447828,\n",
       "              'high_layers': 0.8696248513307187,\n",
       "              'all_layers': 0.7785073726874928}),\n",
       " 'all->t': defaultdict(int,\n",
       "             {'q1_layers': 0.9946716999747656,\n",
       "              'q2_layers': 0.9847246179079293,\n",
       "              'q3_layers': 0.9633879014188113,\n",
       "              'q4_layers': 0.975774884946337,\n",
       "              'low_layers': 0.9654529441792826,\n",
       "              'mid_layers': 0.8466091753986138,\n",
       "              'high_layers': 0.8652557141489696,\n",
       "              'all_layers': 0.745349026128539}),\n",
       " 'ans->s': defaultdict(int,\n",
       "             {'q1_layers': 0.9868191454594858,\n",
       "              'q2_layers': 0.9900647226470655,\n",
       "              'q3_layers': 0.9947073662803396,\n",
       "              'q4_layers': 0.9962095590063736,\n",
       "              'low_layers': 0.9646212092317603,\n",
       "              'mid_layers': 0.9870737207331394,\n",
       "              'high_layers': 0.9942978987104565,\n",
       "              'all_layers': 0.9605662906578918}),\n",
       " 'all->s': defaultdict(int,\n",
       "             {'q1_layers': 0.9495511247867173,\n",
       "              'q2_layers': 0.9846415213288342,\n",
       "              'q3_layers': 0.9945589672603282,\n",
       "              'q4_layers': 0.9961051629829253,\n",
       "              'low_layers': 0.8973616218084921,\n",
       "              'mid_layers': 0.9809546646488222,\n",
       "              'high_layers': 0.9944054611041094,\n",
       "              'all_layers': 0.8988139426412731}),\n",
       " 'ans->p': defaultdict(int,\n",
       "             {'q1_layers': 0.9945866083120604,\n",
       "              'q2_layers': 0.9926594899618697,\n",
       "              'q3_layers': 0.9532355621472774,\n",
       "              'q4_layers': 0.9776786978197944,\n",
       "              'low_layers': 0.9875606488909925,\n",
       "              'mid_layers': 0.9265851658627762,\n",
       "              'high_layers': 0.8738844505183258,\n",
       "              'all_layers': 0.8132977273932551}),\n",
       " 'all->p': defaultdict(int,\n",
       "             {'q1_layers': 0.9803491226451468,\n",
       "              'q2_layers': 0.9782970041354968,\n",
       "              'q3_layers': 0.9427931581354659,\n",
       "              'q4_layers': 0.9773308596161139,\n",
       "              'low_layers': 0.9315862115450884,\n",
       "              'mid_layers': 0.8687140840081402,\n",
       "              'high_layers': 0.8453800312842668,\n",
       "              'all_layers': 0.6508764799719446}),\n",
       " 'ans->o': defaultdict(int,\n",
       "             {'q1_layers': 0.9975263366179615,\n",
       "              'q2_layers': 0.9975120422260193,\n",
       "              'q3_layers': 0.997610687023889,\n",
       "              'q4_layers': 0.9976217283189162,\n",
       "              'low_layers': 0.9974056234005712,\n",
       "              'mid_layers': 0.9974438535893615,\n",
       "              'high_layers': 0.997580882408215,\n",
       "              'all_layers': 0.9972983276660978}),\n",
       " 'all->o': defaultdict(int,\n",
       "             {'q1_layers': 0.9974374340749956,\n",
       "              'q2_layers': 0.9975524941282816,\n",
       "              'q3_layers': 0.9975957313438419,\n",
       "              'q4_layers': 0.9976251479625037,\n",
       "              'low_layers': 0.9973218925329762,\n",
       "              'mid_layers': 0.9974766157982217,\n",
       "              'high_layers': 0.9975722592146562,\n",
       "              'all_layers': 0.9971902840498583}),\n",
       " 'ans->t+o': defaultdict(int,\n",
       "             {'q1_layers': 0.9954431360305773,\n",
       "              'q2_layers': 0.9904148153549044,\n",
       "              'q3_layers': 0.9662767773823581,\n",
       "              'q4_layers': 0.9754596308576543,\n",
       "              'low_layers': 0.9789654327365731,\n",
       "              'mid_layers': 0.8798708824019926,\n",
       "              'high_layers': 0.8645496393109454,\n",
       "              'all_layers': 0.7742868436240915}),\n",
       " 'all->t+o': defaultdict(int,\n",
       "             {'q1_layers': 0.9946770293224044,\n",
       "              'q2_layers': 0.984802173987723,\n",
       "              'q3_layers': 0.9626610521847996,\n",
       "              'q4_layers': 0.9754755938350108,\n",
       "              'low_layers': 0.9651606862127082,\n",
       "              'mid_layers': 0.8411415185035732,\n",
       "              'high_layers': 0.860222189190524,\n",
       "              'all_layers': 0.7417609378669952})}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXX\tq1_layers  \tq2_layers  \tq3_layers  \tq4_layers  \tlow_layers \tmid_layers \thigh_layers\tall_layers \n",
      "all    \t0.8252     \t0.9569     \t0.9585     \t0.9586     \t0.5033     \t0.7413     \t0.7327     \t0.0573     \n",
      "ans->t \t0.9954     \t0.9906     \t0.9672     \t0.9758     \t0.9790     \t0.8837     \t0.8696     \t0.7785     \n",
      "all->t \t0.9947     \t0.9847     \t0.9634     \t0.9758     \t0.9655     \t0.8466     \t0.8653     \t0.7453     \n",
      "ans->s \t0.9868     \t0.9901     \t0.9947     \t0.9962     \t0.9646     \t0.9871     \t0.9943     \t0.9606     \n",
      "all->s \t0.9496     \t0.9846     \t0.9946     \t0.9961     \t0.8974     \t0.9810     \t0.9944     \t0.8988     \n",
      "ans->p \t0.9946     \t0.9927     \t0.9532     \t0.9777     \t0.9876     \t0.9266     \t0.8739     \t0.8133     \n",
      "all->p \t0.9803     \t0.9783     \t0.9428     \t0.9773     \t0.9316     \t0.8687     \t0.8454     \t0.6509     \n",
      "ans->o \t0.9975     \t0.9975     \t0.9976     \t0.9976     \t0.9974     \t0.9974     \t0.9976     \t0.9973     \n",
      "all->o \t0.9974     \t0.9976     \t0.9976     \t0.9976     \t0.9973     \t0.9975     \t0.9976     \t0.9972     \n",
      "ans->t+o\t0.9954     \t0.9904     \t0.9663     \t0.9755     \t0.9790     \t0.8799     \t0.8645     \t0.7743     \n",
      "all->t+o\t0.9947     \t0.9848     \t0.9627     \t0.9755     \t0.9652     \t0.8411     \t0.8602     \t0.7418     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# layers_keys = trace_scores_avg['all'].keys()\n",
    "\n",
    "# for sect_k, sect_d in trace_scores_avg.items():\n",
    "#     print_l = f'{sect_k:<8s}'\n",
    "#     for k in layers_keys:\n",
    "#         s = sect_d[k]\n",
    "#         print_l += f'\\t{s:.4f}'\n",
    "#     print(print_l)\n",
    "\n",
    "format_print_2D_dict(trace_scores_avg, head_col_w=7, col_w=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by expect syntax token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_by_exp_tok = exp6_ob_by_exp_tok(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'count': 394,\n",
       "             '(': 407,\n",
       "             'order': 219,\n",
       "             'avg': 63,\n",
       "             'min': 18,\n",
       "             'max': 28,\n",
       "             'where': 502,\n",
       "             'distinct': 26,\n",
       "             'from': 702,\n",
       "             '>': 65,\n",
       "             'group': 265,\n",
       "             'by': 33,\n",
       "             'between': 6,\n",
       "             'desc': 156,\n",
       "             'or': 34,\n",
       "             'as': 561,\n",
       "             'on': 474,\n",
       "             '>=': 3,\n",
       "             'not': 46,\n",
       "             'intersect': 34,\n",
       "             'select': 44,\n",
       "             'except': 21,\n",
       "             '=': 409,\n",
       "             'join': 20,\n",
       "             'like': 10,\n",
       "             'in': 15,\n",
       "             'having': 62,\n",
       "             'and': 6,\n",
       "             'limit': 16,\n",
       "             '!=': 20,\n",
       "             '*': 10,\n",
       "             'union': 6,\n",
       "             'sum': 22,\n",
       "             'asc': 19,\n",
       "             ')': 17})"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_exp_tok = res_by_exp_tok['cnt']\n",
    "trace_scores_cnt_by_exp_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.exp6_ob_by_exp_tok.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'all': defaultdict(float,\n",
       "                         {'q1_layers': 0.9964363076889575,\n",
       "                          'q2_layers': 0.9963203995739143,\n",
       "                          'q3_layers': 0.9551561746639813,\n",
       "                          'q4_layers': 0.9972184849572061,\n",
       "                          'low_layers': 0.8215906578539822,\n",
       "                          'mid_layers': 0.46418598421683044,\n",
       "                          'high_layers': 0.7123522221803182,\n",
       "                          'all_layers': 0.014818084030064214}),\n",
       "             'ans->t': defaultdict(float,\n",
       "                         {'q1_layers': 0.9994401957480435,\n",
       "                          'q2_layers': 0.9989948929263855,\n",
       "                          'q3_layers': 0.9765654405254729,\n",
       "                          'q4_layers': 0.9960574505255004,\n",
       "                          'low_layers': 0.9980983920206273,\n",
       "                          'mid_layers': 0.7132947778204064,\n",
       "                          'high_layers': 0.8861730706122236,\n",
       "                          'all_layers': 0.44028362028290124}),\n",
       "             'all->t': defaultdict(float,\n",
       "                         {'q1_layers': 0.9988200697802045,\n",
       "                          'q2_layers': 0.998696686803992,\n",
       "                          'q3_layers': 0.9747582198957241,\n",
       "                          'q4_layers': 0.9960432086272288,\n",
       "                          'low_layers': 0.9967487218794484,\n",
       "                          'mid_layers': 0.6770446909783476,\n",
       "                          'high_layers': 0.8788389159396585,\n",
       "                          'all_layers': 0.35087384116220555}),\n",
       "             'ans->s': defaultdict(float,\n",
       "                         {'q1_layers': 0.9994106749592698,\n",
       "                          'q2_layers': 0.999712617415462,\n",
       "                          'q3_layers': 0.9995317062750686,\n",
       "                          'q4_layers': 0.999931743302321,\n",
       "                          'low_layers': 0.9998417478527515,\n",
       "                          'mid_layers': 0.9999815848878193,\n",
       "                          'high_layers': 0.999994937992338,\n",
       "                          'all_layers': 0.9999986511801705}),\n",
       "             'all->s': defaultdict(float,\n",
       "                         {'q1_layers': 0.999680691261582,\n",
       "                          'q2_layers': 0.9995500590595497,\n",
       "                          'q3_layers': 0.999525050977765,\n",
       "                          'q4_layers': 0.9999321718808963,\n",
       "                          'low_layers': 0.9963215853508354,\n",
       "                          'mid_layers': 0.9999843692113906,\n",
       "                          'high_layers': 0.9999947897371302,\n",
       "                          'all_layers': 0.9958879304246098}),\n",
       "             'ans->p': defaultdict(float,\n",
       "                         {'q1_layers': 0.9961130618582229,\n",
       "                          'q2_layers': 0.9985278386452476,\n",
       "                          'q3_layers': 0.9975578447586388,\n",
       "                          'q4_layers': 0.9945496145238731,\n",
       "                          'low_layers': 0.9889740733148207,\n",
       "                          'mid_layers': 0.9956819380297879,\n",
       "                          'high_layers': 0.9878297375131287,\n",
       "                          'all_layers': 0.957358345802683}),\n",
       "             'all->p': defaultdict(float,\n",
       "                         {'q1_layers': 0.9971128671505691,\n",
       "                          'q2_layers': 0.9970539765914684,\n",
       "                          'q3_layers': 0.9963113451518383,\n",
       "                          'q4_layers': 0.9941017802067215,\n",
       "                          'low_layers': 0.9868572877924169,\n",
       "                          'mid_layers': 0.9913899881699061,\n",
       "                          'high_layers': 0.9826842088918296,\n",
       "                          'all_layers': 0.900635620249951})})"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg_by_exp_tok = res_by_exp_tok['avg']\n",
    "trace_scores_avg_by_exp_tok['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "sect_k = 'ans->t'\n",
    "layer_k = 'all_layers'\n",
    "scores_d = dict()\n",
    "\n",
    "for exp_tok, d1 in trace_scores_avg_by_exp_tok.items():\n",
    "    s = d1[sect_k][layer_k]\n",
    "    scores_d[exp_tok] = s\n",
    "    # print(f'{exp_tok:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select    1.0000\n",
      "by        1.0000\n",
      "on        1.0000\n",
      "as        0.9977\n",
      "in        0.9977\n",
      ")         0.9955\n",
      "from      0.9942\n",
      "*         0.9826\n",
      "=         0.9823\n",
      "(         0.9583\n",
      "where     0.9210\n",
      "not       0.8927\n",
      "join      0.8654\n",
      "desc      0.8452\n",
      "having    0.8170\n",
      ">=        0.6667\n",
      "group     0.6521\n",
      "limit     0.6250\n",
      "like      0.5985\n",
      ">         0.5678\n",
      "min       0.5502\n",
      "except    0.5067\n",
      "count     0.4403\n",
      "sum       0.3922\n",
      "or        0.3801\n",
      "order     0.3762\n",
      "union     0.3335\n",
      "distinct  0.3008\n",
      "and       0.1670\n",
      "max       0.1403\n",
      "asc       0.0839\n",
      "intersect 0.0266\n",
      "!=        0.0208\n",
      "avg       0.0062\n",
      "between   0.0000\n"
     ]
    }
   ],
   "source": [
    "format_print_1D_dict(scores_d, sort_by='value', reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXX\tall\tans->t\tall->t\tans->s\tall->s\tans->p\tall->p\n",
      "!=        \t0.0013\t0.0208\t0.0001\t0.9509\t0.8203\t0.7167\t0.5739\n",
      "(         \t0.0747\t0.9583\t0.9549\t0.9997\t0.9923\t0.7309\t0.6955\n",
      ")         \t0.0212\t0.9955\t0.9951\t0.8845\t0.8465\t0.9982\t0.9014\n",
      "*         \t0.1240\t0.9826\t0.9720\t0.9978\t0.9306\t0.7433\t0.5726\n",
      "=         \t0.1195\t0.9823\t0.9761\t0.8742\t0.8298\t0.9526\t0.9377\n",
      ">         \t0.0210\t0.5678\t0.4234\t0.9599\t0.9359\t0.9659\t0.9533\n",
      ">=        \t0.1964\t0.6667\t0.6667\t1.0000\t1.0000\t0.9994\t0.8787\n",
      "and       \t0.1812\t0.1670\t0.1309\t0.9885\t0.6761\t0.9118\t0.6287\n",
      "as        \t0.0883\t0.9977\t0.9969\t0.9404\t0.8392\t0.9844\t0.8963\n",
      "asc       \t0.0000\t0.0839\t0.1381\t0.8809\t0.8523\t0.8530\t0.8652\n",
      "avg       \t0.0018\t0.0062\t0.0049\t1.0000\t1.0000\t0.9441\t0.9177\n",
      "between   \t0.0006\t0.0000\t0.0000\t0.9992\t0.9991\t0.9994\t0.9984\n",
      "by        \t0.0757\t1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t1.0000\n",
      "count     \t0.0148\t0.4403\t0.3509\t1.0000\t0.9959\t0.9574\t0.9006\n",
      "desc      \t0.0511\t0.8452\t0.8698\t0.9805\t0.9593\t0.9229\t0.7996\n",
      "distinct  \t0.0005\t0.3008\t0.2718\t0.9965\t0.9950\t0.8270\t0.7839\n",
      "except    \t0.0000\t0.5067\t0.0165\t0.9522\t0.8531\t0.7611\t0.7102\n",
      "from      \t0.0903\t0.9942\t0.9801\t0.9773\t0.9635\t0.7383\t0.6265\n",
      "group     \t0.0115\t0.6521\t0.4824\t0.9668\t0.9124\t0.9265\t0.5591\n",
      "having    \t0.0365\t0.8170\t0.6288\t0.9281\t0.9484\t0.9138\t0.7298\n",
      "in        \t0.1526\t0.9977\t0.9747\t1.0000\t0.6386\t0.9182\t0.7606\n",
      "intersect \t0.0004\t0.0266\t0.0006\t0.9967\t0.9195\t0.6850\t0.6866\n",
      "join      \t0.1764\t0.8654\t0.8762\t0.3481\t0.1003\t0.6876\t0.6440\n",
      "like      \t0.0016\t0.5985\t0.2897\t1.0000\t0.9999\t0.9997\t0.9992\n",
      "limit     \t0.1190\t0.6250\t0.6243\t0.9971\t0.9944\t0.8910\t0.7684\n",
      "max       \t0.0080\t0.1403\t0.0234\t0.9947\t0.9842\t0.7690\t0.7451\n",
      "min       \t0.0021\t0.5502\t0.2714\t0.9999\t1.0000\t0.6500\t0.6053\n",
      "not       \t0.0000\t0.8927\t0.5348\t0.9550\t0.5140\t0.8692\t0.8318\n",
      "on        \t0.0690\t1.0000\t1.0000\t1.0000\t0.9999\t0.9433\t0.1831\n",
      "or        \t0.0068\t0.3801\t0.0257\t0.9802\t0.8666\t0.9702\t0.9674\n",
      "order     \t0.0053\t0.3762\t0.2628\t0.9307\t0.8960\t0.9191\t0.7436\n",
      "select    \t0.1884\t1.0000\t1.0000\t1.0000\t1.0000\t0.7737\t0.8430\n",
      "sum       \t0.0000\t0.3922\t0.2025\t0.9733\t0.9657\t0.9125\t0.8589\n",
      "union     \t0.0005\t0.3335\t0.3333\t0.9997\t0.9999\t0.3831\t0.3370\n",
      "where     \t0.0129\t0.9210\t0.8000\t0.9285\t0.8903\t0.8458\t0.5845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_exp_toks = sorted(list(trace_scores_cnt_by_exp_tok.keys()))\n",
    "all_sections = list(good_samples[0]['trace_scores'].keys())\n",
    "\n",
    "_d = {exp_tok:\n",
    "          {sect_k: trace_scores_avg_by_exp_tok[exp_tok][sect_k]['all_layers']\n",
    "           for sect_k in all_sections}\n",
    "      for exp_tok in all_exp_toks}\n",
    "\n",
    "format_print_2D_dict(_d, all_k1=all_exp_toks, all_k2=all_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_ids_by_aspect = defaultdict(list)\n",
    "\n",
    "for i, d in enumerate(good_samples):\n",
    "    for asp_k, asp_v in d['category'].items():\n",
    "        asp_str_k = f'{asp_k}={asp_v}'\n",
    "        sample_ids_by_aspect[asp_str_k].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sql_hardness=easy', 689),\n",
       " ('sql_hardness=extra', 1402),\n",
       " ('sql_hardness=hard', 1004),\n",
       " ('sql_hardness=medium', 1843)}"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{(k, len(l)) for k, l in sample_ids_by_aspect.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asp_k -> avg/cnt/sample_ids -> exp_tok -> sect_k -> layer_k -> s\n",
    "all_res_by_exp_tok = {asp_k : exp6_ob_by_exp_tok(good_samples[i] for i in asp_sample_ids)\n",
    "                      for asp_k, asp_sample_ids in sample_ids_by_aspect.items()}\n",
    "\n",
    "# exp_tok -> [sect_k -> [layer_k -> s]]\n",
    "avg_d = all_res_by_exp_tok['sql_hardness=extra']['avg']\n",
    "\n",
    "all_exp_toks = sorted(list(avg_d.keys()))\n",
    "all_sections = list(avg_d[all_exp_toks[0]].keys())\n",
    "\n",
    "_d = {exp_tok:\n",
    "          {sect_k: avg_d[exp_tok][sect_k]['all_layers']\n",
    "           for sect_k in all_sections}\n",
    "      for exp_tok in all_exp_toks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\tall   \tans->t\tall->t\tans->s\tall->s\tans->p\tall->p\n",
      "(           \t0.0960\t0.9150\t0.9145\t0.9995\t0.9683\t0.5015\t0.4892\n",
      ")           \t0.0147\t0.9977\t0.9928\t0.9659\t0.9458\t0.9992\t0.9988\n",
      "*           \t0.2047\t1.0000\t1.0000\t0.9963\t0.8843\t0.9579\t0.6780\n",
      "=           \t0.1128\t0.9823\t0.9769\t0.7711\t0.7308\t0.9014\t0.8690\n",
      ">           \t0.0111\t0.5996\t0.5905\t0.9682\t0.8337\t0.8913\t0.8308\n",
      "as          \t0.0735\t0.9936\t0.9916\t0.9374\t0.8383\t0.9773\t0.8630\n",
      "avg         \t0.0001\t0.0003\t0.0001\t1.0000\t1.0000\t0.9980\t0.9884\n",
      "count       \t0.0166\t0.7992\t0.7450\t1.0000\t1.0000\t0.9679\t0.9111\n",
      "desc        \t0.0754\t0.9459\t0.9655\t1.0000\t1.0000\t0.9224\t0.8590\n",
      "distinct    \t0.0005\t0.5546\t0.5506\t0.9998\t0.9998\t0.8881\t0.8270\n",
      "except      \t0.0000\t0.2832\t0.0007\t0.8574\t0.6992\t0.5941\t0.5798\n",
      "from        \t0.0672\t0.9886\t0.9863\t0.9704\t0.9614\t0.7393\t0.6001\n",
      "group       \t0.0083\t0.3118\t0.1122\t0.9870\t0.8914\t0.8986\t0.3441\n",
      "having      \t0.0316\t0.8593\t0.4232\t0.7806\t0.9744\t0.7360\t0.7438\n",
      "in          \t0.1954\t1.0000\t1.0000\t1.0000\t0.7843\t0.9224\t0.7463\n",
      "intersect   \t0.0002\t0.0326\t0.0007\t0.9979\t0.9393\t0.6963\t0.6989\n",
      "join        \t0.1366\t0.7929\t0.8096\t0.2939\t0.0012\t0.5211\t0.4627\n",
      "limit       \t0.1183\t0.3333\t0.3333\t0.9990\t0.9852\t0.9979\t0.7007\n",
      "min         \t0.0001\t0.4418\t0.3291\t0.9995\t0.9999\t0.2870\t0.2307\n",
      "not         \t0.0000\t0.8387\t0.4470\t0.9174\t0.5643\t0.7416\t0.6721\n",
      "on          \t0.0841\t1.0000\t1.0000\t1.0000\t1.0000\t0.9182\t0.2170\n",
      "or          \t0.0053\t0.0042\t0.0000\t0.9997\t0.8246\t0.9999\t0.9996\n",
      "order       \t0.0126\t0.1665\t0.1381\t1.0000\t0.9583\t0.9471\t0.7631\n",
      "select      \t0.2025\t1.0000\t1.0000\t1.0000\t1.0000\t0.7238\t0.7857\n",
      "sum         \t0.0000\t0.7454\t0.2661\t1.0000\t1.0000\t0.9775\t0.8852\n",
      "union       \t0.0007\t0.0003\t0.0000\t0.9999\t1.0000\t0.5736\t0.5054\n",
      "where       \t0.0256\t0.8334\t0.6574\t0.9657\t0.9136\t0.7431\t0.4669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(_d, all_k1=all_exp_toks, all_k2=all_sections, col_w=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "_d = dict()\n",
    "\n",
    "h_list = ['easy', 'medium', 'hard', 'extra']\n",
    "\n",
    "for exp_tok in all_exp_toks:\n",
    "    _d[exp_tok] = {\n",
    "        h: all_res_by_exp_tok[f'sql_hardness={h}']['avg'][exp_tok]['all->t']['all_layers']\n",
    "        for h in h_list\n",
    "    }\n",
    "    for h in h_list:\n",
    "        _cnt = all_res_by_exp_tok[f'sql_hardness={h}']['cnt'][exp_tok]\n",
    "        if _cnt < 3:\n",
    "            # _d[exp_tok][h] = - 1 - _cnt\n",
    "            _d[exp_tok][h] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\teasy    \tmedium  \thard    \textra   \n",
      "(           \t1.0000  \t1.0000  \t0.8646  \t0.9145  \n",
      ")           \tnan     \tnan     \t0.9994  \t0.9928  \n",
      "*           \tnan     \tnan     \tnan     \t1.0000  \n",
      "=           \t0.9633  \t0.9855  \t0.9654  \t0.9769  \n",
      ">           \t0.4182  \t0.4960  \t0.2578  \t0.5905  \n",
      "as          \t1.0000  \t0.9998  \t1.0000  \t0.9916  \n",
      "avg         \t0.0046  \t0.0101  \t0.0000  \t0.0001  \n",
      "count       \t0.1406  \t0.1884  \t0.5781  \t0.7450  \n",
      "desc        \t0.4946  \t0.6938  \t0.9553  \t0.9655  \n",
      "distinct    \t0.0554  \t0.1229  \t0.3660  \t0.5506  \n",
      "except      \tnan     \tnan     \t0.0244  \t0.0007  \n",
      "from        \t0.9417  \t0.9906  \t0.9807  \t0.9863  \n",
      "group       \t0.5330  \t0.7302  \t0.3732  \t0.1122  \n",
      "having      \t0.6407  \t0.7282  \t0.2358  \t0.4232  \n",
      "in          \tnan     \tnan     \t0.9526  \t1.0000  \n",
      "intersect   \tnan     \tnan     \t0.0005  \t0.0007  \n",
      "join        \tnan     \tnan     \t0.9998  \t0.8096  \n",
      "limit       \tnan     \t0.9985  \tnan     \t0.3333  \n",
      "min         \tnan     \t0.1869  \tnan     \t0.3291  \n",
      "not         \tnan     \tnan     \t0.6226  \t0.4470  \n",
      "on          \t1.0000  \t1.0000  \t1.0000  \t1.0000  \n",
      "or          \tnan     \t0.0008  \t0.1426  \t0.0000  \n",
      "order       \t0.6007  \t0.3280  \t0.2023  \t0.1381  \n",
      "select      \tnan     \tnan     \t1.0000  \t1.0000  \n",
      "sum         \t0.1863  \t0.0601  \t0.4819  \t0.2661  \n",
      "union       \tnan     \tnan     \tnan     \t0.0000  \n",
      "where       \t0.8971  \t0.8593  \t0.7566  \t0.6574  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(_d, sort_k1_kwargs={}, col_w=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _d = dict()\n",
    "\n",
    "# for exp_tok in all_exp_toks:\n",
    "#     _d[exp_tok] = {\n",
    "#         'easy': all_res_by_exp_tok['sql_hardness=easy']['cnt'][exp_tok],\n",
    "#         'extra': all_res_by_exp_tok['sql_hardness=extra']['cnt'][exp_tok],\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-7.0: layer skipping\n",
    "- Including 7.0.[0-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect_type = 'table_alias'\n",
    "\n",
    "# res_path = f'/home/yshao/Projects/rome/results/exp7_0_1_decoder_layer_skip_effect/exp=7.0.1_dev_{expect_type}.jsonl'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp7_0_3_decoder_syntax_layer_skip_effect/exp=7.0.3_dev.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10233, (8609, 8609), 1623, 1, 1624, 'good / correct = 8609 / 8610')"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d.get('is_good_sample', True):\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += v\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXXXXXX\tq1_layers  \tq2_layers  \tq3_layers  \tq4_layers  \tlow_layers \tmid_layers \thigh_layers\tall_layers \n",
      "ans             \t0.0037     \t0.9564     \t0.7786     \t0.5126     \t0.0035     \t0.2946     \t0.0064     \t0.0000     \n",
      "all             \t0.0025     \t0.8803     \t0.7603     \t0.5126     \t0.0024     \t0.2397     \t0.0064     \t0.0000     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trace_scores_avg\n",
    "format_print_2D_dict(trace_scores_avg, head_col_w=16, col_w=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed inspect of sections splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_id = 111\n",
    "a_ex_id = 0\n",
    "\n",
    "ex = processed_spider_dev[ex_id]\n",
    "ex['text_in'], \\\n",
    "ex['struct_in'], \\\n",
    "ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu.create_analysis_sample_dicts(\n",
    "                mt_uskg, ex,\n",
    "                subject_type='column',\n",
    "                remove_struct_duplicate_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = a_ex_list[a_ex_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "_enc_toks = ctu.decode_tokens(mt_uskg.tokenizer, d['enc_tokenized']['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'the', 'accelerate', 'of', 'the', 'car', 'make', 'am', 'c', '', 'horn', 'e', 't', 'sport', 'about', '(', 's', 'w', ')', '?', ';', '', 'struct', 'e', 'd', 'knowledge', ':', '|', 'car', '_', '1', '|', 'continent', 's', '', ':', 'cont', 'i', 'd', '', ',', 'continent', '|', 'countries', '', ':', 'country', 'i', 'd', '', ',', 'country', 'name', '', ',', 'continent', '|', 'car', '_', 'makers', '', ':', '', 'i', 'd', '', ',', 'maker', '(', 'am', 'c', '', ')', '', ',', 'full', 'name', '', ',', 'country', '|', 'model', '_', 'list', '', ':', 'model', 'i', 'd', '', ',', 'maker', '', ',', 'model', '(', 'am', 'c', '', ')', '|', 'car', '_', 'name', 's', '', ':', 'make', 'i', 'd', '', ',', 'model', '(', 'am', 'c', '', ')', '', ',', 'make', '(', 'am', 'c', '', 'horn', 'e', 't', '', ',', 'am', 'c', '', 'horn', 'e', 't', 'sport', 'about', '(', 's', 'w', ')', '', ')', '|', 'cars', '_', 'data', '', ':', '', 'i', 'd', '', ',', '', 'mp', 'g', '', ',', '', 'cylinder', 's', '', ',', '', 'e', 'disp', 'l', '', ',', 'horsepower', '', ',', 'weight', '', ',', 'accelerate', '', ',', 'year', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(_enc_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'the', 'accelerate', 'of', 'the', 'car', 'make', 'am', 'c', '', 'horn', 'e', 't', 'sport', 'about', '(', 's', 'w', ')', '?']\n"
     ]
    }
   ],
   "source": [
    "text_st, text_ed = d['text_range']\n",
    "print(_enc_toks[text_st : text_ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['|', 'car', '_', '1', '|', 'continent', 's', '', ':', 'cont', 'i', 'd', '', ',', 'continent', '|', 'countries', '', ':', 'country', 'i', 'd', '', ',', 'country', 'name', '', ',', 'continent', '|', 'car', '_', 'makers', '', ':', '', 'i', 'd', '', ',', 'maker', '(', 'am', 'c', '', ')', '', ',', 'full', 'name', '', ',', 'country', '|', 'model', '_', 'list', '', ':', 'model', 'i', 'd', '', ',', 'maker', '', ',', 'model', '(', 'am', 'c', '', ')', '|', 'car', '_', 'name', 's', '', ':', 'make', 'i', 'd', '', ',', 'model', '(', 'am', 'c', '', ')', '', ',', 'make', '(', 'am', 'c', '', 'horn', 'e', 't', '', ',', 'am', 'c', '', 'horn', 'e', 't', 'sport', 'about', '(', 's', 'w', ')', '', ')', '|', 'cars', '_', 'data', '', ':', '', 'i', 'd', '', ',', '', 'mp', 'g', '', ',', '', 'cylinder', 's', '', ',', '', 'e', 'disp', 'l', '', ',', 'horsepower', '', ',', 'weight', '', ',', 'accelerate', '', ',', 'year']\n"
     ]
    }
   ],
   "source": [
    "struct_st, struct_ed = d['struct_range']\n",
    "print(_enc_toks[struct_st : struct_ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ',', 'accelerate', '', ',']\n"
     ]
    }
   ],
   "source": [
    "for self_st, self_ed in d['self_ranges']:\n",
    "    print(_enc_toks[self_st : self_ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['|', 'car', '_', '1', '|', 'continent', 's', '', ':', 'cont', 'i', 'd', '', ',', 'continent', '|', 'countries', '', ':', 'country', 'i', 'd', '', ',', 'country', 'name', '', ',', 'continent', '|', 'car', '_', 'makers', '', ':', '', 'i', 'd', '', ',', 'maker', '(', 'am', 'c', '', ')', '', ',', 'full', 'name', '', ',', 'country', '|', 'model', '_', 'list', '', ':', 'model', 'i', 'd', '', ',', 'maker', '', ',', 'model', '(', 'am', 'c', '', ')', '|', 'car', '_', 'name', 's', '', ':', 'make', 'i', 'd', '', ',', 'model', '(', 'am', 'c', '', ')', '', ',', 'make', '(', 'am', 'c', '', 'horn', 'e', 't', '', ',', 'am', 'c', '', 'horn', 'e', 't', 'sport', 'about', '(', 's', 'w', ')', '', ')', '|', 'cars', '_', 'data', '', ':', '', 'i', 'd', '', ',', '', 'mp', 'g', '', ',', '', 'cylinder', 's', '', ',', '', 'e', 'disp', 'l', '', ',', 'horsepower', '', ',', 'weight']\n",
      "['year']\n"
     ]
    }
   ],
   "source": [
    "for s, e in d['context_ranges']:\n",
    "    print(_enc_toks[s : e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_analysis_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is id of the staff who had a Staff Department Assignment earlier than any Clerical Staff?',\n",
       " '| department_store | addresses : address_id , address_details | staff : staff_id , staff_gender , staff_name | suppliers : supplier_id , supplier_name , supplier_phone | department_store_chain : dept_store_chain_id , dept_store_chain_name | customers : customer_id , payment_method_code , customer_code , customer_name , customer_address , customer_phone , customer_email | products : product_id , product_type_code , product_name , product_price | supplier_addresses : supplier_id , address_id , date_from , date_to | customer_addresses : customer_id , address_id , date_from , date_to | customer_orders : order_id , customer_id , order_status_code , order_date | department_stores : dept_store_id , dept_store_chain_id , store_name , store_address , store_phone , store_email | departments : department_id , dept_store_id , department_name | order_items : order_item_id , order_id , product_id | product_suppliers : product_id , supplier_id , date_supplied_from , date_supplied_to , total_amount_purchased , total_value_purchased | staff_department_assignments : staff_id , department_id , date_assigned_from , job_title_code ( Clerical Staff ) , date_assigned_to',\n",
       " \"select staff_id from staff_department_assignments where date_assigned_to < (select max(date_assigned_to) from staff_department_assignments where job_title_code = 'Clerical Staff')\")"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ex_id = 111\n",
    "ex_id = 4755\n",
    "a_ex_id = 0\n",
    "\n",
    "# ex = processed_spider_dev[ex_id]\n",
    "ex = processed_spider_train[ex_id]\n",
    "\n",
    "ex['text_in'], \\\n",
    "ex['struct_in'], \\\n",
    "ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp test\n",
    "# ex['seq_out'] = 'select year from cars_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu.create_analysis_sample_dicts(\n",
    "                mt_uskg, ex,\n",
    "                subject_type='table',\n",
    "                remove_struct_duplicate_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'enc_sentence', 'enc_tokenized', 'text_range', 'struct_range', 'parsed_struct_in', 'alias2table', 'struct_node_ranges_dict', 'dec_prompt', 'expect', 'expect_type', 'remove_struct_duplicate_nodes', 'col2table', 'token_ranges_dict', 'node_name_ranges', 'expect_input_ranges', 'self_ranges', 'context_ranges', 'category'])"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[a_ex_id].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[a_ex_id]['alias2table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k, v) for k, v in a_ex_list[1].items() if k != 'rat_sql_graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(d['dec_prompt'], d['expect'], d['node_name_ranges'], d['expect_input_ranges'], '------',\\\n",
    "  d['self_ranges'], d['context_ranges'],\\\n",
    "  d['category'], '------' * 2) for d in a_ex_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(a_ex_list[a_ex_id])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ctu.add_clean_prediction(mt_uskg, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parse_sql_alias2table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 'table_name', 't2': 'other_table', 't3': 'ttt'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sql = 'SELECT t2.aaa , t3.ccc FROM table_name as t1 JOIN other_table as t2 on table_name.a_a = other_table.b_a JOIN ttt as t3 on other_table.asth = ttt.asth'\n",
    "ctu.parse_sql_alias2table(_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from \t None \t False\n",
      "as \t None \t False\n",
      "join \t None \t False\n",
      "as \t None \t False\n",
      "on \t None \t False\n",
      "= \t None \t False\n",
      "where \t None \t False\n",
      "= \t None \t False\n",
      "' \t ' \t True\n",
      "amc \t ' \t True\n",
      "hornet \t ' \t True\n",
      "sportabout \t ' \t True\n",
      "( \t ' \t True\n",
      "sw \t ' \t True\n",
      ") \t ' \t True\n",
      "' \t None \t True\n"
     ]
    }
   ],
   "source": [
    "_ex = copy.deepcopy(ex)\n",
    "# _ex['seq_out'] += 'order by t1.mpg'\n",
    "a_ex_list_syntax = ctu.create_syntax_analysis_sample_dicts(mt_uskg, _ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select t1.accelerate  -->  from\n",
      "select t1.accelerate from cars_data  -->  as\n",
      "select t1.accelerate from cars_data as t1  -->  join\n",
      "select t1.accelerate from cars_data as t1 join car_names  -->  as\n",
      "select t1.accelerate from cars_data as t1 join car_names as t2  -->  on\n",
      "select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id  -->  =\n",
      "select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid  -->  where\n",
      "select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make  -->  =\n"
     ]
    }
   ],
   "source": [
    "for a_ex in a_ex_list_syntax:\n",
    "    print(a_ex['dec_prompt'], ' --> ', a_ex['expect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [363, 19, 8, 16845, 13, 8, 443, 143, 183, 75, 3, 6293, 15, 17, 2600, 7932, 41, 7, 210, 61, 58, 117, 3, 7593, 15, 26, 1103, 10, 1820, 443, 834, 536, 1820, 10829, 7, 3, 10, 3622, 23, 26, 3, 6, 10829, 1820, 1440, 3, 10, 684, 23, 26, 3, 6, 684, 4350, 3, 6, 10829, 1820, 443, 834, 8910, 3, 10, 3, 23, 26, 3, 6, 13762, 41, 183, 75, 3, 61, 3, 6, 423, 4350, 3, 6, 684, 1820, 825, 834, 3350, 3, 10, 825, 23, 26, 3, 6, 13762, 3, 6, 825, 41, 183, 75, 3, 61, 1820, 443, 834, 4350, 7, 3, 10, 143, 23, 26, 3, 6, 825, 41, 183, 75, 3, 61, 3, 6, 143, 41, 183, 75, 3, 6293, 15, 17, 3, 6, 183, 75, 3, 6293, 15, 17, 2600, 7932, 41, 7, 210, 61, 3, 61, 1820, 2948, 834, 6757, 3, 10, 3, 23, 26, 3, 6, 3, 1167, 122, 3, 6, 3, 12980, 7, 3, 6, 3, 15, 10475, 40, 3, 6, 28906, 3, 6, 1293, 3, 6, 16845, 3, 6, 215, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['enc_tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contid']\n",
      "['continent', 'continent']\n",
      "['countryid']\n",
      "['countryname']\n",
      "['id', 'id']\n",
      "['maker ( amc )', 'maker']\n",
      "['fullname']\n",
      "['country']\n",
      "['modelid']\n",
      "['model ( amc )', 'model ( amc )']\n",
      "['makeid']\n",
      "['make ( amc hornet, amc hornet sportabout (sw) )']\n",
      "['mpg']\n",
      "['cylinders']\n",
      "['edispl']\n",
      "['horsepower']\n",
      "['weight']\n",
      "['accelerate']\n",
      "['year']\n"
     ]
    }
   ],
   "source": [
    "col_name_ranges = a_ex['token_ranges_dict']['col_name_ranges']\n",
    "# col_name_indices = [i for s, e in col_name_ranges.values() for i in range(s, e)]\n",
    "for ranges in col_name_ranges.values():\n",
    "    print([mt_uskg.tokenizer.decode(a_ex['enc_tokenized']['input_ids'][s:e]) for s, e in ranges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['continents']\n",
      "['countries']\n",
      "['car_makers']\n",
      "['model_list']\n",
      "['car_names']\n",
      "['cars_data']\n"
     ]
    }
   ],
   "source": [
    "table_name_ranges = a_ex['token_ranges_dict']['table_name_ranges']\n",
    "# col_name_indices = [i for s, e in col_name_ranges.values() for i in range(s, e)]\n",
    "for ranges in table_name_ranges.values():\n",
    "    print([mt_uskg.tokenizer.decode(a_ex['enc_tokenized']['input_ids'][s:e]) for s, e in ranges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'continents': [(33, 35)],\n",
       "             'countries': [(44, 45)],\n",
       "             'car_makers': [(58, 61)],\n",
       "             'model_list': [(82, 85)],\n",
       "             'car_names': [(102, 106)],\n",
       "             'cars_data': [(146, 149)]})"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_a_ex = ctu.create_analysis_sample_dicts_all_nodes(\n",
    "                    mt_uskg, ex,\n",
    "                    remove_struct_duplicate_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'enc_sentence', 'enc_tokenized', 'text_range', 'struct_range', 'struct_node_ranges_dict', 'dec_prompt', 'remove_struct_duplicate_nodes', 'parsed_struct_in', 'col2table', 'token_ranges_dict', 'alias2table', 'category', 'occ_cols', 'occ_tabs', 'non_occ_cols', 'non_occ_tabs', 'col_self_ranges', 'col_context_ranges', 'tab_self_ranges', 'tab_context_ranges'])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_a_ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_a_ex['enc_sentence'], \\\n",
    "combined_a_ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occ_cols ['accelerate', 'makeid', 'make']\n",
      "occ_tabs ['cars_data', 'car_names']\n",
      "non_occ_cols ['contid', 'countryid', 'countryname', 'fullname', 'country', 'modelid', 'mpg', 'cylinders', 'edispl', 'horsepower', 'weight', 'year']\n",
      "non_occ_tabs ['continents', 'countries', 'car_makers', 'model_list']\n"
     ]
    }
   ],
   "source": [
    "for k, v in combined_a_ex.items():\n",
    "    if 'occ' in k:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_self_ranges {'accelerate': [(176, 181)], 'makeid': [(106, 113)], 'make': [(119, 146)], 'contid': [(35, 42)], 'countryid': [(45, 52)], 'countryname': [(50, 56)], 'fullname': [(74, 80)], 'country': [(78, 82)], 'modelid': [(85, 92)], 'mpg': [(154, 161)], 'cylinders': [(159, 166)], 'edispl': [(164, 172)], 'horsepower': [(170, 175)], 'weight': [(173, 178)], 'year': [(179, 182)]}\n",
      "tab_self_ranges {'cars_data': [(145, 151)], 'car_names': [(101, 108)], 'continents': [(32, 37)], 'countries': [(43, 47)], 'car_makers': [(57, 63)], 'model_list': [(81, 87)]}\n"
     ]
    }
   ],
   "source": [
    "for k, v in combined_a_ex.items():\n",
    "    if '_self' in k:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_context_ranges {'accelerate': [(28, 176), (181, 182)], 'makeid': [(28, 106), (113, 182)], 'make': [(28, 119), (146, 182)], 'contid': [(28, 35), (42, 182)], 'countryid': [(28, 45), (52, 182)], 'countryname': [(28, 50), (56, 182)], 'fullname': [(28, 74), (80, 182)], 'country': [(28, 78), (82, 182)], 'modelid': [(28, 85), (92, 182)], 'mpg': [(28, 154), (161, 182)], 'cylinders': [(28, 159), (166, 182)], 'edispl': [(28, 164), (172, 182)], 'horsepower': [(28, 170), (175, 182)], 'weight': [(28, 173), (178, 182)], 'year': [(28, 179)]}\n",
      "tab_context_ranges {'cars_data': [(28, 145), (151, 182)], 'car_names': [(28, 101), (108, 182)], 'continents': [(28, 32), (37, 182)], 'countries': [(28, 43), (47, 182)], 'car_makers': [(28, 57), (63, 182)], 'model_list': [(28, 81), (87, 182)]}\n"
     ]
    }
   ],
   "source": [
    "for k, v in combined_a_ex.items():\n",
    "    if '_context' in k:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select A from B as t1 join C as t2 on t1 . b = t2 . c where t2 . N = \" Fast as a shark \" ;'"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.separate_punct('select A from B as t1 join C as t2 on t1.b = t2.c where t2.N = \"Fast as a shark\";')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate punct by offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['select', 't2.', 'petid', 'from', 'has_pet', 'as', 't1', 'join', 'pets', 'as', 't2', 'on', 't2.', 'petid', '=', 't1.', 'petid', 'join', 'student', 'as', 't3', 'on', 't3.', 'stuid', '=', 't1.', 'stuid', 'where', 't3.', 'lname', '=', '‘', 'Smith', '’']\n"
     ]
    }
   ],
   "source": [
    "# _sql = 'SELECT t2.aaa, DISTINCT(t3.ccc), COUNT(*) FROM table_name as t1 JOIN other_table as t2 on table_name.a_a = other_table.b_a JOIN ttt as t3 on other_table.asth = ttt.asth WHERE t2.col like \"%hey%\" AND t3.p <= 40'.lower()\n",
    "_sql = 'select t2.petid from has_pet as t1 join pets as t2 on t2.petid = t1.petid join student as t3 on t3.stuid = t1.stuid where t3.lname = ‘Smith’'\n",
    "_tok_ranges = ctu.separate_punct_by_offset(_sql)\n",
    "print([_sql[s:e] for s, e in _tok_ranges])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_a_ex = {\n",
    "    'enc_sentence': 'which school is good? structed_knowledge: school | school : school_name, is_good',\n",
    "    'dec_prompt': 'select distinct',\n",
    "    'expect': 'school_name',  # ['▁school', '_', 'name']\n",
    "    'answers_t': [1,2,3],\n",
    "    'answer': 'school_name',\n",
    "    'text_range': [0, 5],\n",
    "    'struct_range': [15, 25],\n",
    "    'self_ranges': [[18, 21]],\n",
    "    'context_ranges': [[15, 18], [21, 25]],\n",
    "}\n",
    "\n",
    "_test_att_masks = ctu.build_dec_cross_attention_mask(\n",
    "    a_ex=_test_a_ex,\n",
    "    mt=mt_uskg,\n",
    "    use_self_node=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False, False, False, False, False, False, False, False,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "           False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "           False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "           False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "           False, False, False, False, False,  True]]]])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_att_masks['all->t+o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True]]]])"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_att_masks['all->t+o'] | _test_att_masks['all->s'] | _test_att_masks['all->p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False]]]])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(_test_att_masks['all->s'] | _test_att_masks['all->p']) & _test_att_masks['all->t+o']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse SQL alias2table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 'b', 't2': 'c'}"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.parse_sql_alias2table('select A from B as t1 join C as t2 on t1.b = t2.c where t2.N = \"Fast as a shark\";')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorize tokens offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['select', 't2.', 'petid', 'from', 'has_pet', 'as', 't1', 'join', 'pets', 'as', 't2', 'on', 't2.', 'petid', '=', 't1.', 'petid', 'join', 'student', 'as', 't3', 'on', 't3.', 'stuid', '=', 't1.', 'stuid', 'where', 't3.', 'lname', '=', '‘', 'Smith', '’']\n"
     ]
    }
   ],
   "source": [
    "# _sql = 'SELECT t2.aaa, DISTINCT(t3.ccc), COUNT(*) FROM table_name as t1 JOIN other_table as t2 on table_name.a_a = other_table.b_a JOIN ttt as t3 on other_table.asth = ttt.asth WHERE t2.col like \"%hey%\" AND t3.p <= 40'.lower()\n",
    "# _sql = 'select date_incident_start, date_incident_end, d+e from behavior_incident join tb where incident_type_code = \"NOISE\" and 3 < tbcol'\n",
    "_sql = 'select t2.petid from has_pet as t1 join pets as t2 on t2.petid = t1.petid join student as t3 on t3.stuid = t1.stuid where t3.lname = ‘Smith’'\n",
    "_tok_ranges = ctu.separate_punct_by_offset(_sql)\n",
    "print([_sql[s:e] for s, e in _tok_ranges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rgs2type = ctu.categorize_tokens_offset(_sql, _tok_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select syntax\n",
      "t2. table_alias\n",
      "petid column\n",
      "from syntax\n",
      "has_pet table\n",
      "as syntax\n",
      "t1 table_alias\n",
      "join syntax\n",
      "pets table\n",
      "as syntax\n",
      "t2 table_alias\n",
      "on syntax\n",
      "t2. table_alias\n",
      "petid column\n",
      "= syntax\n",
      "t1. table_alias\n",
      "petid column\n",
      "join syntax\n",
      "student table\n",
      "as syntax\n",
      "t3 table_alias\n",
      "on syntax\n",
      "t3. table_alias\n",
      "stuid column\n",
      "= syntax\n",
      "t1. table_alias\n",
      "stuid column\n",
      "where syntax\n",
      "t3. table_alias\n",
      "lname column\n",
      "= syntax\n",
      "‘ val\n",
      "Smith val\n",
      "’ val\n"
     ]
    }
   ],
   "source": [
    "for _rg, _type in _rgs2type.items():\n",
    "    s, e = _rg\n",
    "    print(_sql[s:e], _type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = dict(a_ex_list[a_ex_id])\n",
    "a_ex = ctu.add_clean_prediction(mt_uskg, a_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'What is the accelerate of the car make amc hornet sportabout (sw)?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'seq_out': \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\",\n",
       " 'dec_prompt': 'select t1.',\n",
       " 'expect': 'accelerate',\n",
       " 'expect_type': 'column',\n",
       " 'db_id': 'car_1',\n",
       " 'expect_input_ranges': [(178, 179)],\n",
       " 'self_ranges': [(176, 181)],\n",
       " 'expect_table': 'cars_data',\n",
       " 'answer': 'acc',\n",
       " 'base_score': 0.9999758005142212,\n",
       " 'answers_t': [6004],\n",
       " 'correct_prediction': False,\n",
       " 'category': {'sql_hardness': 'medium',\n",
       "  'node_role': 'select',\n",
       "  'text_match': 'exact',\n",
       "  'node_len': '1'}}"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ctu.make_basic_result_dict(a_ex)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']\n",
    "answer = result['answer']\n",
    "answers_t = result['answers_t']\n",
    "\n",
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 2,\n",
    "    [dec_prompt] * 2,\n",
    "    answer=expect)\n",
    "\n",
    "_, enc_seq_len = inp['input_ids'].size()\n",
    "_, dec_seq_len = inp['decoder_input_ids'].size()\n",
    "\n",
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "self_ranges = a_ex['self_ranges']\n",
    "context_ranges = a_ex['context_ranges']\n",
    "\n",
    "self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "context_tok_indices = corrupt_tok_indices = [i for s, e in context_ranges for i in range(s, e)]\n",
    "text_tok_indices = list(range(*text_range))\n",
    "struct_tok_indices = list(range(*struct_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repatch-uskg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6726], 'city', 0.8450507521629333)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_t, answer, _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8450507521629333"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_to_corrupt = [(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                for tnum in text_tok_indices]\n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=states_to_corrupt,\n",
    "#     tokens_to_mix=corrupt_tok_indices,\n",
    "#     tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9952, device='cuda:0')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pair of identical input to test correctness \n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_patch_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 12))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 23))\n",
    "                    for tnum in struct_tok_indices],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    tokens_to_mix_1st_pass=context_tok_indices,\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9952, device='cuda:0')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_patch_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 12))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 23))\n",
    "                    for tnum in struct_tok_indices],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_corrupt_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                    for tnum in context_tok_indices],\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253002524375916"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test corrupting attention \n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", l, \"self_attn\"))\n",
    "                    for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers)],\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n for n, w in mt_uskg.model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_probs = ctu.run_repatch_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "                    for tnum in self_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "                    for tnum in self_tok_indices],\n",
    "    answer_len=len(answers_t),\n",
    "    tokens_to_mix=corrupt_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32102])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.], device='cuda:0'),\n",
       "indices=tensor([7634], device='cuda:0'))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(vocab_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs[0, 7634]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2642e-25, 1.2223e-15, 7.3942e-18,  ..., 9.1578e-20, 2.6884e-39,\n",
       "         2.8131e-39]], device='cuda:0')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention-manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    ['name of singer'] * 2,\n",
    "    ['select'] * 2,\n",
    "    answer='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 2, 10)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs, enc_seq_len = small_inp['input_ids'].size()\n",
    "bs, dec_seq_len = small_inp['decoder_input_ids'].size()\n",
    "prefix_len = mt_uskg.model.preseqlen\n",
    "\n",
    "bs, enc_seq_len, dec_seq_len, prefix_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False,  True,  True, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False,  True,  True, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False]]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_mask = torch.zeros(1, 1, enc_seq_len, enc_seq_len + prefix_len).bool()\n",
    "mix_mask[:, :, 1:3, 11:13] = True\n",
    "mix_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this checks attention logits/weights to verify that corruption is working \n",
    "\n",
    "corrupted_vocab_probs = ctu.run_attention_manip_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=small_inp,\n",
    "    answer_len=1,\n",
    "    mix_mask_per_layer={ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') : mix_mask for l in [0, 12, 23]},\n",
    "    replace=True,\n",
    "    attn_corrupt_type='logits',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32102])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_vocab_probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer-copy-uskg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999758005142212"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "#     states_to_copy_from=states_to_copy_from,\n",
    "#     states_to_copy_to=states_to_copy_to,\n",
    "#     answer_len=len(answers_t),\n",
    "    states_to_corrupt=[],\n",
    "    replace=True,\n",
    ").item()\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8760302111786586e-07"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_to_copy_to = [\n",
    "    (tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 17))\n",
    "    for tnum in range(enc_seq_len)\n",
    "]\n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "#     states_to_copy_from=states_to_copy_from,\n",
    "#     states_to_copy_to=states_to_copy_to,\n",
    "#     answer_len=len(answers_t),\n",
    "    states_to_corrupt=states_to_copy_to,\n",
    "    replace=True,\n",
    ").item()\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.155608645030952e-08]"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement 1: layer-copy \n",
    "\n",
    "states_to_copy_from = [\n",
    "    (tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "    for tnum in range(enc_seq_len)\n",
    "]\n",
    "\n",
    "states_to_copy_to = [\n",
    "    (tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 12))\n",
    "    for tnum in range(enc_seq_len)\n",
    "]\n",
    "\n",
    "vocab_probs = ctu.run_layer_copy_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[],\n",
    "#     states_to_unpatch=[],\n",
    "#     answers_t=answers_t,\n",
    "    states_to_copy_from=states_to_copy_from,\n",
    "    states_to_copy_to=states_to_copy_to,\n",
    "    answer_len=len(answers_t),\n",
    "#     states_to_corrupt=states_to_corrupt,\n",
    "#     tokens_to_mix=corrupt_tok_indices,\n",
    "#     tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ")\n",
    "\n",
    "ans_probs = [vocab_probs[i, _t].item() for i, _t in enumerate(answers_t)]\n",
    "\n",
    "ans_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.155608645030952e-08"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement 2: sublayer-zero \n",
    "# Should have the same score as implement 1: yes!\n",
    "\n",
    "states_to_zero = [\n",
    "    (tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", l, sublayer))\n",
    "    for tnum in range(enc_seq_len) for l in range(0, 13) for sublayer in ['self_attn', 'mlp']\n",
    "]\n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "#     states_to_copy_from=states_to_copy_from,\n",
    "#     states_to_copy_to=states_to_copy_to,\n",
    "#     answer_len=len(answers_t),\n",
    "    states_to_corrupt=states_to_zero,\n",
    "    replace=True,\n",
    "    noise=0.0,\n",
    ").item()\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'pretrain_model',\n",
    "#  'pretrain_model.shared',\n",
    "#  'pretrain_model.encoder',\n",
    "#  'pretrain_model.encoder.block',\n",
    "#  'pretrain_model.encoder.block.0',\n",
    "#  'pretrain_model.encoder.block.0.layer',\n",
    "#  'pretrain_model.encoder.block.0.layer.0',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention.q',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention.k',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention.v',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention.o',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.layer_norm',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.dropout',\n",
    "#  'pretrain_model.encoder.block.0.layer.1',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.DenseReluDense',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.DenseReluDense.wi',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.DenseReluDense.wo',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.DenseReluDense.dropout',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.layer_norm',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.dropout',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32102, 1024])"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = mt_uskg.model.pretrain_model.encoder.embed_tokens.weight\n",
    "embs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[564], [1246], [2982], [7634]], 'attention_mask': [[1], [1], [1], [1]]}"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.batch_encode_plus(['name', 'age', 'nation', 'singer'], add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.8750,  17.0000,   5.3438,  ..., -15.8750,  -0.8789,   2.6562],\n",
       "        [  6.3750,  13.5000, -35.7500,  ...,   2.3281,  15.7500,   3.5938],\n",
       "        [  3.3750, -16.8750, -25.2500,  ...,   0.9258,  -5.8750,   4.5625],\n",
       "        [  0.4629,  -3.0156, -10.1875,  ...,  -8.4375,   1.8828,   3.3750]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[[564, 1246, 2982, 7634]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12.6989, 15.4454, 16.5982,  ..., 12.3047, 12.5982,  9.7114],\n",
       "        device='cuda:0'),\n",
       " tensor([-4.3081, -2.5801,  2.5176,  ..., -2.8731,  3.0601, 12.4257],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_std, embs_mean = torch.std_mean(embs, dim=0)\n",
    "embs_std, embs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(2.3013, device='cuda:0'), tensor(13.3482, device='cuda:0')),\n",
       " (tensor(4.8516, device='cuda:0'), tensor(0.1390, device='cuda:0')))"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(embs_std), torch.std_mean(embs_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([639.1667, 281.5377, 303.9011,  ..., 242.6456, 397.0485, 398.6314],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_norm = torch.linalg.norm(embs, ord=2, dim=1)\n",
    "embs_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(66.8115, device='cuda:0'), tensor(455.5204, device='cuda:0'))"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(embs_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([719.9138, 459.3446, 463.6613,  ..., 422.5326, 498.5402, 499.7012],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_wid = 564\n",
    "tgt_vec = embs[tgt_wid]\n",
    "# delta = 5.0 * torch.randn_like(tgt_vec)\n",
    "# tgt_vec = tgt_vec + delta\n",
    "\n",
    "embs_dist = torch.linalg.norm(embs - tgt_vec, ord=2, dim=1)\n",
    "embs_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(54.9653, device='cuda:0'), tensor(565.9248, device='cuda:0')),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(564, device='cuda:0'))"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(embs_dist), torch.min(embs_dist), torch.argmin(embs_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 564),\n",
       " (273.6109924316406, 5570),\n",
       " (279.52862548828125, 3056),\n",
       " (315.5259704589844, 4350),\n",
       " (353.9427490234375, 23954),\n",
       " (359.2679443359375, 2650),\n",
       " (369.5257873535156, 10016),\n",
       " (405.4482421875, 2233),\n",
       " (411.2537841796875, 3),\n",
       " (411.6006164550781, 2862)]"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dists = sorted((dist, i) for i, dist in enumerate(embs_dist.cpu().tolist()))\n",
    "sorted_dists[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'Name',\n",
       " 'names',\n",
       " 'name',\n",
       " 'Name',\n",
       " 'named',\n",
       " 'Namen',\n",
       " 'title',\n",
       " '',\n",
       " 'identify']"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.decode_tokens(mt_uskg.tokenizer, [tok_id for _, tok_id in sorted_dists[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([737.6123, 487.0907, 491.6216,  ..., 456.4087, 529.4299, 530.4269],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_wid = 564\n",
    "tgt_vec = embs[tgt_wid]\n",
    "delta = 5.0 * torch.randn_like(tgt_vec)\n",
    "tgt_vec = tgt_vec + delta\n",
    "\n",
    "embs_dist = torch.linalg.norm(embs - tgt_vec, ord=2, dim=1)\n",
    "embs_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(53.0791, device='cuda:0'), tensor(590.1509, device='cuda:0')),\n",
       " tensor(158.3963, device='cuda:0'),\n",
       " tensor(564, device='cuda:0'))"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(embs_dist), torch.min(embs_dist), torch.argmin(embs_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(158.39627075195312, 564),\n",
       " (316.92431640625, 5570),\n",
       " (323.1575927734375, 3056),\n",
       " (357.3472595214844, 4350),\n",
       " (393.6805419921875, 23954),\n",
       " (400.9082946777344, 10016),\n",
       " (402.192138671875, 2650),\n",
       " (433.865234375, 2233),\n",
       " (441.6644592285156, 3),\n",
       " (443.2170715332031, 2862)]"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dists = sorted((dist, i) for i, dist in enumerate(embs_dist.cpu().tolist()))\n",
    "sorted_dists[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'names', 'Name', 'name', 'named', 'Name', 'Namen', '', 'title', '.']"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.decode_tokens(mt_uskg.tokenizer, [tok_id for _, tok_id in sorted_dists[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_id = 111\n",
    "a_ex_id = 0\n",
    "\n",
    "ex = processed_spider_dev[ex_id]\n",
    "ex['text_in'], \\\n",
    "ex['struct_in'], \\\n",
    "ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu.create_analysis_sample_dicts(\n",
    "                mt_uskg, ex,\n",
    "                subject_type='column',\n",
    "                remove_struct_duplicate_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']\n",
    "answer = result['answer']\n",
    "answers_t = result['answers_t']\n",
    "\n",
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "self_ranges = a_ex['self_ranges']\n",
    "struct_context_ranges = a_ex['context_ranges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 2,\n",
    "    [dec_prompt] * 2,\n",
    "    answer=expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import nethook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(), nethook.TraceDict(\n",
    "    mt_uskg.model,\n",
    "    [ctu.layername_uskg(mt_uskg.model, \"encoder\", l) for l in [0, 12, 23]]\n",
    ") as td:\n",
    "    outputs_exp = ctu.run_model_forward_uskg(mt_uskg.model, **inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['pretrain_model.encoder.block.0', 'pretrain_model.encoder.block.12', 'pretrain_model.encoder.block.23'])"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 183, 1024]), torch.Size([2, 16, 183, 193]))"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden, attn = td['pretrain_model.encoder.block.23'].output\n",
    "hidden.size(), attn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 431.2646,   22.2026,  -46.9836,  ...,  236.4605, -101.4929,\n",
       "          -13.4173],\n",
       "        [ 680.9009, -155.7530,   -3.9374,  ...,  357.9876,  -74.5153,\n",
       "         -248.9389],\n",
       "        [ 726.4300,  -97.9734,   82.3419,  ...,  280.2939,  -92.4423,\n",
       "         -208.4543],\n",
       "        ...,\n",
       "        [ -12.3197,  -82.2136,  -86.8491,  ...,  343.5234,   46.3294,\n",
       "          -30.3550],\n",
       "        [ 430.2145,  197.3166, -176.3856,  ...,  235.9048,  -84.3116,\n",
       "         -104.0558],\n",
       "        [ 935.1066,  134.0760,   52.9306,  ...,  -17.0239,  -42.8478,\n",
       "          -13.8100]], device='cuda:0')"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(3933.3369, device='cuda:0'), tensor(-22.5662, device='cuda:0')),\n",
       " (tensor(120171.7969, device='cuda:0'), tensor(38477.7578, device='cuda:0')))"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(hidden[0]), torch.std_mean(torch.norm(hidden[0], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(124030.015625, 28),\n",
       " (145044.171875, 40),\n",
       " (199170.0625, 50),\n",
       " (409527.75, 164),\n",
       " (489051.65625, 143),\n",
       " (592587.4375, 135),\n",
       " (672203.0, 78),\n",
       " (684664.5625, 170),\n",
       " (685764.875, 74),\n",
       " (766906.25, 54)]"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_norms = sorted((dist, i) for i, dist in enumerate(torch.norm(hidden[0], dim=-1).cpu().tolist()))\n",
    "sorted_norms[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 ['▁What', '▁is', '▁the', '▁accelerate', '▁of', '▁the', '▁car', '▁make', '▁am', 'c', '▁', 'horn', 'e', 't', '▁sport', 'about', '▁(', 's', 'w', ')', '?', ';', '▁', 'struct', 'e', 'd', '▁knowledge', ':', '▁|', '▁car', '_', '1', '▁|', '▁continent', 's', '▁', ':', '▁cont', 'i', 'd', '▁', ',', '▁continent', '▁|', '▁countries', '▁', ':', '▁country', 'i', 'd', '▁', ',', '▁country', 'name', '▁', ',', '▁continent', '▁|', '▁car', '_', 'makers', '▁', ':', '▁', 'i', 'd', '▁', ',', '▁maker', '▁(', '▁am', 'c', '▁', ')', '▁', ',', '▁full', 'name', '▁', ',', '▁country', '▁|', '▁model', '_', 'list', '▁', ':', '▁model', 'i', 'd', '▁', ',', '▁maker', '▁', ',', '▁model', '▁(', '▁am', 'c', '▁', ')', '▁|', '▁car', '_', 'name', 's', '▁', ':', '▁make', 'i', 'd', '▁', ',', '▁model', '▁(', '▁am', 'c', '▁', ')', '▁', ',', '▁make', '▁(', '▁am', 'c', '▁', 'horn', 'e', 't', '▁', ',', '▁am', 'c', '▁', 'horn', 'e', 't', '▁sport', 'about', '▁(', 's', 'w', ')', '▁', ')', '▁|', '▁cars', '_', 'data', '▁', ':', '▁', 'i', 'd', '▁', ',', '▁', 'mp', 'g', '▁', ',', '▁', 'cylinder', 's', '▁', ',', '▁', 'e', 'disp', 'l', '▁', ',', '▁horsepower', '▁', ',', '▁weight', '▁', ',', '▁accelerate', '▁', ',', '▁year', '</s>']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = mt_uskg.tokenizer.tokenize(enc_sentence, add_special_tokens=True)\n",
    "print(len(tokenized_input), tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':', ';', '▁', '▁', '▁', '▁', '</s>', 's', '▁', '_', '▁|', '▁', '▁', '▁', '▁', 'e', '▁', '▁', '▁', '▁']\n"
     ]
    }
   ],
   "source": [
    "print([tokenized_input[i] for _, i in sorted_norms[-20:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden[0, ::10, ::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untuple(x):\n",
    "    return x[0] if isinstance(x, tuple) else x\n",
    "\n",
    "def patch_rep(x, layer):\n",
    "    h = untuple(x)\n",
    "    if layer in corrupt_spec:\n",
    "        toks_to_mix = corrupt_spec[layer]\n",
    "        if toks_to_mix:\n",
    "            mix_len = len(toks_to_mix)\n",
    "#             noise_data = noise_fn(\n",
    "#                 torch.from_numpy(prng(h.shape[0] - 1, mix_len, h.shape[2]))\n",
    "#             ).to(device=h.device, dtype=h.dtype)\n",
    "#             if replace:\n",
    "#                 h[1:, toks_to_mix] = noise_data\n",
    "#             else:\n",
    "#                 h[1:, toks_to_mix] += noise_data\n",
    "            h[1:, toks_to_mix] = 0\n",
    "\n",
    "#     # If this layer is in the patch_spec, restore the uncorrupted hidden state\n",
    "#     # for selected tokens.\n",
    "#     toks_to_patch = patch_spec.get(layer, [])\n",
    "#     toks_to_unpatch = unpatch_spec.get(layer, [])\n",
    "\n",
    "#     for t in toks_to_patch:\n",
    "#         h[1:, t] = h[0, t]\n",
    "#     for t in toks_to_unpatch:\n",
    "#         h[1:, t] = untuple(first_pass_trace[layer].output)[1:, t]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 21)"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrupt_spec = {ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\") : list(range(*text_range))}\n",
    "corrupt_spec = {ctu.layername_uskg(mt_uskg.model, \"encoder\", 23) : list(range(*text_range))}\n",
    "\n",
    "hook_layers = [ctu.layername_uskg(mt_uskg.model, \"encoder\", l) for l in [0, 12, 23]] + \\\n",
    "    [ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\")]\n",
    "\n",
    "with torch.no_grad(), nethook.TraceDict(\n",
    "    mt_uskg.model,\n",
    "    layers=hook_layers,\n",
    "    edit_output=patch_rep,\n",
    ") as td:\n",
    "    outputs_exp = ctu.run_model_forward_uskg(mt_uskg.model, **inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 183, 1024]), torch.Size([2, 16, 183, 193]))"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden, attn = td['pretrain_model.encoder.block.0'].output\n",
    "hidden.size(), attn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -0.2820,  -0.0777, -10.0541,  ...,  18.3919,  19.2083,   4.6788],\n",
       "         [  2.3624,  -4.3468,   2.1581,  ...,   0.8777,  -2.4387,   1.6466],\n",
       "         [ -0.4869,   5.1502,   1.1220,  ...,   9.9191,  -7.7408,  -6.1049],\n",
       "         ...,\n",
       "         [  7.9017,  -2.7019, -14.2257,  ...,   6.8594,  -0.4216,   0.3843],\n",
       "         [ -2.5844,  13.8755,   1.1908,  ...,   1.7322,  -7.5010,   6.5653],\n",
       "         [ 19.2494, -10.1652,   1.5651,  ...,   9.0200,  13.4675,  31.8201]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ -0.2820,  -0.0777, -10.0541,  ...,  18.3919,  19.2083,   4.6788],\n",
       "         [  2.3624,  -4.3468,   2.1581,  ...,   0.8777,  -2.4387,   1.6466],\n",
       "         [ -0.4869,   5.1502,   1.1220,  ...,   9.9191,  -7.7408,  -6.1049],\n",
       "         ...,\n",
       "         [  7.9017,  -2.7019, -14.2257,  ...,   6.8594,  -0.4216,   0.3843],\n",
       "         [ -2.5844,  13.8755,   1.1908,  ...,   1.7322,  -7.5010,   6.5653],\n",
       "         [ 19.2494, -10.1652,   1.5651,  ...,   9.0200,  13.4675,  31.8201]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0], hidden[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden, attn = td['pretrain_model.encoder.block.12'].output\n",
    "hidden[0], hidden[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 431.2646,   22.2026,  -46.9836,  ...,  236.4605, -101.4929,\n",
       "           -13.4173],\n",
       "         [ 680.9009, -155.7530,   -3.9374,  ...,  357.9876,  -74.5153,\n",
       "          -248.9389],\n",
       "         [ 726.4300,  -97.9734,   82.3419,  ...,  280.2939,  -92.4423,\n",
       "          -208.4543],\n",
       "         ...,\n",
       "         [ -12.3197,  -82.2136,  -86.8491,  ...,  343.5234,   46.3294,\n",
       "           -30.3550],\n",
       "         [ 430.2145,  197.3166, -176.3856,  ...,  235.9048,  -84.3116,\n",
       "          -104.0558],\n",
       "         [ 935.1066,  134.0760,   52.9306,  ...,  -17.0239,  -42.8478,\n",
       "           -13.8100]], device='cuda:0'),\n",
       " tensor([[   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "             0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "             0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "             0.0000],\n",
       "         ...,\n",
       "         [ -12.3197,  -82.2136,  -86.8491,  ...,  343.5234,   46.3294,\n",
       "           -30.3550],\n",
       "         [ 430.2145,  197.3166, -176.3856,  ...,  235.9048,  -84.3116,\n",
       "          -104.0558],\n",
       "         [ 935.1066,  134.0760,   52.9306,  ...,  -17.0239,  -42.8478,\n",
       "           -13.8100]], device='cuda:0'))"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden, attn = td['pretrain_model.encoder.block.23'].output\n",
    "hidden[0], hidden[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(3933.3369, device='cuda:0'), tensor(-22.5662, device='cuda:0')),\n",
       " (tensor(3931.8728, device='cuda:0'), tensor(-22.0143, device='cuda:0')))"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(hidden[0]), torch.std_mean(hidden[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 32102])"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(outputs_exp.logits[:, -len(answers_t):, :], dim=-1)\n",
    "probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9999758005142212, 6004),\n",
       " (1.38331379275769e-05, 9),\n",
       " (7.489517884096131e-06, 30819),\n",
       " (1.270908683181915e-06, 20246),\n",
       " (5.996853360556997e-07, 21007),\n",
       " (4.935201332045835e-07, 26389),\n",
       " (1.2063669885264972e-07, 11584),\n",
       " (1.1599770033399182e-07, 6500),\n",
       " (1.004895580081211e-07, 291),\n",
       " (3.185817476492048e-08, 12497)]"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_probs = sorted([(p, i) for i, p in enumerate(probs[0, 0].cpu().tolist())], reverse=True)\n",
    "sorted_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'a', 'accelerating', 'inclin', 'acco', 'accelerated', 'fast', 'assi', 'ar', 'appro']\n"
     ]
    }
   ],
   "source": [
    "print(ctu.decode_tokens(mt_uskg.tokenizer, [i for p, i in sorted_probs[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8888899087905884, 6004),\n",
       " (0.10935894399881363, 9),\n",
       " (0.0005981624126434326, 30819),\n",
       " (0.0003909562074113637, 21007),\n",
       " (0.0002998432901222259, 9993),\n",
       " (8.253266423707828e-05, 291),\n",
       " (7.506454858230427e-05, 144),\n",
       " (5.3470714192371815e-05, 8010),\n",
       " (5.256106669548899e-05, 11584),\n",
       " (4.682378130382858e-05, 23)]"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_probs = sorted([(p, i) for i, p in enumerate(probs[1, 0].cpu().tolist())], reverse=True)\n",
    "sorted_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'a', 'accelerating', 'acco', 'speed', 'ar', 'at', 'auto', 'fast', 'i']\n"
     ]
    }
   ],
   "source": [
    "print(ctu.decode_tokens(mt_uskg.tokenizer, [i for p, i in sorted_probs[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-time patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expect_type = 'table_alias'\n",
    "# orig_res_path = f'/home/yshao/Projects/rome/results/exp6_2_decoder_cross_attention_corruption_syntax/no_o_exp=6.2_dev_corrupt=zero.jsonl'\n",
    "# add_res_path = f'/home/yshao/Projects/rome/results/exp6_2_decoder_cross_attention_corruption_syntax/exp=6.2+o_dev_corrupt=zero.jsonl'\n",
    "\n",
    "# merge_res_path = f'/home/yshao/Projects/rome/results/exp6_2_decoder_cross_attention_corruption_syntax/exp=6.2_dev_corrupt=zero.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(orig_res_path, 'r') as f:\n",
    "#     orig_all_samples = [json.loads(l) for l in f]\n",
    "# with open(add_res_path, 'r') as f:\n",
    "#     add_all_samples = [json.loads(l) for l in f]\n",
    "\n",
    "# f = open(merge_res_path, 'w')\n",
    "\n",
    "# for i, (orig_ex, add_ex) in enumerate(zip(orig_all_samples, add_all_samples)):\n",
    "#     assert len(orig_ex['trace_results']) == len(add_ex['trace_results']), i\n",
    "#     # There is randomness in the order of expected node (from set()), thus sorting here \n",
    "#     orig_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     add_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     for j, (orig_d, add_d) in enumerate(zip(orig_ex['trace_results'], add_ex['trace_results'])):\n",
    "#         assert orig_d['is_good_sample'] == add_d['is_good_sample'], (i, j)\n",
    "#         if not orig_d['is_good_sample']:\n",
    "#             continue\n",
    "            \n",
    "#         # is good sample: add the new sections \n",
    "#         for k, v in add_d['trace_scores'].items():\n",
    "#             if k in orig_d['trace_scores']:\n",
    "#                 continue\n",
    "#             orig_d['trace_scores'][k] = add_d['trace_scores'][k]\n",
    "        \n",
    "#     f.write(json.dumps(orig_ex, indent=None) + '\\n')\n",
    "    \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = processed_spider_dev[97]\n",
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "dec_prompt = \"select t1.model from\"\n",
    "expect = \"car_names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    enc_sentences=[enc_sentence]*11,\n",
    "    dec_prompts=[dec_prompt]*11,\n",
    "    answer=expect\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 'aa,bb< cc  \\t dd(  )ee <= ff=5 %h% \"06-15\".'\n",
    "sep_pattern = r'\\s+|\\W'\n",
    "\n",
    "all_matches = re.finditer(sep_pattern, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(2, 3), match=','>,\n",
       " <re.Match object; span=(5, 6), match='<'>,\n",
       " <re.Match object; span=(6, 7), match=' '>,\n",
       " <re.Match object; span=(9, 13), match='  \\t '>,\n",
       " <re.Match object; span=(15, 16), match='('>,\n",
       " <re.Match object; span=(16, 18), match='  '>,\n",
       " <re.Match object; span=(18, 19), match=')'>,\n",
       " <re.Match object; span=(21, 22), match=' '>,\n",
       " <re.Match object; span=(22, 23), match='<'>,\n",
       " <re.Match object; span=(23, 24), match='='>,\n",
       " <re.Match object; span=(24, 25), match=' '>,\n",
       " <re.Match object; span=(27, 28), match='='>,\n",
       " <re.Match object; span=(29, 30), match=' '>,\n",
       " <re.Match object; span=(30, 31), match='%'>,\n",
       " <re.Match object; span=(32, 33), match='%'>,\n",
       " <re.Match object; span=(33, 34), match=' '>,\n",
       " <re.Match object; span=(34, 35), match='\"'>,\n",
       " <re.Match object; span=(37, 38), match='-'>,\n",
       " <re.Match object; span=(40, 41), match='\"'>,\n",
       " <re.Match object; span=(41, 42), match='.'>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches = list(all_matches)\n",
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches[0].span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 5, 6, 7, 9, 13, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42]\n"
     ]
    }
   ],
   "source": [
    "splits = [0] + [i for m in all_matches for i in m.span()] + [len(seq)]\n",
    "splits = sorted(list(set(splits)))\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 0\n",
    "SP = [\"<=\", \">=\", \"<>\", \"!=\"]\n",
    "toks = []\n",
    "\n",
    "for s, e in zip(splits[:-1], splits[1:]):\n",
    "    if not seq[s:e].strip():\n",
    "        # is a whitespace\n",
    "        st = e\n",
    "    else:\n",
    "        # is a punct\n",
    "        if seq[s:s+2] in SP:\n",
    "            # wait next\n",
    "            continue\n",
    "        toks.append(seq[st:e])\n",
    "        st = e\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', ',', 'bb', '<', 'cc', 'dd', '(', ')', 'ee', '<=', 'ff', '=', '5', '%', 'h', '%', '\"', '06', '-', '15', '\"', '.']\n"
     ]
    }
   ],
   "source": [
    "print(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temp observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.98,\n",
       " 0.74,\n",
       " 0.96,\n",
       " 0.82,\n",
       " 0.15,\n",
       " 0.36,\n",
       " 0.82,\n",
       " 0.03,\n",
       " 0.45,\n",
       " 0.18,\n",
       " 0.1,\n",
       " 0.82,\n",
       " 0.82,\n",
       " 0.17,\n",
       " 0.96,\n",
       " 0.96,\n",
       " 0.94,\n",
       " 0.17,\n",
       " 0.01]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weights_dict[23][7]['occ_cols']['prefix#0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'accelerate'),\n",
       " (1, 'makeid'),\n",
       " (1, 'make'),\n",
       " (2, 'city'),\n",
       " (2, 'airportcode'),\n",
       " (2, 'destairport'),\n",
       " (2, 'city'),\n",
       " (4, 'loser_name'),\n",
       " (5, 'first_name'),\n",
       " (5, 'middle_name'),\n",
       " (5, 'last_name'),\n",
       " (5, 'date_first_registered'),\n",
       " (6, 'birth_date'),\n",
       " (6, 'earnings'),\n",
       " (7, 'continent'),\n",
       " (7, 'continent'),\n",
       " (8, 'name'),\n",
       " (8, 'id'),\n",
       " (9, 'treatment_type_description')]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_backtrace_dict['occ_cols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the accelerate of the car make amc hornet sportabout (sw)? --> select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\n",
      "accelerate: 0.5900\n",
      "\n",
      "What is the accelerate of the car make amc hornet sportabout (sw)? --> select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\n",
      "makeid: 0.0900\n",
      "\n",
      "What is the accelerate of the car make amc hornet sportabout (sw)? --> select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\n",
      "make: 0.8200\n",
      "\n",
      "Which city has the most frequent destination airport? --> select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.city order by count(*) desc limit 1\n",
      "city: 0.6100\n",
      "\n",
      "Which city has the most frequent destination airport? --> select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.city order by count(*) desc limit 1\n",
      "airportcode: 0.3300\n",
      "\n",
      "Which city has the most frequent destination airport? --> select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.city order by count(*) desc limit 1\n",
      "destairport: 0.1300\n",
      "\n",
      "Which city has the most frequent destination airport? --> select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.city order by count(*) desc limit 1\n",
      "city: 0.6100\n",
      "\n",
      "How many different loser names are there? --> select count(distinct loser_name) from matches\n",
      "loser_name: 0.5200\n",
      "\n",
      "Who is the first student to register? List the first name, middle name and last name. --> select first_name, middle_name, last_name from students order by date_first_registered asc limit 1\n",
      "first_name: 0.5500\n",
      "\n",
      "Who is the first student to register? List the first name, middle name and last name. --> select first_name, middle_name, last_name from students order by date_first_registered asc limit 1\n",
      "middle_name: 0.8400\n",
      "\n",
      "Who is the first student to register? List the first name, middle name and last name. --> select first_name, middle_name, last_name from students order by date_first_registered asc limit 1\n",
      "last_name: 0.3900\n",
      "\n",
      "Who is the first student to register? List the first name, middle name and last name. --> select first_name, middle_name, last_name from students order by date_first_registered asc limit 1\n",
      "date_first_registered: 0.9300\n",
      "\n",
      "Return the birth date of the poker player with the lowest earnings. --> select t1.birth_date from people as t1 join poker_player as t2 on t1.people_id = t2.people_id order by t2.earnings asc limit 1\n",
      "birth_date: 0.6000\n",
      "\n",
      "Return the birth date of the poker player with the lowest earnings. --> select t1.birth_date from people as t1 join poker_player as t2 on t1.people_id = t2.people_id order by t2.earnings asc limit 1\n",
      "earnings: 0.8900\n",
      "\n",
      "What are the Asian countries which have a population larger than that of any country in Africa? --> select name from country where continent = \"Asia\" and population > (select min(population) from country where continent = \"Africa\")\n",
      "continent: 0.6600\n",
      "\n",
      "What are the Asian countries which have a population larger than that of any country in Africa? --> select name from country where continent = \"Asia\" and population > (select min(population) from country where continent = \"Africa\")\n",
      "continent: 0.6600\n",
      "\n",
      "Show the names of high schoolers who have at least 3 friends. --> select t2.name from friend as t1 join highschooler as t2 on t1.student_id = t2.id group by t1.student_id having count(*) >= 3\n",
      "name: 0.9400\n",
      "\n",
      "Show the names of high schoolers who have at least 3 friends. --> select t2.name from friend as t1 join highschooler as t2 on t1.student_id = t2.id group by t1.student_id having count(*) >= 3\n",
      "id: 0.2000\n",
      "\n",
      "What are each professional's first name and description of the treatment they have performed? --> select distinct t1.first_name, t3.treatment_type_description from professionals as t1 join treatments as t2 on t1.professional_id = t2.professional_id join treatment_types as t3 on t2.treatment_type_code = t3.treatment_type_code\n",
      "treatment_type_description: 0.4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layer_id = 23\n",
    "head_id = 8\n",
    "occ_k = 'occ_cols'\n",
    "sect_k = 'text'\n",
    "\n",
    "for att_w, (ex_id, col_name) in zip(att_weights_dict[layer_id][head_id][occ_k][sect_k], sample_backtrace_dict[occ_k]):\n",
    "    ex = processed_spider_dev[ex_id * 111]\n",
    "    print(ex['text_in'], '-->', ex['seq_out'])\n",
    "    print(f'{col_name}: {att_w:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Show name, country, age for all singers ordered by age from the oldest to the youngest.'"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = processed_spider_dev[2]\n",
    "ex['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903f443f30dc44c296729e6f2aa8ea6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_path = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/exp=4.1_dev.jsonl'\n",
    "\n",
    "with open(_path, 'r') as f:\n",
    "    all_dev_samples = [ujson.loads(l) for l in tqdm(f)]\n",
    "len(all_dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del all_dev_samples\n",
    "# with open(_path, 'r') as f:\n",
    "#     all_dev_samples = [json.loads(l) for l in tqdm(f)]\n",
    "# len(all_dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'db_id', 'col_self_ranges', 'col_context_ranges', 'tab_self_ranges', 'tab_context_ranges', 'category', 'occ_cols', 'non_occ_cols', 'occ_tabs', 'non_occ_tabs', 'attentions'])"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dev_samples[0]['trace_results'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['location', 'capacity', 'highest', 'lowest', 'average', 'country', 'song_name', 'song_release_year', 'age', 'is_male', 'concert_name', 'theme', 'year'])"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dev_samples[0]['trace_results']['attentions']['col'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ['country', 'age', 'age']\n",
      "3 ['country', 'age', 'age']\n",
      "4 ['age', 'age', 'age', 'country']\n",
      "5 ['age', 'age', 'age', 'country']\n",
      "10 ['country', 'country']\n",
      "11 ['country', 'country']\n",
      "12 ['song_name', 'age', 'age']\n",
      "13 ['song_name', 'age', 'age']\n",
      "17 ['capacity', 'capacity']\n",
      "20 ['year', 'year']\n",
      "21 ['year', 'year']\n",
      "26 ['year', 'year']\n",
      "27 ['year', 'year']\n",
      "30 ['country', 'age', 'country', 'age']\n",
      "41 ['location', 'year', 'location', 'year']\n",
      "42 ['location', 'year', 'location', 'year']\n",
      "49 ['weight', 'pettype', 'pettype']\n",
      "50 ['weight', 'pettype', 'pettype']\n",
      "57 ['fname', 'pettype', 'pettype']\n",
      "58 ['fname', 'pettype', 'pettype']\n",
      "59 ['fname', 'pettype', 'fname', 'pettype']\n",
      "60 ['fname', 'pettype', 'fname', 'pettype']\n",
      "65 ['fname', 'age', 'pettype', 'pettype']\n",
      "66 ['fname', 'age', 'pettype', 'pettype']\n",
      "71 ['pet_age', 'pet_age', 'pettype', 'pettype']\n",
      "72 ['pet_age', 'pet_age', 'pettype', 'pettype']\n",
      "73 ['weight', 'pettype', 'pettype']\n",
      "74 ['weight', 'pettype', 'pettype']\n",
      "89 ['contid', 'contid', 'contid']\n",
      "90 ['contid', 'contid', 'contid']\n",
      "97 ['makeid', 'weight', 'weight']\n",
      "98 ['makeid', 'weight', 'weight']\n",
      "101 ['make', 'year', 'makeid', 'year', 'year']\n",
      "102 ['make', 'year', 'makeid', 'year', 'year']\n",
      "107 ['countryname', 'country', 'countryid', 'country']\n",
      "108 ['countryname', 'country', 'countryid', 'country']\n",
      "123 ['countryname', 'countryid', 'countryid', 'country', 'countryid']\n",
      "124 ['countryname', 'countryid', 'countryid', 'country', 'countryid']\n",
      "127 ['weight', 'year', 'year']\n",
      "128 ['weight', 'year', 'year']\n",
      "129 ['countryname', 'contid', 'countryid', 'country', 'countryname']\n",
      "130 ['countryname', 'contid', 'countryid', 'country', 'countryname']\n",
      "131 ['horsepower', 'make', 'makeid', 'cylinders', 'horsepower']\n",
      "132 ['horsepower', 'make', 'makeid', 'cylinders', 'horsepower']\n",
      "139 ['accelerate', 'cylinders', 'cylinders']\n",
      "140 ['accelerate', 'cylinders', 'cylinders']\n",
      "159 ['accelerate', 'accelerate', 'horsepower']\n",
      "160 ['accelerate', 'accelerate', 'horsepower']\n",
      "161 ['countryid', 'country', 'countryid']\n",
      "162 ['countryid', 'country', 'countryid']\n",
      "167 ['makeid', 'make', 'makeid', 'horsepower', 'horsepower', 'cylinders']\n",
      "168 ['makeid', 'make', 'makeid', 'horsepower', 'horsepower', 'cylinders']\n",
      "173 ['countryname', 'countryname', 'countryid', 'country']\n",
      "174 ['countryname', 'countryname', 'countryid', 'country']\n",
      "177 ['countryid', 'countryname', 'countryid', 'country', 'countryid', 'countryid', 'countryname', 'countryid', 'country']\n",
      "178 ['countryid', 'countryname', 'countryid', 'country', 'countryid', 'countryid', 'countryname', 'countryid', 'country']\n",
      "211 ['destairport', 'airportcode', 'sourceairport', 'airportcode', 'city', 'city']\n",
      "212 ['destairport', 'airportcode', 'sourceairport', 'airportcode', 'city', 'city']\n",
      "221 ['city', 'airportcode', 'destairport', 'city']\n",
      "222 ['city', 'airportcode', 'destairport', 'city']\n",
      "223 ['city', 'airportcode', 'sourceairport', 'city']\n",
      "224 ['city', 'airportcode', 'sourceairport', 'city']\n",
      "225 ['airportcode', 'airportcode', 'destairport', 'airportcode', 'sourceairport', 'airportcode']\n",
      "226 ['airportcode', 'airportcode', 'destairport', 'airportcode', 'sourceairport', 'airportcode']\n",
      "227 ['airportcode', 'airportcode', 'destairport', 'airportcode', 'sourceairport', 'airportcode']\n",
      "228 ['airportcode', 'airportcode', 'destairport', 'airportcode', 'sourceairport', 'airportcode']\n",
      "237 ['uid', 'sourceairport', 'uid', 'sourceairport']\n",
      "238 ['uid', 'sourceairport', 'uid', 'sourceairport']\n",
      "239 ['uid', 'sourceairport', 'uid', 'sourceairport']\n",
      "240 ['uid', 'sourceairport', 'uid', 'sourceairport']\n",
      "255 ['destairport', 'airportcode', 'city', 'city']\n",
      "256 ['destairport', 'airportcode', 'city', 'city']\n",
      "263 ['city', 'city']\n",
      "264 ['city', 'city']\n",
      "265 ['city', 'age', 'city']\n",
      "266 ['city', 'age', 'city']\n",
      "267 ['location', 'location']\n",
      "268 ['location', 'location']\n",
      "271 ['number_products', 'number_products']\n",
      "272 ['number_products', 'number_products']\n",
      "275 ['number_products', 'number_products']\n",
      "276 ['number_products', 'number_products']\n",
      "293 ['district', 'number_products', 'district', 'number_products']\n",
      "294 ['district', 'number_products', 'district', 'number_products']\n",
      "327 ['version_number', 'version_number']\n",
      "328 ['version_number', 'version_number']\n",
      "379 ['paragraph_text', 'paragraph_text']\n",
      "380 ['paragraph_text', 'paragraph_text']\n",
      "389 ['name', 'age', 'age']\n",
      "390 ['name', 'age', 'age']\n",
      "393 ['hometown', 'hometown']\n",
      "394 ['hometown', 'hometown']\n",
      "395 ['hometown', 'hometown']\n",
      "396 ['hometown', 'hometown']\n",
      "397 ['hometown', 'hometown']\n",
      "398 ['hometown', 'hometown']\n",
      "401 ['name', 'name']\n",
      "402 ['name', 'name']\n",
      "405 ['name', 'name']\n",
      "406 ['name', 'name']\n",
      "407 ['name', 'name']\n",
      "408 ['name', 'name']\n",
      "412 ['level_of_membership', 'level_of_membership']\n",
      "414 ['level_of_membership', 'level_of_membership', 'age']\n",
      "418 ['num_of_staff', 'num_of_staff', 'open_year']\n",
      "419 ['id', 'age', 'id', 'visitor_id', 'id']\n",
      "420 ['visitor_id', 'level_of_membership', 'id', 'visitor_id', 'visitor_id', 'total_spent']\n",
      "424 ['num_of_ticket', 'num_of_ticket']\n",
      "426 ['id', 'visitor_id', 'open_year', 'id', 'visitor_id', 'open_year']\n",
      "428 ['open_year', 'open_year']\n",
      "445 ['tourney_name', 'tourney_name']\n",
      "446 ['tourney_name', 'tourney_name']\n",
      "447 ['winner_name', 'year', 'winner_name', 'year']\n",
      "448 ['winner_name', 'year', 'winner_name', 'year']\n",
      "449 ['year', 'year']\n",
      "450 ['year', 'year']\n",
      "451 ['country_code', 'first_name', 'winner_id', 'tourney_name', 'country_code', 'first_name', 'winner_id', 'tourney_name']\n",
      "452 ['country_code', 'first_name', 'winner_id', 'tourney_name', 'country_code', 'first_name', 'winner_id', 'tourney_name']\n",
      "461 ['year', 'year']\n",
      "462 ['year', 'year']\n",
      "463 ['winner_name', 'winner_rank_points', 'winner_name']\n",
      "464 ['winner_name', 'winner_rank_points', 'winner_name']\n",
      "469 ['ranking', 'first_name', 'first_name']\n",
      "470 ['ranking', 'first_name', 'first_name']\n",
      "471 ['ranking_points', 'first_name', 'first_name']\n",
      "472 ['ranking_points', 'first_name', 'first_name']\n",
      "473 ['country_code', 'country_code']\n",
      "474 ['country_code', 'country_code']\n",
      "475 ['country_code', 'country_code']\n",
      "476 ['country_code', 'country_code']\n",
      "477 ['country_code', 'country_code']\n",
      "478 ['country_code', 'country_code']\n",
      "479 ['tours', 'ranking_date', 'ranking_date']\n",
      "480 ['tours', 'ranking_date', 'ranking_date']\n",
      "481 ['year', 'year']\n",
      "482 ['year', 'year']\n",
      "489 ['hand', 'hand']\n",
      "490 ['hand', 'hand']\n",
      "494 ['killed', 'killed']\n",
      "504 ['date', 'lost_in_battle', 'date', 'lost_in_battle']\n",
      "505 ['result', 'bulgarian_commander', 'result', 'bulgarian_commander', 'lost_in_battle', 'location']\n",
      "506 ['note', 'note']\n",
      "527 ['section_name', 'section_name']\n",
      "528 ['section_name', 'section_name']\n",
      "537 ['degree_summary_name', 'degree_summary_name']\n",
      "538 ['degree_summary_name', 'degree_summary_name']\n",
      "547 ['course_name', 'course_name']\n",
      "548 ['course_name', 'course_name']\n",
      "549 ['last_name', 'current_address_id', 'address_id', 'state_province_county', 'last_name']\n",
      "550 ['last_name', 'current_address_id', 'address_id', 'state_province_county', 'last_name']\n",
      "561 ['address_id', 'line_1', 'line_2', 'address_id', 'current_address_id', 'address_id']\n",
      "562 ['address_id', 'line_1', 'line_2', 'address_id', 'current_address_id', 'address_id']\n",
      "565 ['transcript_date', 'transcript_date']\n",
      "566 ['transcript_date', 'transcript_date']\n",
      "569 ['transcript_date', 'transcript_date']\n",
      "570 ['transcript_date', 'transcript_date']\n",
      "575 ['degree_summary_name', 'degree_summary_name']\n",
      "576 ['degree_summary_name', 'degree_summary_name']\n",
      "579 ['other_student_details', 'other_student_details']\n",
      "580 ['other_student_details', 'other_student_details']\n",
      "585 ['title', 'title']\n",
      "586 ['title', 'title']\n",
      "593 ['title', 'directed_by', 'directed_by']\n",
      "594 ['title', 'directed_by', 'directed_by']\n",
      "595 ['country', 'country']\n",
      "596 ['country', 'country']\n",
      "605 ['language', 'language']\n",
      "606 ['language', 'language']\n",
      "607 ['language', 'language']\n",
      "608 ['language', 'language']\n",
      "615 ['episode', 'rating', 'rating']\n",
      "616 ['episode', 'rating', 'rating']\n",
      "617 ['share', 'share']\n",
      "618 ['share', 'share']\n",
      "627 ['directed_by', 'directed_by']\n",
      "628 ['directed_by', 'directed_by']\n",
      "635 ['country', 'country', 'written_by']\n",
      "636 ['country', 'country', 'written_by']\n",
      "637 ['series_name', 'country', 'directed_by', 'series_name', 'country', 'directed_by']\n",
      "638 ['series_name', 'country', 'directed_by', 'series_name', 'country', 'directed_by']\n",
      "649 ['earnings', 'earnings']\n",
      "650 ['earnings', 'earnings']\n",
      "673 ['nationality', 'nationality']\n",
      "674 ['nationality', 'nationality']\n",
      "675 ['nationality', 'nationality']\n",
      "676 ['nationality', 'nationality']\n",
      "677 ['nationality', 'nationality']\n",
      "678 ['nationality', 'nationality']\n",
      "679 ['name', 'birth_date', 'name']\n",
      "680 ['name', 'birth_date', 'name']\n",
      "688 ['contestant_name', 'contestant_name']\n",
      "690 ['area_code', 'area_code']\n",
      "692 ['contestant_name', 'contestant_name']\n",
      "698 ['area_code', 'area_code']\n",
      "700 ['area_code', 'contestant_name', 'area_code', 'contestant_name']\n",
      "701 ['contestant_name', 'contestant_name']\n",
      "726 ['surfacearea', 'continent', 'continent']\n",
      "727 ['surfacearea', 'continent', 'continent']\n",
      "742 ['continent', 'code', 'continent']\n",
      "743 ['continent', 'code', 'continent']\n",
      "744 ['code', 'language', 'code', 'language']\n",
      "745 ['code', 'language', 'code', 'language']\n",
      "746 ['code', 'language', 'code', 'language']\n",
      "747 ['code', 'language', 'code', 'language']\n",
      "748 ['code', 'language', 'isofficial', 'code', 'language', 'isofficial']\n",
      "749 ['code', 'language', 'isofficial', 'code', 'language', 'isofficial']\n",
      "752 ['region', 'code', 'language', 'language']\n",
      "753 ['region', 'code', 'language', 'language']\n",
      "754 ['code', 'language', 'isofficial', 'code', 'language', 'isofficial']\n",
      "755 ['code', 'language', 'isofficial', 'code', 'language', 'isofficial']\n",
      "756 ['language', 'code', 'continent', 'language']\n",
      "757 ['language', 'code', 'continent', 'language']\n",
      "758 ['language', 'code', 'governmentform', 'language']\n",
      "759 ['language', 'code', 'governmentform', 'language']\n",
      "772 ['surfacearea', 'surfacearea', 'continent']\n",
      "773 ['surfacearea', 'surfacearea', 'continent']\n",
      "774 ['continent', 'continent']\n",
      "775 ['continent', 'continent']\n",
      "776 ['continent', 'continent']\n",
      "777 ['continent', 'continent']\n",
      "784 ['code', 'continent', 'code', 'isofficial', 'language']\n",
      "785 ['code', 'continent', 'code', 'isofficial', 'language']\n",
      "786 ['code', 'code', 'isofficial', 'language', 'continent']\n",
      "787 ['code', 'code', 'isofficial', 'language', 'continent']\n",
      "794 ['district', 'district']\n",
      "795 ['district', 'district']\n",
      "796 ['governmentform', 'governmentform', 'lifeexpectancy']\n",
      "797 ['governmentform', 'governmentform', 'lifeexpectancy']\n",
      "798 ['lifeexpectancy', 'continent', 'continent', 'lifeexpectancy']\n",
      "799 ['lifeexpectancy', 'continent', 'continent', 'lifeexpectancy']\n",
      "800 ['surfacearea', 'surfacearea']\n",
      "801 ['surfacearea', 'surfacearea']\n",
      "810 ['surfacearea', 'continent', 'surfacearea']\n",
      "811 ['surfacearea', 'continent', 'surfacearea']\n",
      "814 ['language', 'language']\n",
      "815 ['language', 'language']\n",
      "832 ['share', 'share', 'type']\n",
      "833 ['share', 'share', 'type']\n",
      "848 ['record_company', 'record_company']\n",
      "849 ['record_company', 'record_company']\n",
      "850 ['major_record_format', 'major_record_format']\n",
      "851 ['major_record_format', 'major_record_format']\n",
      "852 ['record_company', 'record_company']\n",
      "853 ['record_company', 'record_company']\n",
      "856 ['record_company', 'year_of_founded', 'record_company', 'year_of_founded']\n",
      "857 ['record_company', 'year_of_founded', 'record_company', 'year_of_founded']\n",
      "858 ['major_record_format', 'major_record_format']\n",
      "859 ['major_record_format', 'major_record_format']\n",
      "874 ['grade', 'grade']\n",
      "875 ['grade', 'grade']\n",
      "876 ['grade', 'grade']\n",
      "877 ['grade', 'grade']\n",
      "878 ['grade', 'grade']\n",
      "879 ['grade', 'grade']\n",
      "880 ['grade', 'grade']\n",
      "881 ['grade', 'grade']\n",
      "890 ['name', 'id', 'friend_id', 'id', 'name']\n",
      "891 ['name', 'id', 'friend_id', 'id', 'name']\n",
      "896 ['name', 'name', 'id']\n",
      "897 ['name', 'name', 'id']\n",
      "900 ['name', 'id', 'name', 'liked_id', 'id']\n",
      "901 ['name', 'id', 'name', 'liked_id', 'id']\n",
      "914 ['grade', 'id', 'id']\n",
      "915 ['grade', 'id', 'id']\n",
      "916 ['grade', 'id', 'id']\n",
      "917 ['grade', 'id', 'id']\n",
      "928 ['role_code', 'role_code']\n",
      "929 ['role_code', 'role_code']\n",
      "934 ['breed_name', 'breed_name']\n",
      "935 ['breed_name', 'breed_name']\n",
      "944 ['cost_of_treatment', 'cost_of_treatment']\n",
      "945 ['cost_of_treatment', 'cost_of_treatment']\n",
      "960 ['age', 'age']\n",
      "961 ['age', 'age']\n",
      "974 ['age', 'age']\n",
      "975 ['age', 'age']\n",
      "1008 ['name', 'birth_year', 'birth_year']\n",
      "1009 ['name', 'birth_year', 'birth_year']\n",
      "1012 ['citizenship', 'citizenship']\n",
      "1013 ['citizenship', 'citizenship']\n",
      "1014 ['citizenship', 'citizenship']\n",
      "1015 ['citizenship', 'citizenship']\n",
      "1016 ['citizenship', 'net_worth_millions', 'citizenship']\n",
      "1017 ['citizenship', 'net_worth_millions', 'citizenship']\n",
      "1022 ['name', 'name']\n",
      "1023 ['name', 'name']\n",
      "1024 ['name', 'sales', 'name']\n",
      "1025 ['name', 'sales', 'name']\n",
      "1028 ['citizenship', 'birth_year', 'citizenship', 'birth_year']\n",
      "1029 ['citizenship', 'birth_year', 'citizenship', 'birth_year']\n",
      "1033 ['property_name', 'property_name', 'room_count']\n"
     ]
    }
   ],
   "source": [
    "for i, ex in enumerate(all_dev_samples):\n",
    "    occ_cols = ex['trace_results']['occ_cols']\n",
    "    if len(set(occ_cols)) != len(occ_cols):\n",
    "        print(i, occ_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁school', '_', 'name']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.tokenize('school_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁', 'cylinder']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.tokenize('cylinder ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁', 'cylinder', '▁', 'x', 'a']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.tokenize('cylinder xa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁', 'struct', 'e', 'd', '_', 'in', 'put', '▁', ':', '▁', 'a', '▁|', '▁', 'b']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.tokenize('structed_input : a | b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " 'SEL',\n",
       " 'ECT',\n",
       " '▁',\n",
       " 't',\n",
       " '2.',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " '▁',\n",
       " ',',\n",
       " '▁CO',\n",
       " 'UNT',\n",
       " '(',\n",
       " 'distin',\n",
       " 'c',\n",
       " 't',\n",
       " '▁',\n",
       " 't',\n",
       " '1.',\n",
       " 'name',\n",
       " ')',\n",
       " '▁FROM',\n",
       " '▁cars',\n",
       " '_',\n",
       " 'data',\n",
       " '▁as',\n",
       " '▁',\n",
       " 't',\n",
       " '1',\n",
       " '▁',\n",
       " 'JO',\n",
       " 'IN',\n",
       " '▁models',\n",
       " '▁as',\n",
       " '▁',\n",
       " 't',\n",
       " '2',\n",
       " '▁on',\n",
       " '▁cars',\n",
       " '_',\n",
       " 'data',\n",
       " '.',\n",
       " 'a',\n",
       " '_',\n",
       " 'a',\n",
       " '▁=',\n",
       " '▁models',\n",
       " '.',\n",
       " 'b',\n",
       " '_',\n",
       " 'a']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sql = 'SELECT t2.aaa , COUNT(distinct t1.name) FROM cars_data as t1 JOIN models as t2 on cars_data.a_a = models.b_a'\n",
    "\n",
    "mt_uskg.tokenizer.tokenize(_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q1_layers': range(0, 6),\n",
       " 'q2_layers': range(6, 12),\n",
       " 'q3_layers': range(12, 18),\n",
       " 'q4_layers': range(18, 24),\n",
       " 'low_layers': range(0, 12),\n",
       " 'mid_layers': range(6, 18),\n",
       " 'high_layers': range(12, 24),\n",
       " 'all_layers': range(0, 24)}"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_layers = mt_uskg.num_dec_layers\n",
    "\n",
    "layers_range_dict = {\n",
    "    'q1_layers': range(0, N_layers // 4),\n",
    "    'q2_layers': range(N_layers // 4, N_layers // 2),\n",
    "    'q3_layers': range(N_layers // 2, N_layers * 3 // 4),\n",
    "    'q4_layers': range(N_layers * 3 // 4, N_layers),\n",
    "    'low_layers': range(0, N_layers // 2),\n",
    "    'mid_layers': range(N_layers // 4, N_layers * 3 // 4),\n",
    "    'high_layers': range(N_layers // 2, N_layers),\n",
    "    'all_layers': range(N_layers),\n",
    "}\n",
    "\n",
    "layers_range_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.reverse_2D_dict.<locals>.<lambda>()>,\n",
       "            {'1': defaultdict(float, {'a': 1.0, 'b': 2.0}),\n",
       "             '2': defaultdict(float, {'a': 2.0, 'b': 1.0})})"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    'a': {\n",
    "        '1': 1.0,\n",
    "        '2': 2.0,\n",
    "    },\n",
    "    'b': {\n",
    "        '1': 2.0,\n",
    "        '2': 1.0,\n",
    "    },\n",
    "}\n",
    "reverse_2D_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'a': 1} + {'b': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁(', 'distin', 'c', 't', ')']"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.tokenize('(distinct)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "706px",
    "left": "28px",
    "top": "156px",
    "width": "259px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

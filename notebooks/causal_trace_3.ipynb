{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/causal_trace.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Tracing\n",
    "\n",
    "A demonstration of the double-intervention causal tracing method.\n",
    "\n",
    "The strategy used by causal tracing is to understand important\n",
    "states within a transfomer by doing two interventions simultaneously:\n",
    "\n",
    "1. Corrupt a subset of the input.  In our paper, we corrupt the subject tokens\n",
    "   to frustrate the ability of the transformer to accurately complete factual\n",
    "   prompts about the subject.\n",
    "2. Restore a subset of the internal hidden states.  In our paper, we scan\n",
    "   hidden states at all layers and all tokens, searching for individual states\n",
    "   that carry the necessary information for the transformer to recover its\n",
    "   capability to complete the factual prompt.\n",
    "\n",
    "The traces of decisive states can be shown on a heatmap.  This notebook\n",
    "demonstrates the code for conducting causal traces and creating these heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `experiments.causal_trace` module contains a set of functions for running causal traces.\n",
    "\n",
    "In this notebook, we reproduce, demonstrate and discuss the interesting functions.\n",
    "\n",
    "We begin by importing several utility functions that deal with tokens and transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import defaultdict, Counter\n",
    "from util import nethook\n",
    "from util.globals import DATA_DIR\n",
    "from experiments.causal_trace import (\n",
    "    ModelAndTokenizer,\n",
    "    layername,\n",
    "    guess_subject,\n",
    "    plot_trace_heatmap,\n",
    ")\n",
    "from experiments.causal_trace import (\n",
    "    make_inputs,\n",
    "    decode_tokens,\n",
    "    find_token_range,\n",
    "    predict_token,\n",
    "    predict_from_input,\n",
    "    collect_embedding_std,\n",
    ")\n",
    "from dsets import KnownsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f83484ca640>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "# from uskg.models.unified.prefixtuning import Model\n",
    "from uskg.models.unified import finetune, prefixtuning\n",
    "from uskg.utils.configue import Configure\n",
    "from uskg.utils.training_arguments import WrappedSeq2SeqTrainingArguments\n",
    "from uskg.seq2seq_construction import spider as s2s_spider\n",
    "from uskg.third_party.spider.preprocess.get_tables import dump_db_json_schema\n",
    "from uskg.third_party.spider import evaluation as sp_eval\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# import stanza\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "\n",
    "from experiments import causal_trace_uskg as ctu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tokenizer_uskg: hkunlp/from_all_T5_large_prefix_spider_with_cell_value2\n",
      "Using tokenizer_fast: t5-large\n",
      "prefix-tuning sequence length is 10.\n"
     ]
    }
   ],
   "source": [
    "mt_uskg = ctu.ModelAndTokenizer_USKG('t5-large-prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('constructor', 'seq2seq_construction.spider'),\n",
       " ('schema_serialization_with_db_content', True),\n",
       " ('target_with_db_id', False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mt_uskg.task_args.seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.model.pretrain_model.encoder.embed_tokens is mt_uskg.model.pretrain_model.shared, \\\n",
    "mt_uskg.model.pretrain_model.decoder.embed_tokens is mt_uskg.model.pretrain_model.shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.model.preseqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [k for k,v in mt_uskg.model.named_parameters()]\n",
    "[k for k,v in mt_uskg.model.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    enc_sentences=[\"Translate to German: My name is Wolfgang and I live in Berlin\"],\n",
    "    dec_prompts=[\"Mein Name ist Wolfgang\"],\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ctu.run_model_forward_uskg(mt_uskg.model, **inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(odict_keys(['logits', 'past_key_values', 'encoder_last_hidden_state']),\n",
       " torch.Size([1, 5, 32102]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys(), out['logits'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32102,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = out[\"logits\"][0, -1].detach().cpu().numpy()\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, -1.8642352),\n",
       " (6, -9.727753),\n",
       " (5, -10.966707),\n",
       " (27, -11.037394),\n",
       " (213, -12.864212)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5 = sorted(list(enumerate(logits)), key=lambda p: -p[1])[:5]\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', ',', '.', 'I', 'where']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mt_uskg.tokenizer.decode([p[0]]) for p in top_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spider dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_train_path = '/home/yshao/Projects/SDR-analysis/data/spider/train+ratsql_graph.json'\n",
    "spider_dev_path = '/home/yshao/Projects/SDR-analysis/data/spider/dev+ratsql_graph.json'\n",
    "spider_db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev = ctu.load_raw_dataset(\n",
    "    data_filepath = spider_dev_path,\n",
    "    db_path=spider_db_dir,\n",
    "#     schema_cache=SCHEMA_CACHE\n",
    ")\n",
    "len(raw_spider_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.task_args.dataset.use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_spider_dev = s2s_spider.DevDataset(\n",
    "    args=mt_uskg.task_args,\n",
    "    raw_datasets=raw_spider_dev,\n",
    "    cache_root='../cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What are the names of all European countries with at least 3 manufacturers?',\n",
       " '| car_1 | continents : contid , continent ( europe ) | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.countryname from countries as t1 join continents as t2 on t1.continent = t2.contid join car_makers as t3 on t1.countryid = t3.country where t2.continent = 'europe' group by t1.countryname having count(*) >= 3;\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 130\n",
    "processed_spider_dev[_id]['text_in'], \\\n",
    "processed_spider_dev[_id]['struct_in'], \\\n",
    "processed_spider_dev[_id]['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_enc_sentence = f\"{processed_spider_dev[_id]['text_in']}; structed knowledge: {processed_spider_dev[_id]['struct_in']}\"\n",
    "_toks = mt_uskg.tokenizer.tokenize(_enc_sentence)\n",
    "len(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # _occ_punct = set()\n",
    "\n",
    "# for _id in range(len(processed_spider_dev)):\n",
    "#     ex = processed_spider_dev[_id]\n",
    "# #     _occ_punct.update(set(string.punctuation) & set(ex['seq_out']))\n",
    "#     if '_(' in ex['struct_in']:\n",
    "#         print(_id, ex['question'])\n",
    "#         print(ex['struct_in'])\n",
    "#         print(ex['seq_out'])\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Train set\n",
    "\n",
    "# raw_spider_train = ctu.load_raw_dataset(\n",
    "#     data_filepath = spider_train_path,\n",
    "#     db_path=spider_db_dir,\n",
    "# )\n",
    "# processed_spider_train = s2s_spider.TrainDataset(\n",
    "#     args=mt_uskg.task_args,\n",
    "#     raw_datasets=raw_spider_train,\n",
    "#     cache_root='../cache')\n",
    "# len(processed_spider_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_spider_train[5441]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "- Aspects-related helpers are merged into create_analysis_sample_dicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp6_ob_by_exp_tok(samples):\n",
    "    # samples: usually `good_samples`\n",
    "    \n",
    "    # Key: (expect_tok, sect_k, layer) -> [scores]\n",
    "    trace_scores_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    trace_scores_avg_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "    trace_scores_cnt_by_exp_tok = defaultdict(int)  # no sect key & layer key \n",
    "\n",
    "    trace_sample_ids_by_exp_tok = defaultdict(list)\n",
    "    \n",
    "    for i, d in enumerate(samples):\n",
    "        expect = d['expect']\n",
    "        trace_sample_ids_by_exp_tok[expect].append(i)\n",
    "        for sect_k, sect_d in d['trace_scores'].items():\n",
    "            for layer_k, v in sect_d.items():\n",
    "                trace_scores_by_exp_tok[expect][sect_k][layer_k].append(v)\n",
    "\n",
    "    for exp_tok, d1 in trace_scores_by_exp_tok.items():\n",
    "        if exp_tok.isnumeric(): continue\n",
    "        for sect_k, d2 in d1.items():\n",
    "            for layer_k, scores in d2.items():\n",
    "                if len(scores) <= 2: continue\n",
    "                trace_scores_avg_by_exp_tok[exp_tok][sect_k][layer_k] = np.mean(scores)\n",
    "                trace_scores_cnt_by_exp_tok[exp_tok] = len(scores)\n",
    "    \n",
    "    return {\n",
    "        'avg': trace_scores_avg_by_exp_tok,\n",
    "        'cnt': trace_scores_cnt_by_exp_tok,\n",
    "        'sample_ids': trace_sample_ids_by_exp_tok,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_2D_dict(d):\n",
    "    out_d = defaultdict(lambda: defaultdict(np.nan))\n",
    "    for k1, d1 in d.items():\n",
    "        for k2, v in d1.items():\n",
    "            out_d[k2][k1] = v\n",
    "    return out_d\n",
    "\n",
    "def format_print_1D_dict(d, sort_by=None, reverse=False, head_col_w=10, col_w=6):\n",
    "    # sort: None, 'key' or 'value'\n",
    "    \n",
    "    item_l = list(d.items())\n",
    "    if sort_by == 'key':\n",
    "        item_l.sort(reverse=reverse)\n",
    "    elif sort_by == 'value':\n",
    "        item_l.sort(key=lambda x: (x[1], x[0]), reverse=reverse)\n",
    "    \n",
    "    decm_w = col_w - 2\n",
    "    \n",
    "    for k, v in item_l:\n",
    "        print(f'{k:<{head_col_w}s}{v:.{decm_w}f}')\n",
    "\n",
    "def format_print_2D_dict(d, \n",
    "                         all_k1=None, \n",
    "                         all_k2=None, \n",
    "                         sort_k1_kwargs=None, \n",
    "                         sort_k2_kwargs=None, \n",
    "                         head_col_w=12, \n",
    "                         col_w=6,\n",
    "                         decm_w=4):\n",
    "    if all_k1 is None:\n",
    "        all_k1 = list(d.keys())\n",
    "        if sort_k1_kwargs is not None:\n",
    "            all_k1.sort(**sort_k1_kwargs)\n",
    "    \n",
    "    if all_k2 is None:\n",
    "        for k1, d1 in d.items():\n",
    "            d1_keys = list(d1.keys())\n",
    "            if all_k2 is None:\n",
    "                all_k2 = d1_keys\n",
    "            else:\n",
    "                if set(d1_keys) != set(all_k2):\n",
    "                    print('Warning:\\n', d1_keys, '\\n', all_k2)\n",
    "            # all_k2.update(list(d1.keys()))\n",
    "        if sort_k2_kwargs is not None:\n",
    "            all_k2.sort(**sort_k2_kwargs)\n",
    "    \n",
    "    print_str = '\\t'.join(['X' * head_col_w] + [f'{k2:<{col_w}s}' for k2 in all_k2]) + '\\n'\n",
    "    \n",
    "    for k1 in all_k1:\n",
    "        d1 = d[k1]\n",
    "        print_str += f'{k1:<{head_col_w}s}'\n",
    "        for k2 in all_k2:\n",
    "            v = d1[k2]\n",
    "            print_str += f'\\t{v:<{col_w}.{decm_w}f}'\n",
    "        print_str += '\\n'\n",
    "    \n",
    "    print(print_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = '/home/yshao/Projects/language/language/xsp/data/spider/tables.json'\n",
    "db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmaps = sp_eval.build_foreign_key_map_from_json(table_path)\n",
    "evaluator = sp_eval.Evaluator(db_dir=db_dir, kmaps=kmaps, etype='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctu.evaluate_hardness.evaluator = evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0, 0, 'hard')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "_sql_str = 'select t1.birth_date from people as t1 join poker_player as t2 on t1.people_id = t2.people_id order by t2.earnings asc limit 1'\n",
    "db_name = 'poker_player'\n",
    "schema = evaluator.schemas[db_name]\n",
    "_sql = sp_eval.get_sql(schema, _sql_str)\n",
    "sp_eval.count_component1(_sql), sp_eval.count_component2(_sql), sp_eval.count_others(_sql), \\\n",
    "evaluator.eval_hardness(_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hard'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.evaluate_hardness(_sql_str, db_name, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<uskg.third_party.spider.evaluation.Evaluator at 0x7f81c83e1f40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.evaluate_hardness.evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_prompt = 'select avg(age), min(age), max(age) from'\n",
    "ctu.detect_node_role(dec_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dicts = ctu.create_analysis_sample_dicts(\n",
    "    mt=mt_uskg,\n",
    "    ex=processed_spider_dev[100],\n",
    "    subject_type='table'\n",
    ")\n",
    "len(a_dicts), [d['expect'] for d in a_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = a_dicts[2]\n",
    "ctu.check_table_text_match(a_ex, 'car_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex['text_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-2.3: section corruption effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp2.3_section_corruption_effect/exp=2.3.1_dev_{expect_type}-replace=True-noise=0.0.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2039, (1438, 1438), 339, 262, 601, 'good / correct = 1438 / 1700')"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d.get('is_good_sample', True):\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += v\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': defaultdict(int,\n",
       "             {'embed': 0.7823026149835357, 'final_enc': 0.8686982057318997}),\n",
       " 'struct': defaultdict(int,\n",
       "             {'embed': 0.8156400979291917, 'final_enc': 0.8783989991454734}),\n",
       " 'self': defaultdict(int,\n",
       "             {'embed': 0.9009977694993451, 'final_enc': 0.9186035738517472}),\n",
       " 'struct_context': defaultdict(int,\n",
       "             {'embed': 0.8188476237862654, 'final_enc': 0.9366639298185229}),\n",
       " 'other': defaultdict(int,\n",
       "             {'embed': 0.9668801645956868, 'final_enc': 0.9874240734377392}),\n",
       " 'text+other': defaultdict(int,\n",
       "             {'embed': 0.7898215747748188, 'final_enc': 0.8762273743275982}),\n",
       " 'all': defaultdict(int,\n",
       "             {'embed': 0.05134222172979076, 'final_enc': 0.7129756825101383})}"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\tembed \tfinal_enc\n",
      "text        \t0.7823\t0.8687\n",
      "struct      \t0.8156\t0.8784\n",
      "self        \t0.9010\t0.9186\n",
      "struct_context\t0.8188\t0.9367\n",
      "other       \t0.9669\t0.9874\n",
      "text+other  \t0.7898\t0.8762\n",
      "all         \t0.0513\t0.7130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(trace_scores_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-4.1: attention weights distribution for all nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_path = f'/home/yshao/Projects/rome/results/exp4_1_attention_weights_distribution/exp=4.1_dev.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'db_id', 'col_self_ranges', 'col_context_ranges', 'tab_self_ranges', 'tab_context_ranges', 'category', 'occ_cols', 'non_occ_cols', 'occ_tabs', 'non_occ_tabs', 'attentions'])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples[0]['trace_results'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_sentence : What are  the different countries with singers above age 20?; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id\n",
      "seq_out : select distinct country from singer where age > 20\n",
      "dec_prompt : select\n",
      "db_id : concert_singer\n",
      "col_self_ranges : {'country': [[61, 66]], 'age': [[76, 81]], 'location': [[32, 37]], 'capacity': [[38, 43]], 'highest': [[41, 46]], 'lowest': [[44, 49]], 'average': [[47, 51]], 'song_name': [[64, 71]], 'song_release_year': [[69, 78]], 'is_male': [[79, 85]], 'concert_name': [[92, 99]], 'theme': [[97, 102]], 'year': [[106, 110]]}\n",
      "col_context_ranges : {'country': [[19, 61], [66, 129]], 'age': [[19, 76], [81, 129]], 'location': [[19, 32], [37, 129]], 'capacity': [[19, 38], [43, 129]], 'highest': [[19, 41], [46, 129]], 'lowest': [[19, 44], [49, 129]], 'average': [[19, 47], [51, 129]], 'song_name': [[19, 64], [71, 129]], 'song_release_year': [[19, 69], [78, 129]], 'is_male': [[19, 79], [85, 129]], 'concert_name': [[19, 92], [99, 129]], 'theme': [[19, 97], [102, 129]], 'year': [[19, 106], [110, 129]]}\n",
      "tab_self_ranges : {'singer': [[50, 54]], 'stadium': [[24, 28]], 'concert': [[84, 88]], 'singer_in_concert': [[109, 119]]}\n",
      "tab_context_ranges : {'singer': [[19, 50], [54, 129]], 'stadium': [[19, 24], [28, 129]], 'concert': [[19, 84], [88, 129]], 'singer_in_concert': [[19, 109], [119, 129]]}\n",
      "category : {'sql_hardness': 'easy'}\n",
      "occ_cols : ['country', 'age']\n",
      "non_occ_cols : ['location', 'capacity', 'highest', 'lowest', 'average', 'song_name', 'song_release_year', 'is_male', 'concert_name', 'theme', 'year']\n",
      "occ_tabs : ['singer']\n",
      "non_occ_tabs : ['stadium', 'concert', 'singer_in_concert']\n"
     ]
    }
   ],
   "source": [
    "for k, v in all_samples[9]['trace_results'].items():\n",
    "    if k != 'attentions':\n",
    "        print(k, ':', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _toks = mt_uskg.tokenizer.tokenize(all_samples[100]['trace_results']['enc_sentence'], add_special_tokens=True)\n",
    "# len(_toks), _toks[136:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51317d3c5c92478280f035392d511cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dict: {layer -> {head_id -> {occ_type -> {section -> List[att_w]}}}}; list for all samples, all nodes in each occ_type \n",
    "att_weights_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "\n",
    "# Dict: {layer -> {head_id -> {occ_type -> {section -> avg_att_w}}}}; averaged by all samples, all nodes in each occ_type \n",
    "att_weights_avg_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "\n",
    "\n",
    "for ex_id, ex in enumerate(tqdm(all_samples[::111])):\n",
    "    result_d = ex['trace_results']\n",
    "\n",
    "    all_col_atts = result_d['attentions']['col']\n",
    "    all_tab_atts = result_d['attentions']['tab']\n",
    "    \n",
    "    for col_occ_type in ['occ_cols', 'non_occ_cols']:\n",
    "        for col in result_d[col_occ_type]:\n",
    "            sect_att_dict = all_col_atts[col]\n",
    "            for sect_k, att_mat in sect_att_dict.items():\n",
    "                att_mat = np.array(ctu.nested_list_processing(att_mat, func=float))\n",
    "                n_layers, n_heads = att_mat.shape\n",
    "                for l in range(n_layers):\n",
    "                    for h in range(n_heads):\n",
    "                        att_w = att_mat[l, h]\n",
    "                        att_weights_dict[l][h][col_occ_type][sect_k].append(att_w)\n",
    "    \n",
    "    for tab_occ_type in ['occ_tabs', 'non_occ_tabs']:\n",
    "        for tab in result_d[tab_occ_type]:\n",
    "            sect_att_dict = all_tab_atts[tab]\n",
    "            for sect_k, att_mat in sect_att_dict.items():\n",
    "                att_mat = np.array(ctu.nested_list_processing(att_mat, func=float))\n",
    "                n_layers, n_heads = att_mat.shape\n",
    "                for l in range(n_layers):\n",
    "                    for h in range(n_heads):\n",
    "                        att_w = att_mat[l, h]\n",
    "                        att_weights_dict[l][h][tab_occ_type][sect_k].append(att_w)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_id, layer_d in att_weights_dict.items():\n",
    "    for h_id, head_d in layer_d.items():\n",
    "        for occ_type, occ_type_d in head_d.items():\n",
    "            for sect_k, att_w_list in occ_type_d.items():\n",
    "                att_weights_avg_dict[l_id][h_id][occ_type][sect_k] = np.mean(att_w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'non_occ_cols': defaultdict(float,\n",
       "                         {'prefix#0': 0.004805194805194805,\n",
       "                          'prefix#1': 0.02025974025974026,\n",
       "                          'prefix#2': 0.006038961038961039,\n",
       "                          'prefix#3': 0.0003246753246753247,\n",
       "                          'prefix#4': 0.059350649350649355,\n",
       "                          'prefix#5': 0.03233766233766234,\n",
       "                          'prefix#6': 0.02006493506493506,\n",
       "                          'prefix#7': 0.0011688311688311688,\n",
       "                          'prefix#8': 6.493506493506494e-05,\n",
       "                          'prefix#9': 0.013181818181818183,\n",
       "                          'text': 0.01603896103896104,\n",
       "                          'self': 0.287012987012987,\n",
       "                          'context': 0.5193506493506492,\n",
       "                          'eos': 0.00538961038961039}),\n",
       "             'occ_tabs': defaultdict(float,\n",
       "                         {'prefix#0': 0.0011764705882352942,\n",
       "                          'prefix#1': 0.004117647058823529,\n",
       "                          'prefix#2': 0.06058823529411765,\n",
       "                          'prefix#3': 0.0,\n",
       "                          'prefix#4': 0.004705882352941177,\n",
       "                          'prefix#5': 0.003529411764705882,\n",
       "                          'prefix#6': 0.03,\n",
       "                          'prefix#7': 0.001764705882352941,\n",
       "                          'prefix#8': 0.0,\n",
       "                          'prefix#9': 0.0011764705882352942,\n",
       "                          'text': 0.02882352941176471,\n",
       "                          'self': 0.21411764705882352,\n",
       "                          'context': 0.628235294117647,\n",
       "                          'eos': 0.0}),\n",
       "             'non_occ_tabs': defaultdict(float,\n",
       "                         {'prefix#0': 0.0009375,\n",
       "                          'prefix#1': 0.0015625,\n",
       "                          'prefix#2': 0.0040625,\n",
       "                          'prefix#3': 0.00125,\n",
       "                          'prefix#4': 0.031875,\n",
       "                          'prefix#5': 0.009687500000000002,\n",
       "                          'prefix#6': 0.035625000000000004,\n",
       "                          'prefix#7': 0.0009375,\n",
       "                          'prefix#8': 0.0,\n",
       "                          'prefix#9': 0.0024999999999999996,\n",
       "                          'text': 0.0259375,\n",
       "                          'self': 0.22812500000000002,\n",
       "                          'context': 0.6343749999999999,\n",
       "                          'eos': 0.0}),\n",
       "             'occ_cols': defaultdict(float,\n",
       "                         {'prefix#0': 0.003157894736842105,\n",
       "                          'prefix#1': 0.05368421052631579,\n",
       "                          'prefix#2': 0.00368421052631579,\n",
       "                          'prefix#3': 0.0005263157894736842,\n",
       "                          'prefix#4': 0.05578947368421053,\n",
       "                          'prefix#5': 0.02736842105263158,\n",
       "                          'prefix#6': 0.004210526315789474,\n",
       "                          'prefix#7': 0.006842105263157895,\n",
       "                          'prefix#8': 0.0,\n",
       "                          'prefix#9': 0.00368421052631579,\n",
       "                          'text': 0.021052631578947368,\n",
       "                          'self': 0.31473684210526315,\n",
       "                          'context': 0.4847368421052632,\n",
       "                          'eos': 0.003157894736842105})})"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weights_avg_dict[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Layer 1 =====\n",
      "occ_cols\n",
      "prefix#0  0.00  0.02  0.02  0.00  0.00  0.12  0.01  0.00  0.01  0.01\n",
      "prefix#1  0.00  0.01  0.00  0.00  0.04  0.01  0.02  0.00  0.00  0.00\n",
      "prefix#2  0.00  0.00  0.00  0.01  0.13  0.07  0.01  0.00  0.00  0.01\n",
      "prefix#3  0.03  0.00  0.00  0.00  0.01  0.05  0.02  0.00  0.01  0.00\n",
      "prefix#4  0.01  0.00  0.02  0.00  0.00  0.01  0.04  0.00  0.03  0.00\n",
      "prefix#5  0.01  0.02  0.00  0.00  0.03  0.01  0.02  0.00  0.01  0.00\n",
      "prefix#6  0.00  0.01  0.00  0.00  0.01  0.02  0.01  0.03  0.09  0.00\n",
      "prefix#7  0.01  0.00  0.00  0.00  0.01  0.05  0.00  0.00  0.05  0.00\n",
      "prefix#8  0.09  0.13  0.05  0.00  0.00  0.03  0.00  0.00  0.00  0.00\n",
      "prefix#9  0.00  0.03  0.00  0.00  0.00  0.00  0.00  0.00  0.01  0.00\n",
      "text      0.04  0.03  0.00  0.01  0.02  0.05  0.11  0.00  0.16  0.00\n",
      "self      0.41  0.45  0.80  0.26  0.22  0.11  0.02  0.27  0.00  0.68\n",
      "context   0.37  0.27  0.09  0.68  0.51  0.41  0.55  0.02  0.41  0.28\n",
      "eos       0.01  0.01  0.01  0.00  0.01  0.03  0.06  0.68  0.16  0.00\n",
      "\n",
      "non_occ_cols\n",
      "prefix#0  0.00  0.03  0.03  0.01  0.00  0.10  0.02  0.00  0.01  0.01\n",
      "prefix#1  0.00  0.01  0.00  0.00  0.01  0.02  0.03  0.00  0.00  0.00\n",
      "prefix#2  0.00  0.01  0.00  0.06  0.08  0.07  0.01  0.00  0.02  0.01\n",
      "prefix#3  0.00  0.00  0.00  0.00  0.04  0.02  0.03  0.00  0.03  0.01\n",
      "prefix#4  0.02  0.01  0.01  0.00  0.04  0.02  0.02  0.00  0.01  0.00\n",
      "prefix#5  0.01  0.11  0.00  0.01  0.04  0.02  0.03  0.00  0.00  0.05\n",
      "prefix#6  0.00  0.01  0.00  0.00  0.00  0.05  0.00  0.00  0.03  0.00\n",
      "prefix#7  0.00  0.00  0.00  0.00  0.04  0.02  0.01  0.00  0.08  0.00\n",
      "prefix#8  0.08  0.04  0.02  0.00  0.00  0.04  0.00  0.00  0.00  0.00\n",
      "prefix#9  0.02  0.01  0.00  0.00  0.00  0.00  0.02  0.00  0.01  0.00\n",
      "text      0.01  0.03  0.00  0.01  0.01  0.05  0.08  0.00  0.08  0.00\n",
      "self      0.30  0.40  0.80  0.23  0.17  0.07  0.02  0.20  0.00  0.65\n",
      "context   0.54  0.33  0.10  0.66  0.53  0.47  0.56  0.04  0.52  0.25\n",
      "eos       0.00  0.01  0.03  0.00  0.00  0.03  0.04  0.75  0.15  0.00\n",
      "\n",
      "===== Layer 6 =====\n",
      "occ_cols\n",
      "prefix#0  0.15  0.01  0.02  0.00  0.01  0.00  0.00  0.06  0.02  0.00\n",
      "prefix#1  0.01  0.00  0.04  0.00  0.00  0.00  0.00  0.09  0.01  0.00\n",
      "prefix#2  0.00  0.01  0.00  0.00  0.05  0.00  0.01  0.09  0.12  0.00\n",
      "prefix#3  0.04  0.00  0.05  0.00  0.00  0.00  0.00  0.19  0.00  0.00\n",
      "prefix#4  0.01  0.01  0.02  0.00  0.00  0.00  0.01  0.02  0.00  0.00\n",
      "prefix#5  0.00  0.01  0.01  0.00  0.02  0.01  0.00  0.03  0.01  0.00\n",
      "prefix#6  0.00  0.02  0.00  0.00  0.00  0.00  0.00  0.01  0.11  0.00\n",
      "prefix#7  0.01  0.00  0.15  0.00  0.00  0.00  0.00  0.01  0.00  0.00\n",
      "prefix#8  0.00  0.00  0.01  0.00  0.00  0.03  0.00  0.01  0.00  0.00\n",
      "prefix#9  0.00  0.04  0.00  0.00  0.00  0.00  0.01  0.04  0.04  0.00\n",
      "text      0.03  0.04  0.00  0.01  0.03  0.05  0.12  0.01  0.16  0.00\n",
      "self      0.17  0.45  0.58  0.17  0.31  0.77  0.01  0.31  0.00  0.21\n",
      "context   0.32  0.32  0.09  0.79  0.54  0.12  0.49  0.10  0.44  0.09\n",
      "eos       0.20  0.02  0.03  0.00  0.02  0.00  0.31  0.01  0.03  0.68\n",
      "\n",
      "non_occ_cols\n",
      "prefix#0  0.10  0.01  0.02  0.00  0.00  0.00  0.01  0.10  0.01  0.00\n",
      "prefix#1  0.02  0.01  0.04  0.00  0.00  0.00  0.01  0.06  0.04  0.00\n",
      "prefix#2  0.01  0.02  0.01  0.00  0.03  0.00  0.00  0.05  0.07  0.00\n",
      "prefix#3  0.02  0.00  0.04  0.00  0.00  0.00  0.00  0.22  0.00  0.00\n",
      "prefix#4  0.01  0.02  0.02  0.02  0.00  0.00  0.01  0.00  0.01  0.00\n",
      "prefix#5  0.00  0.01  0.01  0.00  0.09  0.00  0.00  0.02  0.01  0.00\n",
      "prefix#6  0.00  0.06  0.01  0.00  0.02  0.00  0.00  0.03  0.06  0.00\n",
      "prefix#7  0.00  0.00  0.20  0.00  0.00  0.00  0.01  0.03  0.00  0.00\n",
      "prefix#8  0.00  0.01  0.00  0.00  0.01  0.08  0.00  0.02  0.00  0.04\n",
      "prefix#9  0.00  0.08  0.00  0.00  0.00  0.00  0.03  0.09  0.02  0.00\n",
      "text      0.03  0.02  0.00  0.01  0.02  0.02  0.06  0.01  0.08  0.00\n",
      "self      0.14  0.47  0.49  0.21  0.28  0.58  0.01  0.23  0.00  0.13\n",
      "context   0.31  0.24  0.13  0.73  0.53  0.28  0.57  0.11  0.62  0.06\n",
      "eos       0.27  0.01  0.02  0.00  0.00  0.01  0.25  0.01  0.03  0.76\n",
      "\n",
      "===== Layer 12 =====\n",
      "occ_cols\n",
      "prefix#0  0.00  0.04  0.03  0.00  0.00  0.00  0.00  0.08  0.00  0.00\n",
      "prefix#1  0.00  0.00  0.00  0.01  0.00  0.00  0.03  0.20  0.00  0.00\n",
      "prefix#2  0.07  0.00  0.02  0.02  0.00  0.00  0.13  0.19  0.00  0.07\n",
      "prefix#3  0.04  0.00  0.01  0.00  0.00  0.00  0.06  0.00  0.00  0.07\n",
      "prefix#4  0.06  0.06  0.00  0.00  0.00  0.00  0.02  0.00  0.00  0.01\n",
      "prefix#5  0.08  0.04  0.00  0.00  0.00  0.00  0.08  0.02  0.00  0.00\n",
      "prefix#6  0.00  0.02  0.07  0.01  0.00  0.00  0.00  0.03  0.00  0.00\n",
      "prefix#7  0.01  0.00  0.00  0.00  0.00  0.00  0.01  0.02  0.00  0.25\n",
      "prefix#8  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n",
      "prefix#9  0.14  0.03  0.00  0.01  0.00  0.00  0.00  0.00  0.00  0.00\n",
      "text      0.03  0.02  0.00  0.00  0.02  0.04  0.11  0.03  0.30  0.00\n",
      "self      0.20  0.61  0.40  0.29  0.62  0.28  0.01  0.13  0.00  0.33\n",
      "context   0.21  0.13  0.05  0.65  0.34  0.38  0.30  0.08  0.43  0.08\n",
      "eos       0.11  0.01  0.39  0.00  0.02  0.26  0.22  0.20  0.21  0.17\n",
      "\n",
      "non_occ_cols\n",
      "prefix#0  0.00  0.06  0.07  0.00  0.00  0.00  0.00  0.10  0.00  0.00\n",
      "prefix#1  0.01  0.04  0.00  0.04  0.00  0.00  0.06  0.15  0.01  0.00\n",
      "prefix#2  0.10  0.03  0.01  0.02  0.00  0.00  0.05  0.23  0.01  0.15\n",
      "prefix#3  0.03  0.01  0.01  0.00  0.00  0.00  0.02  0.00  0.01  0.05\n",
      "prefix#4  0.04  0.08  0.02  0.00  0.00  0.00  0.12  0.00  0.00  0.01\n",
      "prefix#5  0.06  0.05  0.00  0.00  0.00  0.00  0.03  0.06  0.00  0.00\n",
      "prefix#6  0.01  0.05  0.10  0.00  0.00  0.00  0.00  0.02  0.00  0.01\n",
      "prefix#7  0.01  0.00  0.01  0.00  0.00  0.00  0.01  0.03  0.00  0.21\n",
      "prefix#8  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n",
      "prefix#9  0.14  0.00  0.00  0.02  0.00  0.00  0.01  0.00  0.00  0.00\n",
      "text      0.02  0.01  0.00  0.00  0.01  0.02  0.08  0.01  0.05  0.00\n",
      "self      0.19  0.47  0.38  0.33  0.45  0.27  0.01  0.08  0.00  0.23\n",
      "context   0.27  0.15  0.05  0.56  0.50  0.46  0.39  0.06  0.59  0.06\n",
      "eos       0.08  0.02  0.32  0.00  0.04  0.21  0.18  0.26  0.29  0.27\n",
      "\n",
      "===== Layer 18 =====\n",
      "occ_cols\n",
      "prefix#0  0.01  0.05  0.03  0.14  0.01  0.03  0.00  0.01  0.00  0.04\n",
      "prefix#1  0.00  0.00  0.04  0.01  0.00  0.00  0.00  0.00  0.01  0.01\n",
      "prefix#2  0.00  0.00  0.07  0.04  0.00  0.00  0.47  0.01  0.00  0.06\n",
      "prefix#3  0.00  0.00  0.13  0.00  0.00  0.08  0.05  0.00  0.00  0.02\n",
      "prefix#4  0.00  0.00  0.01  0.00  0.03  0.28  0.01  0.00  0.09  0.06\n",
      "prefix#5  0.00  0.16  0.13  0.09  0.08  0.01  0.00  0.12  0.01  0.02\n",
      "prefix#6  0.00  0.00  0.01  0.00  0.00  0.08  0.01  0.16  0.00  0.02\n",
      "prefix#7  0.05  0.00  0.00  0.00  0.00  0.05  0.09  0.00  0.00  0.05\n",
      "prefix#8  0.00  0.00  0.00  0.01  0.01  0.08  0.00  0.09  0.00  0.00\n",
      "prefix#9  0.00  0.00  0.04  0.00  0.02  0.00  0.00  0.00  0.00  0.00\n",
      "text      0.05  0.02  0.00  0.00  0.04  0.02  0.06  0.01  0.61  0.00\n",
      "self      0.14  0.60  0.08  0.05  0.17  0.14  0.03  0.34  0.00  0.29\n",
      "context   0.09  0.06  0.01  0.42  0.43  0.12  0.15  0.03  0.15  0.08\n",
      "eos       0.65  0.04  0.45  0.21  0.18  0.08  0.11  0.20  0.05  0.36\n",
      "\n",
      "non_occ_cols\n",
      "prefix#0  0.01  0.03  0.17  0.03  0.01  0.02  0.00  0.01  0.01  0.03\n",
      "prefix#1  0.00  0.01  0.02  0.01  0.00  0.02  0.02  0.00  0.00  0.01\n",
      "prefix#2  0.00  0.01  0.09  0.03  0.00  0.01  0.10  0.01  0.02  0.08\n",
      "prefix#3  0.00  0.00  0.07  0.00  0.00  0.01  0.03  0.00  0.00  0.00\n",
      "prefix#4  0.00  0.00  0.01  0.00  0.00  0.10  0.05  0.01  0.00  0.08\n",
      "prefix#5  0.00  0.05  0.04  0.05  0.05  0.02  0.01  0.06  0.02  0.03\n",
      "prefix#6  0.00  0.00  0.02  0.00  0.02  0.13  0.16  0.23  0.00  0.14\n",
      "prefix#7  0.02  0.01  0.00  0.01  0.00  0.11  0.06  0.00  0.00  0.01\n",
      "prefix#8  0.02  0.01  0.00  0.24  0.01  0.04  0.02  0.14  0.14  0.00\n",
      "prefix#9  0.00  0.00  0.04  0.00  0.00  0.01  0.00  0.00  0.01  0.00\n",
      "text      0.02  0.02  0.01  0.00  0.03  0.01  0.03  0.01  0.05  0.00\n",
      "self      0.14  0.52  0.12  0.04  0.23  0.13  0.02  0.29  0.00  0.21\n",
      "context   0.34  0.17  0.02  0.43  0.50  0.22  0.34  0.05  0.43  0.05\n",
      "eos       0.45  0.10  0.41  0.14  0.12  0.13  0.12  0.19  0.24  0.35\n",
      "\n",
      "===== Layer 23 =====\n",
      "occ_cols\n",
      "prefix#0  0.00  0.01  0.00  0.13  0.07  0.05  0.04  0.55  0.02  0.05\n",
      "prefix#1  0.01  0.01  0.16  0.00  0.02  0.00  0.07  0.00  0.00  0.00\n",
      "prefix#2  0.07  0.00  0.00  0.01  0.00  0.00  0.18  0.00  0.00  0.01\n",
      "prefix#3  0.00  0.00  0.10  0.09  0.00  0.00  0.00  0.00  0.00  0.01\n",
      "prefix#4  0.06  0.01  0.11  0.12  0.00  0.00  0.00  0.06  0.00  0.01\n",
      "prefix#5  0.00  0.25  0.01  0.02  0.00  0.00  0.04  0.00  0.00  0.00\n",
      "prefix#6  0.00  0.01  0.00  0.03  0.00  0.01  0.08  0.00  0.00  0.00\n",
      "prefix#7  0.02  0.01  0.01  0.00  0.00  0.00  0.00  0.01  0.00  0.00\n",
      "prefix#8  0.02  0.01  0.03  0.00  0.04  0.00  0.05  0.01  0.01  0.00\n",
      "prefix#9  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n",
      "text      0.00  0.05  0.00  0.00  0.02  0.04  0.05  0.00  0.57  0.00\n",
      "self      0.41  0.07  0.41  0.06  0.28  0.04  0.03  0.22  0.02  0.31\n",
      "context   0.30  0.34  0.08  0.21  0.32  0.76  0.33  0.13  0.26  0.25\n",
      "eos       0.06  0.17  0.08  0.30  0.20  0.05  0.10  0.00  0.07  0.36\n",
      "\n",
      "non_occ_cols\n",
      "prefix#0  0.00  0.01  0.00  0.06  0.03  0.15  0.08  0.06  0.01  0.03\n",
      "prefix#1  0.03  0.04  0.08  0.00  0.00  0.00  0.03  0.00  0.01  0.00\n",
      "prefix#2  0.02  0.19  0.00  0.00  0.00  0.01  0.00  0.00  0.01  0.04\n",
      "prefix#3  0.00  0.03  0.00  0.00  0.01  0.00  0.00  0.00  0.00  0.04\n",
      "prefix#4  0.01  0.01  0.16  0.02  0.00  0.00  0.00  0.04  0.00  0.00\n",
      "prefix#5  0.00  0.04  0.00  0.00  0.00  0.00  0.02  0.03  0.00  0.19\n",
      "prefix#6  0.00  0.19  0.03  0.00  0.00  0.07  0.21  0.00  0.00  0.01\n",
      "prefix#7  0.01  0.13  0.00  0.00  0.03  0.00  0.00  0.00  0.00  0.11\n",
      "prefix#8  0.06  0.01  0.15  0.00  0.01  0.01  0.02  0.02  0.23  0.00\n",
      "prefix#9  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n",
      "text      0.00  0.04  0.00  0.00  0.01  0.01  0.02  0.01  0.05  0.00\n",
      "self      0.39  0.03  0.37  0.21  0.25  0.11  0.03  0.56  0.02  0.28\n",
      "context   0.43  0.22  0.07  0.50  0.45  0.57  0.52  0.26  0.61  0.12\n",
      "eos       0.03  0.04  0.13  0.18  0.18  0.06  0.05  0.01  0.01  0.17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "occ_types = ['occ_cols', 'non_occ_cols']\n",
    "\n",
    "for l_id in [1, 6, 12, 18, 23]:\n",
    "    # Dict: occ_type -> sect -> List[att_w]; list for all heads \n",
    "    layer_ob_dict = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for h_id in range(10):\n",
    "        for occ in occ_types:\n",
    "            for sect_k, att_w in att_weights_avg_dict[l_id][h_id][occ].items():\n",
    "                att_w_str = np.format_float_positional(att_w, precision=2, min_digits=2)\n",
    "                layer_ob_dict[occ][sect_k].append(att_w_str)\n",
    "    \n",
    "    print(f'===== Layer {l_id} =====')\n",
    "    for occ in occ_types:\n",
    "        print(occ)\n",
    "        for sect_k, att_w_list in layer_ob_dict[occ].items():\n",
    "            att_w_list_str = \"  \".join(att_w_list)\n",
    "            print(f'{sect_k:<10s}{att_w_list_str}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.0: dirty attention vector effect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'column'\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_0_dirty_attention_vector_effect/exp=5_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2002, (867, 867), 566, 569, 1135, 1436)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "#         # TEMP adjustment for column results \n",
    "#         d['low_score'] = d['trace_scores']['high_layers_corrupt'].get(\"0\", 0.0)  # \"0\" is key (for layer 0), 0.0 is default \n",
    "#         if d['base_score'] - d['low_score'] < 0.5:\n",
    "#             d['is_good_sample'] = False\n",
    "#         # END_TEMP\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5, (i, d)\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "n_good_samples + n_too_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in bad_samples if s['correct_prediction']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {k: {str(l): 0 for l in range(24)} for k in good_samples[0]['trace_scores'].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for k, layer_d in d['trace_scores'].items():\n",
    "        for l, s in layer_d.items():\n",
    "            trace_scores_avg[k][l] += s\n",
    "\n",
    "for k, layer_d in trace_scores_avg.items():\n",
    "    for l, s in layer_d.items():\n",
    "        layer_d[l] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects (category)\n",
    "- Still kind of linear, as in exp-2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': 'hard', 'node_role': 'where', 'text_match': 'partial'}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (trace_key, aspect, asp_val, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no trace key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for trace_k, trace_layer_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            for l, s in trace_layer_d.items():\n",
    "                trace_scores_by_aspect[trace_k][aspect][asp_val][l].append(s)\n",
    "\n",
    "for trace_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for asp_v, d3 in d2.items():\n",
    "            for l, s in d3.items():\n",
    "                trace_scores_avg_by_aspect[trace_k][asp_k][asp_v][l] = np.mean(s)\n",
    "                trace_scores_cnt_by_aspect[asp_k][asp_v] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(int,\n",
       "                         {'medium': 400,\n",
       "                          'hard': 155,\n",
       "                          'easy': 142,\n",
       "                          'extra': 170}),\n",
       "             'node_role': defaultdict(int,\n",
       "                         {'where': 268,\n",
       "                          'select': 412,\n",
       "                          'order by': 66,\n",
       "                          'join': 92,\n",
       "                          'group by': 25,\n",
       "                          'having': 4}),\n",
       "             'text_match': defaultdict(int,\n",
       "                         {'no-match': 360, 'partial': 148, 'exact': 359})})"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg_by_aspect['high_layers_corrupt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.2: attention section removal effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'table'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/exp=5.2.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1683, (1207, 1207), 136, 340, 476, 'good / correct = 1207 / 1547')"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples),\\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'Find the number of concerts happened in the stadium with the highest capacity .; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id',\n",
       " 'seq_out': 'select count(*) from concert where stadium_id = (select stadium_id from stadium order by capacity desc limit 1)',\n",
       " 'dec_prompt': 'select count(*) from',\n",
       " 'expect': 'concert',\n",
       " 'expect_type': 'table',\n",
       " 'db_id': 'concert_singer',\n",
       " 'expect_input_ranges': [[88, 89]],\n",
       " 'expect_table': 'concert',\n",
       " 'answer': 'stadium',\n",
       " 'base_score': 0.9941871166229248,\n",
       " 'answers_t': [14939],\n",
       " 'correct_prediction': False,\n",
       " 'category': {'sql_hardness': 'hard',\n",
       "  'node_role': 'from',\n",
       "  'text_match': 'exact'},\n",
       " 'self_ranges': [[87, 91]],\n",
       " 'struct_context_ranges': [[22, 87], [91, 132]],\n",
       " 'is_good_sample': False}"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in bad_samples if not s['correct_prediction']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            if k == 'window':\n",
    "                for l, s in v.items():\n",
    "                    trace_scores_avg[sect_k][f'{k}-{l}'] += s\n",
    "            else:\n",
    "                s = v\n",
    "                trace_scores_avg[sect_k][k] += s\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP patch for node_len category \n",
    "for d in good_samples + bad_samples:\n",
    "    node_len = len(d['answers_t'])\n",
    "    assert len(mt_uskg.tokenizer.tokenize(d['expect'])) == node_len, (d['expect'], node_len)\n",
    "    d['category']['node_len'] = str(node_len) if node_len <= 3 else '4+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': 'medium',\n",
       " 'node_role': 'from',\n",
       " 'text_match': 'exact',\n",
       " 'node_len': '1'}"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (sect_k, aspect, asp_val, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no sect key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            for k, v in sect_d.items():\n",
    "                if k == 'window':\n",
    "                    for l, s in v.items():\n",
    "                        if not (int(l) % 4 == 3): continue\n",
    "                        layer_k = f'{k}-{l}'\n",
    "                        trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                else:\n",
    "                    layer_k = k\n",
    "                    s = v\n",
    "                    trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                    \n",
    "for sect_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for asp_v, d3 in d2.items():\n",
    "            for layer_k, s in d3.items():\n",
    "                trace_scores_avg_by_aspect[sect_k][asp_k][asp_v][layer_k] = np.mean(s)\n",
    "                trace_scores_cnt_by_aspect[asp_k][asp_v] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sect_k, sect_d in trace_scores_avg_by_aspect.items():\n",
    "    sect_d['overall'] = dict()\n",
    "    for layer_k, s in trace_scores_avg[sect_k].items():\n",
    "        if layer_k.startswith('window'):\n",
    "            # only keep a subset of layers \n",
    "            _, l = layer_k.split('-')\n",
    "            if not (int(l) % 4 == 3): continue\n",
    "        sect_d['overall'][layer_k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(int,\n",
       "                         {'medium': 378,\n",
       "                          'hard': 148,\n",
       "                          'easy': 134,\n",
       "                          'extra': 160}),\n",
       "             'node_role': defaultdict(int,\n",
       "                         {'where': 248,\n",
       "                          'select': 393,\n",
       "                          'order by': 63,\n",
       "                          'join': 91,\n",
       "                          'group by': 21,\n",
       "                          'having': 4}),\n",
       "             'text_match': defaultdict(int,\n",
       "                         {'no-match': 345, 'partial': 142, 'exact': 333}),\n",
       "             'node_len': defaultdict(int,\n",
       "                         {'1': 329, '3': 238, '4+': 160, '2': 93})})"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace_scores_avg_by_aspect['self']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_d = ctu.nested_json_processing(trace_scores_avg_by_aspect, func=lambda x: np.format_float_positional(x, precision=4, min_digits=4))\n",
    "# dump_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/summ-exp=5.2.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(dump_path, 'w') as f:\n",
    "    json.dump(dump_d, f, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (one-time temp patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect_type = 'table_alias'\n",
    "# orig_res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/no_structcontext-exp=5.2.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "# add_res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/exp=5.2.1+structcontext_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "# merge_res_path = f'/home/yshao/Projects/rome/results/exp5_2_attention_section_removal_effect/exp=5.2.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(orig_res_path, 'r') as f:\n",
    "#     orig_all_samples = [json.loads(l) for l in f]\n",
    "# with open(add_res_path, 'r') as f:\n",
    "#     add_all_samples = [json.loads(l) for l in f]\n",
    "\n",
    "# f = open(merge_res_path, 'w')\n",
    "    \n",
    "# for i, (orig_ex, add_ex) in enumerate(zip(orig_all_samples, add_all_samples)):\n",
    "#     assert len(orig_ex['trace_results']) == len(add_ex['trace_results']), i\n",
    "#     # There is randomness in the order of expected node (from set()), thus sorting here \n",
    "#     orig_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     add_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     for j, (orig_d, add_d) in enumerate(zip(orig_ex['trace_results'], add_ex['trace_results'])):\n",
    "#         assert orig_d['is_good_sample'] == add_d['is_good_sample'], (i, j)\n",
    "#         if not orig_d['is_good_sample']:\n",
    "#             continue\n",
    "            \n",
    "#         # is good sample: add the new sections \n",
    "#         orig_d['trace_scores']['struct_context'] = add_d['trace_scores']['struct_context']\n",
    "#         orig_d['trace_scores']['text+struct_context'] = add_d['trace_scores']['text+struct_context']\n",
    "        \n",
    "#     f.write(json.dumps(orig_ex, indent=None) + '\\n')\n",
    "    \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single samples observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prefix', 'text', 'struct', 'text+struct', 'all', 'self', 'struct_context', 'text+struct_context'])"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples[0]['trace_scores'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = 0\n",
    "\n",
    "d = good_samples[_id]\n",
    "\n",
    "check_info_d = defaultdict(dict)\n",
    "\n",
    "for sect_k, sect_d in d['trace_scores'].items():\n",
    "    for layer_k, s in sect_d.items():\n",
    "        if layer_k == 'window':\n",
    "            layer_k = 'window-19'\n",
    "            s = s['19']\n",
    "        if s < 0.5:\n",
    "            check_info_d[sect_k][layer_k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text+struct\": {\n",
      "    \"all_layers\": 0.3990614414215088\n",
      "  },\n",
      "  \"all\": {\n",
      "    \"all_layers\": 0.4772564172744751\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(check_info_d, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check \"breaking\" window layer, i.e. those with sudden changes \n",
    "### For now: single layer drop > _th\n",
    "\n",
    "_th = 0.4\n",
    "check_info_l = []\n",
    "for i, d in enumerate(good_samples):\n",
    "#     for sect_k, sect_d in d['trace_scores'].items():\n",
    "    sect_k = 'all'\n",
    "    sect_d = d['trace_scores'][sect_k]\n",
    "    window_d = sect_d['window']\n",
    "    for l in range(1, 24):\n",
    "        if window_d[str(l-1)] - window_d[str(l)] > _th:\n",
    "            _info_d = {\n",
    "                'id': i,\n",
    "                'sect_k': sect_k,\n",
    "                'layer': l,\n",
    "                'last_layer_score': window_d[str(l-1)],\n",
    "                'this_layer_score': window_d[str(l)],\n",
    "            }\n",
    "            check_info_l.append(_info_d)\n",
    "            break\n",
    "len(check_info_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(844, 1207)"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_info_l), len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 10),\n",
       " (2, 25),\n",
       " (3, 31),\n",
       " (4, 81),\n",
       " (5, 24),\n",
       " (6, 3),\n",
       " (7, 15),\n",
       " (8, 87),\n",
       " (9, 69),\n",
       " (10, 19),\n",
       " (11, 38),\n",
       " (12, 36),\n",
       " (13, 70),\n",
       " (14, 101),\n",
       " (15, 27),\n",
       " (16, 31),\n",
       " (17, 31),\n",
       " (18, 79),\n",
       " (19, 67)]"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "break_layer_counter = Counter([_d['layer'] for _d in check_info_l])\n",
    "sorted(break_layer_counter.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info_d in check_info_l:\n",
    "    if info_d['layer'] < 6:\n",
    "        print(info_d)\n",
    "        sample_id = info_d['id']\n",
    "        d = good_samples[sample_id]\n",
    "        print(d['enc_sentence'])\n",
    "        print(d['dec_prompt'], '---->', d['expect'])\n",
    "        print('Categories:', d['category'])\n",
    "        print('--' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_counter_by_aspect = defaultdict(Counter)  # [asp_k, asp_v] -> count \n",
    "sample_counter = Counter()\n",
    "\n",
    "for info_d in check_info_l:\n",
    "    if info_d['layer'] < 6:\n",
    "        sample_id = info_d['id']\n",
    "        d = good_samples[sample_id]\n",
    "        text_match = d['category']['text_match']\n",
    "        node_len = d['category']['node_len']\n",
    "        sample_counter[(text_match, node_len)] += 1\n",
    "        \n",
    "        for asp_k, asp_v in d['category'].items():\n",
    "            sample_counter_by_aspect[asp_k][asp_v] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'sql_hardness': Counter({'medium': 58,\n",
       "                      'hard': 42,\n",
       "                      'extra': 51,\n",
       "                      'easy': 20}),\n",
       "             'node_role': Counter({'from': 105, 'join': 66}),\n",
       "             'text_match': Counter({'partial': 59,\n",
       "                      'no-match': 74,\n",
       "                      'exact': 38}),\n",
       "             'node_len': Counter({'4+': 60, '3': 51, '2': 24, '1': 36})})"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_counter_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('partial', '3'), 30),\n",
       " (('partial', '4+'), 29),\n",
       " (('exact', '1'), 22),\n",
       " (('no-match', '3'), 21),\n",
       " (('no-match', '4+'), 21),\n",
       " (('no-match', '2'), 18),\n",
       " (('no-match', '1'), 14),\n",
       " (('exact', '4+'), 10),\n",
       " (('exact', '2'), 6)]"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_counter_by_aspect = defaultdict(Counter)  # [asp_k, asp_v] -> count \n",
    "sample_counter = Counter()\n",
    "\n",
    "for info_d in check_info_l:\n",
    "    if info_d['layer'] > 18:\n",
    "        sample_id = info_d['id']\n",
    "        d = good_samples[sample_id]\n",
    "        text_match = d['category']['text_match']\n",
    "        node_len = d['category']['node_len']\n",
    "        sample_counter[(text_match, node_len)] += 1\n",
    "        \n",
    "        for asp_k, asp_v in d['category'].items():\n",
    "            sample_counter_by_aspect[asp_k][asp_v] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'sql_hardness': Counter({'hard': 9,\n",
       "                      'medium': 27,\n",
       "                      'easy': 11,\n",
       "                      'extra': 20}),\n",
       "             'node_role': Counter({'join': 21, 'from': 46}),\n",
       "             'text_match': Counter({'exact': 46,\n",
       "                      'no-match': 20,\n",
       "                      'partial': 1}),\n",
       "             'node_len': Counter({'3': 12, '1': 46, '2': 6, '4+': 3})})"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_counter_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('exact', '1'), 38),\n",
       " (('no-match', '3'), 9),\n",
       " (('no-match', '1'), 8),\n",
       " (('exact', '3'), 3),\n",
       " (('no-match', '2'), 3),\n",
       " (('exact', '2'), 3),\n",
       " (('exact', '4+'), 2),\n",
       " (('partial', '4+'), 1)]"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.385318918917694e-12"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _min_p = 1.0\n",
    "\n",
    "# for i, d in enumerate(good_samples):\n",
    "#     sect_k = 'text'\n",
    "#     sect_d = d['trace_scores'][sect_k]\n",
    "#     _min_p = min(_min_p, sect_d['all_layers'])\n",
    "\n",
    "# _min_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 916, 1207, 1207)"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Systematic \n",
    "\n",
    "ob_sect_k = 'all'\n",
    "\n",
    "_th = 0.4\n",
    "\n",
    "check_info_l = []\n",
    "all_layers_eff_cnt = 0  # for this section to observe, how many samples are effective with all_layers\n",
    "window_eff_cnt = 0      # for this section to observe, how many samples are effective with any window \n",
    "\n",
    "for i, d in enumerate(good_samples):\n",
    "#     for sect_k, sect_d in d['trace_scores'].items():\n",
    "    sect_k = ob_sect_k\n",
    "    sect_d = d['trace_scores'][sect_k]\n",
    "    if sect_d['all_layers'] > 0.5:\n",
    "        # not effective\n",
    "        continue\n",
    "    else:\n",
    "        all_layers_eff_cnt += 1\n",
    "        \n",
    "    if min(sect_d['window'].values()) > 0.5:\n",
    "        # not effective\n",
    "        continue\n",
    "    else:\n",
    "        window_eff_cnt += 1\n",
    "        \n",
    "    window_d = sect_d['window']\n",
    "    for l in range(1, 24):\n",
    "        if window_d[str(l-1)] - window_d[str(l)] > _th:\n",
    "            _info_d = {\n",
    "                'id': i,\n",
    "                'sect_k': sect_k,\n",
    "                'layer': l,\n",
    "                'last_layer_score': window_d[str(l-1)],\n",
    "                'this_layer_score': window_d[str(l)],\n",
    "            }\n",
    "            check_info_l.append(_info_d)\n",
    "            break\n",
    "len(check_info_l), window_eff_cnt, all_layers_eff_cnt, len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctg_list = [(tm, nl) for tm in ['exact', 'partial', 'no-match'] for nl in ['1', '2', '3', '4+']]\n",
    "layer_list = [str(l) for l in range(1, 24)]\n",
    "\n",
    "ctg_elem2id = {elem : i for i, elem in enumerate(ctg_list)}\n",
    "layer_elem2id = {elem : i for i, elem in enumerate(layer_list)}\n",
    "\n",
    "cnt_matrix = np.zeros((len(ctg_list), len(layer_list)), int)\n",
    "\n",
    "for info_d in check_info_l:\n",
    "    sample_id = info_d['id']\n",
    "    d = good_samples[sample_id]\n",
    "    text_match = d['category']['text_match']\n",
    "    node_len = d['category']['node_len']\n",
    "    _ctg = (text_match, node_len)\n",
    "    _layer = str(info_d['layer'])\n",
    "    \n",
    "    _ctg_idx = ctg_elem2id[_ctg]\n",
    "    _layer_idx = layer_elem2id[_layer]\n",
    "    cnt_matrix[_ctg_idx, _layer_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Display the matrix using imshow\n",
    "im = ax.imshow(cnt_matrix, cmap='Blues')\n",
    "\n",
    "# Set the tick labels for the first and second dimensions\n",
    "ax.set_xticks(np.arange(len(layer_list)))\n",
    "ax.set_yticks(np.arange(len(ctg_list)))\n",
    "\n",
    "# Set the tick labels using the ctg_list and layer_list\n",
    "ax.set_xticklabels(layer_list)\n",
    "ax.set_yticklabels(ctg_list)\n",
    "\n",
    "ax.set_title(f'Section: {ob_sect_k}\\n')\n",
    "\n",
    "# Rotate the x-axis tick labels if needed\n",
    "# plt.xticks(rotation=90)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax, shrink=0.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Display the matrix using imshow\n",
    "im = ax.imshow(cnt_matrix, cmap='Blues')\n",
    "\n",
    "# Set the tick labels for the first and second dimensions\n",
    "ax.set_xticks(np.arange(len(layer_list)))\n",
    "ax.set_yticks(np.arange(len(ctg_list)))\n",
    "\n",
    "# Set the tick labels using the ctg_list and layer_list\n",
    "ax.set_xticklabels(layer_list)\n",
    "ax.set_yticklabels(ctg_list)\n",
    "\n",
    "ax.set_title(f'Section: {ob_sect_k}\\n')\n",
    "\n",
    "# Rotate the x-axis tick labels if needed\n",
    "# plt.xticks(rotation=90)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax, shrink=0.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.3: attention section mutual removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/exp=5.3.2_dev_{expect_type}-attn_crpt=logits.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2039, (425, 425), 339, 1275, 1614, 'good / correct = 425 / 1700')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            if k == 'window':\n",
    "                for l, s in v.items():\n",
    "                    trace_scores_avg[sect_k][f'{k}-{l}'] += s\n",
    "            else:\n",
    "                s = v\n",
    "                trace_scores_avg[sect_k][k] += s\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t->s': defaultdict(int,\n",
       "             {'low_layers': 0.9290514079798852,\n",
       "              'high_layers': 0.869896683267882,\n",
       "              'all_layers': 0.8232868012767746}),\n",
       " 's->t': defaultdict(int,\n",
       "             {'low_layers': 0.93718861461124,\n",
       "              'high_layers': 0.6922465424780495,\n",
       "              'all_layers': 0.6179986795201846}),\n",
       " 't<->s': defaultdict(int,\n",
       "             {'low_layers': 0.8901762831921309,\n",
       "              'high_layers': 0.6223348992867769,\n",
       "              'all_layers': 0.5653289335958119}),\n",
       " 't->p': defaultdict(int,\n",
       "             {'low_layers': 0.9018058195802454,\n",
       "              'high_layers': 0.7151599299841802,\n",
       "              'all_layers': 0.5826505602281772}),\n",
       " 's->p': defaultdict(int,\n",
       "             {'low_layers': 0.8692605289422511,\n",
       "              'high_layers': 0.647997452300951,\n",
       "              'all_layers': 0.6214377000487246}),\n",
       " 'ts->p': defaultdict(int,\n",
       "             {'low_layers': 0.8084217387553845,\n",
       "              'high_layers': 0.5981828650388452,\n",
       "              'all_layers': 0.5190777896359305}),\n",
       " 't->t': defaultdict(int,\n",
       "             {'low_layers': 0.7906251720212268,\n",
       "              'high_layers': 0.7563438485072913,\n",
       "              'all_layers': 0.45595838602426747}),\n",
       " 's->s': defaultdict(int,\n",
       "             {'low_layers': 0.5819380124547597,\n",
       "              'high_layers': 0.7422604869739443,\n",
       "              'all_layers': 0.533616202818682}),\n",
       " 's->c': defaultdict(int,\n",
       "             {'low_layers': 0.6655680766419021,\n",
       "              'high_layers': 0.7871413396441203,\n",
       "              'all_layers': 0.6730743790651316}),\n",
       " 'c->p': defaultdict(int,\n",
       "             {'low_layers': 0.8871276978259787,\n",
       "              'high_layers': 0.7648420881280449,\n",
       "              'all_layers': 0.7126877822261626}),\n",
       " 'c->s': defaultdict(int,\n",
       "             {'low_layers': 0.6496616549795551,\n",
       "              'high_layers': 0.8344911244677504,\n",
       "              'all_layers': 0.6101411809959618}),\n",
       " 'c->c': defaultdict(int,\n",
       "             {'low_layers': 0.6809635196503006,\n",
       "              'high_layers': 0.8472856283550675,\n",
       "              'all_layers': 0.6768490126152779}),\n",
       " 'all': defaultdict(int,\n",
       "             {'low_layers': 0.3621671234769805,\n",
       "              'high_layers': 0.11658283323064308,\n",
       "              'all_layers': 0.053106493203508895})}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\tlow_layers  \thigh_layers \tall_layers  \n",
      "t->s        \t0.9291      \t0.8699      \t0.8233      \n",
      "s->t        \t0.9372      \t0.6922      \t0.6180      \n",
      "t<->s       \t0.8902      \t0.6223      \t0.5653      \n",
      "t->p        \t0.9018      \t0.7152      \t0.5827      \n",
      "s->p        \t0.8693      \t0.6480      \t0.6214      \n",
      "ts->p       \t0.8084      \t0.5982      \t0.5191      \n",
      "t->t        \t0.7906      \t0.7563      \t0.4560      \n",
      "s->s        \t0.5819      \t0.7423      \t0.5336      \n",
      "s->c        \t0.6656      \t0.7871      \t0.6731      \n",
      "c->p        \t0.8871      \t0.7648      \t0.7127      \n",
      "c->s        \t0.6497      \t0.8345      \t0.6101      \n",
      "c->c        \t0.6810      \t0.8473      \t0.6768      \n",
      "all         \t0.3622      \t0.1166      \t0.0531      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(trace_scores_avg, col_w=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': 'medium', 'node_role': 'where', 'text_match': 'no-match'}"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP patch for node_len category \n",
    "# for d in good_samples + bad_samples:\n",
    "#     node_len = len(d['answers_t'])\n",
    "#     assert len(mt_uskg.tokenizer.tokenize(d['expect'])) == node_len, (d['expect'], node_len)\n",
    "#     d['category']['node_len'] = str(node_len) if node_len <= 3 else '4+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_hardness': 'medium',\n",
       " 'node_role': 'group by',\n",
       " 'text_match': 'exact',\n",
       " 'node_len': '3'}"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (sect_k, aspect, asp_val, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no sect key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            for k, v in sect_d.items():\n",
    "                if k == 'window':\n",
    "                    for l, s in v.items():\n",
    "                        if not (int(l) % 4 == 3): continue\n",
    "                        layer_k = f'{k}-{l}'\n",
    "                        trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                else:\n",
    "                    layer_k = k\n",
    "                    s = v\n",
    "                    trace_scores_by_aspect[sect_k][aspect][asp_val][layer_k].append(s)\n",
    "                    \n",
    "for sect_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for asp_v, d3 in d2.items():\n",
    "            for layer_k, s in d3.items():\n",
    "                trace_scores_avg_by_aspect[sect_k][asp_k][asp_v][layer_k] = np.mean(s)\n",
    "                trace_scores_cnt_by_aspect[asp_k][asp_v] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sect_k, sect_d in trace_scores_avg_by_aspect.items():\n",
    "    sect_d['overall'] = dict()\n",
    "    for layer_k, s in trace_scores_avg[sect_k].items():\n",
    "        if layer_k.startswith('window'):\n",
    "            # only keep a subset of layers \n",
    "            _, l = layer_k.split('-')\n",
    "            if not (int(l) % 4 == 3): continue\n",
    "        sect_d['overall'][layer_k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'sql_hardness': defaultdict(int,\n",
       "                         {'medium': 123, 'extra': 175, 'hard': 64, 'easy': 2}),\n",
       "             'node_role': defaultdict(int,\n",
       "                         {'select': 191,\n",
       "                          'group by': 33,\n",
       "                          'join': 12,\n",
       "                          'where': 111,\n",
       "                          'order by': 17}),\n",
       "             'text_match': defaultdict(int,\n",
       "                         {'exact': 230, 'partial': 28, 'no-match': 106}),\n",
       "             'node_len': defaultdict(int, {'3': 364})})"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace_scores_avg_by_aspect['c->p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_d = ctu.nested_json_processing(trace_scores_avg_by_aspect, func=lambda x: np.format_float_positional(x, precision=4, min_digits=4))\n",
    "# dump_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/summ-exp=5.3.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "with open(dump_path, 'w') as f:\n",
    "    json.dump(dump_d, f, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (one-time temp patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect_type = 'table_alias'\n",
    "# orig_res_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/no_c2p_exp=5.3.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "# add_res_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/exp=5.3.1+c2p_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'\n",
    "\n",
    "# merge_res_path = f'/home/yshao/Projects/rome/results/exp5_3_attention_section_mutual_removal/exp=5.3.1_dev_{expect_type}_encoder-attn=self_attn-corrupt=zero.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(orig_res_path, 'r') as f:\n",
    "#     orig_all_samples = [json.loads(l) for l in f]\n",
    "# with open(add_res_path, 'r') as f:\n",
    "#     add_all_samples = [json.loads(l) for l in f]\n",
    "\n",
    "# f = open(merge_res_path, 'w')\n",
    "    \n",
    "# for i, (orig_ex, add_ex) in enumerate(zip(orig_all_samples, add_all_samples)):\n",
    "#     assert len(orig_ex['trace_results']) == len(add_ex['trace_results']), i\n",
    "#     # There is randomness in the order of expected node (from set()), thus sorting here \n",
    "#     orig_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     add_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     for j, (orig_d, add_d) in enumerate(zip(orig_ex['trace_results'], add_ex['trace_results'])):\n",
    "#         assert orig_d['is_good_sample'] == add_d['is_good_sample'], (i, j)\n",
    "#         if not orig_d['is_good_sample']:\n",
    "#             continue\n",
    "            \n",
    "#         # is good sample: add the new sections \n",
    "#         orig_d['trace_scores']['c->p'] = add_d['trace_scores']['c->p']\n",
    "        \n",
    "#         # put all at end in the dict \n",
    "#         _t = orig_d['trace_scores']['all']\n",
    "#         del orig_d['trace_scores']['all']\n",
    "#         orig_d['trace_scores']['all'] = _t\n",
    "        \n",
    "#     f.write(json.dumps(orig_ex, indent=None) + '\\n')\n",
    "    \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.4: attention section mutual removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_4_decoder_cross_attention_removal/exp=5.4.1_dev_{expect_type}-attn_crpt=logits.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2039, (1319, 1319), 339, 381, 720, 'good / correct = 1319 / 1700')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict[sect_k, Dict[layer_k, s]]\n",
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, s in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += s\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': defaultdict(int,\n",
       "             {'low_layers': 0.5061020740059613,\n",
       "              'high_layers': 0.9289341580132038,\n",
       "              'all_layers': 0.0943781443257875}),\n",
       " 'ans->t': defaultdict(int,\n",
       "             {'low_layers': 0.9606344601374024,\n",
       "              'high_layers': 0.9856522831318169,\n",
       "              'all_layers': 0.9386358369672906}),\n",
       " 'all->t': defaultdict(int,\n",
       "             {'low_layers': 0.9525955225675865,\n",
       "              'high_layers': 0.984406448969453,\n",
       "              'all_layers': 0.9322075405197958}),\n",
       " 'ans->s': defaultdict(int,\n",
       "             {'low_layers': 0.9276842575044683,\n",
       "              'high_layers': 0.9624120461844382,\n",
       "              'all_layers': 0.9218344937750477}),\n",
       " 'all->s': defaultdict(int,\n",
       "             {'low_layers': 0.8975644784564366,\n",
       "              'high_layers': 0.9613034508575463,\n",
       "              'all_layers': 0.8944733817566066}),\n",
       " 'ans->p': defaultdict(int,\n",
       "             {'low_layers': 0.9399589094915135,\n",
       "              'high_layers': 0.9322237051346581,\n",
       "              'all_layers': 0.8373065806008967}),\n",
       " 'all->p': defaultdict(int,\n",
       "             {'low_layers': 0.898856776293072,\n",
       "              'high_layers': 0.9179342647650568,\n",
       "              'all_layers': 0.7856266571482643}),\n",
       " 'ans->o': defaultdict(int,\n",
       "             {'low_layers': 0.9910217538713234,\n",
       "              'high_layers': 0.992259306944709,\n",
       "              'all_layers': 0.9919129847983142}),\n",
       " 'all->o': defaultdict(int,\n",
       "             {'low_layers': 0.9898263792577252,\n",
       "              'high_layers': 0.9921658938811347,\n",
       "              'all_layers': 0.990506428793084}),\n",
       " 'ans->t+o': defaultdict(int,\n",
       "             {'low_layers': 0.9604248905456436,\n",
       "              'high_layers': 0.9856715056047203,\n",
       "              'all_layers': 0.9423419624871491}),\n",
       " 'all->t+o': defaultdict(int,\n",
       "             {'low_layers': 0.9517493241124348,\n",
       "              'high_layers': 0.9844401957313307,\n",
       "              'all_layers': 0.9362271152322046}),\n",
       " 'ans->c': defaultdict(int,\n",
       "             {'low_layers': 0.9506645835022022,\n",
       "              'high_layers': 0.9790679521526345,\n",
       "              'all_layers': 0.9579497954662874}),\n",
       " 'all->c': defaultdict(int,\n",
       "             {'low_layers': 0.9285645300281636,\n",
       "              'high_layers': 0.976329830397648,\n",
       "              'all_layers': 0.9339657786557267}),\n",
       " 'ans->self': defaultdict(int,\n",
       "             {'low_layers': 0.9881064115244672,\n",
       "              'high_layers': 0.9769253622111198,\n",
       "              'all_layers': 0.9693454549027601}),\n",
       " 'all->self': defaultdict(int,\n",
       "             {'low_layers': 0.9765905385529681,\n",
       "              'high_layers': 0.9783063100955413,\n",
       "              'all_layers': 0.9585782296587362})}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all     \t0.5061\t0.9289\t0.0944\n",
      "ans->t  \t0.9606\t0.9857\t0.9386\n",
      "ans->s  \t0.9277\t0.9624\t0.9218\n",
      "ans->p  \t0.9400\t0.9322\t0.8373\n",
      "ans->o  \t0.9910\t0.9923\t0.9919\n",
      "ans->t+o\t0.9604\t0.9857\t0.9423\n",
      "ans->c  \t0.9507\t0.9791\t0.9579\n",
      "ans->self\t0.9881\t0.9769\t0.9693\n"
     ]
    }
   ],
   "source": [
    "layers_keys = ['low_layers', 'high_layers', 'all_layers']\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    # 'all->?' results seem similar to 'ans->?' and make less intuitive sense; skip for now \n",
    "    if sect_k.startswith('all->'):\n",
    "        continue\n",
    "    print_l = f'{sect_k:<8s}'\n",
    "    for k in layers_keys:\n",
    "        s = sect_d[k]\n",
    "        print_l += f'\\t{s:.4f}'\n",
    "    print(print_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-5.5: both part attention removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp5_5_both_part_attention_removal/exp=5.5.1_dev_{expect_type}-attn_crpt=logits.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2039, (1631, 1631), 339, 69, 408, 'good / correct = 1631 / 1700')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d['is_good_sample']:\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            if k == 'window':\n",
    "                for l, s in v.items():\n",
    "                    trace_scores_avg[sect_k][f'{k}-{l}'] += s\n",
    "            else:\n",
    "                s = v\n",
    "                trace_scores_avg[sect_k][k] += s\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s->t&all->t': defaultdict(int,\n",
       "             {'E-all&D-all': 0.810587916234049,\n",
       "              'E-all&D-low': 0.8383651262275511,\n",
       "              'E-low&D-all': 0.8902601872852249})}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-all&D-all    0.8106\n",
      "E-all&D-low    0.8384\n",
      "E-low&D-all    0.8903\n"
     ]
    }
   ],
   "source": [
    "format_print_1D_dict(trace_scores_avg['s->t&all->t'], head_col_w=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (sect_k, asp_k, layer) -> [scores]\n",
    "trace_scores_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "trace_scores_avg_by_aspect = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "trace_scores_cnt_by_aspect = defaultdict(lambda: defaultdict(int))  # no sect key & layer key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for aspect, asp_val in d['category'].items():\n",
    "            asp_k = f'{aspect}={asp_val}'\n",
    "            for k, v in sect_d.items():\n",
    "                layer_k = k\n",
    "                s = v\n",
    "                trace_scores_by_aspect[sect_k][asp_k][layer_k].append(s)\n",
    "                    \n",
    "for sect_k, d1 in trace_scores_by_aspect.items():\n",
    "    for asp_k, d2 in d1.items():\n",
    "        for layer_k, s in d2.items():\n",
    "            trace_scores_avg_by_aspect[sect_k][asp_k][layer_k] = np.mean(s)\n",
    "            trace_scores_cnt_by_aspect[asp_k] = len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sect_k, sect_d in trace_scores_avg_by_aspect.items():\n",
    "#     sect_d['overall'] = dict()\n",
    "#     for layer_k, s in trace_scores_avg[sect_k].items():\n",
    "#         if layer_k.startswith('window'):\n",
    "#             # only keep a subset of layers \n",
    "#             _, l = layer_k.split('-')\n",
    "#             if not (int(l) % 4 == 3): continue\n",
    "#         sect_d['overall'][layer_k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('node_len=1', 578),\n",
       " ('node_len=2', 116),\n",
       " ('node_len=3', 369),\n",
       " ('node_len=4+', 203),\n",
       " ('node_role=group by', 82),\n",
       " ('node_role=having', 6),\n",
       " ('node_role=join', 85),\n",
       " ('node_role=order by', 82),\n",
       " ('node_role=select', 630),\n",
       " ('node_role=where', 381),\n",
       " ('sql_hardness=easy', 229),\n",
       " ('sql_hardness=extra', 211),\n",
       " ('sql_hardness=hard', 240),\n",
       " ('sql_hardness=medium', 586),\n",
       " ('text_match=exact', 653),\n",
       " ('text_match=no-match', 419),\n",
       " ('text_match=partial', 194)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(trace_scores_cnt_by_aspect.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'easy': defaultdict(float,\n",
       "             {'E-all&D-all': 0.6952432668401013,\n",
       "              'E-all&D-low': 0.9067031433060689,\n",
       "              'E-low&D-all': 0.9375170493903875}),\n",
       " 'medium': defaultdict(float,\n",
       "             {'E-all&D-all': 0.556048543710707,\n",
       "              'E-all&D-low': 0.8054229393484426,\n",
       "              'E-low&D-all': 0.8955880533978087}),\n",
       " 'hard': defaultdict(float,\n",
       "             {'E-all&D-all': 0.5484870432557414,\n",
       "              'E-all&D-low': 0.8360452807140587,\n",
       "              'E-low&D-all': 0.8290000068771377}),\n",
       " 'extra': defaultdict(float,\n",
       "             {'E-all&D-all': 0.6368124696327836,\n",
       "              'E-all&D-low': 0.8165238064917822,\n",
       "              'E-low&D-all': 0.8967893739510424})}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: trace_scores_avg_by_aspect['s->t&all->t'][f'sql_hardness={k}'] for k in ['easy', 'medium', 'hard', 'extra']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': defaultdict(float,\n",
       "             {'E-all&D-all': 0.5947468875597053,\n",
       "              'E-all&D-low': 0.8776616909043937,\n",
       "              'E-low&D-all': 0.8787339264019262}),\n",
       " 'partial': defaultdict(float,\n",
       "             {'E-all&D-all': 0.49977204983319107,\n",
       "              'E-all&D-low': 0.8079702937117633,\n",
       "              'E-low&D-all': 0.8836331785910234}),\n",
       " 'no-match': defaultdict(float,\n",
       "             {'E-all&D-all': 0.6342099784024492,\n",
       "              'E-all&D-low': 0.7701454216605397,\n",
       "              'E-low&D-all': 0.9127696242686905})}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: trace_scores_avg_by_aspect['s->t&all->t'][f'text_match={k}'] for k in ['exact', 'partial', 'no-match']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_ids = []\n",
    "for i, d in enumerate(good_samples):\n",
    "    if d['category']['text_match'] == 'exact':\n",
    "        continue\n",
    "    # here: no exact text match \n",
    "    if d['trace_scores']['s->t&all->t']['E-all&D-all'] < 0.5:\n",
    "        continue\n",
    "    # here: corrupted pred is correct \n",
    "    ob_ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 [9, 77, 96, 116, 138, 150, 177, 200, 228, 255, 282, 297, 375, 386, 439, 487, 530, 584, 604, 635, 673, 755, 849, 874, 892, 911, 926, 962, 986, 1003, 1019, 1039, 1082, 1108, 1156, 1211]\n"
     ]
    }
   ],
   "source": [
    "print(len(ob_ids), ob_ids[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'What is the average, minimum, and maximum age of all singers from France?; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country ( France ) , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id',\n",
       " 'seq_out': \"select avg(age), min(age), max(age) from singer where country = 'France'\",\n",
       " 'dec_prompt': 'select avg(age), min(age), max(age) from singer where',\n",
       " 'expect': 'country',\n",
       " 'expect_type': 'column',\n",
       " 'db_id': 'concert_singer',\n",
       " 'expect_input_ranges': [[68, 73]],\n",
       " 'self_ranges': [[66, 75]],\n",
       " 'expect_table': 'singer',\n",
       " 'answer': 'country',\n",
       " 'base_score': 0.9999995231628418,\n",
       " 'answers_t': [684],\n",
       " 'correct_prediction': True,\n",
       " 'category': {'sql_hardness': 'medium',\n",
       "  'node_role': 'where',\n",
       "  'text_match': 'no-match',\n",
       "  'node_len': '1'},\n",
       " 'corrupted_answers_t': [2306],\n",
       " 'corrupted_answer': 'album',\n",
       " 'low_score': 5.606463673757389e-06,\n",
       " 'is_good_sample': True,\n",
       " 'trace_scores': {'s->t&all->t': {'E-all&D-all': 0.9999951124191284,\n",
       "   'E-all&D-low': 0.9999991655349731,\n",
       "   'E-low&D-all': 0.9999998807907104}},\n",
       " 'ex_id': 4}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-6.0: corruption effect - syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp6_0_encoding_corruption_effect_syntax/exp=6.0_dev.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10233, (2261, 2261), 1623, 6349, 7972, 'good / correct = 2261 / 8610')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d.get('is_good_sample', True):\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += v\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': defaultdict(int,\n",
       "             {'embed': 0.2704069729491695, 'final_enc': 0.43288231847139375}),\n",
       " 'struct': defaultdict(int,\n",
       "             {'embed': 0.8434888537914244, 'final_enc': 0.7056294551667914}),\n",
       " 'columns': defaultdict(int,\n",
       "             {'embed': 0.8977011346416999, 'final_enc': 0.9094602057515592}),\n",
       " 'tables': defaultdict(int,\n",
       "             {'embed': 0.9401333304200568, 'final_enc': 0.9652279544981762}),\n",
       " 'all': defaultdict(int,\n",
       "             {'embed': 0.04223158108438767, 'final_enc': 0.14583704401879738})}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\tembed \tfinal_enc\n",
      "text        \t0.2704\t0.4329\n",
      "struct      \t0.8435\t0.7056\n",
      "columns     \t0.8977\t0.9095\n",
      "tables      \t0.9401\t0.9652\n",
      "all         \t0.0422\t0.1458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(trace_scores_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corruption overall effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict[str, int]: expect_tok -> num of effective / not effective corruptions (all)\n",
    "eff_counter = Counter()\n",
    "neff_counter = Counter()\n",
    "\n",
    "for d in good_samples:\n",
    "    eff_counter[d['expect']] += 1\n",
    "for d in bad_samples:\n",
    "    if d['correct_prediction']:\n",
    "        # \"too easy\", corruption not effective \n",
    "        neff_counter[d['expect']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_rate_d = dict()\n",
    "\n",
    "for k in list(set(eff_counter.keys()) | set(neff_counter.keys())):\n",
    "    eff_c = eff_counter[k]\n",
    "    neff_c = neff_counter[k]\n",
    "    eff_r = 1.0 * eff_c / (eff_c + neff_c)\n",
    "    eff_rate_d[k] = eff_r\n",
    "    # print(f'{k:<10s}{eff_c:5d} /{eff_c + neff_c:5d} = {eff_r:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union\t6\t6\t1.0000\n",
      "!=\t20\t20\t1.0000\n",
      "like\t12\t12\t1.0000\n",
      "or\t34\t34\t1.0000\n",
      "min\t18\t18\t1.0000\n",
      "asc\t19\t19\t1.0000\n",
      "max\t30\t30\t1.0000\n",
      "between\t6\t6\t1.0000\n",
      "except\t21\t21\t1.0000\n",
      "avg\t65\t65\t1.0000\n",
      "intersect\t34\t34\t1.0000\n",
      "having\t80\t81\t0.9877\n",
      "distinct\t25\t26\t0.9615\n",
      "sum\t21\t22\t0.9545\n",
      "where\t484\t516\t0.9380\n",
      "not\t42\t46\t0.9130\n",
      "group\t225\t265\t0.8491\n",
      "and\t31\t39\t0.7949\n",
      "count\t267\t406\t0.6576\n",
      "order\t142\t221\t0.6425\n",
      ">\t61\t101\t0.6040\n",
      ")\t11\t23\t0.4783\n",
      "=\t191\t968\t0.1973\n",
      "as\t93\t952\t0.0977\n",
      "desc\t16\t164\t0.0976\n",
      "in\t4\t50\t0.0800\n",
      "join\t39\t496\t0.0786\n",
      "from\t49\t1196\t0.0410\n",
      "limit\t6\t177\t0.0339\n",
      ">=\t1\t30\t0.0333\n",
      "(\t22\t675\t0.0326\n",
      "*\t0\t381\t0.0000\n",
      "by\t0\t516\t0.0000\n",
      "on\t0\t516\t0.0000\n",
      "select\t0\t88\t0.0000\n"
     ]
    }
   ],
   "source": [
    "for k, eff_r in sorted(eff_rate_d.items(), key=lambda x: x[1], reverse=True):\n",
    "    eff_c = eff_counter[k]\n",
    "    neff_c = neff_counter[k]\n",
    "    all_c = eff_c + neff_c\n",
    "    if all_c <= 2: continue\n",
    "    if k.isnumeric(): continue\n",
    "#     print(f'{k:<10s}{eff_c:5d} /{all_c:5d} = {eff_r:.4f}')\n",
    "    print(f'{k}\\t{eff_c}\\t{all_c}\\t{eff_r:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by expect syntax token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (expect_tok, sect_k, layer) -> [scores]\n",
    "trace_scores_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "trace_scores_avg_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "trace_scores_cnt_by_exp_tok = defaultdict(int)  # no sect key & layer key \n",
    "\n",
    "trace_sample_ids_by_exp_tok = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(good_samples):\n",
    "    expect = d['expect']\n",
    "    trace_sample_ids_by_exp_tok[expect].append(i)\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for layer_k, v in sect_d.items():\n",
    "            trace_scores_by_exp_tok[expect][sect_k][layer_k].append(v)\n",
    "\n",
    "for exp_tok, d1 in trace_scores_by_exp_tok.items():\n",
    "    if exp_tok.isnumeric(): continue\n",
    "    for sect_k, d2 in d1.items():\n",
    "        for layer_k, scores in d2.items():\n",
    "            if len(scores) <= 2: continue\n",
    "            trace_scores_avg_by_exp_tok[exp_tok][sect_k][layer_k] = np.mean(scores)\n",
    "            trace_scores_cnt_by_exp_tok[exp_tok] = len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'count': 267,\n",
       "             'order': 142,\n",
       "             'avg': 65,\n",
       "             'min': 18,\n",
       "             'max': 30,\n",
       "             'where': 484,\n",
       "             'distinct': 25,\n",
       "             '>': 61,\n",
       "             'group': 225,\n",
       "             '(': 22,\n",
       "             'between': 6,\n",
       "             'from': 49,\n",
       "             'desc': 16,\n",
       "             'or': 34,\n",
       "             'not': 42,\n",
       "             'intersect': 34,\n",
       "             'except': 21,\n",
       "             'as': 93,\n",
       "             'join': 39,\n",
       "             'like': 12,\n",
       "             'and': 31,\n",
       "             '=': 191,\n",
       "             'having': 80,\n",
       "             '!=': 20,\n",
       "             'union': 6,\n",
       "             'limit': 6,\n",
       "             'sum': 21,\n",
       "             'asc': 19,\n",
       "             ')': 11,\n",
       "             'in': 4})"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_exp_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'text': defaultdict(float,\n",
       "                         {'embed': 0.07181598544092065,\n",
       "                          'final_enc': 0.08561127370659098}),\n",
       "             'struct': defaultdict(float,\n",
       "                         {'embed': 0.9997616432579269,\n",
       "                          'final_enc': 0.9906901482785686}),\n",
       "             'columns': defaultdict(float,\n",
       "                         {'embed': 0.9989915059300397,\n",
       "                          'final_enc': 0.9982228384035804}),\n",
       "             'tables': defaultdict(float,\n",
       "                         {'embed': 0.9940267473124387,\n",
       "                          'final_enc': 0.9992919242783879}),\n",
       "             'all': defaultdict(float,\n",
       "                         {'embed': 0.022402080392785025,\n",
       "                          'final_enc': 0.07584266595464821})})"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg_by_exp_tok['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "sect_k = 'struct'\n",
    "layer_k = 'embed'\n",
    "scores_d = dict()\n",
    "\n",
    "for exp_tok, d1 in trace_scores_avg_by_exp_tok.items():\n",
    "    s = d1[sect_k][layer_k]\n",
    "    scores_d[exp_tok] = s\n",
    "    # print(f'{exp_tok:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like      1.0000\n",
      "min       1.0000\n",
      "count     0.9998\n",
      "avg       0.9997\n",
      "limit     0.9993\n",
      "!=        0.9968\n",
      "union     0.9831\n",
      "or        0.9807\n",
      ">         0.9722\n",
      "having    0.9691\n",
      "intersect 0.9634\n",
      "except    0.9442\n",
      "sum       0.9386\n",
      "group     0.9373\n",
      "order     0.9079\n",
      ")         0.9057\n",
      "max       0.9033\n",
      "desc      0.8710\n",
      "where     0.8684\n",
      "distinct  0.8665\n",
      "(         0.8557\n",
      "between   0.8547\n",
      "asc       0.8026\n",
      "not       0.7477\n",
      "and       0.6863\n",
      "from      0.6251\n",
      "=         0.6110\n",
      "in        0.4806\n",
      "as        0.2753\n",
      "join      0.0001\n"
     ]
    }
   ],
   "source": [
    "for k, s in sorted(scores_d.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{k:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from      0.8645\n",
      "as        0.8363\n",
      "=         0.8272\n",
      "in        0.7407\n",
      ")         0.7101\n",
      "desc      0.4644\n",
      "where     0.3572\n",
      ">         0.3472\n",
      "join      0.3131\n",
      "not       0.2707\n",
      "and       0.2300\n",
      "having    0.1737\n",
      "min       0.1698\n",
      "(         0.1657\n",
      "like      0.1639\n",
      "union     0.1435\n",
      "order     0.1126\n",
      "group     0.1046\n",
      "asc       0.0877\n",
      "count     0.0718\n",
      "avg       0.0311\n",
      "or        0.0211\n",
      "except    0.0106\n",
      "distinct  0.0097\n",
      "max       0.0073\n",
      "sum       0.0017\n",
      "intersect 0.0005\n",
      "!=        0.0000\n",
      "between   0.0000\n",
      "limit     0.0000\n"
     ]
    }
   ],
   "source": [
    "sect_k = 'text'\n",
    "layer_k = 'embed'\n",
    "scores_d = dict()\n",
    "\n",
    "for exp_tok, d1 in trace_scores_avg_by_exp_tok.items():\n",
    "    s = d1[sect_k][layer_k]\n",
    "    scores_d[exp_tok] = s\n",
    "    # print(f'{exp_tok:<10s}{s:.4f}')\n",
    "\n",
    "for k, s in sorted(scores_d.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{k:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrupted answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict[str, Dict[str, int]]: exp_tok -> c_ans, cnt\n",
    "confusion_counter = defaultdict(Counter)\n",
    "\n",
    "for d in good_samples:\n",
    "    exp_tok = d['expect']\n",
    "    c_ans = d['corrupted_answer']\n",
    "    if exp_tok.isnumeric():\n",
    "        exp_tok = 'NUM'\n",
    "    if c_ans.isnumeric():\n",
    "        c_ans = 'NUM'\n",
    "    confusion_counter[exp_tok][c_ans] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'count': Counter({'*': 182, '': 64, 'sum': 19, 'count': 2}),\n",
       "             'order': Counter({'</s>': 96,\n",
       "                      'join': 12,\n",
       "                      ')': 2,\n",
       "                      'where': 9,\n",
       "                      'NUM': 5,\n",
       "                      'order': 3,\n",
       "                      'union': 2,\n",
       "                      'and': 2,\n",
       "                      'select': 4,\n",
       "                      's': 6,\n",
       "                      '_': 1}),\n",
       "             'avg': Counter({'*tvg': 43,\n",
       "                      'maxtvg': 8,\n",
       "                      'maxavg': 2,\n",
       "                      'tvg': 6,\n",
       "                      'mintvg': 2,\n",
       "                      'counttvg': 4}),\n",
       "             'min': Counter({'': 9, 'max': 5, '*': 4}),\n",
       "             'max': Counter({'': 13, '*': 16, 'min': 1}),\n",
       "             'where': Counter({'group': 19,\n",
       "                      'except': 2,\n",
       "                      '</s>': 239,\n",
       "                      'order': 114,\n",
       "                      'where': 9,\n",
       "                      ')': 16,\n",
       "                      ';': 5,\n",
       "                      'join': 36,\n",
       "                      'in': 3,\n",
       "                      'union': 2,\n",
       "                      'r': 3,\n",
       "                      '.': 5,\n",
       "                      'as': 17,\n",
       "                      'select': 2,\n",
       "                      '': 1,\n",
       "                      'class': 1,\n",
       "                      's': 10}),\n",
       "             'distinct': Counter({'*': 25}),\n",
       "             '>': Counter({'=': 55, 'in': 2, '</s>': 1, 'not': 1, 'des': 2}),\n",
       "             'NUM': Counter({'=': 70,\n",
       "                      't': 2,\n",
       "                      'NUM': 55,\n",
       "                      '\"': 22,\n",
       "                      '': 12,\n",
       "                      '(': 2,\n",
       "                      '=000': 6,\n",
       "                      ' and': 3,\n",
       "                      '=</s>': 4,\n",
       "                      '= join': 1,\n",
       "                      '3-': 1,\n",
       "                      '3%': 1,\n",
       "                      '%': 2,\n",
       "                      ')': 2,\n",
       "                      '</s>': 2}),\n",
       "             'group': Counter({'join': 21,\n",
       "                      '</s>': 98,\n",
       "                      'order': 29,\n",
       "                      'as': 16,\n",
       "                      'where': 25,\n",
       "                      'group': 3,\n",
       "                      'air': 5,\n",
       "                      '.': 4,\n",
       "                      'r': 1,\n",
       "                      'in': 2,\n",
       "                      'NUM': 2,\n",
       "                      'from': 2,\n",
       "                      'form': 2,\n",
       "                      'union': 4,\n",
       "                      's': 2,\n",
       "                      'express': 2,\n",
       "                      'l': 1,\n",
       "                      ';': 2,\n",
       "                      '=': 2,\n",
       "                      'and': 2}),\n",
       "             '(': Counter({'=': 11, '': 5, 'NUM': 6}),\n",
       "             'between': Counter({'>': 4, '=': 2}),\n",
       "             'from': Counter({'(': 1,\n",
       "                      'a': 2,\n",
       "                      '': 5,\n",
       "                      ')': 5,\n",
       "                      'ious': 2,\n",
       "                      ';': 1,\n",
       "                      'from': 2,\n",
       "                      'up': 2,\n",
       "                      'i': 2,\n",
       "                      'air': 1,\n",
       "                      'de': 8,\n",
       "                      'le': 2,\n",
       "                      'group': 2,\n",
       "                      '=': 2,\n",
       "                      '-': 2,\n",
       "                      ',': 2,\n",
       "                      'al': 4,\n",
       "                      'ture': 2,\n",
       "                      'call': 2}),\n",
       "             'desc': Counter({'desc': 3,\n",
       "                      'c': 2,\n",
       "                      'sc': 1,\n",
       "                      'ec': 2,\n",
       "                      '</s>c': 4,\n",
       "                      ',c': 1,\n",
       "                      'fromc': 2,\n",
       "                      'limitc': 1}),\n",
       "             'or': Counter({'</s>': 28, 'NUM': 2, 'order': 2, 'and': 2}),\n",
       "             '>=': Counter({'= 60': 1}),\n",
       "             'not': Counter({'=': 40, '': 2}),\n",
       "             'intersect': Counter({'and': 3,\n",
       "                      '</s>': 22,\n",
       "                      '-': 1,\n",
       "                      '-04': 4,\n",
       "                      'order': 4}),\n",
       "             'except': Counter({'order': 10, 'join': 4, '</s>': 7}),\n",
       "             'as': Counter({'_': 2,\n",
       "                      'i': 8,\n",
       "                      'order': 6,\n",
       "                      '</s>': 23,\n",
       "                      'er': 21,\n",
       "                      're': 1,\n",
       "                      'base': 6,\n",
       "                      'join': 7,\n",
       "                      'as': 3,\n",
       "                      ';': 2,\n",
       "                      'ment': 12,\n",
       "                      'in': 2}),\n",
       "             'join': Counter({'</s>': 32,\n",
       "                      ')': 2,\n",
       "                      'where': 1,\n",
       "                      'y': 2,\n",
       "                      'order': 1,\n",
       "                      'join': 1}),\n",
       "             'like': Counter({'=': 8, 'not': 1, 'in': 2, '': 1}),\n",
       "             'and': Counter({'</s>': 29, 'group': 2}),\n",
       "             '=': Counter({'a': 2,\n",
       "                      '</s>': 11,\n",
       "                      'y': 4,\n",
       "                      'ance': 4,\n",
       "                      '_': 5,\n",
       "                      'up': 2,\n",
       "                      'al': 2,\n",
       "                      'not': 39,\n",
       "                      'in': 34,\n",
       "                      '': 33,\n",
       "                      '.': 1,\n",
       "                      'd': 2,\n",
       "                      '=': 8,\n",
       "                      ';': 1,\n",
       "                      '>': 4,\n",
       "                      '\"': 9,\n",
       "                      's': 19,\n",
       "                      'ment': 1,\n",
       "                      'language': 4,\n",
       "                      'foreign': 3,\n",
       "                      '*': 1,\n",
       "                      'c': 2}),\n",
       "             'having': Counter({'</s>': 47, 'order': 31, 'a': 2}),\n",
       "             '!=': Counter({'=!=': 16, 'in!=': 2, '=t=': 1, '!=': 1}),\n",
       "             'union': Counter({'NUM': 2, '</s>': 2, 'as': 2}),\n",
       "             'limit': Counter({'des': 6}),\n",
       "             'sum': Counter({'*': 12, 'count': 5, '': 4}),\n",
       "             'asc': Counter({'desc': 17, '</s>c': 2}),\n",
       "             ')': Counter({'group)': 2, ')': 1, 't': 4, '))': 2, ');': 2}),\n",
       "             ',': Counter({'joint': 1}),\n",
       "             'in': Counter({'=': 4})})"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select song_name from singer where age > --> = (()\n",
      "select song_name from singer where age > --> = (()\n",
      "select count(*) from concert where stadium_id = -->  (()\n",
      "select count(*) from concert where stadium_id = -->  (()\n",
      "select t2.make, t1.year from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t1.year = --> 2004 (()\n",
      "select t2.make, t1.year from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t1.year = --> 2004 (()\n",
      "select count(*) from cars_data where accelerate > --> = (()\n",
      "select count(*) from cars_data where accelerate > --> = (()\n",
      "select t2.makeid, t2.make from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t1.horsepower > -->  (()\n",
      "select name from shop where number_products > --> = (()\n",
      "select name from shop where number_products > --> = (()\n",
      "select name from museum where num_of_staff > --> = (()\n",
      "select name from country where surfacearea > --> = (()\n",
      "select name from country where surfacearea > --> = (()\n",
      "select name from country where continent = \"Asia\" and population > --> = (()\n",
      "select name from country where continent = \"Asia\" and population > --> = (()\n",
      "select count(*), district from city where population > --> 100 (()\n",
      "select count(*), district from city where population > --> 100 (()\n",
      "select t1.name, t2.date_of_treatment from dogs as t1 join treatments as t2 on t1.dog_id = t2.dog_id where t1.breed_code = -->  (()\n",
      "select t1.name, t2.date_of_treatment from dogs as t1 join treatments as t2 on t1.dog_id = t2.dog_id where t1.breed_code = -->  (()\n",
      "select t1.last_name from owners as t1 join dogs as t2 on t1.owner_id = t2.owner_id where t2.age = --> 1 (()\n",
      "select t1.last_name from owners as t1 join dogs as t2 on t1.owner_id = t2.owner_id where t2.age = --> 1 (()\n"
     ]
    }
   ],
   "source": [
    "for idx in trace_sample_ids_by_exp_tok['(']:\n",
    "    d = good_samples[idx]\n",
    "    print(f\"{d['dec_prompt']} --> {d['corrupted_answer']} ({d['expect']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-6.1: attention corruption effect - syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp6_1_attention_corruption_effect_syntax/exp=6.1.1_dev-attn_crpt=logits.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10233, (2375, 2375), 1623, 6235, 7858, 'good / correct = 2375 / 8610')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d.get('is_good_sample', True):\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_samples[0]['trace_scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += v\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t->s': defaultdict(int,\n",
       "             {'low_layers': 0.9873034850396216,\n",
       "              'high_layers': 0.9794485656297967,\n",
       "              'all_layers': 0.9705235183159128}),\n",
       " 's->t': defaultdict(int,\n",
       "             {'low_layers': 0.9914981258135093,\n",
       "              'high_layers': 0.9701850305394514,\n",
       "              'all_layers': 0.9438354478774255}),\n",
       " 't<->s': defaultdict(int,\n",
       "             {'low_layers': 0.9846226840465281,\n",
       "              'high_layers': 0.9617710263219753,\n",
       "              'all_layers': 0.9230146904192555}),\n",
       " 't->p': defaultdict(int,\n",
       "             {'low_layers': 0.9806906042866831,\n",
       "              'high_layers': 0.889322833697198,\n",
       "              'all_layers': 0.8364523902912913}),\n",
       " 's->p': defaultdict(int,\n",
       "             {'low_layers': 0.9860267275776025,\n",
       "              'high_layers': 0.9480603549151314,\n",
       "              'all_layers': 0.9385463390567251}),\n",
       " 'ts->p': defaultdict(int,\n",
       "             {'low_layers': 0.9725087593267217,\n",
       "              'high_layers': 0.7826832817374065,\n",
       "              'all_layers': 0.6455722338362194}),\n",
       " 't->t': defaultdict(int,\n",
       "             {'low_layers': 0.9536315989037909,\n",
       "              'high_layers': 0.9105434243858079,\n",
       "              'all_layers': 0.7346053336587007}),\n",
       " 's->s': defaultdict(int,\n",
       "             {'low_layers': 0.8818130838352181,\n",
       "              'high_layers': 0.9008996876131293,\n",
       "              'all_layers': 0.8485663077117429}),\n",
       " 'all': defaultdict(int,\n",
       "             {'low_layers': 0.6232894862470176,\n",
       "              'high_layers': 0.23267148181337774,\n",
       "              'all_layers': 0.034856813143760025})}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t->s    \t0.9873\t0.9794\t0.9705\n",
      "s->t    \t0.9915\t0.9702\t0.9438\n",
      "t<->s   \t0.9846\t0.9618\t0.9230\n",
      "t->p    \t0.9807\t0.8893\t0.8365\n",
      "s->p    \t0.9860\t0.9481\t0.9385\n",
      "ts->p   \t0.9725\t0.7827\t0.6456\n",
      "t->t    \t0.9536\t0.9105\t0.7346\n",
      "s->s    \t0.8818\t0.9009\t0.8486\n",
      "all     \t0.6233\t0.2327\t0.0349\n"
     ]
    }
   ],
   "source": [
    "layers_keys = ['low_layers', 'high_layers', 'all_layers']\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    print_l = f'{sect_k:<8s}'\n",
    "    for k in layers_keys:\n",
    "        s = sect_d[k]\n",
    "        print_l += f'\\t{s:.4f}'\n",
    "    print(print_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corruption overall effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict[str, int]: expect_tok -> num of effective / not effective corruptions (all)\n",
    "eff_counter = Counter()\n",
    "neff_counter = Counter()\n",
    "\n",
    "for d in good_samples:\n",
    "    eff_counter[d['expect']] += 1\n",
    "for d in bad_samples:\n",
    "    if d['correct_prediction']:\n",
    "        # \"too easy\", corruption not effective \n",
    "        neff_counter[d['expect']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_rate_d = dict()\n",
    "\n",
    "for k in list(set(eff_counter.keys()) | set(neff_counter.keys())):\n",
    "    eff_c = eff_counter[k]\n",
    "    neff_c = neff_counter[k]\n",
    "    eff_r = 1.0 * eff_c / (eff_c + neff_c)\n",
    "    eff_rate_d[k] = eff_r\n",
    "    # print(f'{k:<10s}{eff_c:5d} /{eff_c + neff_c:5d} = {eff_r:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union\t6\t6\t1.0000\n",
      "!=\t20\t20\t1.0000\n",
      "like\t12\t12\t1.0000\n",
      "or\t34\t34\t1.0000\n",
      "asc\t19\t19\t1.0000\n",
      "distinct\t26\t26\t1.0000\n",
      "between\t6\t6\t1.0000\n",
      "except\t21\t21\t1.0000\n",
      "intersect\t34\t34\t1.0000\n",
      "not\t45\t46\t0.9783\n",
      "avg\t63\t65\t0.9692\n",
      "max\t29\t30\t0.9667\n",
      "having\t77\t81\t0.9506\n",
      "group\t241\t265\t0.9094\n",
      "sum\t20\t22\t0.9091\n",
      "order\t197\t221\t0.8914\n",
      "min\t14\t18\t0.7778\n",
      "and\t29\t39\t0.7436\n",
      "count\t294\t406\t0.7241\n",
      "where\t350\t516\t0.6783\n",
      ">\t68\t101\t0.6733\n",
      ")\t13\t23\t0.5652\n",
      "desc\t82\t164\t0.5000\n",
      ">=\t11\t30\t0.3667\n",
      "from\t263\t1196\t0.2199\n",
      "in\t8\t50\t0.1600\n",
      "limit\t26\t177\t0.1469\n",
      "(\t98\t675\t0.1452\n",
      "=\t128\t968\t0.1322\n",
      "join\t44\t496\t0.0887\n",
      "as\t52\t952\t0.0546\n",
      "*\t10\t381\t0.0262\n",
      "by\t0\t516\t0.0000\n",
      "on\t0\t516\t0.0000\n",
      "select\t0\t88\t0.0000\n"
     ]
    }
   ],
   "source": [
    "for k, eff_r in sorted(eff_rate_d.items(), key=lambda x: x[1], reverse=True):\n",
    "    eff_c = eff_counter[k]\n",
    "    neff_c = neff_counter[k]\n",
    "    all_c = eff_c + neff_c\n",
    "    if all_c <= 2: continue\n",
    "    if k.isnumeric(): continue\n",
    "#     print(f'{k:<10s}{eff_c:5d} /{all_c:5d} = {eff_r:.4f}')\n",
    "    print(f'{k}\\t{eff_c}\\t{all_c}\\t{eff_r:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by expect syntax token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: (expect_tok, sect_k, layer) -> [scores]\n",
    "trace_scores_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "trace_scores_avg_by_exp_tok = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "trace_scores_cnt_by_exp_tok = defaultdict(int)  # no sect key & layer key \n",
    "\n",
    "trace_sample_ids_by_exp_tok = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(good_samples):\n",
    "    expect = d['expect']\n",
    "    trace_sample_ids_by_exp_tok[expect].append(i)\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for layer_k, v in sect_d.items():\n",
    "            trace_scores_by_exp_tok[expect][sect_k][layer_k].append(v)\n",
    "\n",
    "for exp_tok, d1 in trace_scores_by_exp_tok.items():\n",
    "    if exp_tok.isnumeric(): continue\n",
    "    for sect_k, d2 in d1.items():\n",
    "        for layer_k, scores in d2.items():\n",
    "            if len(scores) <= 2: continue\n",
    "            trace_scores_avg_by_exp_tok[exp_tok][sect_k][layer_k] = np.mean(scores)\n",
    "            trace_scores_cnt_by_exp_tok[exp_tok] = len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'count': 294,\n",
       "             'order': 197,\n",
       "             'desc': 82,\n",
       "             'avg': 63,\n",
       "             'min': 14,\n",
       "             'max': 29,\n",
       "             'where': 350,\n",
       "             '=': 128,\n",
       "             'distinct': 26,\n",
       "             'from': 263,\n",
       "             '>': 68,\n",
       "             'group': 241,\n",
       "             '(': 98,\n",
       "             'between': 6,\n",
       "             'limit': 26,\n",
       "             'or': 34,\n",
       "             '>=': 11,\n",
       "             'not': 45,\n",
       "             'intersect': 34,\n",
       "             'except': 21,\n",
       "             'as': 52,\n",
       "             'join': 44,\n",
       "             'like': 12,\n",
       "             'and': 29,\n",
       "             'in': 8,\n",
       "             'having': 77,\n",
       "             '!=': 20,\n",
       "             '*': 10,\n",
       "             'union': 6,\n",
       "             'sum': 20,\n",
       "             'asc': 19,\n",
       "             ')': 13})"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_exp_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'t->s': defaultdict(float,\n",
       "                         {'low_layers': 0.9978861685107354,\n",
       "                          'high_layers': 0.9932368714425738,\n",
       "                          'all_layers': 0.9911034725571596}),\n",
       "             's->t': defaultdict(float,\n",
       "                         {'low_layers': 0.9994523721892817,\n",
       "                          'high_layers': 0.9979493310865091,\n",
       "                          'all_layers': 0.997748848329596}),\n",
       "             't<->s': defaultdict(float,\n",
       "                         {'low_layers': 0.998062480874613,\n",
       "                          'high_layers': 0.995554579890707,\n",
       "                          'all_layers': 0.9959644333643167}),\n",
       "             't->p': defaultdict(float,\n",
       "                         {'low_layers': 0.9941589293855347,\n",
       "                          'high_layers': 0.9844484830047099,\n",
       "                          'all_layers': 0.9640641826280487}),\n",
       "             's->p': defaultdict(float,\n",
       "                         {'low_layers': 0.9997543060049718,\n",
       "                          'high_layers': 0.9865310551390487,\n",
       "                          'all_layers': 0.9850442271527587}),\n",
       "             'ts->p': defaultdict(float,\n",
       "                         {'low_layers': 0.992053749685993,\n",
       "                          'high_layers': 0.9076947870914203,\n",
       "                          'all_layers': 0.7469466893840571}),\n",
       "             't->t': defaultdict(float,\n",
       "                         {'low_layers': 0.95961485076646,\n",
       "                          'high_layers': 0.9813218236079703,\n",
       "                          'all_layers': 0.8608877147373191}),\n",
       "             's->s': defaultdict(float,\n",
       "                         {'low_layers': 0.9938991388657068,\n",
       "                          'high_layers': 0.9873157823699856,\n",
       "                          'all_layers': 0.8691012370157356}),\n",
       "             'all': defaultdict(float,\n",
       "                         {'low_layers': 0.7315069800832695,\n",
       "                          'high_layers': 0.6354717421335181,\n",
       "                          'all_layers': 0.02197208333187588})})"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg_by_exp_tok['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "sect_k = 't<->s'\n",
    "layer_k = 'all_layers'\n",
    "scores_d = dict()\n",
    "\n",
    "for exp_tok, d1 in trace_scores_avg_by_exp_tok.items():\n",
    "    s = d1[sect_k][layer_k]\n",
    "    scores_d[exp_tok] = s\n",
    "    # print(f'{exp_tok:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">=        1.0000\n",
      ">         1.0000\n",
      "like      1.0000\n",
      "*         1.0000\n",
      "min       1.0000\n",
      "between   1.0000\n",
      "in        0.9992\n",
      "avg       0.9972\n",
      "count     0.9960\n",
      "(         0.9946\n",
      "desc      0.9942\n",
      "having    0.9894\n",
      "order     0.9826\n",
      "!=        0.9825\n",
      "=         0.9786\n",
      "group     0.9771\n",
      "max       0.9741\n",
      ")         0.9716\n",
      "where     0.9702\n",
      "limit     0.9684\n",
      "from      0.9671\n",
      "or        0.9582\n",
      "intersect 0.9522\n",
      "asc       0.9437\n",
      "except    0.9415\n",
      "not       0.9360\n",
      "sum       0.8969\n",
      "as        0.8349\n",
      "distinct  0.8284\n",
      "union     0.8037\n",
      "and       0.6727\n",
      "join      0.4976\n"
     ]
    }
   ],
   "source": [
    "for k, s in sorted(scores_d.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{k:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exp_toks = sorted(list(trace_scores_cnt_by_exp_tok.keys()))\n",
    "all_sections = list(good_samples[0]['trace_scores'].keys())\n",
    "\n",
    "print_str = '\\t'.join(['Syntax-tok'] + all_sections + ['Eff_cnt', 'All_cnt', 'Eff_rate']) + '\\n'\n",
    "\n",
    "for exp_tok in all_exp_toks:\n",
    "    print_str += f'{exp_tok:<10s}'\n",
    "    for sect_k in all_sections:\n",
    "        s = trace_scores_avg_by_exp_tok[exp_tok][sect_k]['all_layers']\n",
    "        print_str += f'\\t{s:.4f}'\n",
    "    eff_c = eff_counter[exp_tok]\n",
    "    neff_c = neff_counter[exp_tok]\n",
    "    all_c = eff_c + neff_c\n",
    "    eff_r = eff_rate_d[exp_tok]\n",
    "    print_str += f'\\t{eff_c:<7d}\\t{all_c:<7d}\\t{eff_r:.4f}'\n",
    "    print_str += '\\n'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntax-tok\tt->s\ts->t\tt<->s\tt->p\ts->p\tts->p\tt->t\ts->s\tall\tEff_cnt\tAll_cnt\tEff_rate\n",
      "!=        \t0.9984\t0.9995\t0.9825\t0.8485\t0.9998\t0.9070\t0.3025\t0.9193\t0.0284\t20     \t20     \t1.0000\n",
      "(         \t0.9999\t0.9794\t0.9946\t0.9719\t0.9795\t0.9685\t0.8983\t0.9467\t0.1856\t98     \t675    \t0.1452\n",
      ")         \t0.9257\t0.9926\t0.9716\t0.9914\t0.9074\t0.8420\t0.9244\t0.4715\t0.1108\t13     \t23     \t0.5652\n",
      "*         \t1.0000\t0.9999\t1.0000\t0.9997\t0.9999\t0.9998\t0.9999\t0.9982\t0.1802\t10     \t381    \t0.0262\n",
      "=         \t0.9784\t0.9923\t0.9786\t0.9378\t0.8940\t0.7439\t0.9466\t0.5933\t0.1149\t128    \t968    \t0.1322\n",
      ">         \t1.0000\t1.0000\t1.0000\t0.9509\t0.9990\t0.9652\t0.8193\t0.9845\t0.0219\t68     \t101    \t0.6733\n",
      ">=        \t1.0000\t1.0000\t1.0000\t0.9151\t1.0000\t0.9048\t0.2593\t0.9964\t0.1703\t11     \t30     \t0.3667\n",
      "and       \t0.7931\t0.8981\t0.6727\t0.4962\t0.8409\t0.3468\t0.3603\t0.6749\t0.0554\t29     \t39     \t0.7436\n",
      "as        \t0.9212\t0.8936\t0.8349\t0.7992\t0.5034\t0.3457\t0.8478\t0.3288\t0.1002\t52     \t952    \t0.0546\n",
      "asc       \t0.9723\t0.9096\t0.9437\t0.4939\t0.8596\t0.3612\t0.6133\t0.6725\t0.0408\t19     \t19     \t1.0000\n",
      "avg       \t0.9996\t0.9940\t0.9972\t0.7660\t0.9996\t0.3619\t0.7743\t0.9513\t0.0360\t63     \t65     \t0.9692\n",
      "between   \t0.9999\t0.9999\t1.0000\t0.7788\t0.9999\t0.3407\t0.0009\t0.9999\t0.0000\t6      \t6      \t1.0000\n",
      "count     \t0.9911\t0.9977\t0.9960\t0.9641\t0.9850\t0.7469\t0.8609\t0.8691\t0.0220\t294    \t406    \t0.7241\n",
      "desc      \t0.9939\t0.9992\t0.9942\t0.9198\t0.9191\t0.7296\t0.9044\t0.6997\t0.1144\t82     \t164    \t0.5000\n",
      "distinct  \t0.8663\t0.8651\t0.8284\t0.6270\t0.9118\t0.4787\t0.6194\t0.7636\t0.0014\t26     \t26     \t1.0000\n",
      "except    \t0.9517\t0.9847\t0.9415\t0.6213\t0.9311\t0.0783\t0.4062\t0.7137\t0.0002\t21     \t21     \t1.0000\n",
      "from      \t0.9924\t0.9703\t0.9671\t0.9781\t0.9519\t0.6276\t0.8407\t0.5194\t0.1384\t263    \t1196   \t0.2199\n",
      "group     \t0.9895\t0.9925\t0.9771\t0.8332\t0.9838\t0.5694\t0.9167\t0.7823\t0.0282\t241    \t265    \t0.9094\n",
      "having    \t0.9978\t0.9924\t0.9894\t0.5962\t0.9993\t0.3893\t0.8985\t0.9348\t0.0262\t77     \t81     \t0.9506\n",
      "in        \t0.9973\t0.9995\t0.9992\t0.9995\t0.9253\t0.5859\t0.7717\t0.3267\t0.1096\t8      \t50     \t0.1600\n",
      "intersect \t0.9649\t0.9938\t0.9522\t0.2385\t0.9592\t0.0575\t0.4348\t0.8243\t0.0001\t34     \t34     \t1.0000\n",
      "join      \t0.9099\t0.6489\t0.4976\t0.7286\t0.3030\t0.1984\t0.7286\t0.1891\t0.0158\t44     \t496    \t0.0887\n",
      "like      \t1.0000\t1.0000\t1.0000\t0.9997\t0.9997\t0.8233\t0.2700\t0.8809\t0.0062\t12     \t12     \t1.0000\n",
      "limit     \t0.9932\t0.9854\t0.9684\t0.8400\t0.9992\t0.7895\t0.8076\t0.7534\t0.1531\t26     \t177    \t0.1469\n",
      "max       \t0.8483\t0.9925\t0.9741\t0.8141\t0.9458\t0.4659\t0.5214\t0.9008\t0.0633\t29     \t30     \t0.9667\n",
      "min       \t0.9962\t1.0000\t1.0000\t0.9906\t0.9993\t0.9377\t0.7412\t0.9999\t0.0450\t14     \t18     \t0.7778\n",
      "not       \t0.9884\t0.9515\t0.9360\t0.9510\t0.9067\t0.6624\t0.8928\t0.7208\t0.0117\t45     \t46     \t0.9783\n",
      "or        \t0.9788\t0.9728\t0.9582\t0.7773\t0.9856\t0.9181\t0.4193\t0.9718\t0.0311\t34     \t34     \t1.0000\n",
      "order     \t0.9964\t0.9891\t0.9826\t0.7079\t0.9802\t0.4836\t0.8542\t0.8393\t0.0680\t197    \t221    \t0.8914\n",
      "sum       \t0.9054\t0.9988\t0.8969\t0.8431\t0.9998\t0.6812\t0.4672\t0.9511\t0.0119\t20     \t22     \t0.9091\n",
      "union     \t0.9990\t0.8977\t0.8037\t0.2034\t0.7390\t0.3218\t0.0174\t0.7111\t0.0001\t6      \t6      \t1.0000\n",
      "where     \t0.9820\t0.9900\t0.9702\t0.9035\t0.9576\t0.7533\t0.8924\t0.7699\t0.0858\t350    \t516    \t0.6783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(print_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', '!', '=']\n",
      "['▁(']\n",
      "['▁', ')']\n",
      "['▁*']\n",
      "['▁=']\n",
      "['▁>']\n",
      "['▁>', '=']\n",
      "['▁and']\n",
      "['▁as']\n",
      "['▁as', 'c']\n",
      "['▁', 'a', 'v', 'g']\n",
      "['▁between']\n",
      "['▁count']\n",
      "['▁des', 'c']\n",
      "['▁distinct']\n",
      "['▁except']\n",
      "['▁from']\n",
      "['▁group']\n",
      "['▁having']\n",
      "['▁in']\n",
      "['▁intersect']\n",
      "['▁join']\n",
      "['▁like']\n",
      "['▁limit']\n",
      "['▁max']\n",
      "['▁min']\n",
      "['▁not']\n",
      "['▁or']\n",
      "['▁order']\n",
      "['▁sum']\n",
      "['▁union']\n",
      "['▁where']\n"
     ]
    }
   ],
   "source": [
    "# Issue checking: multi-token \n",
    "for exp_tok in all_exp_toks:\n",
    "    print(mt_uskg.tokenizer.tokenize(exp_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-6.2: dec cross attention corruption effect - syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect_type = 'table_alias'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp6_2_decoder_cross_attention_corruption_syntax/exp=6.2.1_dev-attn_crpt=logits.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10233, (5731, 5731), 1623, 2879, 4502, 'good / correct = 5731 / 8610')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d.get('is_good_sample', True):\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_samples[0]['trace_scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += v\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': defaultdict(int,\n",
       "             {'q1_layers': 0.8251662824628329,\n",
       "              'q2_layers': 0.9568811011561555,\n",
       "              'q3_layers': 0.9585451913219025,\n",
       "              'q4_layers': 0.9586033384734522,\n",
       "              'low_layers': 0.5032536523294612,\n",
       "              'mid_layers': 0.7412946459743097,\n",
       "              'high_layers': 0.7327423463639,\n",
       "              'all_layers': 0.057349480442763175}),\n",
       " 'ans->t': defaultdict(int,\n",
       "             {'q1_layers': 0.9954168156351754,\n",
       "              'q2_layers': 0.9905822788459185,\n",
       "              'q3_layers': 0.9671664178380461,\n",
       "              'q4_layers': 0.9757743479523219,\n",
       "              'low_layers': 0.9790280398693059,\n",
       "              'mid_layers': 0.8837345000447828,\n",
       "              'high_layers': 0.8696248513307187,\n",
       "              'all_layers': 0.7785073726874928}),\n",
       " 'all->t': defaultdict(int,\n",
       "             {'q1_layers': 0.9946716999747656,\n",
       "              'q2_layers': 0.9847246179079293,\n",
       "              'q3_layers': 0.9633879014188113,\n",
       "              'q4_layers': 0.975774884946337,\n",
       "              'low_layers': 0.9654529441792826,\n",
       "              'mid_layers': 0.8466091753986138,\n",
       "              'high_layers': 0.8652557141489696,\n",
       "              'all_layers': 0.745349026128539}),\n",
       " 'ans->s': defaultdict(int,\n",
       "             {'q1_layers': 0.9868191454594858,\n",
       "              'q2_layers': 0.9900647226470655,\n",
       "              'q3_layers': 0.9947073662803396,\n",
       "              'q4_layers': 0.9962095590063736,\n",
       "              'low_layers': 0.9646212092317603,\n",
       "              'mid_layers': 0.9870737207331394,\n",
       "              'high_layers': 0.9942978987104565,\n",
       "              'all_layers': 0.9605662906578918}),\n",
       " 'all->s': defaultdict(int,\n",
       "             {'q1_layers': 0.9495511247867173,\n",
       "              'q2_layers': 0.9846415213288342,\n",
       "              'q3_layers': 0.9945589672603282,\n",
       "              'q4_layers': 0.9961051629829253,\n",
       "              'low_layers': 0.8973616218084921,\n",
       "              'mid_layers': 0.9809546646488222,\n",
       "              'high_layers': 0.9944054611041094,\n",
       "              'all_layers': 0.8988139426412731}),\n",
       " 'ans->p': defaultdict(int,\n",
       "             {'q1_layers': 0.9945866083120604,\n",
       "              'q2_layers': 0.9926594899618697,\n",
       "              'q3_layers': 0.9532355621472774,\n",
       "              'q4_layers': 0.9776786978197944,\n",
       "              'low_layers': 0.9875606488909925,\n",
       "              'mid_layers': 0.9265851658627762,\n",
       "              'high_layers': 0.8738844505183258,\n",
       "              'all_layers': 0.8132977273932551}),\n",
       " 'all->p': defaultdict(int,\n",
       "             {'q1_layers': 0.9803491226451468,\n",
       "              'q2_layers': 0.9782970041354968,\n",
       "              'q3_layers': 0.9427931581354659,\n",
       "              'q4_layers': 0.9773308596161139,\n",
       "              'low_layers': 0.9315862115450884,\n",
       "              'mid_layers': 0.8687140840081402,\n",
       "              'high_layers': 0.8453800312842668,\n",
       "              'all_layers': 0.6508764799719446}),\n",
       " 'ans->o': defaultdict(int,\n",
       "             {'q1_layers': 0.9975263366179615,\n",
       "              'q2_layers': 0.9975120422260193,\n",
       "              'q3_layers': 0.997610687023889,\n",
       "              'q4_layers': 0.9976217283189162,\n",
       "              'low_layers': 0.9974056234005712,\n",
       "              'mid_layers': 0.9974438535893615,\n",
       "              'high_layers': 0.997580882408215,\n",
       "              'all_layers': 0.9972983276660978}),\n",
       " 'all->o': defaultdict(int,\n",
       "             {'q1_layers': 0.9974374340749956,\n",
       "              'q2_layers': 0.9975524941282816,\n",
       "              'q3_layers': 0.9975957313438419,\n",
       "              'q4_layers': 0.9976251479625037,\n",
       "              'low_layers': 0.9973218925329762,\n",
       "              'mid_layers': 0.9974766157982217,\n",
       "              'high_layers': 0.9975722592146562,\n",
       "              'all_layers': 0.9971902840498583}),\n",
       " 'ans->t+o': defaultdict(int,\n",
       "             {'q1_layers': 0.9954431360305773,\n",
       "              'q2_layers': 0.9904148153549044,\n",
       "              'q3_layers': 0.9662767773823581,\n",
       "              'q4_layers': 0.9754596308576543,\n",
       "              'low_layers': 0.9789654327365731,\n",
       "              'mid_layers': 0.8798708824019926,\n",
       "              'high_layers': 0.8645496393109454,\n",
       "              'all_layers': 0.7742868436240915}),\n",
       " 'all->t+o': defaultdict(int,\n",
       "             {'q1_layers': 0.9946770293224044,\n",
       "              'q2_layers': 0.984802173987723,\n",
       "              'q3_layers': 0.9626610521847996,\n",
       "              'q4_layers': 0.9754755938350108,\n",
       "              'low_layers': 0.9651606862127082,\n",
       "              'mid_layers': 0.8411415185035732,\n",
       "              'high_layers': 0.860222189190524,\n",
       "              'all_layers': 0.7417609378669952})}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXX\tq1_layers  \tq2_layers  \tq3_layers  \tq4_layers  \tlow_layers \tmid_layers \thigh_layers\tall_layers \n",
      "all    \t0.8252     \t0.9569     \t0.9585     \t0.9586     \t0.5033     \t0.7413     \t0.7327     \t0.0573     \n",
      "ans->t \t0.9954     \t0.9906     \t0.9672     \t0.9758     \t0.9790     \t0.8837     \t0.8696     \t0.7785     \n",
      "all->t \t0.9947     \t0.9847     \t0.9634     \t0.9758     \t0.9655     \t0.8466     \t0.8653     \t0.7453     \n",
      "ans->s \t0.9868     \t0.9901     \t0.9947     \t0.9962     \t0.9646     \t0.9871     \t0.9943     \t0.9606     \n",
      "all->s \t0.9496     \t0.9846     \t0.9946     \t0.9961     \t0.8974     \t0.9810     \t0.9944     \t0.8988     \n",
      "ans->p \t0.9946     \t0.9927     \t0.9532     \t0.9777     \t0.9876     \t0.9266     \t0.8739     \t0.8133     \n",
      "all->p \t0.9803     \t0.9783     \t0.9428     \t0.9773     \t0.9316     \t0.8687     \t0.8454     \t0.6509     \n",
      "ans->o \t0.9975     \t0.9975     \t0.9976     \t0.9976     \t0.9974     \t0.9974     \t0.9976     \t0.9973     \n",
      "all->o \t0.9974     \t0.9976     \t0.9976     \t0.9976     \t0.9973     \t0.9975     \t0.9976     \t0.9972     \n",
      "ans->t+o\t0.9954     \t0.9904     \t0.9663     \t0.9755     \t0.9790     \t0.8799     \t0.8645     \t0.7743     \n",
      "all->t+o\t0.9947     \t0.9848     \t0.9627     \t0.9755     \t0.9652     \t0.8411     \t0.8602     \t0.7418     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# layers_keys = trace_scores_avg['all'].keys()\n",
    "\n",
    "# for sect_k, sect_d in trace_scores_avg.items():\n",
    "#     print_l = f'{sect_k:<8s}'\n",
    "#     for k in layers_keys:\n",
    "#         s = sect_d[k]\n",
    "#         print_l += f'\\t{s:.4f}'\n",
    "#     print(print_l)\n",
    "\n",
    "format_print_2D_dict(trace_scores_avg, head_col_w=7, col_w=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg by expect syntax token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_by_exp_tok = exp6_ob_by_exp_tok(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'count': 394,\n",
       "             '(': 407,\n",
       "             'order': 219,\n",
       "             'avg': 63,\n",
       "             'min': 18,\n",
       "             'max': 28,\n",
       "             'where': 502,\n",
       "             'distinct': 26,\n",
       "             'from': 702,\n",
       "             '>': 65,\n",
       "             'group': 265,\n",
       "             'by': 33,\n",
       "             'between': 6,\n",
       "             'desc': 156,\n",
       "             'or': 34,\n",
       "             'as': 561,\n",
       "             'on': 474,\n",
       "             '>=': 3,\n",
       "             'not': 46,\n",
       "             'intersect': 34,\n",
       "             'select': 44,\n",
       "             'except': 21,\n",
       "             '=': 409,\n",
       "             'join': 20,\n",
       "             'like': 10,\n",
       "             'in': 15,\n",
       "             'having': 62,\n",
       "             'and': 6,\n",
       "             'limit': 16,\n",
       "             '!=': 20,\n",
       "             '*': 10,\n",
       "             'union': 6,\n",
       "             'sum': 22,\n",
       "             'asc': 19,\n",
       "             ')': 17})"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_cnt_by_exp_tok = res_by_exp_tok['cnt']\n",
    "trace_scores_cnt_by_exp_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.exp6_ob_by_exp_tok.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'all': defaultdict(float,\n",
       "                         {'q1_layers': 0.9964363076889575,\n",
       "                          'q2_layers': 0.9963203995739143,\n",
       "                          'q3_layers': 0.9551561746639813,\n",
       "                          'q4_layers': 0.9972184849572061,\n",
       "                          'low_layers': 0.8215906578539822,\n",
       "                          'mid_layers': 0.46418598421683044,\n",
       "                          'high_layers': 0.7123522221803182,\n",
       "                          'all_layers': 0.014818084030064214}),\n",
       "             'ans->t': defaultdict(float,\n",
       "                         {'q1_layers': 0.9994401957480435,\n",
       "                          'q2_layers': 0.9989948929263855,\n",
       "                          'q3_layers': 0.9765654405254729,\n",
       "                          'q4_layers': 0.9960574505255004,\n",
       "                          'low_layers': 0.9980983920206273,\n",
       "                          'mid_layers': 0.7132947778204064,\n",
       "                          'high_layers': 0.8861730706122236,\n",
       "                          'all_layers': 0.44028362028290124}),\n",
       "             'all->t': defaultdict(float,\n",
       "                         {'q1_layers': 0.9988200697802045,\n",
       "                          'q2_layers': 0.998696686803992,\n",
       "                          'q3_layers': 0.9747582198957241,\n",
       "                          'q4_layers': 0.9960432086272288,\n",
       "                          'low_layers': 0.9967487218794484,\n",
       "                          'mid_layers': 0.6770446909783476,\n",
       "                          'high_layers': 0.8788389159396585,\n",
       "                          'all_layers': 0.35087384116220555}),\n",
       "             'ans->s': defaultdict(float,\n",
       "                         {'q1_layers': 0.9994106749592698,\n",
       "                          'q2_layers': 0.999712617415462,\n",
       "                          'q3_layers': 0.9995317062750686,\n",
       "                          'q4_layers': 0.999931743302321,\n",
       "                          'low_layers': 0.9998417478527515,\n",
       "                          'mid_layers': 0.9999815848878193,\n",
       "                          'high_layers': 0.999994937992338,\n",
       "                          'all_layers': 0.9999986511801705}),\n",
       "             'all->s': defaultdict(float,\n",
       "                         {'q1_layers': 0.999680691261582,\n",
       "                          'q2_layers': 0.9995500590595497,\n",
       "                          'q3_layers': 0.999525050977765,\n",
       "                          'q4_layers': 0.9999321718808963,\n",
       "                          'low_layers': 0.9963215853508354,\n",
       "                          'mid_layers': 0.9999843692113906,\n",
       "                          'high_layers': 0.9999947897371302,\n",
       "                          'all_layers': 0.9958879304246098}),\n",
       "             'ans->p': defaultdict(float,\n",
       "                         {'q1_layers': 0.9961130618582229,\n",
       "                          'q2_layers': 0.9985278386452476,\n",
       "                          'q3_layers': 0.9975578447586388,\n",
       "                          'q4_layers': 0.9945496145238731,\n",
       "                          'low_layers': 0.9889740733148207,\n",
       "                          'mid_layers': 0.9956819380297879,\n",
       "                          'high_layers': 0.9878297375131287,\n",
       "                          'all_layers': 0.957358345802683}),\n",
       "             'all->p': defaultdict(float,\n",
       "                         {'q1_layers': 0.9971128671505691,\n",
       "                          'q2_layers': 0.9970539765914684,\n",
       "                          'q3_layers': 0.9963113451518383,\n",
       "                          'q4_layers': 0.9941017802067215,\n",
       "                          'low_layers': 0.9868572877924169,\n",
       "                          'mid_layers': 0.9913899881699061,\n",
       "                          'high_layers': 0.9826842088918296,\n",
       "                          'all_layers': 0.900635620249951})})"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg_by_exp_tok = res_by_exp_tok['avg']\n",
    "trace_scores_avg_by_exp_tok['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "sect_k = 'ans->t'\n",
    "layer_k = 'all_layers'\n",
    "scores_d = dict()\n",
    "\n",
    "for exp_tok, d1 in trace_scores_avg_by_exp_tok.items():\n",
    "    s = d1[sect_k][layer_k]\n",
    "    scores_d[exp_tok] = s\n",
    "    # print(f'{exp_tok:<10s}{s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select    1.0000\n",
      "by        1.0000\n",
      "on        1.0000\n",
      "as        0.9977\n",
      "in        0.9977\n",
      ")         0.9955\n",
      "from      0.9942\n",
      "*         0.9826\n",
      "=         0.9823\n",
      "(         0.9583\n",
      "where     0.9210\n",
      "not       0.8927\n",
      "join      0.8654\n",
      "desc      0.8452\n",
      "having    0.8170\n",
      ">=        0.6667\n",
      "group     0.6521\n",
      "limit     0.6250\n",
      "like      0.5985\n",
      ">         0.5678\n",
      "min       0.5502\n",
      "except    0.5067\n",
      "count     0.4403\n",
      "sum       0.3922\n",
      "or        0.3801\n",
      "order     0.3762\n",
      "union     0.3335\n",
      "distinct  0.3008\n",
      "and       0.1670\n",
      "max       0.1403\n",
      "asc       0.0839\n",
      "intersect 0.0266\n",
      "!=        0.0208\n",
      "avg       0.0062\n",
      "between   0.0000\n"
     ]
    }
   ],
   "source": [
    "format_print_1D_dict(scores_d, sort_by='value', reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXX\tall\tans->t\tall->t\tans->s\tall->s\tans->p\tall->p\n",
      "!=        \t0.0013\t0.0208\t0.0001\t0.9509\t0.8203\t0.7167\t0.5739\n",
      "(         \t0.0747\t0.9583\t0.9549\t0.9997\t0.9923\t0.7309\t0.6955\n",
      ")         \t0.0212\t0.9955\t0.9951\t0.8845\t0.8465\t0.9982\t0.9014\n",
      "*         \t0.1240\t0.9826\t0.9720\t0.9978\t0.9306\t0.7433\t0.5726\n",
      "=         \t0.1195\t0.9823\t0.9761\t0.8742\t0.8298\t0.9526\t0.9377\n",
      ">         \t0.0210\t0.5678\t0.4234\t0.9599\t0.9359\t0.9659\t0.9533\n",
      ">=        \t0.1964\t0.6667\t0.6667\t1.0000\t1.0000\t0.9994\t0.8787\n",
      "and       \t0.1812\t0.1670\t0.1309\t0.9885\t0.6761\t0.9118\t0.6287\n",
      "as        \t0.0883\t0.9977\t0.9969\t0.9404\t0.8392\t0.9844\t0.8963\n",
      "asc       \t0.0000\t0.0839\t0.1381\t0.8809\t0.8523\t0.8530\t0.8652\n",
      "avg       \t0.0018\t0.0062\t0.0049\t1.0000\t1.0000\t0.9441\t0.9177\n",
      "between   \t0.0006\t0.0000\t0.0000\t0.9992\t0.9991\t0.9994\t0.9984\n",
      "by        \t0.0757\t1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t1.0000\n",
      "count     \t0.0148\t0.4403\t0.3509\t1.0000\t0.9959\t0.9574\t0.9006\n",
      "desc      \t0.0511\t0.8452\t0.8698\t0.9805\t0.9593\t0.9229\t0.7996\n",
      "distinct  \t0.0005\t0.3008\t0.2718\t0.9965\t0.9950\t0.8270\t0.7839\n",
      "except    \t0.0000\t0.5067\t0.0165\t0.9522\t0.8531\t0.7611\t0.7102\n",
      "from      \t0.0903\t0.9942\t0.9801\t0.9773\t0.9635\t0.7383\t0.6265\n",
      "group     \t0.0115\t0.6521\t0.4824\t0.9668\t0.9124\t0.9265\t0.5591\n",
      "having    \t0.0365\t0.8170\t0.6288\t0.9281\t0.9484\t0.9138\t0.7298\n",
      "in        \t0.1526\t0.9977\t0.9747\t1.0000\t0.6386\t0.9182\t0.7606\n",
      "intersect \t0.0004\t0.0266\t0.0006\t0.9967\t0.9195\t0.6850\t0.6866\n",
      "join      \t0.1764\t0.8654\t0.8762\t0.3481\t0.1003\t0.6876\t0.6440\n",
      "like      \t0.0016\t0.5985\t0.2897\t1.0000\t0.9999\t0.9997\t0.9992\n",
      "limit     \t0.1190\t0.6250\t0.6243\t0.9971\t0.9944\t0.8910\t0.7684\n",
      "max       \t0.0080\t0.1403\t0.0234\t0.9947\t0.9842\t0.7690\t0.7451\n",
      "min       \t0.0021\t0.5502\t0.2714\t0.9999\t1.0000\t0.6500\t0.6053\n",
      "not       \t0.0000\t0.8927\t0.5348\t0.9550\t0.5140\t0.8692\t0.8318\n",
      "on        \t0.0690\t1.0000\t1.0000\t1.0000\t0.9999\t0.9433\t0.1831\n",
      "or        \t0.0068\t0.3801\t0.0257\t0.9802\t0.8666\t0.9702\t0.9674\n",
      "order     \t0.0053\t0.3762\t0.2628\t0.9307\t0.8960\t0.9191\t0.7436\n",
      "select    \t0.1884\t1.0000\t1.0000\t1.0000\t1.0000\t0.7737\t0.8430\n",
      "sum       \t0.0000\t0.3922\t0.2025\t0.9733\t0.9657\t0.9125\t0.8589\n",
      "union     \t0.0005\t0.3335\t0.3333\t0.9997\t0.9999\t0.3831\t0.3370\n",
      "where     \t0.0129\t0.9210\t0.8000\t0.9285\t0.8903\t0.8458\t0.5845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_exp_toks = sorted(list(trace_scores_cnt_by_exp_tok.keys()))\n",
    "all_sections = list(good_samples[0]['trace_scores'].keys())\n",
    "\n",
    "_d = {exp_tok:\n",
    "          {sect_k: trace_scores_avg_by_exp_tok[exp_tok][sect_k]['all_layers']\n",
    "           for sect_k in all_sections}\n",
    "      for exp_tok in all_exp_toks}\n",
    "\n",
    "format_print_2D_dict(_d, all_k1=all_exp_toks, all_k2=all_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_ids_by_aspect = defaultdict(list)\n",
    "\n",
    "for i, d in enumerate(good_samples):\n",
    "    for asp_k, asp_v in d['category'].items():\n",
    "        asp_str_k = f'{asp_k}={asp_v}'\n",
    "        sample_ids_by_aspect[asp_str_k].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sql_hardness=easy', 689),\n",
       " ('sql_hardness=extra', 1402),\n",
       " ('sql_hardness=hard', 1004),\n",
       " ('sql_hardness=medium', 1843)}"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{(k, len(l)) for k, l in sample_ids_by_aspect.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asp_k -> avg/cnt/sample_ids -> exp_tok -> sect_k -> layer_k -> s\n",
    "all_res_by_exp_tok = {asp_k : exp6_ob_by_exp_tok(good_samples[i] for i in asp_sample_ids)\n",
    "                      for asp_k, asp_sample_ids in sample_ids_by_aspect.items()}\n",
    "\n",
    "# exp_tok -> [sect_k -> [layer_k -> s]]\n",
    "avg_d = all_res_by_exp_tok['sql_hardness=extra']['avg']\n",
    "\n",
    "all_exp_toks = sorted(list(avg_d.keys()))\n",
    "all_sections = list(avg_d[all_exp_toks[0]].keys())\n",
    "\n",
    "_d = {exp_tok:\n",
    "          {sect_k: avg_d[exp_tok][sect_k]['all_layers']\n",
    "           for sect_k in all_sections}\n",
    "      for exp_tok in all_exp_toks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\tall   \tans->t\tall->t\tans->s\tall->s\tans->p\tall->p\n",
      "(           \t0.0960\t0.9150\t0.9145\t0.9995\t0.9683\t0.5015\t0.4892\n",
      ")           \t0.0147\t0.9977\t0.9928\t0.9659\t0.9458\t0.9992\t0.9988\n",
      "*           \t0.2047\t1.0000\t1.0000\t0.9963\t0.8843\t0.9579\t0.6780\n",
      "=           \t0.1128\t0.9823\t0.9769\t0.7711\t0.7308\t0.9014\t0.8690\n",
      ">           \t0.0111\t0.5996\t0.5905\t0.9682\t0.8337\t0.8913\t0.8308\n",
      "as          \t0.0735\t0.9936\t0.9916\t0.9374\t0.8383\t0.9773\t0.8630\n",
      "avg         \t0.0001\t0.0003\t0.0001\t1.0000\t1.0000\t0.9980\t0.9884\n",
      "count       \t0.0166\t0.7992\t0.7450\t1.0000\t1.0000\t0.9679\t0.9111\n",
      "desc        \t0.0754\t0.9459\t0.9655\t1.0000\t1.0000\t0.9224\t0.8590\n",
      "distinct    \t0.0005\t0.5546\t0.5506\t0.9998\t0.9998\t0.8881\t0.8270\n",
      "except      \t0.0000\t0.2832\t0.0007\t0.8574\t0.6992\t0.5941\t0.5798\n",
      "from        \t0.0672\t0.9886\t0.9863\t0.9704\t0.9614\t0.7393\t0.6001\n",
      "group       \t0.0083\t0.3118\t0.1122\t0.9870\t0.8914\t0.8986\t0.3441\n",
      "having      \t0.0316\t0.8593\t0.4232\t0.7806\t0.9744\t0.7360\t0.7438\n",
      "in          \t0.1954\t1.0000\t1.0000\t1.0000\t0.7843\t0.9224\t0.7463\n",
      "intersect   \t0.0002\t0.0326\t0.0007\t0.9979\t0.9393\t0.6963\t0.6989\n",
      "join        \t0.1366\t0.7929\t0.8096\t0.2939\t0.0012\t0.5211\t0.4627\n",
      "limit       \t0.1183\t0.3333\t0.3333\t0.9990\t0.9852\t0.9979\t0.7007\n",
      "min         \t0.0001\t0.4418\t0.3291\t0.9995\t0.9999\t0.2870\t0.2307\n",
      "not         \t0.0000\t0.8387\t0.4470\t0.9174\t0.5643\t0.7416\t0.6721\n",
      "on          \t0.0841\t1.0000\t1.0000\t1.0000\t1.0000\t0.9182\t0.2170\n",
      "or          \t0.0053\t0.0042\t0.0000\t0.9997\t0.8246\t0.9999\t0.9996\n",
      "order       \t0.0126\t0.1665\t0.1381\t1.0000\t0.9583\t0.9471\t0.7631\n",
      "select      \t0.2025\t1.0000\t1.0000\t1.0000\t1.0000\t0.7238\t0.7857\n",
      "sum         \t0.0000\t0.7454\t0.2661\t1.0000\t1.0000\t0.9775\t0.8852\n",
      "union       \t0.0007\t0.0003\t0.0000\t0.9999\t1.0000\t0.5736\t0.5054\n",
      "where       \t0.0256\t0.8334\t0.6574\t0.9657\t0.9136\t0.7431\t0.4669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(_d, all_k1=all_exp_toks, all_k2=all_sections, col_w=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "_d = dict()\n",
    "\n",
    "h_list = ['easy', 'medium', 'hard', 'extra']\n",
    "\n",
    "for exp_tok in all_exp_toks:\n",
    "    _d[exp_tok] = {\n",
    "        h: all_res_by_exp_tok[f'sql_hardness={h}']['avg'][exp_tok]['all->t']['all_layers']\n",
    "        for h in h_list\n",
    "    }\n",
    "    for h in h_list:\n",
    "        _cnt = all_res_by_exp_tok[f'sql_hardness={h}']['cnt'][exp_tok]\n",
    "        if _cnt < 3:\n",
    "            # _d[exp_tok][h] = - 1 - _cnt\n",
    "            _d[exp_tok][h] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\teasy    \tmedium  \thard    \textra   \n",
      "(           \t1.0000  \t1.0000  \t0.8646  \t0.9145  \n",
      ")           \tnan     \tnan     \t0.9994  \t0.9928  \n",
      "*           \tnan     \tnan     \tnan     \t1.0000  \n",
      "=           \t0.9633  \t0.9855  \t0.9654  \t0.9769  \n",
      ">           \t0.4182  \t0.4960  \t0.2578  \t0.5905  \n",
      "as          \t1.0000  \t0.9998  \t1.0000  \t0.9916  \n",
      "avg         \t0.0046  \t0.0101  \t0.0000  \t0.0001  \n",
      "count       \t0.1406  \t0.1884  \t0.5781  \t0.7450  \n",
      "desc        \t0.4946  \t0.6938  \t0.9553  \t0.9655  \n",
      "distinct    \t0.0554  \t0.1229  \t0.3660  \t0.5506  \n",
      "except      \tnan     \tnan     \t0.0244  \t0.0007  \n",
      "from        \t0.9417  \t0.9906  \t0.9807  \t0.9863  \n",
      "group       \t0.5330  \t0.7302  \t0.3732  \t0.1122  \n",
      "having      \t0.6407  \t0.7282  \t0.2358  \t0.4232  \n",
      "in          \tnan     \tnan     \t0.9526  \t1.0000  \n",
      "intersect   \tnan     \tnan     \t0.0005  \t0.0007  \n",
      "join        \tnan     \tnan     \t0.9998  \t0.8096  \n",
      "limit       \tnan     \t0.9985  \tnan     \t0.3333  \n",
      "min         \tnan     \t0.1869  \tnan     \t0.3291  \n",
      "not         \tnan     \tnan     \t0.6226  \t0.4470  \n",
      "on          \t1.0000  \t1.0000  \t1.0000  \t1.0000  \n",
      "or          \tnan     \t0.0008  \t0.1426  \t0.0000  \n",
      "order       \t0.6007  \t0.3280  \t0.2023  \t0.1381  \n",
      "select      \tnan     \tnan     \t1.0000  \t1.0000  \n",
      "sum         \t0.1863  \t0.0601  \t0.4819  \t0.2661  \n",
      "union       \tnan     \tnan     \tnan     \t0.0000  \n",
      "where       \t0.8971  \t0.8593  \t0.7566  \t0.6574  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(_d, sort_k1_kwargs={}, col_w=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _d = dict()\n",
    "\n",
    "# for exp_tok in all_exp_toks:\n",
    "#     _d[exp_tok] = {\n",
    "#         'easy': all_res_by_exp_tok['sql_hardness=easy']['cnt'][exp_tok],\n",
    "#         'extra': all_res_by_exp_tok['sql_hardness=extra']['cnt'][exp_tok],\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp-7.0: layer skipping\n",
    "- Including 7.0.[0-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect_type = 'table_alias'\n",
    "\n",
    "# res_path = f'/home/yshao/Projects/rome/results/exp7_0_1_decoder_layer_skip_effect/exp=7.0.1_dev_{expect_type}.jsonl'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/exp7_0_3_decoder_syntax_layer_skip_effect/exp=7.0.3_dev.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10233, (8609, 8609), 1623, 1, 1624, 'good / correct = 8609 / 8610')"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d.get('is_good_sample', True):\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_scores_avg = {sect_k : defaultdict(int) for sect_k in good_samples[0]['trace_scores'].keys()}\n",
    "\n",
    "for d in good_samples:\n",
    "    for sect_k, sect_d in d['trace_scores'].items():\n",
    "        for k, v in sect_d.items():\n",
    "            trace_scores_avg[sect_k][k] += v\n",
    "\n",
    "for sect_k, sect_d in trace_scores_avg.items():\n",
    "    for k, s in sect_d.items():\n",
    "        sect_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXXXXXX\tq1_layers  \tq2_layers  \tq3_layers  \tq4_layers  \tlow_layers \tmid_layers \thigh_layers\tall_layers \n",
      "ans             \t0.0037     \t0.9564     \t0.7786     \t0.5126     \t0.0035     \t0.2946     \t0.0064     \t0.0000     \n",
      "all             \t0.0025     \t0.8803     \t0.7603     \t0.5126     \t0.0024     \t0.2397     \t0.0064     \t0.0000     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trace_scores_avg\n",
    "format_print_2D_dict(trace_scores_avg, head_col_w=16, col_w=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed inspect of sections splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_id = 111\n",
    "a_ex_id = 0\n",
    "\n",
    "ex = processed_spider_dev[ex_id]\n",
    "ex['text_in'], \\\n",
    "ex['struct_in'], \\\n",
    "ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu.create_analysis_sample_dicts(\n",
    "                mt_uskg, ex,\n",
    "                subject_type='column',\n",
    "                remove_struct_duplicate_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = a_ex_list[a_ex_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "_enc_toks = ctu.decode_tokens(mt_uskg.tokenizer, d['enc_tokenized']['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'the', 'accelerate', 'of', 'the', 'car', 'make', 'am', 'c', '', 'horn', 'e', 't', 'sport', 'about', '(', 's', 'w', ')', '?', ';', '', 'struct', 'e', 'd', 'knowledge', ':', '|', 'car', '_', '1', '|', 'continent', 's', '', ':', 'cont', 'i', 'd', '', ',', 'continent', '|', 'countries', '', ':', 'country', 'i', 'd', '', ',', 'country', 'name', '', ',', 'continent', '|', 'car', '_', 'makers', '', ':', '', 'i', 'd', '', ',', 'maker', '(', 'am', 'c', '', ')', '', ',', 'full', 'name', '', ',', 'country', '|', 'model', '_', 'list', '', ':', 'model', 'i', 'd', '', ',', 'maker', '', ',', 'model', '(', 'am', 'c', '', ')', '|', 'car', '_', 'name', 's', '', ':', 'make', 'i', 'd', '', ',', 'model', '(', 'am', 'c', '', ')', '', ',', 'make', '(', 'am', 'c', '', 'horn', 'e', 't', '', ',', 'am', 'c', '', 'horn', 'e', 't', 'sport', 'about', '(', 's', 'w', ')', '', ')', '|', 'cars', '_', 'data', '', ':', '', 'i', 'd', '', ',', '', 'mp', 'g', '', ',', '', 'cylinder', 's', '', ',', '', 'e', 'disp', 'l', '', ',', 'horsepower', '', ',', 'weight', '', ',', 'accelerate', '', ',', 'year', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(_enc_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'the', 'accelerate', 'of', 'the', 'car', 'make', 'am', 'c', '', 'horn', 'e', 't', 'sport', 'about', '(', 's', 'w', ')', '?']\n"
     ]
    }
   ],
   "source": [
    "text_st, text_ed = d['text_range']\n",
    "print(_enc_toks[text_st : text_ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['|', 'car', '_', '1', '|', 'continent', 's', '', ':', 'cont', 'i', 'd', '', ',', 'continent', '|', 'countries', '', ':', 'country', 'i', 'd', '', ',', 'country', 'name', '', ',', 'continent', '|', 'car', '_', 'makers', '', ':', '', 'i', 'd', '', ',', 'maker', '(', 'am', 'c', '', ')', '', ',', 'full', 'name', '', ',', 'country', '|', 'model', '_', 'list', '', ':', 'model', 'i', 'd', '', ',', 'maker', '', ',', 'model', '(', 'am', 'c', '', ')', '|', 'car', '_', 'name', 's', '', ':', 'make', 'i', 'd', '', ',', 'model', '(', 'am', 'c', '', ')', '', ',', 'make', '(', 'am', 'c', '', 'horn', 'e', 't', '', ',', 'am', 'c', '', 'horn', 'e', 't', 'sport', 'about', '(', 's', 'w', ')', '', ')', '|', 'cars', '_', 'data', '', ':', '', 'i', 'd', '', ',', '', 'mp', 'g', '', ',', '', 'cylinder', 's', '', ',', '', 'e', 'disp', 'l', '', ',', 'horsepower', '', ',', 'weight', '', ',', 'accelerate', '', ',', 'year']\n"
     ]
    }
   ],
   "source": [
    "struct_st, struct_ed = d['struct_range']\n",
    "print(_enc_toks[struct_st : struct_ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ',', 'accelerate', '', ',']\n"
     ]
    }
   ],
   "source": [
    "for self_st, self_ed in d['self_ranges']:\n",
    "    print(_enc_toks[self_st : self_ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['|', 'car', '_', '1', '|', 'continent', 's', '', ':', 'cont', 'i', 'd', '', ',', 'continent', '|', 'countries', '', ':', 'country', 'i', 'd', '', ',', 'country', 'name', '', ',', 'continent', '|', 'car', '_', 'makers', '', ':', '', 'i', 'd', '', ',', 'maker', '(', 'am', 'c', '', ')', '', ',', 'full', 'name', '', ',', 'country', '|', 'model', '_', 'list', '', ':', 'model', 'i', 'd', '', ',', 'maker', '', ',', 'model', '(', 'am', 'c', '', ')', '|', 'car', '_', 'name', 's', '', ':', 'make', 'i', 'd', '', ',', 'model', '(', 'am', 'c', '', ')', '', ',', 'make', '(', 'am', 'c', '', 'horn', 'e', 't', '', ',', 'am', 'c', '', 'horn', 'e', 't', 'sport', 'about', '(', 's', 'w', ')', '', ')', '|', 'cars', '_', 'data', '', ':', '', 'i', 'd', '', ',', '', 'mp', 'g', '', ',', '', 'cylinder', 's', '', ',', '', 'e', 'disp', 'l', '', ',', 'horsepower', '', ',', 'weight']\n",
      "['year']\n"
     ]
    }
   ],
   "source": [
    "for s, e in d['context_ranges']:\n",
    "    print(_enc_toks[s : e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_analysis_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_id = 111\n",
    "a_ex_id = 0\n",
    "\n",
    "ex = processed_spider_dev[ex_id]\n",
    "ex['text_in'], \\\n",
    "ex['struct_in'], \\\n",
    "ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp test\n",
    "# ex['seq_out'] = 'select year from cars_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu.create_analysis_sample_dicts(\n",
    "                mt_uskg, ex,\n",
    "                subject_type='column',\n",
    "                remove_struct_duplicate_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'enc_sentence', 'enc_tokenized', 'text_range', 'struct_range', 'struct_node_ranges_dict', 'dec_prompt', 'expect', 'expect_type', 'remove_struct_duplicate_nodes', 'parsed_struct_in', 'col2table', 'token_ranges_dict', 'node_name_ranges', 'expect_input_ranges', 'alias2table', 'self_ranges', 'context_ranges', 'category'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[a_ex_id].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 'cars_data', 't2': 'car_names'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[a_ex_id]['alias2table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(d['dec_prompt'], d['expect'], d['node_name_ranges'], d['expect_input_ranges'], '------',\\\n",
    "  d['self_ranges'], d['context_ranges'],\\\n",
    "  d['category'], '------' * 2) for d in a_ex_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(a_ex_list[a_ex_id])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ctu.add_clean_prediction(mt_uskg, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parse_sql_alias2table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 'table_name', 't2': 'other_table', 't3': 'ttt'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sql = 'SELECT t2.aaa , t3.ccc FROM table_name as t1 JOIN other_table as t2 on table_name.a_a = other_table.b_a JOIN ttt as t3 on other_table.asth = ttt.asth'\n",
    "ctu.parse_sql_alias2table(_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from \t None \t False\n",
      "as \t None \t False\n",
      "join \t None \t False\n",
      "as \t None \t False\n",
      "on \t None \t False\n",
      "= \t None \t False\n",
      "where \t None \t False\n",
      "= \t None \t False\n",
      "' \t ' \t True\n",
      "amc \t ' \t True\n",
      "hornet \t ' \t True\n",
      "sportabout \t ' \t True\n",
      "( \t ' \t True\n",
      "sw \t ' \t True\n",
      ") \t ' \t True\n",
      "' \t None \t True\n"
     ]
    }
   ],
   "source": [
    "_ex = copy.deepcopy(ex)\n",
    "# _ex['seq_out'] += 'order by t1.mpg'\n",
    "a_ex_list_syntax = ctu.create_syntax_analysis_sample_dicts(mt_uskg, _ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select t1.accelerate  -->  from\n",
      "select t1.accelerate from cars_data  -->  as\n",
      "select t1.accelerate from cars_data as t1  -->  join\n",
      "select t1.accelerate from cars_data as t1 join car_names  -->  as\n",
      "select t1.accelerate from cars_data as t1 join car_names as t2  -->  on\n",
      "select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id  -->  =\n",
      "select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid  -->  where\n",
      "select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make  -->  =\n"
     ]
    }
   ],
   "source": [
    "for a_ex in a_ex_list_syntax:\n",
    "    print(a_ex['dec_prompt'], ' --> ', a_ex['expect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [363, 19, 8, 16845, 13, 8, 443, 143, 183, 75, 3, 6293, 15, 17, 2600, 7932, 41, 7, 210, 61, 58, 117, 3, 7593, 15, 26, 1103, 10, 1820, 443, 834, 536, 1820, 10829, 7, 3, 10, 3622, 23, 26, 3, 6, 10829, 1820, 1440, 3, 10, 684, 23, 26, 3, 6, 684, 4350, 3, 6, 10829, 1820, 443, 834, 8910, 3, 10, 3, 23, 26, 3, 6, 13762, 41, 183, 75, 3, 61, 3, 6, 423, 4350, 3, 6, 684, 1820, 825, 834, 3350, 3, 10, 825, 23, 26, 3, 6, 13762, 3, 6, 825, 41, 183, 75, 3, 61, 1820, 443, 834, 4350, 7, 3, 10, 143, 23, 26, 3, 6, 825, 41, 183, 75, 3, 61, 3, 6, 143, 41, 183, 75, 3, 6293, 15, 17, 3, 6, 183, 75, 3, 6293, 15, 17, 2600, 7932, 41, 7, 210, 61, 3, 61, 1820, 2948, 834, 6757, 3, 10, 3, 23, 26, 3, 6, 3, 1167, 122, 3, 6, 3, 12980, 7, 3, 6, 3, 15, 10475, 40, 3, 6, 28906, 3, 6, 1293, 3, 6, 16845, 3, 6, 215, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['enc_tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contid']\n",
      "['continent', 'continent']\n",
      "['countryid']\n",
      "['countryname']\n",
      "['id', 'id']\n",
      "['maker ( amc )', 'maker']\n",
      "['fullname']\n",
      "['country']\n",
      "['modelid']\n",
      "['model ( amc )', 'model ( amc )']\n",
      "['makeid']\n",
      "['make ( amc hornet, amc hornet sportabout (sw) )']\n",
      "['mpg']\n",
      "['cylinders']\n",
      "['edispl']\n",
      "['horsepower']\n",
      "['weight']\n",
      "['accelerate']\n",
      "['year']\n"
     ]
    }
   ],
   "source": [
    "col_name_ranges = a_ex['token_ranges_dict']['col_name_ranges']\n",
    "# col_name_indices = [i for s, e in col_name_ranges.values() for i in range(s, e)]\n",
    "for ranges in col_name_ranges.values():\n",
    "    print([mt_uskg.tokenizer.decode(a_ex['enc_tokenized']['input_ids'][s:e]) for s, e in ranges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['continents']\n",
      "['countries']\n",
      "['car_makers']\n",
      "['model_list']\n",
      "['car_names']\n",
      "['cars_data']\n"
     ]
    }
   ],
   "source": [
    "table_name_ranges = a_ex['token_ranges_dict']['table_name_ranges']\n",
    "# col_name_indices = [i for s, e in col_name_ranges.values() for i in range(s, e)]\n",
    "for ranges in table_name_ranges.values():\n",
    "    print([mt_uskg.tokenizer.decode(a_ex['enc_tokenized']['input_ids'][s:e]) for s, e in ranges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'continents': [(33, 35)],\n",
       "             'countries': [(44, 45)],\n",
       "             'car_makers': [(58, 61)],\n",
       "             'model_list': [(82, 85)],\n",
       "             'car_names': [(102, 106)],\n",
       "             'cars_data': [(146, 149)]})"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_a_ex = ctu.create_analysis_sample_dicts_all_nodes(\n",
    "                    mt_uskg, ex,\n",
    "                    remove_struct_duplicate_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'enc_sentence', 'enc_tokenized', 'text_range', 'struct_range', 'struct_node_ranges_dict', 'dec_prompt', 'remove_struct_duplicate_nodes', 'parsed_struct_in', 'col2table', 'token_ranges_dict', 'alias2table', 'category', 'occ_cols', 'occ_tabs', 'non_occ_cols', 'non_occ_tabs', 'col_self_ranges', 'col_context_ranges', 'tab_self_ranges', 'tab_context_ranges'])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_a_ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_a_ex['enc_sentence'], \\\n",
    "combined_a_ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occ_cols ['accelerate', 'makeid', 'make']\n",
      "occ_tabs ['cars_data', 'car_names']\n",
      "non_occ_cols ['contid', 'countryid', 'countryname', 'fullname', 'country', 'modelid', 'mpg', 'cylinders', 'edispl', 'horsepower', 'weight', 'year']\n",
      "non_occ_tabs ['continents', 'countries', 'car_makers', 'model_list']\n"
     ]
    }
   ],
   "source": [
    "for k, v in combined_a_ex.items():\n",
    "    if 'occ' in k:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_self_ranges {'accelerate': [(176, 181)], 'makeid': [(106, 113)], 'make': [(119, 146)], 'contid': [(35, 42)], 'countryid': [(45, 52)], 'countryname': [(50, 56)], 'fullname': [(74, 80)], 'country': [(78, 82)], 'modelid': [(85, 92)], 'mpg': [(154, 161)], 'cylinders': [(159, 166)], 'edispl': [(164, 172)], 'horsepower': [(170, 175)], 'weight': [(173, 178)], 'year': [(179, 182)]}\n",
      "tab_self_ranges {'cars_data': [(145, 151)], 'car_names': [(101, 108)], 'continents': [(32, 37)], 'countries': [(43, 47)], 'car_makers': [(57, 63)], 'model_list': [(81, 87)]}\n"
     ]
    }
   ],
   "source": [
    "for k, v in combined_a_ex.items():\n",
    "    if '_self' in k:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_context_ranges {'accelerate': [(28, 176), (181, 182)], 'makeid': [(28, 106), (113, 182)], 'make': [(28, 119), (146, 182)], 'contid': [(28, 35), (42, 182)], 'countryid': [(28, 45), (52, 182)], 'countryname': [(28, 50), (56, 182)], 'fullname': [(28, 74), (80, 182)], 'country': [(28, 78), (82, 182)], 'modelid': [(28, 85), (92, 182)], 'mpg': [(28, 154), (161, 182)], 'cylinders': [(28, 159), (166, 182)], 'edispl': [(28, 164), (172, 182)], 'horsepower': [(28, 170), (175, 182)], 'weight': [(28, 173), (178, 182)], 'year': [(28, 179)]}\n",
      "tab_context_ranges {'cars_data': [(28, 145), (151, 182)], 'car_names': [(28, 101), (108, 182)], 'continents': [(28, 32), (37, 182)], 'countries': [(28, 43), (47, 182)], 'car_makers': [(28, 57), (63, 182)], 'model_list': [(28, 81), (87, 182)]}\n"
     ]
    }
   ],
   "source": [
    "for k, v in combined_a_ex.items():\n",
    "    if '_context' in k:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['select', 't2.', 'aaa', ',', 'distinct', '(', 't3.', 'ccc', ')', ',', 'count', '(', '*', ')', 'from', 'table_name', 'as', 't1', 'join', 'other_table', 'as', 't2', 'on', 'table_name', '.', 'a_a', '=', 'other_table', '.', 'b_a', 'join', 'ttt', 'as', 't3', 'on', 'other_table', '.', 'asth', '=', 'ttt', '.', 'asth', 'where', 't2.', 'col', 'like', '%', 'hey', '%', 'and', 't3.', 'p', '<=', '40']\n"
     ]
    }
   ],
   "source": [
    "_sql = 'SELECT t2.aaa, DISTINCT(t3.ccc), COUNT(*) FROM table_name as t1 JOIN other_table as t2 on table_name.a_a = other_table.b_a JOIN ttt as t3 on other_table.asth = ttt.asth WHERE t2.col like %hey% AND t3.p <= 40'.lower()\n",
    "_tok_ranges = ctu.separate_punct_by_offset(_sql)\n",
    "print([_sql[s:e] for s, e in _tok_ranges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ['▁which', '▁school', '▁is', '▁good', '?', '▁', 'struct', 'e', 'd', '_', 'know', 'ledge', ':', '▁school', '▁|', '▁school', '▁', ':', '▁school', '_', 'name', ',', '▁is', '_', 'good']\n"
     ]
    }
   ],
   "source": [
    "_toks = mt_uskg.tokenizer.tokenize('which school is good? structed_knowledge: school | school : school_name, is_good')\n",
    "print(len(_toks), _toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_a_ex = {\n",
    "    'enc_sentence': 'which school is good? structed_knowledge: school | school : school_name, is_good',\n",
    "    'dec_prompt': 'select distinct',\n",
    "    'expect': 'school_name',  # ['▁school', '_', 'name']\n",
    "    'answers_t': [1,2,3],\n",
    "    'answer': 'school_name',\n",
    "    'text_range': [0, 5],\n",
    "    'struct_range': [15, 25],\n",
    "    'self_ranges': [[18, 21]],\n",
    "    'context_ranges': [[15, 18], [21, 25]],\n",
    "}\n",
    "\n",
    "_test_att_masks = ctu.build_dec_cross_attention_mask(\n",
    "    a_ex=_test_a_ex,\n",
    "    mt=mt_uskg,\n",
    "    use_self_node=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False, False, False, False, False, False, False, False,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "           False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "           False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "           False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "           False, False, False, False, False,  True]]]])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_att_masks['all->t+o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True, True, True, True, True, True, True, True, True,\n",
       "           True, True, True]]]])"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_att_masks['all->t+o'] | _test_att_masks['all->s'] | _test_att_masks['all->p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False]]]])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(_test_att_masks['all->s'] | _test_att_masks['all->p']) & _test_att_masks['all->t+o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = dict(a_ex_list[a_ex_id])\n",
    "a_ex = ctu.add_clean_prediction(mt_uskg, a_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'What is the accelerate of the car make amc hornet sportabout (sw)?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'seq_out': \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\",\n",
       " 'dec_prompt': 'select t1.',\n",
       " 'expect': 'accelerate',\n",
       " 'expect_type': 'column',\n",
       " 'db_id': 'car_1',\n",
       " 'expect_input_ranges': [(178, 179)],\n",
       " 'self_ranges': [(176, 181)],\n",
       " 'expect_table': 'cars_data',\n",
       " 'answer': 'acc',\n",
       " 'base_score': 0.9999758005142212,\n",
       " 'answers_t': [6004],\n",
       " 'correct_prediction': False,\n",
       " 'category': {'sql_hardness': 'medium',\n",
       "  'node_role': 'select',\n",
       "  'text_match': 'exact',\n",
       "  'node_len': '1'}}"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ctu.make_basic_result_dict(a_ex)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']\n",
    "answer = result['answer']\n",
    "answers_t = result['answers_t']\n",
    "\n",
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 2,\n",
    "    [dec_prompt] * 2,\n",
    "    answer=expect)\n",
    "\n",
    "_, enc_seq_len = inp['input_ids'].size()\n",
    "_, dec_seq_len = inp['decoder_input_ids'].size()\n",
    "\n",
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "self_ranges = a_ex['self_ranges']\n",
    "context_ranges = a_ex['context_ranges']\n",
    "\n",
    "self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "context_tok_indices = corrupt_tok_indices = [i for s, e in context_ranges for i in range(s, e)]\n",
    "text_tok_indices = list(range(*text_range))\n",
    "struct_tok_indices = list(range(*struct_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repatch-uskg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6726], 'city', 0.8450507521629333)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_t, answer, _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8450507521629333"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_to_corrupt = [(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                for tnum in text_tok_indices]\n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=states_to_corrupt,\n",
    "#     tokens_to_mix=corrupt_tok_indices,\n",
    "#     tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9952, device='cuda:0')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pair of identical input to test correctness \n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_patch_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 12))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 23))\n",
    "                    for tnum in struct_tok_indices],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    tokens_to_mix_1st_pass=context_tok_indices,\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9952, device='cuda:0')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_patch_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 12))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 23))\n",
    "                    for tnum in struct_tok_indices],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_corrupt_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                    for tnum in context_tok_indices],\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253002524375916"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test corrupting attention \n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", l, \"self_attn\"))\n",
    "                    for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers)],\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n for n, w in mt_uskg.model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_probs = ctu.run_repatch_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "                    for tnum in self_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "                    for tnum in self_tok_indices],\n",
    "    answer_len=len(answers_t),\n",
    "    tokens_to_mix=corrupt_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32102])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.], device='cuda:0'),\n",
       "indices=tensor([7634], device='cuda:0'))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(vocab_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs[0, 7634]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2642e-25, 1.2223e-15, 7.3942e-18,  ..., 9.1578e-20, 2.6884e-39,\n",
       "         2.8131e-39]], device='cuda:0')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention-manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    ['name of singer'] * 2,\n",
    "    ['select'] * 2,\n",
    "    answer='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 2, 10)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs, enc_seq_len = small_inp['input_ids'].size()\n",
    "bs, dec_seq_len = small_inp['decoder_input_ids'].size()\n",
    "prefix_len = mt_uskg.model.preseqlen\n",
    "\n",
    "bs, enc_seq_len, dec_seq_len, prefix_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False,  True,  True, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False,  True,  True, False],\n",
       "          [False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False]]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_mask = torch.zeros(1, 1, enc_seq_len, enc_seq_len + prefix_len).bool()\n",
    "mix_mask[:, :, 1:3, 11:13] = True\n",
    "mix_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this checks attention logits/weights to verify that corruption is working \n",
    "\n",
    "corrupted_vocab_probs = ctu.run_attention_manip_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=small_inp,\n",
    "    answer_len=1,\n",
    "    mix_mask_per_layer={ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') : mix_mask for l in [0, 12, 23]},\n",
    "    replace=True,\n",
    "    attn_corrupt_type='logits',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32102])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_vocab_probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer-copy-uskg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999758005142212"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "#     states_to_copy_from=states_to_copy_from,\n",
    "#     states_to_copy_to=states_to_copy_to,\n",
    "#     answer_len=len(answers_t),\n",
    "    states_to_corrupt=[],\n",
    "    replace=True,\n",
    ").item()\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8760302111786586e-07"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_to_copy_to = [\n",
    "    (tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 17))\n",
    "    for tnum in range(enc_seq_len)\n",
    "]\n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "#     states_to_copy_from=states_to_copy_from,\n",
    "#     states_to_copy_to=states_to_copy_to,\n",
    "#     answer_len=len(answers_t),\n",
    "    states_to_corrupt=states_to_copy_to,\n",
    "    replace=True,\n",
    ").item()\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.155608645030952e-08]"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement 1: layer-copy \n",
    "\n",
    "states_to_copy_from = [\n",
    "    (tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "    for tnum in range(enc_seq_len)\n",
    "]\n",
    "\n",
    "states_to_copy_to = [\n",
    "    (tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 12))\n",
    "    for tnum in range(enc_seq_len)\n",
    "]\n",
    "\n",
    "vocab_probs = ctu.run_layer_copy_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[],\n",
    "#     states_to_unpatch=[],\n",
    "#     answers_t=answers_t,\n",
    "    states_to_copy_from=states_to_copy_from,\n",
    "    states_to_copy_to=states_to_copy_to,\n",
    "    answer_len=len(answers_t),\n",
    "#     states_to_corrupt=states_to_corrupt,\n",
    "#     tokens_to_mix=corrupt_tok_indices,\n",
    "#     tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ")\n",
    "\n",
    "ans_probs = [vocab_probs[i, _t].item() for i, _t in enumerate(answers_t)]\n",
    "\n",
    "ans_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.155608645030952e-08"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement 2: sublayer-zero \n",
    "# Should have the same score as implement 1: yes!\n",
    "\n",
    "states_to_zero = [\n",
    "    (tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", l, sublayer))\n",
    "    for tnum in range(enc_seq_len) for l in range(0, 13) for sublayer in ['self_attn', 'mlp']\n",
    "]\n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "#     states_to_copy_from=states_to_copy_from,\n",
    "#     states_to_copy_to=states_to_copy_to,\n",
    "#     answer_len=len(answers_t),\n",
    "    states_to_corrupt=states_to_zero,\n",
    "    replace=True,\n",
    "    noise=0.0,\n",
    ").item()\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'pretrain_model',\n",
    "#  'pretrain_model.shared',\n",
    "#  'pretrain_model.encoder',\n",
    "#  'pretrain_model.encoder.block',\n",
    "#  'pretrain_model.encoder.block.0',\n",
    "#  'pretrain_model.encoder.block.0.layer',\n",
    "#  'pretrain_model.encoder.block.0.layer.0',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention.q',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention.k',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention.v',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention.o',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.layer_norm',\n",
    "#  'pretrain_model.encoder.block.0.layer.0.dropout',\n",
    "#  'pretrain_model.encoder.block.0.layer.1',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.DenseReluDense',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.DenseReluDense.wi',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.DenseReluDense.wo',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.DenseReluDense.dropout',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.layer_norm',\n",
    "#  'pretrain_model.encoder.block.0.layer.1.dropout',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32102, 1024])"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = mt_uskg.model.pretrain_model.encoder.embed_tokens.weight\n",
    "embs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[564], [1246], [2982], [7634]], 'attention_mask': [[1], [1], [1], [1]]}"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.batch_encode_plus(['name', 'age', 'nation', 'singer'], add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.8750,  17.0000,   5.3438,  ..., -15.8750,  -0.8789,   2.6562],\n",
       "        [  6.3750,  13.5000, -35.7500,  ...,   2.3281,  15.7500,   3.5938],\n",
       "        [  3.3750, -16.8750, -25.2500,  ...,   0.9258,  -5.8750,   4.5625],\n",
       "        [  0.4629,  -3.0156, -10.1875,  ...,  -8.4375,   1.8828,   3.3750]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[[564, 1246, 2982, 7634]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12.6989, 15.4454, 16.5982,  ..., 12.3047, 12.5982,  9.7114],\n",
       "        device='cuda:0'),\n",
       " tensor([-4.3081, -2.5801,  2.5176,  ..., -2.8731,  3.0601, 12.4257],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_std, embs_mean = torch.std_mean(embs, dim=0)\n",
    "embs_std, embs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(2.3013, device='cuda:0'), tensor(13.3482, device='cuda:0')),\n",
       " (tensor(4.8516, device='cuda:0'), tensor(0.1390, device='cuda:0')))"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(embs_std), torch.std_mean(embs_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([639.1667, 281.5377, 303.9011,  ..., 242.6456, 397.0485, 398.6314],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_norm = torch.linalg.norm(embs, ord=2, dim=1)\n",
    "embs_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(66.8115, device='cuda:0'), tensor(455.5204, device='cuda:0'))"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(embs_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([719.9138, 459.3446, 463.6613,  ..., 422.5326, 498.5402, 499.7012],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_wid = 564\n",
    "tgt_vec = embs[tgt_wid]\n",
    "# delta = 5.0 * torch.randn_like(tgt_vec)\n",
    "# tgt_vec = tgt_vec + delta\n",
    "\n",
    "embs_dist = torch.linalg.norm(embs - tgt_vec, ord=2, dim=1)\n",
    "embs_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(54.9653, device='cuda:0'), tensor(565.9248, device='cuda:0')),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(564, device='cuda:0'))"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(embs_dist), torch.min(embs_dist), torch.argmin(embs_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 564),\n",
       " (273.6109924316406, 5570),\n",
       " (279.52862548828125, 3056),\n",
       " (315.5259704589844, 4350),\n",
       " (353.9427490234375, 23954),\n",
       " (359.2679443359375, 2650),\n",
       " (369.5257873535156, 10016),\n",
       " (405.4482421875, 2233),\n",
       " (411.2537841796875, 3),\n",
       " (411.6006164550781, 2862)]"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dists = sorted((dist, i) for i, dist in enumerate(embs_dist.cpu().tolist()))\n",
    "sorted_dists[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'Name',\n",
       " 'names',\n",
       " 'name',\n",
       " 'Name',\n",
       " 'named',\n",
       " 'Namen',\n",
       " 'title',\n",
       " '',\n",
       " 'identify']"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.decode_tokens(mt_uskg.tokenizer, [tok_id for _, tok_id in sorted_dists[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([737.6123, 487.0907, 491.6216,  ..., 456.4087, 529.4299, 530.4269],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_wid = 564\n",
    "tgt_vec = embs[tgt_wid]\n",
    "delta = 5.0 * torch.randn_like(tgt_vec)\n",
    "tgt_vec = tgt_vec + delta\n",
    "\n",
    "embs_dist = torch.linalg.norm(embs - tgt_vec, ord=2, dim=1)\n",
    "embs_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(53.0791, device='cuda:0'), tensor(590.1509, device='cuda:0')),\n",
       " tensor(158.3963, device='cuda:0'),\n",
       " tensor(564, device='cuda:0'))"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(embs_dist), torch.min(embs_dist), torch.argmin(embs_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(158.39627075195312, 564),\n",
       " (316.92431640625, 5570),\n",
       " (323.1575927734375, 3056),\n",
       " (357.3472595214844, 4350),\n",
       " (393.6805419921875, 23954),\n",
       " (400.9082946777344, 10016),\n",
       " (402.192138671875, 2650),\n",
       " (433.865234375, 2233),\n",
       " (441.6644592285156, 3),\n",
       " (443.2170715332031, 2862)]"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dists = sorted((dist, i) for i, dist in enumerate(embs_dist.cpu().tolist()))\n",
    "sorted_dists[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'names', 'Name', 'name', 'named', 'Name', 'Namen', '', 'title', '.']"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.decode_tokens(mt_uskg.tokenizer, [tok_id for _, tok_id in sorted_dists[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_id = 111\n",
    "a_ex_id = 0\n",
    "\n",
    "ex = processed_spider_dev[ex_id]\n",
    "ex['text_in'], \\\n",
    "ex['struct_in'], \\\n",
    "ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu.create_analysis_sample_dicts(\n",
    "                mt_uskg, ex,\n",
    "                subject_type='column',\n",
    "                remove_struct_duplicate_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']\n",
    "answer = result['answer']\n",
    "answers_t = result['answers_t']\n",
    "\n",
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "self_ranges = a_ex['self_ranges']\n",
    "struct_context_ranges = a_ex['context_ranges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 2,\n",
    "    [dec_prompt] * 2,\n",
    "    answer=expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import nethook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(), nethook.TraceDict(\n",
    "    mt_uskg.model,\n",
    "    [ctu.layername_uskg(mt_uskg.model, \"encoder\", l) for l in [0, 12, 23]]\n",
    ") as td:\n",
    "    outputs_exp = ctu.run_model_forward_uskg(mt_uskg.model, **inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['pretrain_model.encoder.block.0', 'pretrain_model.encoder.block.12', 'pretrain_model.encoder.block.23'])"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 183, 1024]), torch.Size([2, 16, 183, 193]))"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden, attn = td['pretrain_model.encoder.block.23'].output\n",
    "hidden.size(), attn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 431.2646,   22.2026,  -46.9836,  ...,  236.4605, -101.4929,\n",
       "          -13.4173],\n",
       "        [ 680.9009, -155.7530,   -3.9374,  ...,  357.9876,  -74.5153,\n",
       "         -248.9389],\n",
       "        [ 726.4300,  -97.9734,   82.3419,  ...,  280.2939,  -92.4423,\n",
       "         -208.4543],\n",
       "        ...,\n",
       "        [ -12.3197,  -82.2136,  -86.8491,  ...,  343.5234,   46.3294,\n",
       "          -30.3550],\n",
       "        [ 430.2145,  197.3166, -176.3856,  ...,  235.9048,  -84.3116,\n",
       "         -104.0558],\n",
       "        [ 935.1066,  134.0760,   52.9306,  ...,  -17.0239,  -42.8478,\n",
       "          -13.8100]], device='cuda:0')"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(3933.3369, device='cuda:0'), tensor(-22.5662, device='cuda:0')),\n",
       " (tensor(120171.7969, device='cuda:0'), tensor(38477.7578, device='cuda:0')))"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(hidden[0]), torch.std_mean(torch.norm(hidden[0], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(124030.015625, 28),\n",
       " (145044.171875, 40),\n",
       " (199170.0625, 50),\n",
       " (409527.75, 164),\n",
       " (489051.65625, 143),\n",
       " (592587.4375, 135),\n",
       " (672203.0, 78),\n",
       " (684664.5625, 170),\n",
       " (685764.875, 74),\n",
       " (766906.25, 54)]"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_norms = sorted((dist, i) for i, dist in enumerate(torch.norm(hidden[0], dim=-1).cpu().tolist()))\n",
    "sorted_norms[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 ['▁What', '▁is', '▁the', '▁accelerate', '▁of', '▁the', '▁car', '▁make', '▁am', 'c', '▁', 'horn', 'e', 't', '▁sport', 'about', '▁(', 's', 'w', ')', '?', ';', '▁', 'struct', 'e', 'd', '▁knowledge', ':', '▁|', '▁car', '_', '1', '▁|', '▁continent', 's', '▁', ':', '▁cont', 'i', 'd', '▁', ',', '▁continent', '▁|', '▁countries', '▁', ':', '▁country', 'i', 'd', '▁', ',', '▁country', 'name', '▁', ',', '▁continent', '▁|', '▁car', '_', 'makers', '▁', ':', '▁', 'i', 'd', '▁', ',', '▁maker', '▁(', '▁am', 'c', '▁', ')', '▁', ',', '▁full', 'name', '▁', ',', '▁country', '▁|', '▁model', '_', 'list', '▁', ':', '▁model', 'i', 'd', '▁', ',', '▁maker', '▁', ',', '▁model', '▁(', '▁am', 'c', '▁', ')', '▁|', '▁car', '_', 'name', 's', '▁', ':', '▁make', 'i', 'd', '▁', ',', '▁model', '▁(', '▁am', 'c', '▁', ')', '▁', ',', '▁make', '▁(', '▁am', 'c', '▁', 'horn', 'e', 't', '▁', ',', '▁am', 'c', '▁', 'horn', 'e', 't', '▁sport', 'about', '▁(', 's', 'w', ')', '▁', ')', '▁|', '▁cars', '_', 'data', '▁', ':', '▁', 'i', 'd', '▁', ',', '▁', 'mp', 'g', '▁', ',', '▁', 'cylinder', 's', '▁', ',', '▁', 'e', 'disp', 'l', '▁', ',', '▁horsepower', '▁', ',', '▁weight', '▁', ',', '▁accelerate', '▁', ',', '▁year', '</s>']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = mt_uskg.tokenizer.tokenize(enc_sentence, add_special_tokens=True)\n",
    "print(len(tokenized_input), tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':', ';', '▁', '▁', '▁', '▁', '</s>', 's', '▁', '_', '▁|', '▁', '▁', '▁', '▁', 'e', '▁', '▁', '▁', '▁']\n"
     ]
    }
   ],
   "source": [
    "print([tokenized_input[i] for _, i in sorted_norms[-20:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden[0, ::10, ::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untuple(x):\n",
    "    return x[0] if isinstance(x, tuple) else x\n",
    "\n",
    "def patch_rep(x, layer):\n",
    "    h = untuple(x)\n",
    "    if layer in corrupt_spec:\n",
    "        toks_to_mix = corrupt_spec[layer]\n",
    "        if toks_to_mix:\n",
    "            mix_len = len(toks_to_mix)\n",
    "#             noise_data = noise_fn(\n",
    "#                 torch.from_numpy(prng(h.shape[0] - 1, mix_len, h.shape[2]))\n",
    "#             ).to(device=h.device, dtype=h.dtype)\n",
    "#             if replace:\n",
    "#                 h[1:, toks_to_mix] = noise_data\n",
    "#             else:\n",
    "#                 h[1:, toks_to_mix] += noise_data\n",
    "            h[1:, toks_to_mix] = 0\n",
    "\n",
    "#     # If this layer is in the patch_spec, restore the uncorrupted hidden state\n",
    "#     # for selected tokens.\n",
    "#     toks_to_patch = patch_spec.get(layer, [])\n",
    "#     toks_to_unpatch = unpatch_spec.get(layer, [])\n",
    "\n",
    "#     for t in toks_to_patch:\n",
    "#         h[1:, t] = h[0, t]\n",
    "#     for t in toks_to_unpatch:\n",
    "#         h[1:, t] = untuple(first_pass_trace[layer].output)[1:, t]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 21)"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrupt_spec = {ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\") : list(range(*text_range))}\n",
    "corrupt_spec = {ctu.layername_uskg(mt_uskg.model, \"encoder\", 23) : list(range(*text_range))}\n",
    "\n",
    "hook_layers = [ctu.layername_uskg(mt_uskg.model, \"encoder\", l) for l in [0, 12, 23]] + \\\n",
    "    [ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\")]\n",
    "\n",
    "with torch.no_grad(), nethook.TraceDict(\n",
    "    mt_uskg.model,\n",
    "    layers=hook_layers,\n",
    "    edit_output=patch_rep,\n",
    ") as td:\n",
    "    outputs_exp = ctu.run_model_forward_uskg(mt_uskg.model, **inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 183, 1024]), torch.Size([2, 16, 183, 193]))"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden, attn = td['pretrain_model.encoder.block.0'].output\n",
    "hidden.size(), attn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -0.2820,  -0.0777, -10.0541,  ...,  18.3919,  19.2083,   4.6788],\n",
       "         [  2.3624,  -4.3468,   2.1581,  ...,   0.8777,  -2.4387,   1.6466],\n",
       "         [ -0.4869,   5.1502,   1.1220,  ...,   9.9191,  -7.7408,  -6.1049],\n",
       "         ...,\n",
       "         [  7.9017,  -2.7019, -14.2257,  ...,   6.8594,  -0.4216,   0.3843],\n",
       "         [ -2.5844,  13.8755,   1.1908,  ...,   1.7322,  -7.5010,   6.5653],\n",
       "         [ 19.2494, -10.1652,   1.5651,  ...,   9.0200,  13.4675,  31.8201]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ -0.2820,  -0.0777, -10.0541,  ...,  18.3919,  19.2083,   4.6788],\n",
       "         [  2.3624,  -4.3468,   2.1581,  ...,   0.8777,  -2.4387,   1.6466],\n",
       "         [ -0.4869,   5.1502,   1.1220,  ...,   9.9191,  -7.7408,  -6.1049],\n",
       "         ...,\n",
       "         [  7.9017,  -2.7019, -14.2257,  ...,   6.8594,  -0.4216,   0.3843],\n",
       "         [ -2.5844,  13.8755,   1.1908,  ...,   1.7322,  -7.5010,   6.5653],\n",
       "         [ 19.2494, -10.1652,   1.5651,  ...,   9.0200,  13.4675,  31.8201]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0], hidden[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden, attn = td['pretrain_model.encoder.block.12'].output\n",
    "hidden[0], hidden[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 431.2646,   22.2026,  -46.9836,  ...,  236.4605, -101.4929,\n",
       "           -13.4173],\n",
       "         [ 680.9009, -155.7530,   -3.9374,  ...,  357.9876,  -74.5153,\n",
       "          -248.9389],\n",
       "         [ 726.4300,  -97.9734,   82.3419,  ...,  280.2939,  -92.4423,\n",
       "          -208.4543],\n",
       "         ...,\n",
       "         [ -12.3197,  -82.2136,  -86.8491,  ...,  343.5234,   46.3294,\n",
       "           -30.3550],\n",
       "         [ 430.2145,  197.3166, -176.3856,  ...,  235.9048,  -84.3116,\n",
       "          -104.0558],\n",
       "         [ 935.1066,  134.0760,   52.9306,  ...,  -17.0239,  -42.8478,\n",
       "           -13.8100]], device='cuda:0'),\n",
       " tensor([[   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "             0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "             0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "             0.0000],\n",
       "         ...,\n",
       "         [ -12.3197,  -82.2136,  -86.8491,  ...,  343.5234,   46.3294,\n",
       "           -30.3550],\n",
       "         [ 430.2145,  197.3166, -176.3856,  ...,  235.9048,  -84.3116,\n",
       "          -104.0558],\n",
       "         [ 935.1066,  134.0760,   52.9306,  ...,  -17.0239,  -42.8478,\n",
       "           -13.8100]], device='cuda:0'))"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden, attn = td['pretrain_model.encoder.block.23'].output\n",
    "hidden[0], hidden[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(3933.3369, device='cuda:0'), tensor(-22.5662, device='cuda:0')),\n",
       " (tensor(3931.8728, device='cuda:0'), tensor(-22.0143, device='cuda:0')))"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(hidden[0]), torch.std_mean(hidden[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 32102])"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(outputs_exp.logits[:, -len(answers_t):, :], dim=-1)\n",
    "probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9999758005142212, 6004),\n",
       " (1.38331379275769e-05, 9),\n",
       " (7.489517884096131e-06, 30819),\n",
       " (1.270908683181915e-06, 20246),\n",
       " (5.996853360556997e-07, 21007),\n",
       " (4.935201332045835e-07, 26389),\n",
       " (1.2063669885264972e-07, 11584),\n",
       " (1.1599770033399182e-07, 6500),\n",
       " (1.004895580081211e-07, 291),\n",
       " (3.185817476492048e-08, 12497)]"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_probs = sorted([(p, i) for i, p in enumerate(probs[0, 0].cpu().tolist())], reverse=True)\n",
    "sorted_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'a', 'accelerating', 'inclin', 'acco', 'accelerated', 'fast', 'assi', 'ar', 'appro']\n"
     ]
    }
   ],
   "source": [
    "print(ctu.decode_tokens(mt_uskg.tokenizer, [i for p, i in sorted_probs[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8888899087905884, 6004),\n",
       " (0.10935894399881363, 9),\n",
       " (0.0005981624126434326, 30819),\n",
       " (0.0003909562074113637, 21007),\n",
       " (0.0002998432901222259, 9993),\n",
       " (8.253266423707828e-05, 291),\n",
       " (7.506454858230427e-05, 144),\n",
       " (5.3470714192371815e-05, 8010),\n",
       " (5.256106669548899e-05, 11584),\n",
       " (4.682378130382858e-05, 23)]"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_probs = sorted([(p, i) for i, p in enumerate(probs[1, 0].cpu().tolist())], reverse=True)\n",
    "sorted_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'a', 'accelerating', 'acco', 'speed', 'ar', 'at', 'auto', 'fast', 'i']\n"
     ]
    }
   ],
   "source": [
    "print(ctu.decode_tokens(mt_uskg.tokenizer, [i for p, i in sorted_probs[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-time patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expect_type = 'table_alias'\n",
    "# orig_res_path = f'/home/yshao/Projects/rome/results/exp6_2_decoder_cross_attention_corruption_syntax/no_o_exp=6.2_dev_corrupt=zero.jsonl'\n",
    "# add_res_path = f'/home/yshao/Projects/rome/results/exp6_2_decoder_cross_attention_corruption_syntax/exp=6.2+o_dev_corrupt=zero.jsonl'\n",
    "\n",
    "# merge_res_path = f'/home/yshao/Projects/rome/results/exp6_2_decoder_cross_attention_corruption_syntax/exp=6.2_dev_corrupt=zero.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(orig_res_path, 'r') as f:\n",
    "#     orig_all_samples = [json.loads(l) for l in f]\n",
    "# with open(add_res_path, 'r') as f:\n",
    "#     add_all_samples = [json.loads(l) for l in f]\n",
    "\n",
    "# f = open(merge_res_path, 'w')\n",
    "\n",
    "# for i, (orig_ex, add_ex) in enumerate(zip(orig_all_samples, add_all_samples)):\n",
    "#     assert len(orig_ex['trace_results']) == len(add_ex['trace_results']), i\n",
    "#     # There is randomness in the order of expected node (from set()), thus sorting here \n",
    "#     orig_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     add_ex['trace_results'].sort(key=lambda d: len(d['dec_prompt']))\n",
    "#     for j, (orig_d, add_d) in enumerate(zip(orig_ex['trace_results'], add_ex['trace_results'])):\n",
    "#         assert orig_d['is_good_sample'] == add_d['is_good_sample'], (i, j)\n",
    "#         if not orig_d['is_good_sample']:\n",
    "#             continue\n",
    "            \n",
    "#         # is good sample: add the new sections \n",
    "#         for k, v in add_d['trace_scores'].items():\n",
    "#             if k in orig_d['trace_scores']:\n",
    "#                 continue\n",
    "#             orig_d['trace_scores'][k] = add_d['trace_scores'][k]\n",
    "        \n",
    "#     f.write(json.dumps(orig_ex, indent=None) + '\\n')\n",
    "    \n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = processed_spider_dev[97]\n",
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "\n",
    "enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "dec_prompt = \"select t1.model from\"\n",
    "expect = \"car_names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    enc_sentences=[enc_sentence]*11,\n",
    "    dec_prompts=[dec_prompt]*11,\n",
    "    answer=expect\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 'aa,bb< cc  \\t dd(  )ee <= ff=5 %h% \"06-15\".'\n",
    "sep_pattern = r'\\s+|\\W'\n",
    "\n",
    "all_matches = re.finditer(sep_pattern, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(2, 3), match=','>,\n",
       " <re.Match object; span=(5, 6), match='<'>,\n",
       " <re.Match object; span=(6, 7), match=' '>,\n",
       " <re.Match object; span=(9, 13), match='  \\t '>,\n",
       " <re.Match object; span=(15, 16), match='('>,\n",
       " <re.Match object; span=(16, 18), match='  '>,\n",
       " <re.Match object; span=(18, 19), match=')'>,\n",
       " <re.Match object; span=(21, 22), match=' '>,\n",
       " <re.Match object; span=(22, 23), match='<'>,\n",
       " <re.Match object; span=(23, 24), match='='>,\n",
       " <re.Match object; span=(24, 25), match=' '>,\n",
       " <re.Match object; span=(27, 28), match='='>,\n",
       " <re.Match object; span=(29, 30), match=' '>,\n",
       " <re.Match object; span=(30, 31), match='%'>,\n",
       " <re.Match object; span=(32, 33), match='%'>,\n",
       " <re.Match object; span=(33, 34), match=' '>,\n",
       " <re.Match object; span=(34, 35), match='\"'>,\n",
       " <re.Match object; span=(37, 38), match='-'>,\n",
       " <re.Match object; span=(40, 41), match='\"'>,\n",
       " <re.Match object; span=(41, 42), match='.'>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches = list(all_matches)\n",
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches[0].span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 5, 6, 7, 9, 13, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42]\n"
     ]
    }
   ],
   "source": [
    "splits = [0] + [i for m in all_matches for i in m.span()] + [len(seq)]\n",
    "splits = sorted(list(set(splits)))\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 0\n",
    "SP = [\"<=\", \">=\", \"<>\", \"!=\"]\n",
    "toks = []\n",
    "\n",
    "for s, e in zip(splits[:-1], splits[1:]):\n",
    "    if not seq[s:e].strip():\n",
    "        # is a whitespace\n",
    "        st = e\n",
    "    else:\n",
    "        # is a punct\n",
    "        if seq[s:s+2] in SP:\n",
    "            # wait next\n",
    "            continue\n",
    "        toks.append(seq[st:e])\n",
    "        st = e\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', ',', 'bb', '<', 'cc', 'dd', '(', ')', 'ee', '<=', 'ff', '=', '5', '%', 'h', '%', '\"', '06', '-', '15', '\"', '.']\n"
     ]
    }
   ],
   "source": [
    "print(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁school', '_', 'name']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.tokenize('school_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁', 'cylinder']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.tokenize('cylinder ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁', 'cylinder', '▁', 'x', 'a']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.tokenize('cylinder xa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁', 'struct', 'e', 'd', '_', 'in', 'put', '▁', ':', '▁', 'a', '▁|', '▁', 'b']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.tokenize('structed_input : a | b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " 'SEL',\n",
       " 'ECT',\n",
       " '▁',\n",
       " 't',\n",
       " '2.',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " '▁',\n",
       " ',',\n",
       " '▁CO',\n",
       " 'UNT',\n",
       " '(',\n",
       " 'distin',\n",
       " 'c',\n",
       " 't',\n",
       " '▁',\n",
       " 't',\n",
       " '1.',\n",
       " 'name',\n",
       " ')',\n",
       " '▁FROM',\n",
       " '▁cars',\n",
       " '_',\n",
       " 'data',\n",
       " '▁as',\n",
       " '▁',\n",
       " 't',\n",
       " '1',\n",
       " '▁',\n",
       " 'JO',\n",
       " 'IN',\n",
       " '▁models',\n",
       " '▁as',\n",
       " '▁',\n",
       " 't',\n",
       " '2',\n",
       " '▁on',\n",
       " '▁cars',\n",
       " '_',\n",
       " 'data',\n",
       " '.',\n",
       " 'a',\n",
       " '_',\n",
       " 'a',\n",
       " '▁=',\n",
       " '▁models',\n",
       " '.',\n",
       " 'b',\n",
       " '_',\n",
       " 'a']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sql = 'SELECT t2.aaa , COUNT(distinct t1.name) FROM cars_data as t1 JOIN models as t2 on cars_data.a_a = models.b_a'\n",
    "\n",
    "mt_uskg.tokenizer.tokenize(_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q1_layers': range(0, 6),\n",
       " 'q2_layers': range(6, 12),\n",
       " 'q3_layers': range(12, 18),\n",
       " 'q4_layers': range(18, 24),\n",
       " 'low_layers': range(0, 12),\n",
       " 'mid_layers': range(6, 18),\n",
       " 'high_layers': range(12, 24),\n",
       " 'all_layers': range(0, 24)}"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_layers = mt_uskg.num_dec_layers\n",
    "\n",
    "layers_range_dict = {\n",
    "    'q1_layers': range(0, N_layers // 4),\n",
    "    'q2_layers': range(N_layers // 4, N_layers // 2),\n",
    "    'q3_layers': range(N_layers // 2, N_layers * 3 // 4),\n",
    "    'q4_layers': range(N_layers * 3 // 4, N_layers),\n",
    "    'low_layers': range(0, N_layers // 2),\n",
    "    'mid_layers': range(N_layers // 4, N_layers * 3 // 4),\n",
    "    'high_layers': range(N_layers // 2, N_layers),\n",
    "    'all_layers': range(N_layers),\n",
    "}\n",
    "\n",
    "layers_range_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.reverse_2D_dict.<locals>.<lambda>()>,\n",
       "            {'1': defaultdict(float, {'a': 1.0, 'b': 2.0}),\n",
       "             '2': defaultdict(float, {'a': 2.0, 'b': 1.0})})"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    'a': {\n",
    "        '1': 1.0,\n",
    "        '2': 2.0,\n",
    "    },\n",
    "    'b': {\n",
    "        '1': 2.0,\n",
    "        '2': 1.0,\n",
    "    },\n",
    "}\n",
    "reverse_2D_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'a': 1} + {'b': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "706px",
    "left": "28px",
    "top": "156px",
    "width": "259px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

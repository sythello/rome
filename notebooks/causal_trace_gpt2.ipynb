{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2caf5237",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/causal_trace.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ff194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aaf804",
   "metadata": {},
   "source": [
    "## Causal Tracing\n",
    "\n",
    "A demonstration of the double-intervention causal tracing method.\n",
    "\n",
    "The strategy used by causal tracing is to understand important\n",
    "states within a transfomer by doing two interventions simultaneously:\n",
    "\n",
    "1. Corrupt a subset of the input.  In our paper, we corrupt the subject tokens\n",
    "   to frustrate the ability of the transformer to accurately complete factual\n",
    "   prompts about the subject.\n",
    "2. Restore a subset of the internal hidden states.  In our paper, we scan\n",
    "   hidden states at all layers and all tokens, searching for individual states\n",
    "   that carry the necessary information for the transformer to recover its\n",
    "   capability to complete the factual prompt.\n",
    "\n",
    "The traces of decisive states can be shown on a heatmap.  This notebook\n",
    "demonstrates the code for conducting causal traces and creating these heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d501c2c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8aa3bf",
   "metadata": {},
   "source": [
    "The `experiments.causal_trace` module contains a set of functions for running causal traces.\n",
    "\n",
    "In this notebook, we reproduce, demonstrate and discuss the interesting functions.\n",
    "\n",
    "We begin by importing several utility functions that deal with tokens and transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356b3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import defaultdict, Counter\n",
    "from util import nethook\n",
    "from util.globals import DATA_DIR\n",
    "from experiments.causal_trace import (\n",
    "    ModelAndTokenizer,\n",
    "    layername,\n",
    "    guess_subject,\n",
    "    plot_trace_heatmap,\n",
    ")\n",
    "from experiments.causal_trace import (\n",
    "    make_inputs,\n",
    "    decode_tokens,\n",
    "    find_token_range,\n",
    "    predict_token,\n",
    "    predict_from_input,\n",
    "    collect_embedding_std,\n",
    ")\n",
    "from dsets import KnownsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92eb49c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fd1ec0d1bb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77904da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf0c69",
   "metadata": {},
   "source": [
    "## USKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "774591a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    AutoTokenizer\n",
    ")\n",
    "from transformers import AutoModelForPreTraining\n",
    "\n",
    "import uskg\n",
    "# from uskg.models.unified.prefixtuning import Model\n",
    "from uskg.models.unified import finetune, prefixtuning\n",
    "from uskg.utils.configue import Configure\n",
    "from uskg.utils.training_arguments import WrappedSeq2SeqTrainingArguments\n",
    "from uskg.seq2seq_construction import spider as s2s_spider\n",
    "from uskg.third_party.spider.preprocess.get_tables import dump_db_json_schema\n",
    "from uskg.third_party.spider import evaluation as sp_eval\n",
    "\n",
    "from uskg.utils.dataset import gpt2_construct_input\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# import stanza\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import ujson\n",
    "import pickle\n",
    "\n",
    "# import experiments\n",
    "from experiments import causal_trace_uskg as ctu\n",
    "from experiments import causal_trace_uskg_gpt2 as ctu2\n",
    "\n",
    "# import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ed5111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to re-import to solve the class mismatch problem, but still not working...\n",
    "\n",
    "# import importlib\n",
    "\n",
    "# importlib.reload(uskg.models.prompt.modeling_auto)\n",
    "# importlib.reload(uskg.models.prompt.modeling_gpt2)\n",
    "# importlib.reload(uskg.models.unified)\n",
    "# importlib.reload(experiments)\n",
    "# importlib.reload(ctu)\n",
    "# importlib.reload(util)\n",
    "# importlib.reload(util.uskg)\n",
    "# importlib.reload(uskg.utils)\n",
    "\n",
    "# from uskg.models.unified import finetune, prefixtuning\n",
    "\n",
    "# from uskg.models.prompt.modeling_auto import AutoModelForPreTraining\n",
    "# from uskg.models.prompt.modeling_gpt2 import GPT2LMHeadModel\n",
    "# from uskg.models.prompt.modeling_t5 import T5ForConditionalGeneration\n",
    "\n",
    "# from experiments import causal_trace_uskg as ctu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2379880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import uskg as uu\n",
    "from util import uskg_gpt2 as uu2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d89de",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c91e95cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tokenizer_uskg: /home/yshao/Projects/UnifiedSKG/output/A-GPT2_medium_prefix_spider_with_cell_value-pfx=20/run-20231113/checkpoint-23500\n",
      "Using tokenizer_fast: gpt2-medium\n",
      "gpt2-medium\n",
      "prefix-tuning sequence length is 20.\n"
     ]
    }
   ],
   "source": [
    "# uskg_gpt2_model, tokenizer_uskg, tokenizer_fast, training_args, model_args, task_args = ctu.load_model_uskg('gpt2-prefix', untie_embeddings=False)\n",
    "mt_uskg_gpt2 = ctu.ModelAndTokenizer_USKG_GPT2('gpt2-medium-prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_uskg_gpt2.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b7df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [k for k, v in mt_uskg_gpt2.model.named_modules()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87289f95",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f5bff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_train_path = '/home/yshao/Projects/SDR-analysis/data/spider/train+ratsql_graph.json'\n",
    "spider_dev_path = '/home/yshao/Projects/SDR-analysis/data/spider/dev+ratsql_graph.json'\n",
    "spider_db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "516536fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev = ctu.load_raw_dataset(\n",
    "    data_filepath = spider_dev_path,\n",
    "    db_path=spider_db_dir,\n",
    "#     schema_cache=SCHEMA_CACHE\n",
    ")\n",
    "len(raw_spider_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0095fcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d81a8860",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg_gpt2.task_args.dataset.use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee20a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_spider_dev = s2s_spider.DevDataset(\n",
    "    args=mt_uskg_gpt2.task_args,\n",
    "    raw_datasets=raw_spider_dev,\n",
    "    cache_root='../cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "375805ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What are the names of all European countries with at least 3 manufacturers?',\n",
       " '| car_1 | continents : contid , continent ( europe ) | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.countryname from countries as t1 join continents as t2 on t1.continent = t2.contid join car_makers as t3 on t1.countryid = t3.country where t2.continent = 'europe' group by t1.countryname having count(*) >= 3;\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 130\n",
    "processed_spider_dev[_id]['text_in'], \\\n",
    "processed_spider_dev[_id]['struct_in'], \\\n",
    "processed_spider_dev[_id]['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d89f7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_enc_sentence = f\"{processed_spider_dev[_id]['text_in']}; structed knowledge: {processed_spider_dev[_id]['struct_in']}\"\n",
    "_toks = mt_uskg_gpt2.tokenizer.tokenize(_enc_sentence)\n",
    "len(_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65470561",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3116577e",
   "metadata": {},
   "source": [
    "#### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "01486fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_2D_dict(d):\n",
    "    out_d = defaultdict(lambda: defaultdict(np.nan))\n",
    "    for k1, d1 in d.items():\n",
    "        for k2, v in d1.items():\n",
    "            out_d[k2][k1] = v\n",
    "    return out_d\n",
    "\n",
    "def format_print_1D_dict(d, sort_by=None, reverse=False, head_col_w=10, col_w=6):\n",
    "    # sort: None, 'key' or 'value'\n",
    "    \n",
    "    item_l = list(d.items())\n",
    "    if sort_by == 'key':\n",
    "        item_l.sort(reverse=reverse)\n",
    "    elif sort_by == 'value':\n",
    "        item_l.sort(key=lambda x: (x[1], x[0]), reverse=reverse)\n",
    "    \n",
    "    decm_w = col_w - 2\n",
    "    \n",
    "    for k, v in item_l:\n",
    "        print(f'{k:<{head_col_w}s}{v:.{decm_w}f}')\n",
    "\n",
    "def format_print_2D_dict(d, \n",
    "                         all_k1=None, \n",
    "                         all_k2=None, \n",
    "                         sort_k1_kwargs=None, \n",
    "                         sort_k2_kwargs=None, \n",
    "                         head_col_w=12, \n",
    "                         col_w=6,\n",
    "                         decm_w=4):\n",
    "    if all_k1 is None:\n",
    "        all_k1 = list(d.keys())\n",
    "        if sort_k1_kwargs is not None:\n",
    "            all_k1.sort(**sort_k1_kwargs)\n",
    "    \n",
    "    if all_k2 is None:\n",
    "        for k1, d1 in d.items():\n",
    "            d1_keys = list(d1.keys())\n",
    "            if all_k2 is None:\n",
    "                all_k2 = d1_keys\n",
    "            else:\n",
    "                if set(d1_keys) != set(all_k2):\n",
    "                    print('Warning:\\n', d1_keys, '\\n', all_k2)\n",
    "            # all_k2.update(list(d1.keys()))\n",
    "        if sort_k2_kwargs is not None:\n",
    "            all_k2.sort(**sort_k2_kwargs)\n",
    "    \n",
    "    print_str = '\\t'.join(['X' * head_col_w] + [f'{k2:<{col_w}s}' for k2 in all_k2]) + '\\n'\n",
    "    \n",
    "    for k1 in all_k1:\n",
    "        d1 = d[k1]\n",
    "        print_str += f'{k1:<{head_col_w}s}'\n",
    "        for k2 in all_k2:\n",
    "            v = d1[k2]\n",
    "            print_str += f'\\t{v:<{col_w}.{decm_w}f}'\n",
    "        print_str += '\\n'\n",
    "    \n",
    "    print(print_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826702b",
   "metadata": {},
   "source": [
    "#### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d704414",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = '/home/yshao/Projects/language/language/xsp/data/spider/tables.json'\n",
    "db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0972291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmaps = sp_eval.build_foreign_key_map_from_json(table_path)\n",
    "evaluator = sp_eval.Evaluator(db_dir=db_dir, kmaps=kmaps, etype='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b223d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctu.evaluate_hardness.evaluator = evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c0da13",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c87650",
   "metadata": {},
   "source": [
    "### find_text_struct_in_range_gpt2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25076520",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = 130\n",
    "ex = processed_spider_dev[_id]\n",
    "seq_in = f\"{ex['text_in']}; structed knowledge: {ex['struct_in']}\"\n",
    "seq_out = ex['seq_out']\n",
    "_test_seq_input = gpt2_construct_input(seq_in, seq_out, mt_uskg_gpt2.tokenizer,\n",
    "                                       in_maxlen=362,\n",
    "                                       out_maxlen=128,\n",
    "                                       padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "188e9d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What are the names of all European countries with at least 3 manufacturers?; structed knowledge: | car_1 | continents : contid, continent ( europe ) | countries : countryid, countryname, continent | car_makers : id, maker, fullname, country | model_list : modelid, maker, model | car_names : makeid, model, make | cars_data : id, mpg, cylinders, edispl, horsepower, weight, accelerate, year ; SQL: select t1.countryname from countries as t1 join continents as t2 on t1.continent = t2.contid join car_makers as t3 on t1.countryid = t3.country where t2.continent = 'europe' group by t1.countryname having count(*) >= 3; END OF SQL\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_seq = mt_uskg_gpt2.tokenizer.decode(_test_seq_input['input_ids'])\n",
    "_test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "21e7ae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', ' are', ' the', ' names', ' of', ' all', ' European', ' countries', ' with', ' at', ' least', ' 3', ' manufacturers', '?', ';', ' struct', 'ed', ' knowledge', ':', ' |', ' car', '_', '1', ' |', ' continents', ' :', ' cont', 'id', ',', ' continent', ' (', ' euro', 'pe', ' )', ' |', ' countries', ' :', ' country', 'id', ',', ' country', 'name', ',', ' continent', ' |', ' car', '_', 'makers', ' :', ' id', ',', ' maker', ',', ' full', 'name', ',', ' country', ' |', ' model', '_', 'list', ' :', ' model', 'id', ',', ' maker', ',', ' model', ' |', ' car', '_', 'names', ' :', ' make', 'id', ',', ' model', ',', ' make', ' |', ' cars', '_', 'data', ' :', ' id', ',', ' m', 'pg', ',', ' cylinders', ',', ' ed', 'is', 'pl', ',', ' horsepower', ',', ' weight', ',', ' accelerate', ',', ' year', ' ;', ' SQL', ':', ' select', ' t', '1', '.', 'country', 'name', ' from', ' countries', ' as', ' t', '1', ' join', ' continents', ' as', ' t', '2', ' on', ' t', '1', '.', 'cont', 'inent', ' =', ' t', '2', '.', 'cont', 'id', ' join', ' car', '_', 'makers', ' as', ' t', '3', ' on', ' t', '1', '.', 'country', 'id', ' =', ' t', '3', '.', 'country', ' where', ' t', '2', '.', 'cont', 'inent', ' =', \" '\", 'euro', 'pe', \"'\", ' group', ' by', ' t', '1', '.', 'country', 'name', ' having', ' count', '(', '*)', ' >=', ' 3', ';', ' END', ' OF', ' SQL']\n"
     ]
    }
   ],
   "source": [
    "_toks = uu.decode_tokens(mt_uskg_gpt2.tokenizer, _test_seq_input['input_ids'])\n",
    "print(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "493b2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_range, struct_range, out_range = uu2.find_text_struct_in_range_gpt2(mt_uskg_gpt2.tokenizer, _test_seq_input['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa20a002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 14), (19, 102), (105, 176))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_range, struct_range, out_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e2308ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What are the names of all European countries with at least 3 manufacturers?',\n",
       " ' | car_1 | continents : contid, continent ( europe ) | countries : countryid, countryname, continent | car_makers : id, maker, fullname, country | model_list : modelid, maker, model | car_names : makeid, model, make | cars_data : id, mpg, cylinders, edispl, horsepower, weight, accelerate, year',\n",
       " \" select t1.countryname from countries as t1 join continents as t2 on t1.continent = t2.contid join car_makers as t3 on t1.countryid = t3.country where t2.continent = 'europe' group by t1.countryname having count(*) >= 3;\")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_st, text_ed = text_range\n",
    "struct_st, struct_ed = struct_range\n",
    "out_st, out_ed = out_range\n",
    "\n",
    "''.join(_toks[text_st : text_ed]), \\\n",
    "''.join(_toks[struct_st : struct_ed]), \\\n",
    "''.join(_toks[out_st : out_ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "284d9296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' : countryid,'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(_toks[36 : 40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b60804",
   "metadata": {},
   "source": [
    "### create_analysis_sample_dicts() (& syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "963c3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = 222\n",
    "ex = copy.deepcopy(processed_spider_dev[_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "89f75f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Which city has the most frequent destination airport?',\n",
       " '| flight_2 | airlines : uid , airline , abbreviation , country | airports : city , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport',\n",
       " 'select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.city order by count(*) desc limit 1')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['text_in'], ex['struct_in'], ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "18e8031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu2.create_analysis_sample_dicts_gpt2(mt_uskg_gpt2, ex, subject_type='column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "142c2e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'enc_sentence', 'tokenized_item', 'pre_sql_sequence', 'text_range', 'struct_range', 'sql_range', 'parsed_struct_in', 'alias2table', 'col2table', 'col_name_counter', 'tab_name_counter', 'struct_node_ranges_dict', 'sql_tokens', 'sql_token_ranges', 'tok_ranges2type', 'type2tok_ranges', 'sql_col_nodes', 'sql_tab_nodes', 'sql_alias_nodes', 'dec_prompt', 'expect', 'expect_type', 'remove_struct_duplicate_nodes', 'token_ranges_dict', 'node_name_ranges', 'expect_input_ranges', 'self_ranges', 'context_ranges', 'category'])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "acf2d3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 'airports', 't2': 'flights'}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[0]['alias2table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4cda0577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'syntax': [(0, 6),\n",
       "              (15, 19),\n",
       "              (29, 31),\n",
       "              (35, 39),\n",
       "              (48, 50),\n",
       "              (54, 56),\n",
       "              (72, 73),\n",
       "              (89, 94),\n",
       "              (95, 97),\n",
       "              (106, 111),\n",
       "              (112, 114),\n",
       "              (115, 120),\n",
       "              (120, 121),\n",
       "              (121, 122),\n",
       "              (122, 123),\n",
       "              (124, 128),\n",
       "              (129, 134)],\n",
       "             'table_alias': [(7, 10),\n",
       "              (32, 34),\n",
       "              (51, 53),\n",
       "              (57, 60),\n",
       "              (74, 77),\n",
       "              (98, 101)],\n",
       "             'column': [(10, 14), (60, 71), (77, 88), (101, 105)],\n",
       "             'table': [(20, 28), (40, 47)],\n",
       "             'val': [(135, 136)]})"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[0]['type2tok_ranges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "84b7376f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_toks = mt_uskg_gpt2.tokenizer.tokenize(a_ex_list[0]['seq_out'])\n",
    "len(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "54e14e44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġas', 'Ġt', '1']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_toks[7:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ce392d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t1.'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[0]['seq_out'][7:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7fcda1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu2.create_analysis_sample_dicts_gpt2(mt_uskg_gpt2, ex, subject_type='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "072e881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu2.create_syntax_analysis_sample_dicts_gpt2(mt_uskg_gpt2, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d03af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0f554",
   "metadata": {},
   "source": [
    "#### create_analysis_sample_dicts_all_nodes_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "48206cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = 222\n",
    "ex = copy.deepcopy(processed_spider_dev[_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8ed1d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = ctu2.create_analysis_sample_dicts_all_nodes_gpt2(mt_uskg_gpt2, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ec238d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db_table_names : ['airlines', 'airports', 'flights']\n",
      "db_column_names : {'table_id': [-1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2], 'column_name': ['*', 'uid', 'Airline', 'Abbreviation', 'Country', 'City', 'AirportCode', 'AirportName', 'Country', 'CountryAbbrev', 'Airline', 'FlightNo', 'SourceAirport', 'DestAirport']}\n",
      "db_column_types : ['text', 'number', 'text', 'text', 'text', 'text', 'text', 'text', 'text', 'text', 'number', 'number', 'text', 'text']\n",
      "alias2table : {'t1': 'airports', 't2': 'flights'}\n",
      "col2table : defaultdict(<class 'list'>, {'uid': ['airlines'], 'airline': ['airlines', 'flights'], 'abbreviation': ['airlines'], 'country': ['airlines', 'airports'], 'city': ['airports'], 'airportcode': ['airports'], 'airportname': ['airports'], 'countryabbrev': ['airports'], 'flightno': ['flights'], 'sourceairport': ['flights'], 'destairport': ['flights']})\n",
      "col_name_counter : Counter({'airline': 2, 'country': 2, 'uid': 1, 'abbreviation': 1, 'city': 1, 'airportcode': 1, 'airportname': 1, 'countryabbrev': 1, 'flightno': 1, 'sourceairport': 1, 'destairport': 1})\n",
      "tab_name_counter : Counter({'airlines': 1, 'airports': 1, 'flights': 1})\n",
      "sql_col_nodes : {'airportcode', 'city', 'destairport'}\n",
      "sql_tab_nodes : {'flights', 'airports'}\n",
      "occ_cols : ['airportcode', 'city', 'destairport']\n",
      "occ_tabs : ['flights', 'airports']\n",
      "non_occ_cols : ['uid', 'abbreviation', 'airportname', 'countryabbrev', 'flightno', 'sourceairport']\n",
      "non_occ_tabs : ['airlines']\n",
      "col_self_ranges : {'airportcode': [(34, 38)], 'city': [(32, 35)], 'destairport': [(58, 62)], 'uid': [(20, 24)], 'abbreviation': [(25, 29)], 'airportname': [(37, 41)], 'countryabbrev': [(42, 48)], 'flightno': [(51, 55)], 'sourceairport': [(54, 59)]}\n",
      "col_context_ranges : {'airportcode': [(14, 34), (38, 62)], 'city': [(14, 32), (35, 62)], 'destairport': [(14, 58)], 'uid': [(14, 20), (24, 62)], 'abbreviation': [(14, 25), (29, 62)], 'airportname': [(14, 37), (41, 62)], 'countryabbrev': [(14, 42), (48, 62)], 'flightno': [(14, 51), (55, 62)], 'sourceairport': [(14, 54), (59, 62)]}\n",
      "tab_self_ranges : {'flights': [(47, 50)], 'airports': [(30, 33)], 'airlines': [(18, 21)]}\n",
      "tab_context_ranges : {'flights': [(14, 47), (50, 62)], 'airports': [(14, 30), (33, 62)], 'airlines': [(14, 18), (21, 62)]}\n"
     ]
    }
   ],
   "source": [
    "for k, v in a_ex.items():\n",
    "    if 'col' in k or 'tab' in k:\n",
    "        print(k, ':', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "06458901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.city order by count(*) desc limit 1'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9fde4822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_toks = mt_uskg_gpt2.tokenizer.tokenize(a_ex_list[0]['enc_sentence'])\n",
    "len(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a6d55d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airportcode ['Ġ,', 'Ġairport', 'code', 'Ġ,']\n",
      "city ['Ġ:', 'Ġcity', 'Ġ,']\n",
      "destairport ['Ġ,', 'Ġdest', 'air', 'port']\n",
      "uid ['Ġ:', 'Ġu', 'id', 'Ġ,']\n",
      "abbreviation ['Ġ,', 'Ġabbre', 'viation', 'Ġ,']\n",
      "airportname ['Ġ,', 'Ġairport', 'name', 'Ġ,']\n",
      "countryabbrev ['Ġ,', 'Ġcountry', 'ab', 'bre', 'v', 'Ġ|']\n",
      "flightno ['Ġ,', 'Ġflight', 'no', 'Ġ,']\n",
      "sourceairport ['Ġ,', 'Ġsource', 'air', 'port', 'Ġ,']\n"
     ]
    }
   ],
   "source": [
    "for k, v in a_ex['col_self_ranges'].items():\n",
    "    print(k, _toks[v[0][0]:v[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a2fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9f540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3af9cb6e",
   "metadata": {},
   "source": [
    "### add_clean_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "139f548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = 130\n",
    "ex = copy.deepcopy(processed_spider_dev[_id])\n",
    "a_ex_list = ctu2.create_analysis_sample_dicts_gpt2(mt_uskg_gpt2, ex, subject_type='column')\n",
    "a_ex = a_ex_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29748725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What are the names of all European countries with at least 3 manufacturers?; structed knowledge: | car_1 | continents : contid, continent ( europe ) | countries : countryid, countryname, continent | car_makers : id, maker, fullname, country | model_list : modelid, maker, model | car_names : makeid, model, make | cars_data : id, mpg, cylinders, edispl, horsepower, weight, accelerate, year ; SQL: select t1.',\n",
       " 'countryname')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['dec_prompt'], a_ex['expect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86a62f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = ctu2.add_clean_prediction_gpt2(mt_uskg_gpt2, a_ex, samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f107083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " 0.9999053478240967,\n",
       " tensor([19315,  3672], device='cuda:0'),\n",
       " 'countryname',\n",
       " True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['answer_len'], \\\n",
    "a_ex['base_score'], \\\n",
    "a_ex['answers_t'], \\\n",
    "a_ex['answer'], \\\n",
    "a_ex['correct_prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b7e8f",
   "metadata": {},
   "source": [
    "### find_struct_name_ranges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dc9a16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = 130\n",
    "ex = copy.deepcopy(processed_spider_dev[_id])\n",
    "ctu2.add_basic_analysis_info_gpt2(mt_uskg_gpt2, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "99d3fd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'enc_sentence', 'tokenized_item', 'pre_sql_sequence', 'text_range', 'struct_range', 'sql_range', 'parsed_struct_in', 'alias2table', 'col2table', 'col_name_counter', 'tab_name_counter', 'struct_node_ranges_dict', 'sql_tokens', 'sql_token_ranges', 'tok_ranges2type', 'type2tok_ranges', 'sql_col_nodes', 'sql_tab_nodes', 'sql_alias_nodes'])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "33d7e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_node_ranges_dict = uu2.find_struct_name_ranges_gpt2(mt_uskg_gpt2.tokenizer, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "09102523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db_id_ranges': defaultdict(list, {'car_1': [(20, 23)]}),\n",
       " 'table_name_ranges': defaultdict(list,\n",
       "             {'continents': [(24, 25)],\n",
       "              'countries': [(35, 36)],\n",
       "              'car_makers': [(45, 48)],\n",
       "              'model_list': [(58, 61)],\n",
       "              'car_names': [(69, 72)],\n",
       "              'cars_data': [(80, 83)]}),\n",
       " 'col_name_ranges': defaultdict(list,\n",
       "             {'contid': [(26, 28)],\n",
       "              'continent': [(29, 34), (43, 44)],\n",
       "              'countryid': [(37, 39)],\n",
       "              'countryname': [(40, 42)],\n",
       "              'id': [(49, 50), (84, 85)],\n",
       "              'maker': [(51, 52), (65, 66)],\n",
       "              'fullname': [(53, 55)],\n",
       "              'country': [(56, 57)],\n",
       "              'modelid': [(62, 64)],\n",
       "              'model': [(67, 68), (76, 77)],\n",
       "              'makeid': [(73, 75)],\n",
       "              'make': [(78, 79)],\n",
       "              'mpg': [(86, 88)],\n",
       "              'cylinders': [(89, 90)],\n",
       "              'edispl': [(91, 94)],\n",
       "              'horsepower': [(95, 96)],\n",
       "              'weight': [(97, 98)],\n",
       "              'accelerate': [(99, 100)],\n",
       "              'year': [(101, 102)]}),\n",
       " 'val_name_ranges': defaultdict(list, {'europe': [(31, 33)]})}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_node_ranges_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bc52feb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'Ġare', 'Ġthe', 'Ġnames', 'Ġof', 'Ġall', 'ĠEuropean', 'Ġcountries', 'Ġwith', 'Ġat', 'Ġleast', 'Ġ3', 'Ġmanufacturers', '?', ';', 'Ġstruct', 'ed', 'Ġknowledge', ':', 'Ġ|', 'Ġcar', '_', '1', 'Ġ|', 'Ġcontinents', 'Ġ:', 'Ġcont', 'id', 'Ġ,', 'Ġcontinent', 'Ġ(', 'Ġeuro', 'pe', 'Ġ)', 'Ġ|', 'Ġcountries', 'Ġ:', 'Ġcountry', 'id', 'Ġ,', 'Ġcountry', 'name', 'Ġ,', 'Ġcontinent', 'Ġ|', 'Ġcar', '_', 'makers', 'Ġ:', 'Ġid', 'Ġ,', 'Ġmaker', 'Ġ,', 'Ġfull', 'name', 'Ġ,', 'Ġcountry', 'Ġ|', 'Ġmodel', '_', 'list', 'Ġ:', 'Ġmodel', 'id', 'Ġ,', 'Ġmaker', 'Ġ,', 'Ġmodel', 'Ġ|', 'Ġcar', '_', 'names', 'Ġ:', 'Ġmake', 'id', 'Ġ,', 'Ġmodel', 'Ġ,', 'Ġmake', 'Ġ|', 'Ġcars', '_', 'data', 'Ġ:', 'Ġid', 'Ġ,', 'Ġm', 'pg', 'Ġ,', 'Ġcylinders', 'Ġ,', 'Ġed', 'is', 'pl', 'Ġ,', 'Ġhorsepower', 'Ġ,', 'Ġweight', 'Ġ,', 'Ġaccelerate', 'Ġ,', 'Ġyear', 'Ġ;', 'ĠSQL', ':', 'Ġselect', 'Ġt', '1', '.', 'country', 'name', 'Ġfrom', 'Ġcountries', 'Ġas', 'Ġt', '1', 'Ġjoin', 'Ġcontinents', 'Ġas', 'Ġt', '2', 'Ġon', 'Ġt', '1', '.', 'cont', 'inent', 'Ġ=', 'Ġt', '2', '.', 'cont', 'id', 'Ġjoin', 'Ġcar', '_', 'makers', 'Ġas', 'Ġt', '3', 'Ġon', 'Ġt', '1', '.', 'country', 'id', 'Ġ=', 'Ġt', '3', '.', 'country', 'Ġwhere', 'Ġt', '2', '.', 'cont', 'inent', 'Ġ=', \"Ġ'\", 'euro', 'pe', \"'\", 'Ġgroup', 'Ġby', 'Ġt', '1', '.', 'country', 'name', 'Ġhaving', 'Ġcount', '(', '*)', 'Ġ>=', 'Ġ3', ';', 'ĠEND', 'ĠOF', 'ĠSQL']\n"
     ]
    }
   ],
   "source": [
    "_toks = mt_uskg_gpt2.tokenizer.convert_ids_to_tokens(ex['tokenized_item']['input_ids'])\n",
    "print(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1c957b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contid\n",
      "['Ġcont', 'id']\n",
      "--------------------\n",
      "continent\n",
      "['Ġcontinent', 'Ġ(', 'Ġeuro', 'pe', 'Ġ)']\n",
      "['Ġcontinent']\n",
      "--------------------\n",
      "countryid\n",
      "['Ġcountry', 'id']\n",
      "--------------------\n",
      "countryname\n",
      "['Ġcountry', 'name']\n",
      "--------------------\n",
      "id\n",
      "['Ġid']\n",
      "['Ġid']\n",
      "--------------------\n",
      "maker\n",
      "['Ġmaker']\n",
      "['Ġmaker']\n",
      "--------------------\n",
      "fullname\n",
      "['Ġfull', 'name']\n",
      "--------------------\n",
      "country\n",
      "['Ġcountry']\n",
      "--------------------\n",
      "modelid\n",
      "['Ġmodel', 'id']\n",
      "--------------------\n",
      "model\n",
      "['Ġmodel']\n",
      "['Ġmodel']\n",
      "--------------------\n",
      "makeid\n",
      "['Ġmake', 'id']\n",
      "--------------------\n",
      "make\n",
      "['Ġmake']\n",
      "--------------------\n",
      "mpg\n",
      "['Ġm', 'pg']\n",
      "--------------------\n",
      "cylinders\n",
      "['Ġcylinders']\n",
      "--------------------\n",
      "edispl\n",
      "['Ġed', 'is', 'pl']\n",
      "--------------------\n",
      "horsepower\n",
      "['Ġhorsepower']\n",
      "--------------------\n",
      "weight\n",
      "['Ġweight']\n",
      "--------------------\n",
      "accelerate\n",
      "['Ġaccelerate']\n",
      "--------------------\n",
      "year\n",
      "['Ġyear']\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for k, v in struct_node_ranges_dict['col_name_ranges'].items():\n",
    "    print(k)\n",
    "    for s, e in v:\n",
    "        print(_toks[s:e])\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "26c4fb0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('| car_1 | continents : contid , continent ( europe ) | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " ((1, 'car_1', 'car_1'),\n",
       "  [((3, 'continents', 'continents'),\n",
       "    [[(5, 'contid', 'contid'), []],\n",
       "     [(7, 'continent', 'continent ( europe )'), [(9, 'europe', 'europe')]]]),\n",
       "   ((12, 'countries', 'countries'),\n",
       "    [[(14, 'countryid', 'countryid'), []],\n",
       "     [(16, 'countryname', 'countryname'), []],\n",
       "     [(18, 'continent', 'continent'), []]]),\n",
       "   ((20, 'car_makers', 'car_makers'),\n",
       "    [[(22, 'id', 'id'), []],\n",
       "     [(24, 'maker', 'maker'), []],\n",
       "     [(26, 'fullname', 'fullname'), []],\n",
       "     [(28, 'country', 'country'), []]]),\n",
       "   ((30, 'model_list', 'model_list'),\n",
       "    [[(32, 'modelid', 'modelid'), []],\n",
       "     [(34, 'maker', 'maker'), []],\n",
       "     [(36, 'model', 'model'), []]]),\n",
       "   ((38, 'car_names', 'car_names'),\n",
       "    [[(40, 'makeid', 'makeid'), []],\n",
       "     [(42, 'model', 'model'), []],\n",
       "     [(44, 'make', 'make'), []]]),\n",
       "   ((46, 'cars_data', 'cars_data'),\n",
       "    [[(48, 'id', 'id'), []],\n",
       "     [(50, 'mpg', 'mpg'), []],\n",
       "     [(52, 'cylinders', 'cylinders'), []],\n",
       "     [(54, 'edispl', 'edispl'), []],\n",
       "     [(56, 'horsepower', 'horsepower'), []],\n",
       "     [(58, 'weight', 'weight'), []],\n",
       "     [(60, 'accelerate', 'accelerate'), []],\n",
       "     [(62, 'year', 'year'), []]])]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['struct_in'], ex['parsed_struct_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ecf24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc29fcbf",
   "metadata": {},
   "source": [
    "### test exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7dadd43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.exp_2_gpt2 import trace_exp2_section_corrupt_restore_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ed4aa600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 10\n",
    "ex = copy.deepcopy(processed_spider_dev[_id])\n",
    "a_ex_list = ctu2.create_analysis_sample_dicts_gpt2(mt_uskg_gpt2, ex, subject_type='column')\n",
    "len(a_ex_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4e6ee0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.9999260902404785, tensor([1499], device='cuda:0'), ' country', True)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex = a_ex_list[0]\n",
    "a_ex = ctu2.add_clean_prediction_gpt2(mt_uskg_gpt2, a_ex, samples=2)\n",
    "\n",
    "a_ex['answer_len'], \\\n",
    "a_ex['base_score'], \\\n",
    "a_ex['answers_t'], \\\n",
    "a_ex['answer'], \\\n",
    "a_ex['correct_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4c666935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = trace_exp2_section_corrupt_restore_gpt2(mt_uskg_gpt2, a_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "592b09f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 11),\n",
       " (16, 97),\n",
       " (100, 112),\n",
       " 'Show all countries and the number of singers in each country.; structed knowledge: | concert_singer | stadium : stadium_id, location, name, capacity, highest, lowest, average | singer : singer_id, name, country, song_name, song_release_year, age, is_male | concert : concert_id, concert_name, theme, stadium_id, year | singer_in_concert : concert_id, singer_id ; SQL: select',\n",
       " 'country')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['text_range'], a_ex['struct_range'], a_ex['sql_range'], a_ex['dec_prompt'], a_ex['expect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4fdadd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(47, 50)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['self_ranges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8c7232cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_toks = mt_uskg_gpt2.tokenizer.tokenize(a_ex['dec_prompt'])\n",
    "len(dec_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e5b2fbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', 'Ġcountry', ',']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_toks[a_ex['self_ranges'][0][0] : a_ex['self_ranges'][0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "15d75ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mt_uskg_gpt2.tokenizer.tokenize(a_ex['expect']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6b39d994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'Show all countries and the number of singers in each country.; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id',\n",
       " 'seq_out': 'select country, count(*) from singer group by country',\n",
       " 'dec_prompt': 'Show all countries and the number of singers in each country.; structed knowledge: | concert_singer | stadium : stadium_id, location, name, capacity, highest, lowest, average | singer : singer_id, name, country, song_name, song_release_year, age, is_male | concert : concert_id, concert_name, theme, stadium_id, year | singer_in_concert : concert_id, singer_id ; SQL: select',\n",
       " 'db_id': 'concert_singer',\n",
       " 'expect': 'country',\n",
       " 'expect_type': 'column',\n",
       " 'expect_input_ranges': [(48, 49)],\n",
       " 'self_ranges': [(47, 50)],\n",
       " 'expect_table': 'singer',\n",
       " 'answer': ' country',\n",
       " 'base_score': 0.9999260902404785,\n",
       " 'answers_t': [1499],\n",
       " 'correct_prediction': True,\n",
       " 'category': {'sql_hardness': 'medium',\n",
       "  'node_role': 'select',\n",
       "  'text_match': 'exact',\n",
       "  'node_len': '1'},\n",
       " 'trace_scores': {'corrupt': {'text': 3.304064739495516e-05,\n",
       "   'struct': 2.078924808301963e-06,\n",
       "   'self': 0.3419209420681,\n",
       "   'struct_context': 1.1454174142500051e-07,\n",
       "   'all': 9.779104637175351e-09},\n",
       "  'corrupt_text_restore': {'text': 0.004112886730581522,\n",
       "   'struct': 0.9999667406082153,\n",
       "   'self': 0.1688166707754135,\n",
       "   'struct_context': 0.04002547264099121,\n",
       "   'all': 0.9998542070388794}},\n",
       " 'low_score': 9.779104637175351e-09,\n",
       " 'is_good_sample': True}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f6a96",
   "metadata": {},
   "source": [
    "### test exp4, exp4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "5b146b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.exp_4_gpt2 import trace_exp4_1_attention_patterns_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "024fb16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'enc_sentence', 'tokenized_item', 'pre_sql_sequence', 'text_range', 'struct_range', 'sql_range', 'parsed_struct_in', 'alias2table', 'col2table', 'col_name_counter', 'tab_name_counter', 'struct_node_ranges_dict', 'sql_tokens', 'sql_token_ranges', 'tok_ranges2type', 'type2tok_ranges', 'sql_col_nodes', 'sql_tab_nodes', 'sql_alias_nodes', 'dec_prompt', 'occ_cols', 'occ_tabs', 'non_occ_cols', 'non_occ_tabs', 'col_self_ranges', 'col_context_ranges', 'tab_self_ranges', 'tab_context_ranges'])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 111\n",
    "ex = copy.deepcopy(processed_spider_dev[_id])\n",
    "a_ex = ctu2.create_analysis_sample_dicts_all_nodes_gpt2(mt_uskg_gpt2, ex)\n",
    "a_ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "53f8f0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['enc_sentence'], a_ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "229a5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trace_exp4_1_attention_patterns_gpt2(mt_uskg_gpt2, a_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e1e500e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'db_id', 'col_self_ranges', 'col_context_ranges', 'tab_self_ranges', 'tab_context_ranges', 'occ_cols', 'non_occ_cols', 'occ_tabs', 'non_occ_tabs', 'attentions'])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "78ef4db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['makeid', 'make', 'accelerate', 'contid', 'countryid', 'countryname', 'fullname', 'country', 'modelid', 'mpg', 'cylinders', 'edispl', 'horsepower', 'weight', 'year'])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['attentions']['col'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "7a1dfc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix#0 Layer=22 Head=9 -> 0.55\n",
      "prefix#1 Layer=17 Head=13 -> 0.67\n",
      "prefix#1 Layer=18 Head=1 -> 0.61\n",
      "prefix#1 Layer=18 Head=12 -> 0.7\n",
      "prefix#2 Layer=18 Head=6 -> 0.78\n",
      "prefix#2 Layer=21 Head=11 -> 0.67\n",
      "prefix#4 Layer=18 Head=5 -> 0.54\n",
      "prefix#4 Layer=18 Head=14 -> 0.88\n",
      "prefix#4 Layer=21 Head=0 -> 0.56\n",
      "prefix#4 Layer=21 Head=6 -> 0.6\n",
      "prefix#5 Layer=17 Head=1 -> 0.54\n",
      "prefix#6 Layer=10 Head=1 -> 0.92\n",
      "prefix#6 Layer=19 Head=0 -> 0.77\n",
      "prefix#7 Layer=23 Head=14 -> 0.62\n",
      "prefix#8 Layer=16 Head=10 -> 0.52\n",
      "prefix#8 Layer=19 Head=13 -> 0.62\n",
      "prefix#8 Layer=21 Head=9 -> 0.52\n",
      "prefix#10 Layer=5 Head=8 -> 0.55\n",
      "prefix#10 Layer=10 Head=2 -> 0.54\n",
      "prefix#10 Layer=10 Head=6 -> 0.82\n",
      "prefix#10 Layer=14 Head=0 -> 0.56\n",
      "prefix#10 Layer=21 Head=2 -> 0.71\n",
      "prefix#11 Layer=13 Head=11 -> 0.92\n",
      "prefix#11 Layer=15 Head=14 -> 0.89\n",
      "prefix#11 Layer=19 Head=2 -> 0.78\n",
      "prefix#11 Layer=19 Head=15 -> 0.78\n",
      "prefix#12 Layer=18 Head=13 -> 0.61\n",
      "prefix#12 Layer=20 Head=7 -> 0.77\n",
      "prefix#12 Layer=20 Head=14 -> 0.61\n",
      "prefix#12 Layer=22 Head=5 -> 0.61\n",
      "prefix#12 Layer=23 Head=1 -> 0.71\n",
      "prefix#12 Layer=23 Head=10 -> 0.58\n",
      "prefix#14 Layer=5 Head=3 -> 0.60\n",
      "prefix#14 Layer=21 Head=8 -> 0.53\n",
      "prefix#14 Layer=23 Head=3 -> 0.60\n",
      "prefix#15 Layer=5 Head=6 -> 0.51\n",
      "prefix#15 Layer=16 Head=8 -> 0.86\n",
      "prefix#15 Layer=16 Head=12 -> 0.76\n",
      "prefix#16 Layer=15 Head=10 -> 0.72\n",
      "prefix#16 Layer=20 Head=15 -> 0.52\n",
      "prefix#17 Layer=10 Head=14 -> 0.74\n",
      "prefix#18 Layer=20 Head=13 -> 0.89\n",
      "prefix#19 Layer=23 Head=2 -> 0.62\n",
      "text Layer=4 Head=6 -> 0.82\n",
      "text Layer=6 Head=4 -> 0.83\n",
      "text Layer=6 Head=9 -> 0.54\n",
      "text Layer=6 Head=15 -> 0.52\n",
      "text Layer=7 Head=2 -> 1.\n",
      "text Layer=7 Head=4 -> 0.53\n",
      "text Layer=7 Head=11 -> 0.92\n",
      "text Layer=8 Head=15 -> 0.51\n",
      "text Layer=9 Head=3 -> 0.97\n",
      "text Layer=9 Head=9 -> 0.62\n",
      "text Layer=10 Head=8 -> 0.57\n",
      "text Layer=10 Head=11 -> 0.58\n",
      "text Layer=11 Head=1 -> 0.96\n",
      "text Layer=11 Head=3 -> 0.96\n",
      "text Layer=11 Head=14 -> 0.83\n",
      "text Layer=12 Head=0 -> 0.64\n",
      "text Layer=12 Head=1 -> 0.99\n",
      "text Layer=12 Head=4 -> 0.58\n",
      "text Layer=12 Head=12 -> 0.78\n",
      "text Layer=12 Head=13 -> 0.61\n",
      "text Layer=13 Head=14 -> 0.94\n",
      "text Layer=14 Head=8 -> 0.62\n",
      "text Layer=14 Head=9 -> 1.\n",
      "text Layer=14 Head=14 -> 0.57\n",
      "text Layer=15 Head=6 -> 0.67\n",
      "text Layer=16 Head=15 -> 0.84\n",
      "self Layer=3 Head=3 -> 0.55\n",
      "self Layer=4 Head=3 -> 0.62\n",
      "self Layer=4 Head=4 -> 0.53\n",
      "self Layer=4 Head=13 -> 0.99\n",
      "self Layer=5 Head=11 -> 1.\n",
      "self Layer=6 Head=7 -> 0.94\n",
      "context Layer=0 Head=0 -> 0.68\n",
      "context Layer=0 Head=1 -> 0.76\n",
      "context Layer=0 Head=2 -> 0.83\n",
      "context Layer=0 Head=3 -> 0.61\n",
      "context Layer=0 Head=4 -> 0.75\n",
      "context Layer=0 Head=5 -> 0.69\n",
      "context Layer=0 Head=6 -> 0.55\n",
      "context Layer=0 Head=7 -> 0.71\n",
      "context Layer=0 Head=8 -> 0.75\n",
      "context Layer=0 Head=9 -> 0.71\n",
      "context Layer=0 Head=10 -> 0.70\n",
      "context Layer=0 Head=11 -> 0.82\n",
      "context Layer=0 Head=12 -> 0.71\n",
      "context Layer=0 Head=13 -> 0.55\n",
      "context Layer=0 Head=14 -> 0.77\n",
      "context Layer=0 Head=15 -> 0.75\n",
      "context Layer=1 Head=1 -> 0.72\n",
      "context Layer=1 Head=2 -> 0.63\n",
      "context Layer=1 Head=7 -> 0.87\n",
      "context Layer=1 Head=8 -> 0.68\n",
      "context Layer=1 Head=9 -> 0.62\n",
      "context Layer=1 Head=11 -> 0.63\n",
      "context Layer=1 Head=12 -> 0.64\n",
      "context Layer=1 Head=13 -> 0.62\n",
      "context Layer=1 Head=14 -> 0.52\n",
      "context Layer=2 Head=5 -> 0.72\n",
      "context Layer=2 Head=6 -> 0.56\n",
      "context Layer=2 Head=7 -> 0.72\n",
      "context Layer=2 Head=9 -> 0.54\n",
      "context Layer=2 Head=10 -> 0.51\n",
      "context Layer=2 Head=15 -> 0.76\n",
      "context Layer=3 Head=2 -> 0.63\n",
      "context Layer=3 Head=13 -> 0.70\n",
      "context Layer=3 Head=14 -> 0.73\n",
      "context Layer=4 Head=1 -> 0.57\n",
      "context Layer=4 Head=12 -> 0.53\n",
      "context Layer=4 Head=15 -> 0.75\n",
      "context Layer=5 Head=13 -> 0.64\n",
      "context Layer=6 Head=5 -> 0.55\n",
      "context Layer=6 Head=11 -> 0.71\n",
      "context Layer=7 Head=6 -> 0.57\n",
      "context Layer=8 Head=3 -> 0.55\n",
      "context Layer=8 Head=7 -> 0.87\n",
      "context Layer=8 Head=12 -> 0.52\n",
      "context Layer=9 Head=4 -> 0.57\n",
      "context Layer=9 Head=10 -> 0.53\n",
      "context Layer=9 Head=11 -> 0.51\n",
      "context Layer=9 Head=14 -> 0.68\n",
      "context Layer=10 Head=15 -> 0.81\n",
      "context Layer=11 Head=2 -> 0.63\n",
      "context Layer=11 Head=6 -> 0.92\n",
      "context Layer=11 Head=7 -> 0.66\n",
      "context Layer=12 Head=8 -> 0.88\n",
      "context Layer=12 Head=15 -> 0.81\n",
      "context Layer=13 Head=3 -> 0.93\n",
      "context Layer=13 Head=5 -> 0.88\n",
      "context Layer=13 Head=7 -> 0.70\n",
      "context Layer=13 Head=10 -> 0.84\n",
      "context Layer=13 Head=13 -> 0.71\n",
      "context Layer=14 Head=3 -> 0.72\n",
      "context Layer=14 Head=4 -> 0.70\n",
      "context Layer=14 Head=7 -> 0.58\n",
      "context Layer=14 Head=12 -> 0.69\n",
      "context Layer=14 Head=13 -> 0.76\n",
      "context Layer=14 Head=15 -> 0.54\n",
      "context Layer=15 Head=13 -> 0.85\n",
      "context Layer=16 Head=7 -> 0.68\n",
      "context Layer=17 Head=15 -> 0.78\n",
      "context Layer=18 Head=3 -> 0.88\n",
      "context Layer=18 Head=15 -> 0.73\n",
      "context Layer=20 Head=1 -> 0.84\n",
      "context Layer=21 Head=1 -> 0.71\n",
      "context Layer=21 Head=4 -> 0.52\n",
      "context Layer=23 Head=5 -> 0.88\n",
      "context Layer=23 Head=6 -> 0.75\n",
      "context Layer=23 Head=11 -> 0.81\n",
      "context Layer=23 Head=13 -> 0.53\n"
     ]
    }
   ],
   "source": [
    "_c = 'accelerate'\n",
    "\n",
    "for sect_k, sect_l in res['attentions']['col'][_c].items():\n",
    "    for layer_i, layer_l in enumerate(sect_l):\n",
    "        for head_i, w in enumerate(layer_l):\n",
    "            if float(w) > 0.5:\n",
    "                print(f'{sect_k} Layer={layer_i} Head={head_i} -> {w}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "02de2892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix#0 Layer=12 Head=6 -> 0.53\n",
      "prefix#0 Layer=21 Head=5 -> 0.54\n",
      "prefix#1 Layer=17 Head=5 -> 0.86\n",
      "prefix#1 Layer=18 Head=1 -> 0.56\n",
      "prefix#1 Layer=18 Head=8 -> 0.55\n",
      "prefix#1 Layer=21 Head=0 -> 0.90\n",
      "prefix#2 Layer=15 Head=8 -> 0.57\n",
      "prefix#3 Layer=13 Head=4 -> 0.55\n",
      "prefix#3 Layer=14 Head=4 -> 0.56\n",
      "prefix#3 Layer=18 Head=3 -> 0.52\n",
      "prefix#3 Layer=23 Head=15 -> 0.84\n",
      "prefix#4 Layer=23 Head=6 -> 0.72\n",
      "prefix#5 Layer=7 Head=2 -> 0.81\n",
      "prefix#5 Layer=21 Head=15 -> 0.75\n",
      "prefix#6 Layer=14 Head=1 -> 0.62\n",
      "prefix#6 Layer=15 Head=10 -> 0.63\n",
      "prefix#6 Layer=19 Head=4 -> 0.6\n",
      "prefix#6 Layer=20 Head=4 -> 0.76\n",
      "prefix#6 Layer=23 Head=9 -> 0.74\n",
      "prefix#6 Layer=23 Head=12 -> 0.85\n",
      "prefix#7 Layer=21 Head=14 -> 0.72\n",
      "prefix#8 Layer=16 Head=2 -> 0.94\n",
      "prefix#8 Layer=21 Head=3 -> 0.56\n",
      "prefix#9 Layer=19 Head=10 -> 0.53\n",
      "prefix#9 Layer=21 Head=10 -> 0.53\n",
      "prefix#9 Layer=23 Head=14 -> 0.69\n",
      "prefix#10 Layer=5 Head=8 -> 0.66\n",
      "prefix#10 Layer=11 Head=5 -> 0.62\n",
      "prefix#10 Layer=18 Head=5 -> 0.76\n",
      "prefix#10 Layer=20 Head=3 -> 0.84\n",
      "prefix#11 Layer=7 Head=14 -> 0.51\n",
      "prefix#11 Layer=15 Head=14 -> 0.66\n",
      "prefix#11 Layer=16 Head=0 -> 0.60\n",
      "prefix#11 Layer=18 Head=2 -> 0.62\n",
      "prefix#11 Layer=20 Head=6 -> 0.85\n",
      "prefix#11 Layer=22 Head=8 -> 0.52\n",
      "prefix#12 Layer=15 Head=15 -> 0.53\n",
      "prefix#13 Layer=6 Head=8 -> 0.76\n",
      "prefix#13 Layer=17 Head=0 -> 0.68\n",
      "prefix#13 Layer=17 Head=3 -> 0.69\n",
      "prefix#13 Layer=22 Head=15 -> 0.77\n",
      "prefix#14 Layer=18 Head=9 -> 0.65\n",
      "prefix#15 Layer=16 Head=4 -> 0.51\n",
      "prefix#15 Layer=23 Head=1 -> 0.66\n",
      "prefix#16 Layer=18 Head=14 -> 0.93\n",
      "prefix#16 Layer=20 Head=15 -> 0.78\n",
      "prefix#17 Layer=19 Head=0 -> 0.54\n",
      "prefix#17 Layer=23 Head=13 -> 0.83\n",
      "prefix#18 Layer=20 Head=13 -> 0.69\n",
      "prefix#19 Layer=22 Head=6 -> 0.87\n",
      "prefix#19 Layer=22 Head=9 -> 0.52\n",
      "prefix#19 Layer=23 Head=2 -> 0.89\n",
      "text Layer=0 Head=0 -> 0.53\n",
      "text Layer=0 Head=1 -> 0.59\n",
      "text Layer=0 Head=3 -> 0.56\n",
      "text Layer=0 Head=4 -> 0.61\n",
      "text Layer=0 Head=6 -> 0.55\n",
      "text Layer=0 Head=7 -> 0.52\n",
      "text Layer=0 Head=11 -> 0.59\n",
      "text Layer=0 Head=12 -> 0.56\n",
      "text Layer=0 Head=13 -> 0.54\n",
      "text Layer=0 Head=15 -> 0.57\n",
      "text Layer=1 Head=6 -> 0.55\n",
      "text Layer=1 Head=8 -> 0.69\n",
      "text Layer=7 Head=11 -> 0.83\n",
      "text Layer=8 Head=15 -> 0.56\n",
      "text Layer=9 Head=9 -> 0.82\n",
      "text Layer=9 Head=13 -> 0.58\n",
      "text Layer=10 Head=8 -> 0.91\n",
      "text Layer=11 Head=1 -> 1.\n",
      "text Layer=11 Head=3 -> 0.92\n",
      "text Layer=11 Head=4 -> 0.65\n",
      "text Layer=12 Head=0 -> 0.88\n",
      "text Layer=12 Head=1 -> 0.99\n",
      "text Layer=12 Head=2 -> 0.9\n",
      "text Layer=12 Head=12 -> 0.8\n",
      "text Layer=12 Head=13 -> 0.94\n",
      "text Layer=13 Head=2 -> 0.84\n",
      "text Layer=13 Head=8 -> 0.57\n",
      "text Layer=13 Head=12 -> 0.81\n",
      "text Layer=13 Head=13 -> 0.65\n",
      "text Layer=13 Head=14 -> 0.97\n",
      "text Layer=14 Head=2 -> 0.96\n",
      "text Layer=14 Head=5 -> 0.52\n",
      "text Layer=14 Head=9 -> 0.97\n",
      "text Layer=14 Head=14 -> 0.87\n",
      "text Layer=15 Head=6 -> 0.90\n",
      "text Layer=15 Head=12 -> 0.9\n",
      "text Layer=16 Head=10 -> 0.52\n",
      "text Layer=16 Head=13 -> 0.59\n",
      "text Layer=16 Head=15 -> 0.95\n",
      "text Layer=17 Head=2 -> 0.73\n",
      "text Layer=18 Head=0 -> 0.69\n",
      "text Layer=18 Head=7 -> 0.58\n",
      "text Layer=23 Head=5 -> 0.66\n",
      "self Layer=1 Head=4 -> 0.57\n",
      "self Layer=3 Head=3 -> 0.52\n",
      "self Layer=4 Head=13 -> 0.97\n",
      "self Layer=5 Head=3 -> 0.80\n",
      "self Layer=5 Head=11 -> 1.\n",
      "self Layer=6 Head=7 -> 1.\n",
      "self Layer=8 Head=1 -> 0.69\n",
      "self Layer=10 Head=15 -> 0.66\n",
      "self Layer=11 Head=6 -> 0.64\n",
      "self Layer=12 Head=8 -> 0.93\n",
      "self Layer=13 Head=5 -> 0.92\n",
      "self Layer=16 Head=7 -> 0.86\n",
      "self Layer=16 Head=12 -> 0.52\n",
      "context Layer=3 Head=8 -> 0.66\n",
      "context Layer=3 Head=10 -> 0.67\n",
      "context Layer=3 Head=13 -> 0.76\n",
      "context Layer=4 Head=1 -> 0.53\n",
      "context Layer=4 Head=11 -> 0.55\n",
      "context Layer=6 Head=4 -> 0.52\n",
      "context Layer=8 Head=6 -> 0.51\n",
      "context Layer=11 Head=14 -> 0.59\n",
      "context Layer=13 Head=3 -> 0.81\n",
      "context Layer=13 Head=11 -> 0.75\n",
      "context Layer=14 Head=7 -> 0.77\n",
      "context Layer=14 Head=13 -> 0.53\n",
      "context Layer=15 Head=3 -> 0.52\n",
      "context Layer=15 Head=4 -> 0.51\n"
     ]
    }
   ],
   "source": [
    "_c = 'contid'\n",
    "\n",
    "for sect_k, sect_l in res['attentions']['col'][_c].items():\n",
    "    for layer_i, layer_l in enumerate(sect_l):\n",
    "        for head_i, w in enumerate(layer_l):\n",
    "            if float(w) > 0.5:\n",
    "                print(f'{sect_k} Layer={layer_i} Head={head_i} -> {w}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790496a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adda5e9e",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e177124",
   "metadata": {},
   "source": [
    "### Exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9de567c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_type = 'column'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/gpt2_tracing/exp2_section_corrupt_restore_gpt2/exp=gpt2_2.0_dev_{expect_type}-replace=True-noise=0.0.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "98758f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2002, (1364, 1364), 614, 24, 638, 'good / correct = 1364 / 1388')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_samples = 0\n",
    "n_good_samples = 0\n",
    "n_too_hard = 0      # wrong answer \n",
    "n_too_easy = 0      # base - low < 0.5\n",
    "\n",
    "good_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, ex in enumerate(all_samples):\n",
    "    for d in ex['trace_results']:\n",
    "        total_samples += 1\n",
    "\n",
    "        if d.get('is_good_sample', True):\n",
    "            n_good_samples += 1\n",
    "            d['ex_id'] = i\n",
    "            good_samples.append(d)\n",
    "        elif not d['correct_prediction']:\n",
    "            n_too_hard += 1\n",
    "            bad_samples.append(d)\n",
    "        else:\n",
    "            assert d['base_score'] - d['low_score'] < 0.5\n",
    "            n_too_easy += 1\n",
    "            bad_samples.append(d)\n",
    "            \n",
    "total_samples, (n_good_samples, len(good_samples)), n_too_hard, n_too_easy, len(bad_samples), \\\n",
    "f'good / correct = {n_good_samples} / {n_good_samples + n_too_easy}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "87f77135",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'Show name, country, age for all singers ordered by age from the oldest to the youngest.; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id',\n",
       " 'seq_out': 'select name, country, age from singer order by age desc',\n",
       " 'dec_prompt': 'Show name, country, age for all singers ordered by age from the oldest to the youngest.; structed knowledge: | concert_singer | stadium : stadium_id, location, name, capacity, highest, lowest, average | singer : singer_id, name, country, song_name, song_release_year, age, is_male | concert : concert_id, concert_name, theme, stadium_id, year | singer_in_concert : concert_id, singer_id ; SQL: select name,',\n",
       " 'db_id': 'concert_singer',\n",
       " 'expect': 'country',\n",
       " 'expect_type': 'column',\n",
       " 'expect_input_ranges': [[55, 56]],\n",
       " 'self_ranges': [[54, 57]],\n",
       " 'expect_table': 'singer',\n",
       " 'answer': ' country',\n",
       " 'base_score': 0.9999970197677612,\n",
       " 'answers_t': [1499],\n",
       " 'correct_prediction': True,\n",
       " 'category': {'sql_hardness': 'medium',\n",
       "  'node_role': 'select',\n",
       "  'text_match': 'exact',\n",
       "  'node_len': '1'},\n",
       " 'trace_scores': {'corrupt': {'text': 0.004921693354845047,\n",
       "   'struct': 1.7719933964599477e-08,\n",
       "   'self': 0.9998030066490173,\n",
       "   'struct_context': 3.7146175912994295e-08,\n",
       "   'all': 1.004086982447916e-07},\n",
       "  'corrupt_text_restore': {'text': 0.12290767580270767,\n",
       "   'struct': 0.09271180629730225,\n",
       "   'self': 0.003406661096960306,\n",
       "   'struct_context': 0.6112548112869263,\n",
       "   'all': 0.7805094718933105}},\n",
       " 'low_score': 1.004086982447916e-07,\n",
       " 'is_good_sample': True,\n",
       " 'ex_id': 2}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b406f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Overall avg\n",
    "\n",
    "trace_scores_avg = {\n",
    "    'corrupt' : defaultdict(float),\n",
    "    'corrupt_text_restore': defaultdict(float),\n",
    "}\n",
    "\n",
    "for d in good_samples:\n",
    "    for type_k, type_d in d['trace_scores'].items():\n",
    "        for k, v in type_d.items():\n",
    "            trace_scores_avg[type_k][k] += v\n",
    "\n",
    "for type_k, type_d in trace_scores_avg.items():\n",
    "    for k, s in type_d.items():\n",
    "        type_d[k] = s / len(good_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6c3e3324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corrupt': defaultdict(float,\n",
       "             {'text': 0.041550320565249876,\n",
       "              'struct': 0.0037280468717201805,\n",
       "              'self': 0.3648502066803721,\n",
       "              'struct_context': 0.006297542297234418,\n",
       "              'all': 5.139980438708388e-05}),\n",
       " 'corrupt_text_restore': defaultdict(float,\n",
       "             {'text': 0.07921842629209634,\n",
       "              'struct': 0.2023287613100771,\n",
       "              'self': 0.11909362401478271,\n",
       "              'struct_context': 0.11375640216889772,\n",
       "              'all': 0.24608358883900305})}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_scores_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d451fefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\ttext  \tstruct\tself  \tstruct_context\tall   \n",
      "corrupt     \t0.0416\t0.0037\t0.3649\t0.0063\t0.0001\n",
      "corrupt_text_restore\t0.0792\t0.2023\t0.1191\t0.1138\t0.2461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(trace_scores_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494d44b0",
   "metadata": {},
   "source": [
    "### Exp4: inspect attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f48d52ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_type = 'table'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/gpt2_tracing/exp4_inspect_attention_gpt2/exp=4_dev_{exp_type}.jsonl'\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    all_samples = [json.loads(l) for l in f]\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "bbfa8d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'db_id', 'expect', 'expect_type', 'expect_input_ranges', 'self_ranges', 'expect_table', 'category', 'answer', 'probs', 'base_score', 'answers_t', 'correct_prediction', 'attentions'])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples[1]['trace_results'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "70d4b7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"What are the students' first names who have both cats and dogs as pets?; structed knowledge: | pets_1 | student : stuid , lname , fname , age , sex , major , advisor , city_code | has_pet : stuid , petid | pets : petid , pettype ( dog , cat ) , pet_age , weight\",\n",
       " \"What are the students' first names who have both cats and dogs as pets?; structed knowledge: | pets_1 | student : stuid, lname, fname, age, sex, major, advisor, city_code | has_pet : stuid, petid | pets : petid, pettype ( dog, cat ), pet_age, weight ; SQL: select t1.fname from\",\n",
       " 'student')"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 6\n",
    "d = all_samples[_id]['trace_results'][0]\n",
    "d['enc_sentence'], d['dec_prompt'], d['expect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "61808bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'db_id', 'expect', 'expect_type', 'expect_input_ranges', 'self_ranges', 'expect_table', 'category', 'answer', 'probs', 'base_score', 'answers_t', 'correct_prediction', 'attentions']),\n",
       " dict_keys(['all']),\n",
       " dict_keys(['attn', 'head_tokens', 'cand_tokens']))"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys(), d['attentions'].keys(), d['attentions']['all'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "c99e2fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' select', ' t', '1', '.', 'f', 'name', ' from']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tokens = d['attentions']['all']['cand_tokens']\n",
    "prompt_tokens = '@'.join(prompt_tokens).split('@ ;@ SQL@:@')[1].split('@')\n",
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121763f7",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "fac9ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _draw_single_plot_2(ax, val_mat, x_labels=None, y_labels=None, title=None):\n",
    "    \"\"\"\n",
    "    X: # heads\n",
    "    Y: cand tokens\n",
    "    Title: head token (together with full expect)\n",
    "    \"\"\"\n",
    "    if isinstance(val_mat, list):\n",
    "        val_mat = numpy.array(val_mat)\n",
    "    h = ax.pcolormesh(\n",
    "        val_mat,\n",
    "        cmap=\"Reds\",\n",
    "        vmax=1.0,\n",
    "        vmin=0.0,\n",
    "    )\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_yticks([0.5 + i for i in range(val_mat.shape[0])])\n",
    "    ax.set_xticks([0.5 + i for i in range(val_mat.shape[1])])\n",
    "    if x_labels is not None:\n",
    "        ax.set_xticklabels(x_labels, fontsize=8)\n",
    "    if y_labels is not None:\n",
    "        ax.set_yticklabels(y_labels, fontsize=8)\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.set_xlabel(f\"# Head\")\n",
    "    ax.set_ylabel(f\"Attention candidate tokens\")\n",
    "    \n",
    "    # cb = plt.colorbar(h)\n",
    "    # divider = make_axes_locatable(ax)\n",
    "    # cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    # cb = fig.colorbar(h, cax=cax)\n",
    "    cb = plt.colorbar(h, ax=ax)\n",
    "\n",
    "#     if xlabel is not None:\n",
    "#         ax.set_xlabel(xlabel)\n",
    "#     elif answer is not None:\n",
    "#         # The following should be cb.ax.set_xlabel, but this is broken in matplotlib 3.5.1.\n",
    "#         cb.ax.set_title(f\"p({str(answer).strip()})\", y=-0.16, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "af0bb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uskg_attention_gpt2(d, inspect_layers=None, savepdf=None):\n",
    "    \"\"\"\n",
    "    Assume 16 heads, 24 layers (T5 large config)\n",
    "    \n",
    "    att_part: enc, cross, dec \n",
    "    \"\"\"\n",
    "    \n",
    "    ## encoder self attention \n",
    "    if inspect_layers is None:\n",
    "        inspect_layers = [0, 6, 12, 18, 23]\n",
    "    elif inspect_layers == 'all':\n",
    "        inspect_layers = [i for i in range(24)]\n",
    "    att_dict = d['attentions']['all']\n",
    "    \n",
    "    cand_len = len(att_dict['cand_tokens'])\n",
    "    head_len = len(att_dict['head_tokens'])\n",
    "    # prompt_tokens: for title\n",
    "    prompt_tokens = d['attentions']['all']['cand_tokens']\n",
    "    prompt_tokens = '@'.join(prompt_tokens).split('@ ;@ SQL@:@')[1].split('@')\n",
    "    prompt_len = len(prompt_tokens)\n",
    "\n",
    "    fig_w = len(inspect_layers) * 4 + 2\n",
    "    fig_h = (0.11*cand_len + 1) * head_len + 2\n",
    "    fig, ax_list = plt.subplots(\n",
    "        nrows=head_len,\n",
    "        ncols=len(inspect_layers),\n",
    "        squeeze=False,\n",
    "        figsize=(fig_w, fig_h))\n",
    "\n",
    "    att_mat = ctu.nested_list_processing(att_dict['attn'], func=float)\n",
    "    att_mat = np.array(att_mat)\n",
    "    \n",
    "    for expect_i in range(len(att_dict['head_tokens'])):\n",
    "        for l_id, layer in enumerate(inspect_layers):\n",
    "            val_mat = att_mat[layer, :, expect_i, :]  # layer, all heads, expect tok i -> all toks \n",
    "            val_mat = val_mat.transpose()    # (cand_toks, n_heads)\n",
    "            x_labels = range(val_mat.shape[1])\n",
    "            y_labels = att_dict['cand_tokens']\n",
    "#             if att_part == 'enc':\n",
    "#                 # enc: correct tokens\n",
    "#                 title_toks = att_dict['head_tokens'][:expect_i] + [f\"*{att_dict['head_tokens'][expect_i]}*\"]\n",
    "#             else:\n",
    "            # cross / dec: use gold tokens from dec_prompt for previous steps and predicted token at this step\n",
    "            # (dec_prompt ends with the first (head_len-1) tokens of the target node)\n",
    "            title_toks = prompt_tokens[prompt_len - (head_len-1) : prompt_len - (head_len-1) + expect_i] + [f\"*{att_dict['head_tokens'][expect_i]}*\"]\n",
    "            \n",
    "            title = f\"L{layer}  Head token: {' '.join(title_toks)}\\n\"\n",
    "            \n",
    "            ax = ax_list[expect_i, l_id]\n",
    "            _draw_single_plot_2(ax,\n",
    "                                val_mat=val_mat, \n",
    "                                x_labels=x_labels, \n",
    "                                y_labels=y_labels,\n",
    "                                title=title)\n",
    "            \n",
    "    fig.tight_layout()\n",
    "    if savepdf:\n",
    "        plt.savefig(savepdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "921639fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepdf_dir = '/home/yshao/Projects/rome/results/figs/gpt2_tracing/exp4_inspect_attention'\n",
    "os.makedirs(savepdf_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "3c648b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepdf_tmpl = os.path.join(savepdf_dir, f'tmp-{_id}.pdf')\n",
    "plot_uskg_attention_gpt2(d, savepdf=savepdf_tmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "fb74edde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf971c4b749c4f63bd9d0255ddc5913f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Run for all! \n",
    "\n",
    "fig_dir = os.path.join(savepdf_dir, f'dev_{exp_type}')\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "global_ex_id = 0\n",
    "for ex_id in tqdm(range(len(all_samples))):\n",
    "    for a_ex_id in range(len(all_samples[ex_id]['trace_results'])):\n",
    "        d = all_samples[ex_id]['trace_results'][a_ex_id]\n",
    "        _suffix = '-WRONGPRED' if not d['correct_prediction'] else ''\n",
    "        savepdf_path = os.path.join(fig_dir, f'{global_ex_id}-ex={ex_id}.{a_ex_id}{_suffix}.pdf')\n",
    "        plot_uskg_attention_gpt2(d, savepdf=savepdf_path)\n",
    "        # print(f'{global_ex_id}-ex={ex_id}.{a_ex_id}')\n",
    "        global_ex_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "20e42336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not correct: 0-ex=0.0\n",
      "Not correct: 1-ex=1.0\n",
      "Not correct: 3-ex=3.0\n",
      "Not correct: 4-ex=3.1\n",
      "Not correct: 5-ex=4.0\n",
      "Not correct: 6-ex=5.0\n",
      "Not correct: 9-ex=6.2\n",
      "Not correct: 12-ex=6.5\n",
      "Not correct: 13-ex=7.0\n",
      "Not correct: 16-ex=9.0\n",
      "Not correct: 17-ex=9.1\n",
      "Not correct: 19-ex=10.1\n",
      "Not correct: 20-ex=10.2\n",
      "Not correct: 21-ex=10.3\n",
      "Not correct: 22-ex=11.0\n",
      "Not correct: 24-ex=12.0\n",
      "Not correct: 25-ex=13.0\n",
      "Not correct: 26-ex=13.1\n",
      "Not correct: 31-ex=16.0\n",
      "Not correct: 32-ex=16.1\n",
      "Not correct: 33-ex=17.0\n",
      "Not correct: 34-ex=18.0\n",
      "Not correct: 35-ex=19.0\n",
      "Not correct: 36-ex=20.0\n",
      "Not correct: 37-ex=21.0\n",
      "Not correct: 38-ex=21.1\n",
      "Not correct: 39-ex=22.0\n",
      "Not correct: 40-ex=22.1\n",
      "Not correct: 41-ex=22.2\n",
      "Not correct: 42-ex=23.0\n",
      "Not correct: 43-ex=23.1\n",
      "Not correct: 44-ex=24.0\n",
      "Not correct: 45-ex=24.1\n",
      "Not correct: 46-ex=24.2\n",
      "Not correct: 47-ex=24.3\n",
      "Not correct: 48-ex=25.0\n",
      "Not correct: 49-ex=26.0\n",
      "Not correct: 51-ex=28.0\n",
      "Not correct: 52-ex=28.1\n",
      "Not correct: 53-ex=29.0\n",
      "Not correct: 54-ex=30.0\n",
      "Not correct: 55-ex=31.0\n",
      "Not correct: 56-ex=32.0\n",
      "Not correct: 57-ex=33.0\n",
      "Not correct: 58-ex=34.0\n",
      "Not correct: 59-ex=34.1\n",
      "Not correct: 61-ex=36.0\n",
      "Not correct: 62-ex=36.1\n",
      "Not correct: 63-ex=37.0\n",
      "Not correct: 64-ex=37.1\n",
      "Not correct: 65-ex=38.0\n",
      "Not correct: 66-ex=38.1\n",
      "Not correct: 67-ex=39.0\n",
      "Not correct: 68-ex=40.0\n",
      "Not correct: 69-ex=40.1\n",
      "Not correct: 70-ex=41.0\n",
      "Not correct: 72-ex=42.0\n",
      "Not correct: 73-ex=42.1\n",
      "Not correct: 75-ex=44.0\n",
      "Not correct: 76-ex=45.0\n",
      "Not correct: 78-ex=46.1\n",
      "Not correct: 80-ex=47.1\n",
      "Not correct: 81-ex=48.0\n",
      "Not correct: 85-ex=51.0\n",
      "Not correct: 87-ex=53.0\n",
      "Not correct: 88-ex=53.1\n",
      "Not correct: 90-ex=54.1\n",
      "Not correct: 91-ex=55.0\n",
      "Not correct: 92-ex=55.1\n",
      "Not correct: 93-ex=55.2\n",
      "Not correct: 94-ex=55.3\n",
      "Not correct: 95-ex=56.0\n",
      "Not correct: 96-ex=57.0\n",
      "Not correct: 97-ex=58.0\n",
      "Not correct: 98-ex=59.0\n",
      "Not correct: 99-ex=60.0\n",
      "Not correct: 100-ex=61.0\n",
      "Not correct: 101-ex=61.1\n",
      "Not correct: 103-ex=63.0\n",
      "Not correct: 105-ex=65.0\n",
      "Not correct: 106-ex=66.0\n",
      "Not correct: 107-ex=66.1\n",
      "Not correct: 108-ex=67.0\n",
      "Not correct: 109-ex=67.1\n",
      "Not correct: 111-ex=69.0\n",
      "Not correct: 112-ex=70.0\n",
      "Not correct: 114-ex=70.2\n",
      "Not correct: 115-ex=70.3\n",
      "Not correct: 118-ex=71.0\n",
      "Not correct: 134-ex=82.0\n",
      "Not correct: 136-ex=84.0\n",
      "Not correct: 140-ex=89.0\n",
      "Not correct: 141-ex=89.1\n",
      "Not correct: 142-ex=89.2\n",
      "Not correct: 143-ex=90.0\n",
      "Not correct: 144-ex=90.1\n",
      "Not correct: 145-ex=90.2\n",
      "Not correct: 147-ex=91.0\n",
      "Not correct: 150-ex=92.1\n",
      "Not correct: 151-ex=93.0\n",
      "Not correct: 155-ex=94.2\n",
      "Not correct: 161-ex=97.0\n",
      "Not correct: 165-ex=100.0\n",
      "Not correct: 166-ex=101.0\n",
      "Not correct: 167-ex=102.0\n"
     ]
    }
   ],
   "source": [
    "# Check correctness stats\n",
    "\n",
    "# corr_cnt = 0\n",
    "err_cnt = 0\n",
    "global_ex_id = 0\n",
    "for ex_id in range(len(all_samples)):\n",
    "    for a_ex_id in range(len(all_samples[ex_id]['trace_results'])):\n",
    "        d = all_samples[ex_id]['trace_results'][a_ex_id]\n",
    "        if not d['correct_prediction']:\n",
    "            print(f'Not correct: {global_ex_id}-ex={ex_id}.{a_ex_id}')\n",
    "#             savepdf_path = os.path.join(fig_dir, f'{global_ex_id}-ex={ex_id}.{a_ex_id}.pdf')\n",
    "#             new_path = os.path.join(fig_dir, f'{global_ex_id}-ex={ex_id}.{a_ex_id}-WRONGPRED.pdf')\n",
    "#             os.rename(savepdf_path, new_path)\n",
    "            err_cnt += 1\n",
    "        global_ex_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "010dee68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c914509f",
   "metadata": {},
   "source": [
    "### Exp4.1: attention pattern for schema linking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36500505",
   "metadata": {},
   "source": [
    "#### Check sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "147dac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = f'/home/yshao/Projects/rome/results/gpt2_tracing/exp4_1_attention_weights_distribution_gpt2/exp=4.1_dev.jsonl'\n",
    "samples_N = len(processed_spider_dev)\n",
    "\n",
    "# check one sample (ex)\n",
    "with open(res_path, 'r') as f:\n",
    "    for l in f:\n",
    "        ex = ujson.loads(l)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "e2e28e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['ex_id', 'trace_results']),\n",
       " dict_keys(['enc_sentence', 'seq_out', 'dec_prompt', 'db_id', 'col_self_ranges', 'col_context_ranges', 'tab_self_ranges', 'tab_context_ranges', 'occ_cols', 'non_occ_cols', 'occ_tabs', 'non_occ_tabs', 'attentions']))"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.keys(), ex['trace_results'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "0d0c9710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_sentence : How many singers do we have?; structed knowledge: | concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , average | singer : singer_id , name , country , song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , stadium_id , year | singer_in_concert : concert_id , singer_id\n",
      "seq_out : select count(*) from singer\n",
      "dec_prompt : select\n",
      "db_id : concert_singer\n",
      "col_self_ranges : {'location': [[23, 26]], 'capacity': [[27, 30]], 'highest': [[29, 32]], 'lowest': [[31, 34]], 'average': [[33, 36]], 'country': [[43, 46]], 'song_name': [[45, 50]], 'song_release_year': [[49, 56]], 'age': [[55, 58]], 'is_male': [[57, 62]], 'concert_name': [[67, 72]], 'theme': [[71, 74]], 'year': [[77, 80]]}\n",
      "col_context_ranges : {'location': [[12, 23], [26, 93]], 'capacity': [[12, 27], [30, 93]], 'highest': [[12, 29], [32, 93]], 'lowest': [[12, 31], [34, 93]], 'average': [[12, 33], [36, 93]], 'country': [[12, 43], [46, 93]], 'song_name': [[12, 45], [50, 93]], 'song_release_year': [[12, 49], [56, 93]], 'age': [[12, 55], [58, 93]], 'is_male': [[12, 57], [62, 93]], 'concert_name': [[12, 67], [72, 93]], 'theme': [[12, 71], [74, 93]], 'year': [[12, 77], [80, 93]]}\n",
      "tab_self_ranges : {'singer': [[35, 38]], 'stadium': [[17, 20]], 'concert': [[61, 64]], 'singer_in_concert': [[79, 86]]}\n",
      "tab_context_ranges : {'singer': [[12, 35], [38, 93]], 'stadium': [[12, 17], [20, 93]], 'concert': [[12, 61], [64, 93]], 'singer_in_concert': [[12, 79], [86, 93]]}\n",
      "occ_cols : []\n",
      "non_occ_cols : ['location', 'capacity', 'highest', 'lowest', 'average', 'country', 'song_name', 'song_release_year', 'age', 'is_male', 'concert_name', 'theme', 'year']\n",
      "occ_tabs : ['singer']\n",
      "non_occ_tabs : ['stadium', 'concert', 'singer_in_concert']\n"
     ]
    }
   ],
   "source": [
    "for k, v in ex['trace_results'].items():\n",
    "    if k != 'attentions':\n",
    "        print(k, ':', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d9881",
   "metadata": {},
   "source": [
    "#### Full loading & processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e61954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'dev'\n",
    "\n",
    "res_path = f'/home/yshao/Projects/rome/results/gpt2_tracing/exp4_1_attention_weights_distribution_gpt2/exp=4.1_{ds}.jsonl'\n",
    "samples_N = len(processed_spider_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "38edd666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3ac0a98dda47e6aed2b46a5a5c6173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dict: {layer -> {head_id -> {occ_type -> {section -> List[att_w]}}}}; list for all samples, all nodes in each occ_type \n",
    "# Perhaps too large...\n",
    "# att_weights_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list))))\n",
    "att_weights_sum_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "\n",
    "# Dict: {occ_type -> int}\n",
    "att_weights_cnt_dict = defaultdict(int)\n",
    "\n",
    "# Dict: {layer -> {head_id -> {occ_type -> {section -> avg_att_w}}}}; averaged by all samples, all nodes in each occ_type \n",
    "att_weights_avg_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(float))))\n",
    "\n",
    "# Dict: {occ_type -> List[Tuple(ex_id, node_name)]}\n",
    "sample_backtrace_dict = defaultdict(list)\n",
    "\n",
    "\n",
    "with open(res_path, 'r') as f:\n",
    "    for l in tqdm(f, total=samples_N):\n",
    "        ex = ujson.loads(l)\n",
    "        ex_id = ex['ex_id']\n",
    "\n",
    "        if 'err_msg' in ex:\n",
    "            continue\n",
    "\n",
    "        result_d = ex['trace_results']\n",
    "\n",
    "        all_col_atts = result_d['attentions']['col']\n",
    "        all_tab_atts = result_d['attentions']['tab']\n",
    "\n",
    "        for col_occ_type in ['occ_cols', 'non_occ_cols']:\n",
    "            for col in result_d[col_occ_type]:\n",
    "                sect_att_dict = all_col_atts[col]\n",
    "                sample_backtrace_dict[col_occ_type].append((ex_id, col))\n",
    "                att_weights_cnt_dict[col_occ_type] += 1\n",
    "\n",
    "                for sect_k, att_mat in sect_att_dict.items():\n",
    "                    att_mat = np.array(ctu.nested_list_processing(att_mat, func=float))\n",
    "                    n_layers, n_heads = att_mat.shape\n",
    "                    for l in range(n_layers):\n",
    "                        for h in range(n_heads):\n",
    "                            att_w = att_mat[l, h]\n",
    "                            # att_weights_dict[l][h][col_occ_type][sect_k].append(att_w)\n",
    "                            att_weights_sum_dict[l][h][col_occ_type][sect_k] += att_w\n",
    "\n",
    "        for tab_occ_type in ['occ_tabs', 'non_occ_tabs']:\n",
    "            for tab in result_d[tab_occ_type]:\n",
    "                sect_att_dict = all_tab_atts[tab]\n",
    "                sample_backtrace_dict[tab_occ_type].append((ex_id, tab))\n",
    "                att_weights_cnt_dict[tab_occ_type] += 1\n",
    "\n",
    "                for sect_k, att_mat in sect_att_dict.items():\n",
    "                    att_mat = np.array(ctu.nested_list_processing(att_mat, func=float))\n",
    "                    n_layers, n_heads = att_mat.shape\n",
    "                    for l in range(n_layers):\n",
    "                        for h in range(n_heads):\n",
    "                            att_w = att_mat[l, h]\n",
    "                            # att_weights_dict[l][h][tab_occ_type][sect_k].append(att_w)\n",
    "                            att_weights_sum_dict[l][h][tab_occ_type][sect_k] += att_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "98f1ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_id, layer_d in att_weights_sum_dict.items():\n",
    "    for h_id, head_d in layer_d.items():\n",
    "        for occ_type, occ_type_d in head_d.items():\n",
    "            att_w_cnt = att_weights_cnt_dict[occ_type]\n",
    "            for sect_k, att_w_sum in occ_type_d.items():\n",
    "                att_weights_avg_dict[l_id][h_id][occ_type][sect_k] = att_w_sum / att_w_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "35c785d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'non_occ_cols': defaultdict(float,\n",
       "                         {'prefix#0': 0.00020246420246420108,\n",
       "                          'prefix#1': 0.00043223443223442597,\n",
       "                          'prefix#2': 0.00011388611388611397,\n",
       "                          'prefix#3': 0.0013413253413253647,\n",
       "                          'prefix#4': 0.0001092241092241093,\n",
       "                          'prefix#5': 0.003972027972027774,\n",
       "                          'prefix#6': 0.00046486846486845797,\n",
       "                          'prefix#7': 0.001931401931402047,\n",
       "                          'prefix#8': 0.0007958707958707819,\n",
       "                          'prefix#9': 7.992007992007997e-05,\n",
       "                          'prefix#10': 0.0005328005328005245,\n",
       "                          'prefix#11': 0.0010236430236430047,\n",
       "                          'prefix#12': 0.0002477522477522454,\n",
       "                          'prefix#13': 0.006751248751249487,\n",
       "                          'prefix#14': 0.014741258741258464,\n",
       "                          'prefix#15': 0.00138927738927742,\n",
       "                          'prefix#16': 0.00025308025308025064,\n",
       "                          'prefix#17': 0.006893772893773302,\n",
       "                          'prefix#18': 0.0002823842823842793,\n",
       "                          'prefix#19': 0.00019114219114219,\n",
       "                          'text': 0.27961971361970833,\n",
       "                          'self': 0.05460073260072387,\n",
       "                          'context': 0.5567678987678978,\n",
       "                          'others': 0.04184948384947878}),\n",
       "             'occ_tabs': defaultdict(float,\n",
       "                         {'prefix#0': 0.0001237785016286645,\n",
       "                          'prefix#1': 0.0008664495114006521,\n",
       "                          'prefix#2': 0.00011726384364820848,\n",
       "                          'prefix#3': 0.0020912052117263683,\n",
       "                          'prefix#4': 0.0,\n",
       "                          'prefix#5': 0.0032052117263843254,\n",
       "                          'prefix#6': 0.0017263843648208388,\n",
       "                          'prefix#7': 0.001713355048859927,\n",
       "                          'prefix#8': 0.0005667752442996746,\n",
       "                          'prefix#9': 0.0004169381107491859,\n",
       "                          'prefix#10': 0.0002475570032573291,\n",
       "                          'prefix#11': 0.002710097719869678,\n",
       "                          'prefix#12': 6.5146579804560266e-06,\n",
       "                          'prefix#13': 0.006749185667752359,\n",
       "                          'prefix#14': 0.008052117263843524,\n",
       "                          'prefix#15': 0.0037198697068403404,\n",
       "                          'prefix#16': 0.0007426710097719875,\n",
       "                          'prefix#17': 0.010338762214983538,\n",
       "                          'prefix#18': 0.0007557003257328995,\n",
       "                          'prefix#19': 1.9543973941368078e-05,\n",
       "                          'text': 0.3733224755700338,\n",
       "                          'self': 0.04472964169381094,\n",
       "                          'context': 0.4403517915309431,\n",
       "                          'others': 0.06973289902280136}),\n",
       "             'non_occ_tabs': defaultdict(float,\n",
       "                         {'prefix#0': 0.0002609802673456399,\n",
       "                          'prefix#1': 0.0007733927434754908,\n",
       "                          'prefix#2': 8.274984086569067e-05,\n",
       "                          'prefix#3': 0.0017600254614894737,\n",
       "                          'prefix#4': 3.182686187141948e-06,\n",
       "                          'prefix#5': 0.0027943984723105848,\n",
       "                          'prefix#6': 0.0015626989178866772,\n",
       "                          'prefix#7': 0.0025270528325906667,\n",
       "                          'prefix#8': 0.00034691279439847257,\n",
       "                          'prefix#9': 0.0002800763844684916,\n",
       "                          'prefix#10': 0.0005315085932527057,\n",
       "                          'prefix#11': 0.0024315722469764106,\n",
       "                          'prefix#12': 3.819223424570337e-05,\n",
       "                          'prefix#13': 0.006187141947803984,\n",
       "                          'prefix#14': 0.009506683640993222,\n",
       "                          'prefix#15': 0.002593889242520646,\n",
       "                          'prefix#16': 0.0005346912794398477,\n",
       "                          'prefix#17': 0.00936028007638459,\n",
       "                          'prefix#18': 0.00044875875238701494,\n",
       "                          'prefix#19': 0.00021642266072565257,\n",
       "                          'text': 0.3510789306174431,\n",
       "                          'self': 0.04371101209420805,\n",
       "                          'context': 0.477542966263527,\n",
       "                          'others': 0.059904519414387146}),\n",
       "             'occ_cols': defaultdict(float,\n",
       "                         {'prefix#0': 0.00024615384615384625,\n",
       "                          'prefix#1': 0.0008738461538461545,\n",
       "                          'prefix#2': 0.0002276923076923078,\n",
       "                          'prefix#3': 0.000892307692307693,\n",
       "                          'prefix#4': 6.153846153846154e-05,\n",
       "                          'prefix#5': 0.004344615384615319,\n",
       "                          'prefix#6': 0.0007446153846153851,\n",
       "                          'prefix#7': 0.0021353846153845967,\n",
       "                          'prefix#8': 0.0009292307692307699,\n",
       "                          'prefix#9': 4.923076923076923e-05,\n",
       "                          'prefix#10': 0.0006092307692307697,\n",
       "                          'prefix#11': 0.001864615384615372,\n",
       "                          'prefix#12': 0.0005292307692307696,\n",
       "                          'prefix#13': 0.005218461538461468,\n",
       "                          'prefix#14': 0.01278153846153841,\n",
       "                          'prefix#15': 0.0023261538461538237,\n",
       "                          'prefix#16': 0.00045538461538461564,\n",
       "                          'prefix#17': 0.009470769230769067,\n",
       "                          'prefix#18': 0.0004430769230769233,\n",
       "                          'prefix#19': 0.0003261538461538463,\n",
       "                          'text': 0.3280000000000008,\n",
       "                          'self': 0.05887384615384619,\n",
       "                          'context': 0.4853107692307687,\n",
       "                          'others': 0.055833846153846164})})"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weights_avg_dict[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc0321",
   "metadata": {},
   "source": [
    "#### Dump results \n",
    "- do not rerun unless updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "abc6be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = f'/home/yshao/Projects/rome/results/gpt2_tracing/exp4_1_attention_weights_distribution_gpt2/exp=4.1_{ds}_dump.pkl'\n",
    "\n",
    "dump_d = {\n",
    "    'att_weights_sum_dict': ctu.nested_json_processing(att_weights_sum_dict, func=lambda x: x),   # defaultdict -> dict \n",
    "    'att_weights_cnt_dict': ctu.nested_json_processing(att_weights_cnt_dict, func=lambda x: x),\n",
    "    'att_weights_avg_dict': ctu.nested_json_processing(att_weights_avg_dict, func=lambda x: x),\n",
    "    'sample_backtrace_dict': ctu.nested_json_processing(sample_backtrace_dict, func=lambda x: x),\n",
    "}\n",
    "\n",
    "with open(res_path, 'wb') as f:\n",
    "    pickle.dump(dump_d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194ea04",
   "metadata": {},
   "source": [
    "#### Load results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "9f8b98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = f'/home/yshao/Projects/rome/results/gpt2_tracing/exp4_1_attention_weights_distribution_gpt2/exp=4.1_dev_dump.pkl'\n",
    "\n",
    "with open(res_path, 'rb') as f:\n",
    "    dump_d = pickle.load(f)\n",
    "\n",
    "att_weights_sum_dict = dump_d['att_weights_sum_dict']\n",
    "att_weights_cnt_dict = dump_d['att_weights_cnt_dict']\n",
    "att_weights_avg_dict = dump_d['att_weights_avg_dict']\n",
    "sample_backtrace_dict = dump_d['sample_backtrace_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a3079132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'non_occ_cols': {'prefix#0': 0.00020246420246420108,\n",
       "  'prefix#1': 0.00043223443223442597,\n",
       "  'prefix#2': 0.00011388611388611397,\n",
       "  'prefix#3': 0.0013413253413253647,\n",
       "  'prefix#4': 0.0001092241092241093,\n",
       "  'prefix#5': 0.003972027972027774,\n",
       "  'prefix#6': 0.00046486846486845797,\n",
       "  'prefix#7': 0.001931401931402047,\n",
       "  'prefix#8': 0.0007958707958707819,\n",
       "  'prefix#9': 7.992007992007997e-05,\n",
       "  'prefix#10': 0.0005328005328005245,\n",
       "  'prefix#11': 0.0010236430236430047,\n",
       "  'prefix#12': 0.0002477522477522454,\n",
       "  'prefix#13': 0.006751248751249487,\n",
       "  'prefix#14': 0.014741258741258464,\n",
       "  'prefix#15': 0.00138927738927742,\n",
       "  'prefix#16': 0.00025308025308025064,\n",
       "  'prefix#17': 0.006893772893773302,\n",
       "  'prefix#18': 0.0002823842823842793,\n",
       "  'prefix#19': 0.00019114219114219,\n",
       "  'text': 0.27961971361970833,\n",
       "  'self': 0.05460073260072387,\n",
       "  'context': 0.5567678987678978,\n",
       "  'others': 0.04184948384947878},\n",
       " 'occ_tabs': {'prefix#0': 0.0001237785016286645,\n",
       "  'prefix#1': 0.0008664495114006521,\n",
       "  'prefix#2': 0.00011726384364820848,\n",
       "  'prefix#3': 0.0020912052117263683,\n",
       "  'prefix#4': 0.0,\n",
       "  'prefix#5': 0.0032052117263843254,\n",
       "  'prefix#6': 0.0017263843648208388,\n",
       "  'prefix#7': 0.001713355048859927,\n",
       "  'prefix#8': 0.0005667752442996746,\n",
       "  'prefix#9': 0.0004169381107491859,\n",
       "  'prefix#10': 0.0002475570032573291,\n",
       "  'prefix#11': 0.002710097719869678,\n",
       "  'prefix#12': 6.5146579804560266e-06,\n",
       "  'prefix#13': 0.006749185667752359,\n",
       "  'prefix#14': 0.008052117263843524,\n",
       "  'prefix#15': 0.0037198697068403404,\n",
       "  'prefix#16': 0.0007426710097719875,\n",
       "  'prefix#17': 0.010338762214983538,\n",
       "  'prefix#18': 0.0007557003257328995,\n",
       "  'prefix#19': 1.9543973941368078e-05,\n",
       "  'text': 0.3733224755700338,\n",
       "  'self': 0.04472964169381094,\n",
       "  'context': 0.4403517915309431,\n",
       "  'others': 0.06973289902280136},\n",
       " 'non_occ_tabs': {'prefix#0': 0.0002609802673456399,\n",
       "  'prefix#1': 0.0007733927434754908,\n",
       "  'prefix#2': 8.274984086569067e-05,\n",
       "  'prefix#3': 0.0017600254614894737,\n",
       "  'prefix#4': 3.182686187141948e-06,\n",
       "  'prefix#5': 0.0027943984723105848,\n",
       "  'prefix#6': 0.0015626989178866772,\n",
       "  'prefix#7': 0.0025270528325906667,\n",
       "  'prefix#8': 0.00034691279439847257,\n",
       "  'prefix#9': 0.0002800763844684916,\n",
       "  'prefix#10': 0.0005315085932527057,\n",
       "  'prefix#11': 0.0024315722469764106,\n",
       "  'prefix#12': 3.819223424570337e-05,\n",
       "  'prefix#13': 0.006187141947803984,\n",
       "  'prefix#14': 0.009506683640993222,\n",
       "  'prefix#15': 0.002593889242520646,\n",
       "  'prefix#16': 0.0005346912794398477,\n",
       "  'prefix#17': 0.00936028007638459,\n",
       "  'prefix#18': 0.00044875875238701494,\n",
       "  'prefix#19': 0.00021642266072565257,\n",
       "  'text': 0.3510789306174431,\n",
       "  'self': 0.04371101209420805,\n",
       "  'context': 0.477542966263527,\n",
       "  'others': 0.059904519414387146},\n",
       " 'occ_cols': {'prefix#0': 0.00024615384615384625,\n",
       "  'prefix#1': 0.0008738461538461545,\n",
       "  'prefix#2': 0.0002276923076923078,\n",
       "  'prefix#3': 0.000892307692307693,\n",
       "  'prefix#4': 6.153846153846154e-05,\n",
       "  'prefix#5': 0.004344615384615319,\n",
       "  'prefix#6': 0.0007446153846153851,\n",
       "  'prefix#7': 0.0021353846153845967,\n",
       "  'prefix#8': 0.0009292307692307699,\n",
       "  'prefix#9': 4.923076923076923e-05,\n",
       "  'prefix#10': 0.0006092307692307697,\n",
       "  'prefix#11': 0.001864615384615372,\n",
       "  'prefix#12': 0.0005292307692307696,\n",
       "  'prefix#13': 0.005218461538461468,\n",
       "  'prefix#14': 0.01278153846153841,\n",
       "  'prefix#15': 0.0023261538461538237,\n",
       "  'prefix#16': 0.00045538461538461564,\n",
       "  'prefix#17': 0.009470769230769067,\n",
       "  'prefix#18': 0.0004430769230769233,\n",
       "  'prefix#19': 0.0003261538461538463,\n",
       "  'text': 0.3280000000000008,\n",
       "  'self': 0.05887384615384619,\n",
       "  'context': 0.4853107692307687,\n",
       "  'others': 0.055833846153846164}}"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weights_avg_dict[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "8e74783f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Layer 1 =====\n",
      "occ_cols\n",
      "prefix#0  0.01  0.01  0.00  0.01  0.00  0.01  0.01  0.00  0.00  0.02  0.04  0.02  0.02  0.00  0.01  0.00\n",
      "prefix#1  0.01  0.02  0.01  0.02  0.00  0.02  0.00  0.01  0.01  0.01  0.05  0.01  0.01  0.02  0.03  0.00\n",
      "prefix#2  0.01  0.01  0.00  0.02  0.00  0.01  0.01  0.01  0.01  0.01  0.02  0.02  0.00  0.01  0.00  0.01\n",
      "prefix#3  0.01  0.01  0.01  0.05  0.00  0.01  0.01  0.00  0.00  0.01  0.03  0.01  0.00  0.03  0.00  0.02\n",
      "prefix#4  0.00  0.01  0.01  0.01  0.00  0.01  0.00  0.00  0.00  0.01  0.03  0.01  0.02  0.01  0.01  0.01\n",
      "prefix#5  0.02  0.04  0.02  0.08  0.00  0.06  0.02  0.00  0.01  0.01  0.04  0.01  0.02  0.02  0.00  0.00\n",
      "prefix#6  0.01  0.01  0.01  0.04  0.00  0.01  0.00  0.00  0.00  0.02  0.02  0.02  0.03  0.01  0.03  0.00\n",
      "prefix#7  0.00  0.02  0.01  0.00  0.00  0.01  0.00  0.00  0.00  0.01  0.05  0.03  0.03  0.01  0.01  0.01\n",
      "prefix#8  0.01  0.01  0.02  0.03  0.00  0.01  0.00  0.01  0.00  0.01  0.02  0.01  0.01  0.04  0.00  0.01\n",
      "prefix#9  0.01  0.01  0.01  0.02  0.00  0.01  0.01  0.01  0.01  0.01  0.04  0.01  0.02  0.01  0.01  0.01\n",
      "prefix#10 0.01  0.01  0.03  0.01  0.00  0.05  0.01  0.00  0.01  0.03  0.04  0.02  0.01  0.03  0.01  0.03\n",
      "prefix#11 0.01  0.01  0.01  0.06  0.00  0.01  0.00  0.01  0.00  0.02  0.04  0.02  0.01  0.03  0.01  0.01\n",
      "prefix#12 0.00  0.00  0.01  0.01  0.00  0.00  0.00  0.00  0.00  0.02  0.03  0.02  0.03  0.02  0.01  0.00\n",
      "prefix#13 0.00  0.02  0.04  0.01  0.00  0.02  0.01  0.00  0.00  0.03  0.02  0.02  0.01  0.04  0.00  0.06\n",
      "prefix#14 0.00  0.02  0.04  0.01  0.00  0.04  0.02  0.00  0.01  0.01  0.03  0.03  0.00  0.02  0.01  0.01\n",
      "prefix#15 0.03  0.01  0.01  0.07  0.00  0.02  0.00  0.02  0.01  0.01  0.05  0.01  0.01  0.03  0.01  0.01\n",
      "prefix#16 0.00  0.01  0.02  0.01  0.00  0.02  0.02  0.00  0.01  0.03  0.04  0.02  0.01  0.03  0.01  0.01\n",
      "prefix#17 0.00  0.02  0.00  0.03  0.00  0.01  0.01  0.00  0.00  0.03  0.02  0.01  0.02  0.01  0.00  0.00\n",
      "prefix#18 0.01  0.01  0.00  0.02  0.00  0.01  0.00  0.00  0.00  0.02  0.02  0.01  0.02  0.01  0.00  0.00\n",
      "prefix#19 0.01  0.00  0.02  0.01  0.00  0.01  0.03  0.00  0.00  0.03  0.02  0.03  0.02  0.01  0.00  0.00\n",
      "text      0.27  0.16  0.19  0.30  0.41  0.32  0.39  0.02  0.44  0.16  0.08  0.16  0.23  0.15  0.10  0.30\n",
      "self      0.03  0.04  0.04  0.00  0.27  0.02  0.02  0.16  0.05  0.02  0.01  0.03  0.03  0.01  0.19  0.05\n",
      "context   0.44  0.49  0.43  0.13  0.27  0.23  0.35  0.70  0.38  0.41  0.25  0.41  0.40  0.39  0.51  0.37\n",
      "others    0.09  0.03  0.04  0.04  0.02  0.08  0.07  0.03  0.03  0.06  0.03  0.05  0.04  0.06  0.02  0.05\n",
      "\n",
      "non_occ_cols\n",
      "prefix#0  0.01  0.01  0.01  0.01  0.00  0.01  0.01  0.00  0.00  0.02  0.03  0.02  0.03  0.00  0.01  0.00\n",
      "prefix#1  0.00  0.01  0.02  0.02  0.00  0.03  0.00  0.01  0.01  0.01  0.04  0.01  0.01  0.02  0.03  0.00\n",
      "prefix#2  0.01  0.01  0.00  0.02  0.00  0.01  0.01  0.01  0.01  0.01  0.02  0.02  0.00  0.01  0.00  0.01\n",
      "prefix#3  0.01  0.01  0.01  0.04  0.00  0.01  0.00  0.00  0.00  0.01  0.02  0.01  0.00  0.02  0.00  0.03\n",
      "prefix#4  0.00  0.01  0.01  0.01  0.00  0.01  0.00  0.00  0.00  0.01  0.02  0.01  0.02  0.01  0.01  0.01\n",
      "prefix#5  0.01  0.03  0.02  0.07  0.00  0.05  0.01  0.00  0.01  0.01  0.04  0.01  0.02  0.02  0.00  0.01\n",
      "prefix#6  0.01  0.01  0.01  0.06  0.00  0.01  0.00  0.00  0.00  0.02  0.02  0.02  0.03  0.01  0.03  0.00\n",
      "prefix#7  0.00  0.02  0.01  0.01  0.00  0.01  0.00  0.00  0.00  0.01  0.05  0.02  0.03  0.01  0.01  0.01\n",
      "prefix#8  0.01  0.00  0.02  0.03  0.00  0.01  0.00  0.00  0.00  0.01  0.02  0.01  0.01  0.03  0.00  0.01\n",
      "prefix#9  0.01  0.01  0.00  0.02  0.00  0.01  0.00  0.01  0.01  0.01  0.04  0.01  0.02  0.01  0.01  0.01\n",
      "prefix#10 0.01  0.01  0.03  0.01  0.00  0.04  0.01  0.00  0.01  0.04  0.04  0.01  0.01  0.03  0.01  0.03\n",
      "prefix#11 0.01  0.01  0.01  0.06  0.00  0.01  0.00  0.01  0.00  0.02  0.04  0.01  0.01  0.03  0.01  0.01\n",
      "prefix#12 0.00  0.00  0.01  0.01  0.00  0.00  0.00  0.00  0.00  0.02  0.03  0.03  0.02  0.01  0.01  0.00\n",
      "prefix#13 0.00  0.02  0.02  0.01  0.00  0.02  0.01  0.00  0.00  0.03  0.01  0.02  0.01  0.04  0.00  0.06\n",
      "prefix#14 0.00  0.02  0.03  0.01  0.00  0.04  0.02  0.00  0.01  0.01  0.03  0.03  0.01  0.02  0.01  0.01\n",
      "prefix#15 0.03  0.01  0.02  0.06  0.00  0.02  0.00  0.02  0.01  0.01  0.04  0.01  0.01  0.03  0.01  0.01\n",
      "prefix#16 0.00  0.01  0.02  0.01  0.00  0.02  0.01  0.00  0.00  0.04  0.03  0.02  0.01  0.03  0.01  0.01\n",
      "prefix#17 0.00  0.02  0.00  0.03  0.00  0.01  0.00  0.00  0.00  0.02  0.01  0.01  0.02  0.01  0.00  0.00\n",
      "prefix#18 0.01  0.01  0.00  0.02  0.00  0.01  0.00  0.00  0.00  0.01  0.02  0.01  0.02  0.01  0.00  0.01\n",
      "prefix#19 0.01  0.00  0.02  0.01  0.00  0.01  0.03  0.00  0.00  0.03  0.01  0.03  0.01  0.01  0.00  0.00\n",
      "text      0.25  0.14  0.15  0.29  0.11  0.31  0.35  0.02  0.37  0.15  0.07  0.14  0.16  0.14  0.09  0.27\n",
      "self      0.02  0.04  0.04  0.00  0.39  0.02  0.02  0.15  0.05  0.02  0.01  0.03  0.03  0.01  0.18  0.04\n",
      "context   0.49  0.56  0.50  0.16  0.45  0.26  0.41  0.73  0.46  0.44  0.31  0.46  0.47  0.45  0.52  0.40\n",
      "others    0.08  0.03  0.04  0.04  0.03  0.09  0.07  0.02  0.03  0.05  0.03  0.04  0.04  0.05  0.01  0.05\n",
      "\n",
      "===== Layer 6 =====\n",
      "occ_cols\n",
      "prefix#0  0.03  0.00  0.02  0.03  0.00  0.01  0.00  0.00  0.01  0.03  0.00  0.02  0.08  0.06  0.00  0.04\n",
      "prefix#1  0.02  0.03  0.06  0.03  0.00  0.01  0.04  0.00  0.00  0.03  0.01  0.01  0.10  0.07  0.00  0.01\n",
      "prefix#2  0.02  0.01  0.03  0.03  0.00  0.00  0.00  0.00  0.04  0.02  0.02  0.01  0.02  0.05  0.03  0.06\n",
      "prefix#3  0.01  0.02  0.03  0.05  0.00  0.00  0.00  0.00  0.12  0.04  0.01  0.00  0.01  0.01  0.05  0.03\n",
      "prefix#4  0.01  0.16  0.02  0.02  0.00  0.01  0.02  0.00  0.00  0.01  0.03  0.01  0.02  0.09  0.00  0.01\n",
      "prefix#5  0.03  0.02  0.08  0.04  0.01  0.02  0.00  0.00  0.05  0.01  0.01  0.01  0.01  0.03  0.01  0.02\n",
      "prefix#6  0.03  0.07  0.03  0.03  0.00  0.00  0.00  0.00  0.01  0.01  0.00  0.02  0.08  0.03  0.00  0.03\n",
      "prefix#7  0.03  0.02  0.02  0.03  0.00  0.00  0.01  0.00  0.01  0.03  0.01  0.00  0.04  0.03  0.00  0.10\n",
      "prefix#8  0.03  0.03  0.09  0.06  0.01  0.01  0.00  0.00  0.01  0.03  0.03  0.00  0.02  0.02  0.00  0.08\n",
      "prefix#9  0.04  0.08  0.01  0.07  0.00  0.00  0.00  0.00  0.01  0.01  0.01  0.03  0.07  0.02  0.06  0.00\n",
      "prefix#10 0.01  0.04  0.02  0.01  0.00  0.00  0.01  0.00  0.01  0.05  0.04  0.00  0.01  0.03  0.01  0.01\n",
      "prefix#11 0.01  0.02  0.09  0.03  0.00  0.00  0.00  0.00  0.03  0.02  0.03  0.00  0.03  0.02  0.01  0.02\n",
      "prefix#12 0.01  0.06  0.03  0.03  0.00  0.00  0.00  0.00  0.00  0.03  0.02  0.01  0.01  0.10  0.00  0.01\n",
      "prefix#13 0.02  0.00  0.02  0.02  0.00  0.00  0.00  0.00  0.14  0.01  0.04  0.03  0.02  0.01  0.01  0.01\n",
      "prefix#14 0.03  0.01  0.04  0.04  0.00  0.00  0.24  0.00  0.01  0.01  0.05  0.03  0.00  0.09  0.03  0.05\n",
      "prefix#15 0.02  0.03  0.06  0.09  0.01  0.00  0.01  0.00  0.01  0.01  0.02  0.00  0.03  0.06  0.00  0.01\n",
      "prefix#16 0.03  0.01  0.04  0.04  0.00  0.00  0.00  0.00  0.03  0.04  0.02  0.07  0.02  0.04  0.01  0.01\n",
      "prefix#17 0.02  0.05  0.02  0.03  0.00  0.00  0.00  0.00  0.00  0.01  0.03  0.01  0.02  0.07  0.00  0.07\n",
      "prefix#18 0.01  0.02  0.01  0.01  0.00  0.01  0.00  0.00  0.01  0.01  0.04  0.01  0.01  0.02  0.01  0.03\n",
      "prefix#19 0.02  0.01  0.02  0.03  0.01  0.01  0.00  0.00  0.01  0.00  0.03  0.06  0.03  0.03  0.01  0.06\n",
      "text      0.26  0.21  0.13  0.11  0.75  0.04  0.12  0.00  0.06  0.35  0.17  0.03  0.11  0.09  0.22  0.12\n",
      "self      0.04  0.00  0.01  0.01  0.09  0.33  0.22  0.96  0.04  0.00  0.05  0.11  0.05  0.00  0.16  0.02\n",
      "context   0.27  0.10  0.10  0.14  0.10  0.50  0.29  0.04  0.34  0.21  0.30  0.51  0.19  0.02  0.36  0.19\n",
      "others    0.01  0.00  0.01  0.02  0.00  0.01  0.01  0.00  0.02  0.02  0.02  0.01  0.01  0.01  0.01  0.00\n",
      "\n",
      "non_occ_cols\n",
      "prefix#0  0.03  0.00  0.02  0.03  0.00  0.00  0.00  0.00  0.02  0.03  0.00  0.02  0.08  0.05  0.01  0.05\n",
      "prefix#1  0.02  0.02  0.07  0.02  0.00  0.01  0.03  0.00  0.00  0.03  0.01  0.02  0.08  0.09  0.00  0.01\n",
      "prefix#2  0.01  0.01  0.03  0.02  0.01  0.00  0.00  0.00  0.05  0.02  0.02  0.01  0.03  0.05  0.05  0.06\n",
      "prefix#3  0.01  0.01  0.02  0.04  0.01  0.00  0.00  0.00  0.11  0.04  0.02  0.00  0.01  0.02  0.05  0.04\n",
      "prefix#4  0.01  0.08  0.01  0.02  0.00  0.01  0.02  0.00  0.01  0.01  0.02  0.01  0.02  0.08  0.00  0.01\n",
      "prefix#5  0.03  0.02  0.08  0.04  0.04  0.01  0.00  0.00  0.05  0.01  0.01  0.01  0.02  0.02  0.01  0.02\n",
      "prefix#6  0.01  0.08  0.03  0.03  0.00  0.00  0.00  0.00  0.02  0.01  0.00  0.02  0.07  0.03  0.00  0.02\n",
      "prefix#7  0.05  0.02  0.01  0.03  0.00  0.00  0.02  0.00  0.01  0.03  0.01  0.00  0.04  0.03  0.00  0.09\n",
      "prefix#8  0.04  0.04  0.09  0.06  0.01  0.01  0.00  0.00  0.01  0.03  0.04  0.00  0.02  0.02  0.00  0.07\n",
      "prefix#9  0.02  0.08  0.02  0.08  0.01  0.00  0.00  0.00  0.01  0.01  0.01  0.04  0.06  0.02  0.04  0.00\n",
      "prefix#10 0.01  0.05  0.02  0.01  0.00  0.00  0.01  0.00  0.02  0.04  0.04  0.00  0.01  0.05  0.01  0.02\n",
      "prefix#11 0.01  0.02  0.08  0.03  0.00  0.00  0.00  0.00  0.03  0.02  0.04  0.00  0.03  0.02  0.01  0.01\n",
      "prefix#12 0.01  0.04  0.04  0.03  0.00  0.00  0.00  0.00  0.00  0.02  0.02  0.01  0.02  0.10  0.00  0.02\n",
      "prefix#13 0.02  0.00  0.01  0.02  0.02  0.00  0.00  0.00  0.10  0.02  0.04  0.03  0.01  0.01  0.02  0.01\n",
      "prefix#14 0.03  0.01  0.03  0.03  0.00  0.00  0.25  0.00  0.02  0.01  0.07  0.02  0.01  0.07  0.02  0.05\n",
      "prefix#15 0.02  0.03  0.06  0.11  0.03  0.00  0.01  0.00  0.01  0.01  0.03  0.00  0.04  0.05  0.00  0.02\n",
      "prefix#16 0.03  0.01  0.04  0.04  0.00  0.00  0.00  0.00  0.04  0.04  0.02  0.06  0.01  0.04  0.01  0.01\n",
      "prefix#17 0.01  0.06  0.02  0.03  0.00  0.00  0.00  0.00  0.01  0.01  0.02  0.00  0.03  0.06  0.00  0.05\n",
      "prefix#18 0.01  0.01  0.01  0.01  0.00  0.00  0.00  0.00  0.02  0.01  0.05  0.01  0.01  0.02  0.01  0.03\n",
      "prefix#19 0.01  0.02  0.03  0.03  0.03  0.00  0.00  0.00  0.02  0.00  0.04  0.06  0.04  0.03  0.01  0.04\n",
      "text      0.26  0.14  0.14  0.12  0.45  0.04  0.14  0.00  0.08  0.34  0.17  0.02  0.10  0.08  0.22  0.07\n",
      "self      0.03  0.01  0.01  0.01  0.14  0.33  0.22  0.95  0.05  0.00  0.04  0.08  0.03  0.00  0.15  0.05\n",
      "context   0.30  0.22  0.11  0.15  0.23  0.53  0.25  0.05  0.32  0.22  0.26  0.54  0.19  0.03  0.37  0.28\n",
      "others    0.01  0.00  0.01  0.02  0.01  0.01  0.00  0.00  0.01  0.02  0.01  0.01  0.01  0.01  0.00  0.00\n",
      "\n",
      "===== Layer 12 =====\n",
      "occ_cols\n",
      "prefix#0  0.01  0.00  0.00  0.00  0.01  0.02  0.03  0.02  0.00  0.02  0.00  0.01  0.04  0.00  0.00  0.00\n",
      "prefix#1  0.02  0.00  0.03  0.01  0.02  0.08  0.05  0.02  0.00  0.01  0.00  0.03  0.00  0.04  0.00  0.00\n",
      "prefix#2  0.00  0.00  0.02  0.02  0.02  0.01  0.03  0.01  0.00  0.05  0.01  0.03  0.03  0.00  0.00  0.00\n",
      "prefix#3  0.00  0.00  0.02  0.00  0.01  0.00  0.01  0.01  0.00  0.03  0.00  0.01  0.00  0.00  0.00  0.00\n",
      "prefix#4  0.02  0.00  0.01  0.00  0.02  0.01  0.02  0.00  0.00  0.04  0.00  0.02  0.01  0.42  0.00  0.02\n",
      "prefix#5  0.00  0.00  0.11  0.00  0.02  0.02  0.01  0.11  0.00  0.01  0.03  0.01  0.03  0.00  0.00  0.02\n",
      "prefix#6  0.02  0.00  0.01  0.02  0.00  0.01  0.01  0.00  0.00  0.03  0.02  0.01  0.00  0.00  0.00  0.01\n",
      "prefix#7  0.01  0.00  0.01  0.01  0.01  0.01  0.03  0.07  0.00  0.09  0.02  0.01  0.00  0.00  0.00  0.00\n",
      "prefix#8  0.00  0.00  0.01  0.06  0.01  0.01  0.06  0.01  0.00  0.04  0.00  0.01  0.11  0.00  0.00  0.05\n",
      "prefix#9  0.00  0.00  0.02  0.01  0.00  0.00  0.03  0.00  0.00  0.00  0.00  0.01  0.00  0.00  0.00  0.00\n",
      "prefix#10 0.00  0.00  0.01  0.05  0.07  0.07  0.12  0.09  0.00  0.07  0.03  0.06  0.00  0.00  0.02  0.01\n",
      "prefix#11 0.00  0.00  0.01  0.16  0.01  0.01  0.07  0.01  0.00  0.08  0.02  0.08  0.04  0.00  0.01  0.01\n",
      "prefix#12 0.01  0.00  0.00  0.05  0.02  0.00  0.14  0.02  0.00  0.01  0.02  0.07  0.03  0.07  0.01  0.01\n",
      "prefix#13 0.00  0.01  0.01  0.00  0.02  0.01  0.00  0.05  0.00  0.14  0.00  0.02  0.00  0.00  0.00  0.01\n",
      "prefix#14 0.00  0.01  0.07  0.01  0.00  0.02  0.01  0.01  0.01  0.02  0.09  0.01  0.00  0.00  0.00  0.01\n",
      "prefix#15 0.12  0.00  0.01  0.03  0.00  0.03  0.09  0.00  0.00  0.01  0.03  0.02  0.01  0.00  0.00  0.00\n",
      "prefix#16 0.00  0.00  0.00  0.02  0.05  0.00  0.00  0.07  0.00  0.02  0.11  0.02  0.00  0.00  0.00  0.00\n",
      "prefix#17 0.03  0.00  0.00  0.04  0.11  0.01  0.09  0.00  0.01  0.02  0.03  0.03  0.02  0.01  0.00  0.02\n",
      "prefix#18 0.01  0.00  0.01  0.00  0.00  0.01  0.02  0.01  0.00  0.01  0.01  0.02  0.05  0.00  0.00  0.02\n",
      "prefix#19 0.00  0.00  0.02  0.01  0.00  0.00  0.00  0.06  0.00  0.02  0.08  0.01  0.01  0.00  0.01  0.01\n",
      "text      0.57  0.89  0.52  0.11  0.44  0.38  0.08  0.32  0.05  0.11  0.22  0.46  0.49  0.29  0.64  0.07\n",
      "self      0.02  0.01  0.01  0.12  0.02  0.01  0.01  0.01  0.39  0.02  0.04  0.01  0.04  0.02  0.08  0.09\n",
      "context   0.08  0.04  0.07  0.26  0.10  0.23  0.07  0.09  0.50  0.11  0.23  0.04  0.06  0.14  0.20  0.63\n",
      "others    0.06  0.04  0.00  0.01  0.00  0.01  0.00  0.01  0.00  0.00  0.00  0.00  0.02  0.00  0.01  0.01\n",
      "\n",
      "non_occ_cols\n",
      "prefix#0  0.01  0.00  0.00  0.00  0.04  0.04  0.44  0.05  0.01  0.02  0.00  0.00  0.02  0.00  0.00  0.00\n",
      "prefix#1  0.02  0.00  0.02  0.01  0.03  0.06  0.02  0.02  0.01  0.03  0.00  0.03  0.00  0.05  0.00  0.00\n",
      "prefix#2  0.00  0.00  0.02  0.02  0.01  0.04  0.04  0.01  0.00  0.07  0.01  0.05  0.01  0.00  0.00  0.00\n",
      "prefix#3  0.00  0.00  0.02  0.00  0.00  0.00  0.01  0.01  0.00  0.04  0.00  0.01  0.00  0.00  0.00  0.00\n",
      "prefix#4  0.02  0.00  0.02  0.00  0.31  0.09  0.02  0.01  0.00  0.03  0.00  0.02  0.00  0.26  0.00  0.01\n",
      "prefix#5  0.00  0.00  0.05  0.00  0.02  0.02  0.01  0.09  0.01  0.01  0.02  0.00  0.12  0.00  0.00  0.02\n",
      "prefix#6  0.06  0.00  0.00  0.06  0.00  0.01  0.01  0.00  0.00  0.05  0.02  0.01  0.00  0.00  0.00  0.00\n",
      "prefix#7  0.04  0.00  0.01  0.01  0.01  0.02  0.02  0.17  0.00  0.07  0.01  0.01  0.00  0.00  0.00  0.01\n",
      "prefix#8  0.00  0.00  0.02  0.03  0.00  0.02  0.04  0.02  0.00  0.03  0.00  0.01  0.04  0.00  0.00  0.02\n",
      "prefix#9  0.00  0.00  0.01  0.00  0.00  0.00  0.03  0.01  0.00  0.00  0.00  0.02  0.00  0.00  0.00  0.00\n",
      "prefix#10 0.00  0.00  0.01  0.03  0.03  0.04  0.03  0.13  0.00  0.02  0.02  0.07  0.00  0.00  0.01  0.00\n",
      "prefix#11 0.00  0.00  0.04  0.19  0.00  0.01  0.01  0.04  0.01  0.04  0.01  0.14  0.04  0.00  0.01  0.00\n",
      "prefix#12 0.02  0.00  0.00  0.02  0.01  0.01  0.04  0.02  0.00  0.01  0.01  0.16  0.01  0.05  0.01  0.01\n",
      "prefix#13 0.00  0.02  0.01  0.00  0.01  0.02  0.00  0.02  0.00  0.17  0.01  0.01  0.01  0.00  0.01  0.00\n",
      "prefix#14 0.00  0.00  0.05  0.00  0.01  0.03  0.01  0.01  0.03  0.01  0.03  0.02  0.00  0.00  0.00  0.01\n",
      "prefix#15 0.06  0.00  0.02  0.01  0.00  0.09  0.04  0.00  0.00  0.01  0.03  0.01  0.02  0.00  0.00  0.00\n",
      "prefix#16 0.01  0.00  0.00  0.02  0.04  0.01  0.00  0.03  0.01  0.01  0.26  0.01  0.00  0.00  0.00  0.00\n",
      "prefix#17 0.01  0.00  0.00  0.04  0.02  0.01  0.09  0.01  0.01  0.04  0.03  0.03  0.02  0.00  0.00  0.01\n",
      "prefix#18 0.01  0.00  0.00  0.00  0.00  0.02  0.02  0.01  0.00  0.02  0.01  0.01  0.07  0.00  0.00  0.02\n",
      "prefix#19 0.01  0.01  0.01  0.01  0.00  0.00  0.00  0.07  0.00  0.02  0.04  0.00  0.02  0.00  0.04  0.00\n",
      "text      0.47  0.86  0.57  0.07  0.29  0.25  0.04  0.17  0.14  0.13  0.23  0.32  0.49  0.41  0.52  0.04\n",
      "self      0.03  0.01  0.00  0.10  0.02  0.00  0.01  0.01  0.27  0.02  0.02  0.00  0.03  0.02  0.06  0.05\n",
      "context   0.19  0.09  0.09  0.34  0.13  0.20  0.07  0.10  0.48  0.14  0.23  0.04  0.08  0.19  0.29  0.77\n",
      "others    0.01  0.01  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.01  0.00  0.00  0.00\n",
      "\n",
      "===== Layer 18 =====\n",
      "occ_cols\n",
      "prefix#0  0.00  0.04  0.13  0.00  0.01  0.01  0.08  0.12  0.01  0.04  0.02  0.07  0.01  0.00  0.01  0.00\n",
      "prefix#1  0.00  0.25  0.00  0.01  0.01  0.07  0.00  0.02  0.16  0.02  0.03  0.00  0.15  0.04  0.01  0.00\n",
      "prefix#2  0.00  0.02  0.14  0.00  0.01  0.00  0.33  0.02  0.01  0.32  0.14  0.11  0.01  0.01  0.01  0.01\n",
      "prefix#3  0.00  0.00  0.01  0.12  0.01  0.03  0.01  0.04  0.01  0.10  0.08  0.08  0.00  0.00  0.04  0.08\n",
      "prefix#4  0.01  0.02  0.00  0.00  0.01  0.15  0.00  0.03  0.02  0.04  0.02  0.02  0.01  0.00  0.09  0.01\n",
      "prefix#5  0.03  0.08  0.01  0.10  0.05  0.00  0.00  0.01  0.00  0.01  0.02  0.00  0.02  0.01  0.03  0.01\n",
      "prefix#6  0.00  0.02  0.03  0.00  0.01  0.00  0.06  0.02  0.03  0.01  0.01  0.01  0.04  0.00  0.13  0.01\n",
      "prefix#7  0.00  0.00  0.02  0.00  0.01  0.00  0.00  0.04  0.03  0.02  0.01  0.05  0.08  0.00  0.01  0.00\n",
      "prefix#8  0.01  0.01  0.04  0.00  0.02  0.00  0.10  0.02  0.00  0.03  0.01  0.05  0.00  0.24  0.01  0.03\n",
      "prefix#9  0.01  0.01  0.01  0.00  0.01  0.08  0.00  0.02  0.04  0.08  0.02  0.00  0.02  0.00  0.08  0.05\n",
      "prefix#10 0.25  0.04  0.00  0.00  0.00  0.01  0.01  0.02  0.05  0.04  0.06  0.01  0.04  0.02  0.00  0.01\n",
      "prefix#11 0.02  0.03  0.04  0.00  0.30  0.00  0.04  0.02  0.07  0.02  0.11  0.00  0.03  0.01  0.00  0.01\n",
      "prefix#12 0.02  0.07  0.02  0.00  0.02  0.03  0.01  0.01  0.03  0.01  0.00  0.02  0.05  0.11  0.06  0.01\n",
      "prefix#13 0.02  0.02  0.07  0.00  0.00  0.09  0.00  0.00  0.00  0.01  0.10  0.03  0.02  0.00  0.01  0.03\n",
      "prefix#14 0.00  0.01  0.00  0.00  0.02  0.08  0.00  0.01  0.00  0.08  0.05  0.02  0.01  0.00  0.11  0.00\n",
      "prefix#15 0.04  0.00  0.01  0.00  0.04  0.00  0.03  0.00  0.01  0.01  0.06  0.02  0.00  0.03  0.01  0.01\n",
      "prefix#16 0.02  0.00  0.13  0.00  0.05  0.04  0.00  0.02  0.04  0.01  0.04  0.33  0.01  0.01  0.16  0.02\n",
      "prefix#17 0.01  0.03  0.02  0.00  0.02  0.00  0.02  0.03  0.00  0.01  0.01  0.03  0.01  0.20  0.04  0.13\n",
      "prefix#18 0.02  0.00  0.05  0.01  0.01  0.00  0.00  0.04  0.00  0.01  0.01  0.05  0.00  0.01  0.01  0.01\n",
      "prefix#19 0.00  0.04  0.22  0.00  0.04  0.00  0.00  0.21  0.01  0.01  0.09  0.01  0.02  0.01  0.03  0.00\n",
      "text      0.32  0.19  0.01  0.00  0.14  0.09  0.02  0.16  0.24  0.06  0.07  0.04  0.20  0.15  0.07  0.04\n",
      "self      0.07  0.03  0.00  0.37  0.03  0.09  0.09  0.05  0.08  0.01  0.01  0.01  0.09  0.04  0.02  0.10\n",
      "context   0.12  0.07  0.01  0.37  0.17  0.21  0.18  0.07  0.14  0.06  0.04  0.03  0.14  0.10  0.05  0.42\n",
      "others    0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.01\n",
      "\n",
      "non_occ_cols\n",
      "prefix#0  0.00  0.04  0.07  0.00  0.01  0.01  0.13  0.07  0.01  0.04  0.02  0.07  0.01  0.00  0.01  0.00\n",
      "prefix#1  0.00  0.25  0.00  0.01  0.01  0.09  0.00  0.01  0.11  0.07  0.02  0.00  0.17  0.06  0.02  0.00\n",
      "prefix#2  0.00  0.02  0.22  0.00  0.03  0.00  0.33  0.04  0.01  0.19  0.14  0.07  0.02  0.00  0.00  0.01\n",
      "prefix#3  0.00  0.02  0.01  0.14  0.07  0.08  0.01  0.08  0.00  0.04  0.06  0.12  0.00  0.00  0.05  0.06\n",
      "prefix#4  0.01  0.03  0.00  0.00  0.00  0.29  0.00  0.03  0.02  0.03  0.01  0.03  0.01  0.00  0.13  0.00\n",
      "prefix#5  0.04  0.03  0.00  0.06  0.09  0.00  0.00  0.01  0.00  0.02  0.01  0.00  0.02  0.02  0.02  0.00\n",
      "prefix#6  0.00  0.01  0.06  0.00  0.01  0.00  0.08  0.01  0.07  0.01  0.01  0.01  0.02  0.00  0.05  0.01\n",
      "prefix#7  0.01  0.00  0.01  0.00  0.00  0.00  0.00  0.02  0.03  0.01  0.01  0.10  0.14  0.00  0.00  0.00\n",
      "prefix#8  0.01  0.01  0.03  0.00  0.03  0.00  0.04  0.20  0.01  0.01  0.06  0.02  0.00  0.16  0.00  0.05\n",
      "prefix#9  0.01  0.01  0.02  0.01  0.01  0.04  0.00  0.02  0.04  0.06  0.02  0.00  0.01  0.00  0.06  0.03\n",
      "prefix#10 0.20  0.04  0.00  0.00  0.01  0.02  0.01  0.01  0.05  0.00  0.14  0.00  0.11  0.02  0.00  0.00\n",
      "prefix#11 0.02  0.03  0.16  0.00  0.09  0.00  0.04  0.02  0.07  0.01  0.06  0.00  0.02  0.01  0.00  0.00\n",
      "prefix#12 0.01  0.05  0.03  0.00  0.01  0.03  0.01  0.01  0.06  0.02  0.00  0.01  0.13  0.12  0.07  0.00\n",
      "prefix#13 0.02  0.01  0.06  0.00  0.02  0.04  0.00  0.00  0.00  0.01  0.09  0.03  0.04  0.00  0.02  0.01\n",
      "prefix#14 0.00  0.03  0.00  0.00  0.03  0.10  0.00  0.02  0.00  0.38  0.05  0.03  0.00  0.02  0.03  0.00\n",
      "prefix#15 0.02  0.01  0.03  0.00  0.03  0.00  0.04  0.01  0.03  0.00  0.07  0.02  0.00  0.07  0.01  0.01\n",
      "prefix#16 0.02  0.00  0.08  0.00  0.05  0.06  0.00  0.01  0.01  0.00  0.02  0.26  0.01  0.01  0.34  0.01\n",
      "prefix#17 0.01  0.02  0.02  0.00  0.03  0.00  0.02  0.02  0.01  0.00  0.01  0.03  0.01  0.15  0.02  0.07\n",
      "prefix#18 0.02  0.01  0.02  0.01  0.02  0.00  0.00  0.05  0.00  0.01  0.01  0.05  0.00  0.01  0.00  0.00\n",
      "prefix#19 0.00  0.04  0.12  0.00  0.05  0.00  0.01  0.08  0.13  0.01  0.05  0.00  0.01  0.01  0.03  0.00\n",
      "text      0.23  0.13  0.01  0.00  0.13  0.07  0.03  0.10  0.15  0.03  0.06  0.04  0.10  0.12  0.04  0.03\n",
      "self      0.06  0.05  0.00  0.32  0.03  0.02  0.06  0.03  0.03  0.00  0.01  0.01  0.03  0.04  0.01  0.11\n",
      "context   0.27  0.15  0.03  0.43  0.23  0.12  0.17  0.12  0.14  0.04  0.06  0.08  0.13  0.16  0.06  0.55\n",
      "others    0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n",
      "\n",
      "===== Layer 23 =====\n",
      "occ_cols\n",
      "prefix#0  0.10  0.08  0.03  0.02  0.00  0.00  0.00  0.01  0.02  0.02  0.01  0.22  0.03  0.01  0.00  0.00\n",
      "prefix#1  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.09  0.00  0.11  0.17  0.00  0.01  0.06  0.00  0.00\n",
      "prefix#2  0.17  0.00  0.00  0.01  0.05  0.00  0.00  0.00  0.01  0.24  0.01  0.05  0.00  0.00  0.00  0.10\n",
      "prefix#3  0.02  0.00  0.00  0.00  0.03  0.00  0.00  0.00  0.01  0.02  0.03  0.00  0.09  0.00  0.00  0.08\n",
      "prefix#4  0.00  0.01  0.01  0.15  0.00  0.00  0.07  0.26  0.00  0.02  0.02  0.00  0.05  0.01  0.01  0.00\n",
      "prefix#5  0.00  0.01  0.00  0.02  0.00  0.00  0.00  0.04  0.27  0.09  0.01  0.00  0.00  0.00  0.01  0.01\n",
      "prefix#6  0.01  0.01  0.00  0.13  0.00  0.00  0.00  0.03  0.00  0.07  0.02  0.11  0.00  0.11  0.00  0.00\n",
      "prefix#7  0.14  0.03  0.00  0.04  0.00  0.00  0.00  0.06  0.18  0.01  0.01  0.00  0.26  0.12  0.07  0.00\n",
      "prefix#8  0.00  0.00  0.04  0.01  0.09  0.00  0.00  0.02  0.03  0.00  0.01  0.00  0.02  0.01  0.01  0.01\n",
      "prefix#9  0.03  0.00  0.00  0.02  0.02  0.00  0.00  0.00  0.00  0.01  0.15  0.00  0.00  0.00  0.03  0.01\n",
      "prefix#10 0.00  0.03  0.00  0.01  0.00  0.01  0.00  0.00  0.01  0.00  0.05  0.00  0.03  0.01  0.31  0.12\n",
      "prefix#11 0.18  0.01  0.00  0.00  0.29  0.02  0.00  0.00  0.00  0.02  0.12  0.00  0.11  0.00  0.24  0.01\n",
      "prefix#12 0.09  0.07  0.00  0.36  0.01  0.00  0.00  0.08  0.05  0.04  0.07  0.11  0.18  0.03  0.01  0.00\n",
      "prefix#13 0.11  0.00  0.00  0.01  0.00  0.00  0.00  0.00  0.01  0.01  0.06  0.00  0.01  0.00  0.00  0.21\n",
      "prefix#14 0.00  0.15  0.00  0.03  0.01  0.00  0.00  0.27  0.00  0.01  0.01  0.00  0.00  0.04  0.08  0.00\n",
      "prefix#15 0.00  0.10  0.00  0.00  0.17  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.23  0.02  0.02\n",
      "prefix#16 0.06  0.01  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.01  0.00  0.00  0.00  0.00  0.04\n",
      "prefix#17 0.01  0.00  0.23  0.02  0.15  0.00  0.00  0.07  0.01  0.02  0.01  0.08  0.02  0.11  0.01  0.00\n",
      "prefix#18 0.00  0.00  0.01  0.08  0.00  0.00  0.00  0.01  0.15  0.01  0.04  0.00  0.05  0.01  0.02  0.01\n",
      "prefix#19 0.03  0.00  0.49  0.00  0.00  0.00  0.00  0.01  0.02  0.13  0.03  0.11  0.06  0.00  0.04  0.00\n",
      "text      0.01  0.04  0.02  0.03  0.05  0.27  0.19  0.01  0.02  0.05  0.08  0.01  0.02  0.04  0.03  0.09\n",
      "self      0.00  0.12  0.03  0.01  0.01  0.08  0.16  0.01  0.04  0.02  0.01  0.10  0.01  0.09  0.02  0.03\n",
      "context   0.01  0.31  0.13  0.02  0.09  0.59  0.53  0.01  0.15  0.08  0.05  0.17  0.04  0.11  0.07  0.22\n",
      "others    0.00  0.00  0.00  0.00  0.00  0.02  0.04  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.01\n",
      "\n",
      "non_occ_cols\n",
      "prefix#0  0.15  0.12  0.02  0.02  0.00  0.00  0.00  0.00  0.02  0.03  0.01  0.24  0.03  0.00  0.00  0.00\n",
      "prefix#1  0.00  0.00  0.00  0.01  0.00  0.00  0.00  0.02  0.00  0.14  0.09  0.00  0.01  0.06  0.01  0.00\n",
      "prefix#2  0.14  0.00  0.00  0.02  0.12  0.00  0.00  0.00  0.01  0.14  0.01  0.06  0.01  0.00  0.00  0.15\n",
      "prefix#3  0.02  0.00  0.00  0.01  0.01  0.00  0.00  0.00  0.00  0.02  0.07  0.00  0.04  0.00  0.01  0.15\n",
      "prefix#4  0.00  0.01  0.01  0.19  0.00  0.00  0.19  0.12  0.00  0.04  0.04  0.00  0.03  0.00  0.01  0.00\n",
      "prefix#5  0.00  0.00  0.00  0.05  0.00  0.00  0.00  0.04  0.17  0.10  0.00  0.00  0.00  0.00  0.02  0.00\n",
      "prefix#6  0.02  0.01  0.00  0.09  0.00  0.00  0.00  0.03  0.00  0.05  0.01  0.12  0.04  0.09  0.00  0.00\n",
      "prefix#7  0.07  0.01  0.00  0.06  0.00  0.00  0.00  0.20  0.09  0.01  0.02  0.00  0.06  0.23  0.08  0.00\n",
      "prefix#8  0.00  0.00  0.04  0.02  0.06  0.00  0.00  0.15  0.05  0.00  0.01  0.00  0.03  0.01  0.01  0.01\n",
      "prefix#9  0.06  0.00  0.00  0.03  0.02  0.00  0.00  0.00  0.00  0.01  0.09  0.00  0.01  0.00  0.16  0.01\n",
      "prefix#10 0.00  0.03  0.00  0.03  0.00  0.07  0.00  0.01  0.00  0.00  0.03  0.00  0.04  0.00  0.07  0.05\n",
      "prefix#11 0.11  0.01  0.00  0.00  0.25  0.02  0.00  0.00  0.00  0.02  0.11  0.00  0.17  0.00  0.16  0.01\n",
      "prefix#12 0.06  0.10  0.00  0.20  0.01  0.00  0.00  0.09  0.30  0.08  0.15  0.07  0.13  0.01  0.02  0.00\n",
      "prefix#13 0.10  0.01  0.00  0.01  0.00  0.00  0.00  0.00  0.01  0.00  0.15  0.00  0.00  0.00  0.00  0.16\n",
      "prefix#14 0.00  0.11  0.00  0.04  0.03  0.00  0.00  0.13  0.00  0.01  0.01  0.00  0.02  0.02  0.18  0.00\n",
      "prefix#15 0.00  0.23  0.00  0.01  0.04  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.02  0.12  0.03  0.01\n",
      "prefix#16 0.03  0.01  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.01  0.01  0.00  0.00  0.03\n",
      "prefix#17 0.02  0.00  0.31  0.03  0.22  0.00  0.00  0.11  0.02  0.02  0.06  0.17  0.02  0.32  0.01  0.00\n",
      "prefix#18 0.00  0.00  0.00  0.05  0.00  0.00  0.00  0.01  0.12  0.03  0.03  0.00  0.10  0.01  0.05  0.01\n",
      "prefix#19 0.16  0.00  0.24  0.00  0.00  0.00  0.00  0.07  0.01  0.24  0.01  0.14  0.15  0.00  0.08  0.00\n",
      "text      0.01  0.02  0.02  0.04  0.05  0.19  0.12  0.01  0.01  0.02  0.05  0.00  0.01  0.02  0.02  0.08\n",
      "self      0.00  0.04  0.05  0.02  0.02  0.07  0.09  0.00  0.02  0.00  0.01  0.04  0.01  0.03  0.01  0.02\n",
      "context   0.02  0.26  0.29  0.08  0.16  0.62  0.53  0.01  0.14  0.02  0.05  0.12  0.04  0.06  0.05  0.29\n",
      "others    0.00  0.00  0.01  0.00  0.00  0.03  0.06  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "occ_types = ['occ_cols', 'non_occ_cols']\n",
    "\n",
    "for l_id in [1, 6, 12, 18, 23]:\n",
    "    # Dict: occ_type -> sect -> List[att_w]; list for all heads \n",
    "    layer_ob_dict = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for h_id in range(len(att_weights_avg_dict[l_id])):\n",
    "        for occ in occ_types:\n",
    "            for sect_k, att_w in att_weights_avg_dict[l_id][h_id][occ].items():\n",
    "                att_w_str = np.format_float_positional(att_w, precision=2, min_digits=2)\n",
    "                layer_ob_dict[occ][sect_k].append(att_w_str)\n",
    "    \n",
    "    print(f'===== Layer {l_id} =====')\n",
    "    for occ in occ_types:\n",
    "        print(occ)\n",
    "        for sect_k, att_w_list in layer_ob_dict[occ].items():\n",
    "            att_w_list_str = \"  \".join(att_w_list)\n",
    "            print(f'{sect_k:<10s}{att_w_list_str}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "94f8c6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(att_weights_avg_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba518c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95bc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d38540f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c64b99f8",
   "metadata": {},
   "source": [
    "## Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f20a4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_model = AutoModelForPreTraining.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d8519c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd15395",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c41c39f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a8701d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f105e976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ĠSelect', 'Ġ*', 'Ġfrom', 'Ġsinger']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_toks = gpt2_tokenizer.tokenize(' Select * from singer')\n",
    "_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e4664d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'Ġ;', 'ĠSQL', ':', 'ĠSelect']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_toks = gpt2_tokenizer.tokenize('x ; SQL: Select')\n",
    "_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85344dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x ; SQL: Select'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_tokenizer.convert_tokens_to_string(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bce0884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87, 2162, 16363, 25, 9683]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_tokenizer.convert_tokens_to_ids(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e35d6a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_sql = \"select role_code from project_staff where date_from > '2003-04-19 15:06:20' and date_to < '2016-03-15 00:33:18'\"\n",
    "_toks = gpt2_tokenizer.tokenize(_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f97f4b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['select', 'Ġrole', '_', 'code', 'Ġfrom', 'Ġproject', '_', 'staff', 'Ġwhere', 'Ġdate', '_', 'from', 'Ġ>', \"Ġ'\", '2003', '-', '04', '-', '19', 'Ġ15', ':', '06', ':', '20', \"'\", 'Ġand', 'Ġdate', '_', 'to', 'Ġ<', \"Ġ'\", '2016', '-', '03', '-', '15', 'Ġ00', ':', '33', ':', '18', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "print(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2600372",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "364f651b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"select role_code from project_staff where date_from > '2003-04-19 15:06:20' and date_to < '2016-03-15 00:33:18'\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_tokenizer.convert_tokens_to_string(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eadfdc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cc5d021e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 'car_1', 'car_1'),\n",
       " [((3, 'continents', 'continents'),\n",
       "   [[(5, 'contid', 'contid'), []],\n",
       "    [(7, 'continent', 'continent ( europe )'), [(9, 'europe', 'europe')]]]),\n",
       "  ((12, 'countries', 'countries'),\n",
       "   [[(14, 'countryid', 'countryid'), []],\n",
       "    [(16, 'countryname', 'countryname'), []],\n",
       "    [(18, 'continent', 'continent'), []]]),\n",
       "  ((20, 'car_makers', 'car_makers'),\n",
       "   [[(22, 'id', 'id'), []],\n",
       "    [(24, 'maker', 'maker'), []],\n",
       "    [(26, 'fullname', 'fullname'), []],\n",
       "    [(28, 'country', 'country'), []]]),\n",
       "  ((30, 'model_list', 'model_list'),\n",
       "   [[(32, 'modelid', 'modelid'), []],\n",
       "    [(34, 'maker', 'maker'), []],\n",
       "    [(36, 'model', 'model'), []]]),\n",
       "  ((38, 'car_names', 'car_names'),\n",
       "   [[(40, 'makeid', 'makeid'), []],\n",
       "    [(42, 'model', 'model'), []],\n",
       "    [(44, 'make', 'make'), []]]),\n",
       "  ((46, 'cars_data', 'cars_data'),\n",
       "   [[(48, 'id', 'id'), []],\n",
       "    [(50, 'mpg', 'mpg'), []],\n",
       "    [(52, 'cylinders', 'cylinders'), []],\n",
       "    [(54, 'edispl', 'edispl'), []],\n",
       "    [(56, 'horsepower', 'horsepower'), []],\n",
       "    [(58, 'weight', 'weight'), []],\n",
       "    [(60, 'accelerate', 'accelerate'), []],\n",
       "    [(62, 'year', 'year'), []]])])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['parsed_struct_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "214c2e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'| car_1 | continents : contid , continent ( europe ) | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _sent = 'What are the names of all European countries with at least 3 manufacturers?; structed knowledge: | car_1 | continents : contid , continent ( europe ) | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year'\n",
    "_sent = '| car_1 | continents : contid , continent ( europe ) | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year'\n",
    "_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2999076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_toks = mt_uskg_gpt2.tokenizer.tokenize(_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "feac6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sent = mt_uskg_gpt2.tokenizer(_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c1143eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '|'),\n",
       " (1, 'car_1'),\n",
       " (2, '|'),\n",
       " (3, 'continents'),\n",
       " (4, ':'),\n",
       " (5, 'contid'),\n",
       " (6, ','),\n",
       " (7, 'continent'),\n",
       " (8, '('),\n",
       " (9, 'europe'),\n",
       " (10, ')'),\n",
       " (11, '|'),\n",
       " (12, 'countries'),\n",
       " (13, ':'),\n",
       " (14, 'countryid'),\n",
       " (15, ','),\n",
       " (16, 'countryname'),\n",
       " (17, ','),\n",
       " (18, 'continent'),\n",
       " (19, '|'),\n",
       " (20, 'car_makers'),\n",
       " (21, ':'),\n",
       " (22, 'id'),\n",
       " (23, ','),\n",
       " (24, 'maker'),\n",
       " (25, ','),\n",
       " (26, 'fullname'),\n",
       " (27, ','),\n",
       " (28, 'country'),\n",
       " (29, '|'),\n",
       " (30, 'model_list'),\n",
       " (31, ':'),\n",
       " (32, 'modelid'),\n",
       " (33, ','),\n",
       " (34, 'maker'),\n",
       " (35, ','),\n",
       " (36, 'model'),\n",
       " (37, '|'),\n",
       " (38, 'car_names'),\n",
       " (39, ':'),\n",
       " (40, 'makeid'),\n",
       " (41, ','),\n",
       " (42, 'model'),\n",
       " (43, ','),\n",
       " (44, 'make'),\n",
       " (45, '|'),\n",
       " (46, 'cars_data'),\n",
       " (47, ':'),\n",
       " (48, 'id'),\n",
       " (49, ','),\n",
       " (50, 'mpg'),\n",
       " (51, ','),\n",
       " (52, 'cylinders'),\n",
       " (53, ','),\n",
       " (54, 'edispl'),\n",
       " (55, ','),\n",
       " (56, 'horsepower'),\n",
       " (57, ','),\n",
       " (58, 'weight'),\n",
       " (59, ','),\n",
       " (60, 'accelerate'),\n",
       " (61, ','),\n",
       " (62, 'year')]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(_sent.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d2edcbb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '|'),\n",
       " (1, 'Ġcar'),\n",
       " (2, '_'),\n",
       " (3, '1'),\n",
       " (4, 'Ġ|'),\n",
       " (5, 'Ġcontinents'),\n",
       " (6, 'Ġ:'),\n",
       " (7, 'Ġcont'),\n",
       " (8, 'id'),\n",
       " (9, 'Ġ,'),\n",
       " (10, 'Ġcontinent'),\n",
       " (11, 'Ġ('),\n",
       " (12, 'Ġeuro'),\n",
       " (13, 'pe'),\n",
       " (14, 'Ġ)'),\n",
       " (15, 'Ġ|'),\n",
       " (16, 'Ġcountries'),\n",
       " (17, 'Ġ:'),\n",
       " (18, 'Ġcountry'),\n",
       " (19, 'id'),\n",
       " (20, 'Ġ,'),\n",
       " (21, 'Ġcountry'),\n",
       " (22, 'name'),\n",
       " (23, 'Ġ,'),\n",
       " (24, 'Ġcontinent'),\n",
       " (25, 'Ġ|'),\n",
       " (26, 'Ġcar'),\n",
       " (27, '_'),\n",
       " (28, 'makers'),\n",
       " (29, 'Ġ:'),\n",
       " (30, 'Ġid'),\n",
       " (31, 'Ġ,'),\n",
       " (32, 'Ġmaker'),\n",
       " (33, 'Ġ,'),\n",
       " (34, 'Ġfull'),\n",
       " (35, 'name'),\n",
       " (36, 'Ġ,'),\n",
       " (37, 'Ġcountry'),\n",
       " (38, 'Ġ|'),\n",
       " (39, 'Ġmodel'),\n",
       " (40, '_'),\n",
       " (41, 'list'),\n",
       " (42, 'Ġ:'),\n",
       " (43, 'Ġmodel'),\n",
       " (44, 'id'),\n",
       " (45, 'Ġ,'),\n",
       " (46, 'Ġmaker'),\n",
       " (47, 'Ġ,'),\n",
       " (48, 'Ġmodel'),\n",
       " (49, 'Ġ|'),\n",
       " (50, 'Ġcar'),\n",
       " (51, '_'),\n",
       " (52, 'names'),\n",
       " (53, 'Ġ:'),\n",
       " (54, 'Ġmake'),\n",
       " (55, 'id'),\n",
       " (56, 'Ġ,'),\n",
       " (57, 'Ġmodel'),\n",
       " (58, 'Ġ,'),\n",
       " (59, 'Ġmake'),\n",
       " (60, 'Ġ|'),\n",
       " (61, 'Ġcars'),\n",
       " (62, '_'),\n",
       " (63, 'data'),\n",
       " (64, 'Ġ:'),\n",
       " (65, 'Ġid'),\n",
       " (66, 'Ġ,'),\n",
       " (67, 'Ġm'),\n",
       " (68, 'pg'),\n",
       " (69, 'Ġ,'),\n",
       " (70, 'Ġcylinders'),\n",
       " (71, 'Ġ,'),\n",
       " (72, 'Ġed'),\n",
       " (73, 'is'),\n",
       " (74, 'pl'),\n",
       " (75, 'Ġ,'),\n",
       " (76, 'Ġhorsepower'),\n",
       " (77, 'Ġ,'),\n",
       " (78, 'Ġweight'),\n",
       " (79, 'Ġ,'),\n",
       " (80, 'Ġaccelerate'),\n",
       " (81, 'Ġ,'),\n",
       " (82, 'Ġyear')]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(_toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b24925cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '|'),\n",
       " (1, ' car'),\n",
       " (2, '_'),\n",
       " (3, '1'),\n",
       " (4, ' |'),\n",
       " (5, ' continents'),\n",
       " (6, ' :'),\n",
       " (7, ' cont'),\n",
       " (8, 'id'),\n",
       " (9, ','),\n",
       " (10, ' continent'),\n",
       " (11, ' ('),\n",
       " (12, ' euro'),\n",
       " (13, 'pe'),\n",
       " (14, ' )'),\n",
       " (15, ' |'),\n",
       " (16, ' countries'),\n",
       " (17, ' :'),\n",
       " (18, ' country'),\n",
       " (19, 'id'),\n",
       " (20, ','),\n",
       " (21, ' country'),\n",
       " (22, 'name'),\n",
       " (23, ','),\n",
       " (24, ' continent'),\n",
       " (25, ' |'),\n",
       " (26, ' car'),\n",
       " (27, '_'),\n",
       " (28, 'makers'),\n",
       " (29, ' :'),\n",
       " (30, ' id'),\n",
       " (31, ','),\n",
       " (32, ' maker'),\n",
       " (33, ','),\n",
       " (34, ' full'),\n",
       " (35, 'name'),\n",
       " (36, ','),\n",
       " (37, ' country'),\n",
       " (38, ' |'),\n",
       " (39, ' model'),\n",
       " (40, '_'),\n",
       " (41, 'list'),\n",
       " (42, ' :'),\n",
       " (43, ' model'),\n",
       " (44, 'id'),\n",
       " (45, ','),\n",
       " (46, ' maker'),\n",
       " (47, ','),\n",
       " (48, ' model'),\n",
       " (49, ' |'),\n",
       " (50, ' car'),\n",
       " (51, '_'),\n",
       " (52, 'names'),\n",
       " (53, ' :'),\n",
       " (54, ' make'),\n",
       " (55, 'id'),\n",
       " (56, ','),\n",
       " (57, ' model'),\n",
       " (58, ','),\n",
       " (59, ' make'),\n",
       " (60, ' |'),\n",
       " (61, ' cars'),\n",
       " (62, '_'),\n",
       " (63, 'data'),\n",
       " (64, ' :'),\n",
       " (65, ' id'),\n",
       " (66, ','),\n",
       " (67, ' m'),\n",
       " (68, 'pg'),\n",
       " (69, ','),\n",
       " (70, ' cylinders'),\n",
       " (71, ','),\n",
       " (72, ' ed'),\n",
       " (73, 'is'),\n",
       " (74, 'pl'),\n",
       " (75, ','),\n",
       " (76, ' horsepower'),\n",
       " (77, ','),\n",
       " (78, ' weight'),\n",
       " (79, ','),\n",
       " (80, ' accelerate'),\n",
       " (81, ','),\n",
       " (82, ' year')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list([(i, mt_uskg_gpt2.tokenizer.decode(tokenized_sent['input_ids'][i])) for i in range(len(tokenized_sent['input_ids']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6fe72010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenSpan(start=12, end=13)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent.word_to_tokens(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3844ac7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83,\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  64,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_sent.word_ids()), tokenized_sent.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4fca9a02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "_words = []\n",
    "while True:\n",
    "    try:\n",
    "        s, e = tokenized_sent.word_to_chars(i)\n",
    "        _words.append(_sent[s : e])\n",
    "        i += 1\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "29a9a125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " ' are',\n",
       " ' the',\n",
       " ' names',\n",
       " ' of',\n",
       " ' all',\n",
       " ' European',\n",
       " ' countries',\n",
       " ' with',\n",
       " ' at',\n",
       " ' least',\n",
       " ' 3',\n",
       " ' manufacturers',\n",
       " '?;',\n",
       " ' structed',\n",
       " ' knowledge',\n",
       " ':',\n",
       " ' |',\n",
       " ' car',\n",
       " '_',\n",
       " '1',\n",
       " ' |',\n",
       " ' continents',\n",
       " ' :',\n",
       " ' contid',\n",
       " ' ,',\n",
       " ' continent',\n",
       " ' (',\n",
       " ' europe',\n",
       " ' )',\n",
       " ' |',\n",
       " ' countries',\n",
       " ' :',\n",
       " ' countryid',\n",
       " ' ,',\n",
       " ' countryname',\n",
       " ' ,',\n",
       " ' continent',\n",
       " ' |',\n",
       " ' car',\n",
       " '_',\n",
       " 'makers',\n",
       " ' :',\n",
       " ' id',\n",
       " ' ,',\n",
       " ' maker',\n",
       " ' ,',\n",
       " ' fullname',\n",
       " ' ,',\n",
       " ' country',\n",
       " ' |',\n",
       " ' model',\n",
       " '_',\n",
       " 'list',\n",
       " ' :',\n",
       " ' modelid',\n",
       " ' ,',\n",
       " ' maker',\n",
       " ' ,',\n",
       " ' model',\n",
       " ' |',\n",
       " ' car',\n",
       " '_',\n",
       " 'names',\n",
       " ' :',\n",
       " ' makeid',\n",
       " ' ,',\n",
       " ' model',\n",
       " ' ,',\n",
       " ' make',\n",
       " ' |',\n",
       " ' cars',\n",
       " '_',\n",
       " 'data',\n",
       " ' :',\n",
       " ' id',\n",
       " ' ,',\n",
       " ' mpg',\n",
       " ' ,',\n",
       " ' cylinders',\n",
       " ' ,',\n",
       " ' edispl',\n",
       " ' ,',\n",
       " ' horsepower',\n",
       " ' ,',\n",
       " ' weight',\n",
       " ' ,',\n",
       " ' accelerate',\n",
       " ' ,',\n",
       " ' year']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "00680fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent.char_to_token(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "60499a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('| co', 'Ġcontinents')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sent[8:12], _toks[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78190d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "880647d7",
   "metadata": {},
   "source": [
    "### GPT2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20eda41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'transformer',\n",
       " 'transformer.wte',\n",
       " 'transformer.wpe',\n",
       " 'transformer.drop',\n",
       " 'transformer.h',\n",
       " 'transformer.h.0',\n",
       " 'transformer.h.0.ln_1',\n",
       " 'transformer.h.0.attn',\n",
       " 'transformer.h.0.attn.c_attn',\n",
       " 'transformer.h.0.attn.c_proj',\n",
       " 'transformer.h.0.attn.attn_dropout',\n",
       " 'transformer.h.0.attn.resid_dropout',\n",
       " 'transformer.h.0.ln_2',\n",
       " 'transformer.h.0.mlp',\n",
       " 'transformer.h.0.mlp.c_fc',\n",
       " 'transformer.h.0.mlp.c_proj',\n",
       " 'transformer.h.0.mlp.dropout',\n",
       " 'transformer.h.1',\n",
       " 'transformer.h.1.ln_1',\n",
       " 'transformer.h.1.attn',\n",
       " 'transformer.h.1.attn.c_attn',\n",
       " 'transformer.h.1.attn.c_proj',\n",
       " 'transformer.h.1.attn.attn_dropout',\n",
       " 'transformer.h.1.attn.resid_dropout',\n",
       " 'transformer.h.1.ln_2',\n",
       " 'transformer.h.1.mlp',\n",
       " 'transformer.h.1.mlp.c_fc',\n",
       " 'transformer.h.1.mlp.c_proj',\n",
       " 'transformer.h.1.mlp.dropout',\n",
       " 'transformer.h.2',\n",
       " 'transformer.h.2.ln_1',\n",
       " 'transformer.h.2.attn',\n",
       " 'transformer.h.2.attn.c_attn',\n",
       " 'transformer.h.2.attn.c_proj',\n",
       " 'transformer.h.2.attn.attn_dropout',\n",
       " 'transformer.h.2.attn.resid_dropout',\n",
       " 'transformer.h.2.ln_2',\n",
       " 'transformer.h.2.mlp',\n",
       " 'transformer.h.2.mlp.c_fc',\n",
       " 'transformer.h.2.mlp.c_proj',\n",
       " 'transformer.h.2.mlp.dropout',\n",
       " 'transformer.h.3',\n",
       " 'transformer.h.3.ln_1',\n",
       " 'transformer.h.3.attn',\n",
       " 'transformer.h.3.attn.c_attn',\n",
       " 'transformer.h.3.attn.c_proj',\n",
       " 'transformer.h.3.attn.attn_dropout',\n",
       " 'transformer.h.3.attn.resid_dropout',\n",
       " 'transformer.h.3.ln_2',\n",
       " 'transformer.h.3.mlp',\n",
       " 'transformer.h.3.mlp.c_fc',\n",
       " 'transformer.h.3.mlp.c_proj',\n",
       " 'transformer.h.3.mlp.dropout',\n",
       " 'transformer.h.4',\n",
       " 'transformer.h.4.ln_1',\n",
       " 'transformer.h.4.attn',\n",
       " 'transformer.h.4.attn.c_attn',\n",
       " 'transformer.h.4.attn.c_proj',\n",
       " 'transformer.h.4.attn.attn_dropout',\n",
       " 'transformer.h.4.attn.resid_dropout',\n",
       " 'transformer.h.4.ln_2',\n",
       " 'transformer.h.4.mlp',\n",
       " 'transformer.h.4.mlp.c_fc',\n",
       " 'transformer.h.4.mlp.c_proj',\n",
       " 'transformer.h.4.mlp.dropout',\n",
       " 'transformer.h.5',\n",
       " 'transformer.h.5.ln_1',\n",
       " 'transformer.h.5.attn',\n",
       " 'transformer.h.5.attn.c_attn',\n",
       " 'transformer.h.5.attn.c_proj',\n",
       " 'transformer.h.5.attn.attn_dropout',\n",
       " 'transformer.h.5.attn.resid_dropout',\n",
       " 'transformer.h.5.ln_2',\n",
       " 'transformer.h.5.mlp',\n",
       " 'transformer.h.5.mlp.c_fc',\n",
       " 'transformer.h.5.mlp.c_proj',\n",
       " 'transformer.h.5.mlp.dropout',\n",
       " 'transformer.h.6',\n",
       " 'transformer.h.6.ln_1',\n",
       " 'transformer.h.6.attn',\n",
       " 'transformer.h.6.attn.c_attn',\n",
       " 'transformer.h.6.attn.c_proj',\n",
       " 'transformer.h.6.attn.attn_dropout',\n",
       " 'transformer.h.6.attn.resid_dropout',\n",
       " 'transformer.h.6.ln_2',\n",
       " 'transformer.h.6.mlp',\n",
       " 'transformer.h.6.mlp.c_fc',\n",
       " 'transformer.h.6.mlp.c_proj',\n",
       " 'transformer.h.6.mlp.dropout',\n",
       " 'transformer.h.7',\n",
       " 'transformer.h.7.ln_1',\n",
       " 'transformer.h.7.attn',\n",
       " 'transformer.h.7.attn.c_attn',\n",
       " 'transformer.h.7.attn.c_proj',\n",
       " 'transformer.h.7.attn.attn_dropout',\n",
       " 'transformer.h.7.attn.resid_dropout',\n",
       " 'transformer.h.7.ln_2',\n",
       " 'transformer.h.7.mlp',\n",
       " 'transformer.h.7.mlp.c_fc',\n",
       " 'transformer.h.7.mlp.c_proj',\n",
       " 'transformer.h.7.mlp.dropout',\n",
       " 'transformer.h.8',\n",
       " 'transformer.h.8.ln_1',\n",
       " 'transformer.h.8.attn',\n",
       " 'transformer.h.8.attn.c_attn',\n",
       " 'transformer.h.8.attn.c_proj',\n",
       " 'transformer.h.8.attn.attn_dropout',\n",
       " 'transformer.h.8.attn.resid_dropout',\n",
       " 'transformer.h.8.ln_2',\n",
       " 'transformer.h.8.mlp',\n",
       " 'transformer.h.8.mlp.c_fc',\n",
       " 'transformer.h.8.mlp.c_proj',\n",
       " 'transformer.h.8.mlp.dropout',\n",
       " 'transformer.h.9',\n",
       " 'transformer.h.9.ln_1',\n",
       " 'transformer.h.9.attn',\n",
       " 'transformer.h.9.attn.c_attn',\n",
       " 'transformer.h.9.attn.c_proj',\n",
       " 'transformer.h.9.attn.attn_dropout',\n",
       " 'transformer.h.9.attn.resid_dropout',\n",
       " 'transformer.h.9.ln_2',\n",
       " 'transformer.h.9.mlp',\n",
       " 'transformer.h.9.mlp.c_fc',\n",
       " 'transformer.h.9.mlp.c_proj',\n",
       " 'transformer.h.9.mlp.dropout',\n",
       " 'transformer.h.10',\n",
       " 'transformer.h.10.ln_1',\n",
       " 'transformer.h.10.attn',\n",
       " 'transformer.h.10.attn.c_attn',\n",
       " 'transformer.h.10.attn.c_proj',\n",
       " 'transformer.h.10.attn.attn_dropout',\n",
       " 'transformer.h.10.attn.resid_dropout',\n",
       " 'transformer.h.10.ln_2',\n",
       " 'transformer.h.10.mlp',\n",
       " 'transformer.h.10.mlp.c_fc',\n",
       " 'transformer.h.10.mlp.c_proj',\n",
       " 'transformer.h.10.mlp.dropout',\n",
       " 'transformer.h.11',\n",
       " 'transformer.h.11.ln_1',\n",
       " 'transformer.h.11.attn',\n",
       " 'transformer.h.11.attn.c_attn',\n",
       " 'transformer.h.11.attn.c_proj',\n",
       " 'transformer.h.11.attn.attn_dropout',\n",
       " 'transformer.h.11.attn.resid_dropout',\n",
       " 'transformer.h.11.ln_2',\n",
       " 'transformer.h.11.mlp',\n",
       " 'transformer.h.11.mlp.c_fc',\n",
       " 'transformer.h.11.mlp.c_proj',\n",
       " 'transformer.h.11.mlp.dropout',\n",
       " 'transformer.ln_f',\n",
       " 'lm_head']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k, v in gpt2_model.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f1a801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4de7812",
   "metadata": {},
   "source": [
    "### Attention Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d65dbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = 130\n",
    "ex = copy.deepcopy(processed_spider_dev[_id])\n",
    "ctu2.add_basic_analysis_info_gpt2(mt_uskg_gpt2, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9bfa1a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'enc_sentence', 'tokenized_item', 'pre_sql_sequence', 'text_range', 'struct_range', 'sql_range', 'parsed_struct_in', 'alias2table', 'col2table', 'col_name_counter', 'tab_name_counter', 'struct_node_ranges_dict', 'sql_tokens', 'sql_token_ranges', 'tok_ranges2type', 'type2tok_ranges', 'sql_col_nodes', 'sql_tab_nodes', 'sql_alias_nodes'])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a0aa73b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'predict_input_ids', 'predict_attention_mask', 'labels'])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_item = ex['tokenized_item']\n",
    "_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "407d3551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What are the names of all European countries with at least 3 manufacturers?; structed knowledge: | car_1 | continents : contid, continent ( europe ) | countries : countryid, countryname, continent | car_makers : id, maker, fullname, country | model_list : modelid, maker, model | car_names : makeid, model, make | cars_data : id, mpg, cylinders, edispl, horsepower, weight, accelerate, year ; SQL: select t1.countryname from countries as t1 join continents as t2 on t1.continent = t2.contid join car_makers as t3 on t1.countryid = t3.country where t2.continent = 'europe' group by t1.countryname having count(*) >= 3;\""
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_prompt = ex['pre_sql_sequence'] + ' ' + ex['seq_out']\n",
    "dec_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "de1372a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input_ids', 'attention_mask']), torch.Size([2, 176]))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = ctu2.make_inputs_gpt2(mt_uskg_gpt2.tokenizer, [dec_prompt] * 2)\n",
    "inp.keys(), inp['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c235116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs_exp = ctu2.run_model_forward_uskg_gpt2(mt_uskg_gpt2.model, **inp, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "09ad961d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'attentions'])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_exp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "34507645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs_exp['attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "936260c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 176, 196])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_exp['attentions'][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cebdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## outputs_exp['attentions']: (n_layers, (bsz, n_heads, seq_len, seq_len + prompt_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc625616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "580886e1",
   "metadata": {},
   "source": [
    "### Temp debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bab69448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uskg\n",
    "\n",
    "from transformers.models.auto.configuration_auto import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cce8bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(uskg.models.prompt.modeling_auto)\n",
    "\n",
    "from uskg.models.unified import finetune, prefixtuning\n",
    "\n",
    "from uskg.models.prompt.modeling_auto import AutoModelForPreTraining\n",
    "from uskg.models.prompt.modeling_gpt2 import GPT2LMHeadModel\n",
    "from uskg.models.prompt.modeling_t5 import T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15e67e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "_m = AutoModelForPreTraining.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ee72fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uskg.models.prompt.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "896f1df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94854136059536"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(type(_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4f6fa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(_m, uskg.models.prompt.modeling_gpt2.GPT2LMHeadModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b78c47b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(_m, GPT2LMHeadModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61238372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT2LMHeadModel is uskg.models.prompt.modeling_gpt2.GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d491d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94854135704752"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(uskg.models.prompt.modeling_gpt2.GPT2LMHeadModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d80f5ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_m) is uskg.models.prompt.modeling_gpt2.GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "13d3e588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_m) is GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc2ef4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(_m, type(_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03a18e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uskg.models.prompt.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "785d77d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uskg.models.prompt.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_m.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3d9ca0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_cfg = AutoConfig.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2266cb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.9.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "## T5\n",
    "_m2 = AutoModelForPreTraining.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "80359c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(_m2, uskg.models.prompt.modeling_t5.T5ForConditionalGeneration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b70fb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(_m2, T5ForConditionalGeneration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77b19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c116a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "670px",
    "left": "21px",
    "top": "135px",
    "width": "269px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

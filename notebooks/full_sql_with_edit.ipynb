{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/causal_trace.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Tracing\n",
    "\n",
    "A demonstration of the double-intervention causal tracing method.\n",
    "\n",
    "The strategy used by causal tracing is to understand important\n",
    "states within a transfomer by doing two interventions simultaneously:\n",
    "\n",
    "1. Corrupt a subset of the input.  In our paper, we corrupt the subject tokens\n",
    "   to frustrate the ability of the transformer to accurately complete factual\n",
    "   prompts about the subject.\n",
    "2. Restore a subset of the internal hidden states.  In our paper, we scan\n",
    "   hidden states at all layers and all tokens, searching for individual states\n",
    "   that carry the necessary information for the transformer to recover its\n",
    "   capability to complete the factual prompt.\n",
    "\n",
    "The traces of decisive states can be shown on a heatmap.  This notebook\n",
    "demonstrates the code for conducting causal traces and creating these heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `experiments.causal_trace` module contains a set of functions for running causal traces.\n",
    "\n",
    "In this notebook, we reproduce, demonstrate and discuss the interesting functions.\n",
    "\n",
    "We begin by importing several utility functions that deal with tokens and transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import defaultdict, Counter\n",
    "from util import nethook\n",
    "from util.globals import DATA_DIR\n",
    "from experiments.causal_trace import (\n",
    "    ModelAndTokenizer,\n",
    "    layername,\n",
    "    guess_subject,\n",
    "    plot_trace_heatmap,\n",
    ")\n",
    "from experiments.causal_trace import (\n",
    "    make_inputs,\n",
    "    decode_tokens,\n",
    "    find_token_range,\n",
    "    predict_token,\n",
    "    predict_from_input,\n",
    "    collect_embedding_std,\n",
    ")\n",
    "from dsets import KnownsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f4d4c49bb80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "# from uskg.models.unified.prefixtuning import Model\n",
    "from uskg.models.unified import finetune, prefixtuning\n",
    "from uskg.utils.configue import Configure\n",
    "from uskg.utils.training_arguments import WrappedSeq2SeqTrainingArguments\n",
    "from uskg.seq2seq_construction import spider as s2s_spider\n",
    "from uskg.third_party.spider.preprocess.get_tables import dump_db_json_schema\n",
    "from uskg.third_party.spider import evaluation as sp_eval\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# import stanza\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from experiments import causal_trace_uskg as ctu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tokenizer_uskg: hkunlp/from_all_T5_large_prefix_spider_with_cell_value2\n",
      "Using tokenizer_fast: t5-large\n",
      "prefix-tuning sequence length is 10.\n"
     ]
    }
   ],
   "source": [
    "mt_uskg = ctu.ModelAndTokenizer_USKG('t5-large-prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('constructor', 'seq2seq_construction.spider'),\n",
       " ('schema_serialization_with_db_content', True),\n",
       " ('target_with_db_id', False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mt_uskg.task_args.seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.model.pretrain_model.encoder.embed_tokens is mt_uskg.model.pretrain_model.shared, \\\n",
    "mt_uskg.model.pretrain_model.decoder.embed_tokens is mt_uskg.model.pretrain_model.shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.model.preseqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [k for k,v in mt_uskg.model.named_parameters()]\n",
    "# [k for k,v in mt_uskg.model.named_modules()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spider dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_train_path = '/home/yshao/Projects/SDR-analysis/data/spider/train+ratsql_graph.json'\n",
    "spider_dev_path = '/home/yshao/Projects/SDR-analysis/data/spider/dev+ratsql_graph.json'\n",
    "spider_db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev = ctu.load_raw_dataset(\n",
    "    data_filepath = spider_dev_path,\n",
    "    db_path=spider_db_dir,\n",
    "#     schema_cache=SCHEMA_CACHE\n",
    ")\n",
    "len(raw_spider_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph'])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.task_args.dataset.use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_spider_dev = s2s_spider.DevDataset(\n",
    "    args=mt_uskg.task_args,\n",
    "    raw_datasets=raw_spider_dev,\n",
    "    cache_root='../cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What are the names of all European countries with at least 3 manufacturers?',\n",
       " '| car_1 | continents : contid , continent ( europe ) | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.countryname from countries as t1 join continents as t2 on t1.continent = t2.contid join car_makers as t3 on t1.countryid = t3.country where t2.continent = 'europe' group by t1.countryname having count(*) >= 3;\")"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 130\n",
    "processed_spider_dev[_id]['text_in'], \\\n",
    "processed_spider_dev[_id]['struct_in'], \\\n",
    "processed_spider_dev[_id]['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_enc_sentence = f\"{processed_spider_dev[_id]['text_in']}; structed knowledge: {processed_spider_dev[_id]['struct_in']}\"\n",
    "_toks = mt_uskg.tokenizer.tokenize(_enc_sentence)\n",
    "len(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # _occ_punct = set()\n",
    "\n",
    "# for _id in range(len(processed_spider_dev)):\n",
    "#     ex = processed_spider_dev[_id]\n",
    "# #     _occ_punct.update(set(string.punctuation) & set(ex['seq_out']))\n",
    "#     if '_(' in ex['struct_in']:\n",
    "#         print(_id, ex['question'])\n",
    "#         print(ex['struct_in'])\n",
    "#         print(ex['seq_out'])\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Train set\n",
    "\n",
    "# raw_spider_train = ctu.load_raw_dataset(\n",
    "#     data_filepath = spider_train_path,\n",
    "#     db_path=spider_db_dir,\n",
    "# )\n",
    "# processed_spider_train = s2s_spider.TrainDataset(\n",
    "#     args=mt_uskg.task_args,\n",
    "#     raw_datasets=raw_spider_train,\n",
    "#     cache_root='../cache')\n",
    "# len(processed_spider_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_spider_train[5441]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "- merged in create_analysis_sample_dicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = '/home/yshao/Projects/language/language/xsp/data/spider/tables.json'\n",
    "db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmaps = sp_eval.build_foreign_key_map_from_json(table_path)\n",
    "evaluator = sp_eval.Evaluator(db_dir=db_dir, kmaps=kmaps, etype='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctu.evaluate_hardness.evaluator = evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0, 0, 'hard')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "_sql_str = 'select t1.birth_date from people as t1 join poker_player as t2 on t1.people_id = t2.people_id order by t2.earnings asc limit 1'\n",
    "db_name = 'poker_player'\n",
    "schema = evaluator.schemas[db_name]\n",
    "_sql = sp_eval.get_sql(schema, _sql_str)\n",
    "sp_eval.count_component1(_sql), sp_eval.count_component2(_sql), sp_eval.count_others(_sql), \\\n",
    "evaluator.eval_hardness(_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_2D_dict(d):\n",
    "    out_d = defaultdict(lambda: defaultdict(np.nan))\n",
    "    for k1, d1 in d.items():\n",
    "        for k2, v in d1.items():\n",
    "            out_d[k2][k1] = v\n",
    "    return out_d\n",
    "\n",
    "def format_print_1D_dict(d, sort_by=None, reverse=False, head_col_w=10, col_w=6):\n",
    "    # sort: None, 'key' or 'value'\n",
    "    \n",
    "    item_l = list(d.items())\n",
    "    if sort_by == 'key':\n",
    "        item_l.sort(reverse=reverse)\n",
    "    elif sort_by == 'value':\n",
    "        item_l.sort(key=lambda x: (x[1], x[0]), reverse=reverse)\n",
    "    \n",
    "    decm_w = col_w - 2\n",
    "    \n",
    "    for k, v in item_l:\n",
    "        print(f'{k:<{head_col_w}s}{v:.{decm_w}f}')\n",
    "\n",
    "def format_print_2D_dict(d, \n",
    "                         all_k1=None, \n",
    "                         all_k2=None, \n",
    "                         sort_k1_kwargs=None, \n",
    "                         sort_k2_kwargs=None, \n",
    "                         head_col_w=12, \n",
    "                         col_w=6,\n",
    "                         decm_w=4):\n",
    "    if all_k1 is None:\n",
    "        all_k1 = list(d.keys())\n",
    "        if sort_k1_kwargs is not None:\n",
    "            all_k1.sort(**sort_k1_kwargs)\n",
    "    \n",
    "    if all_k2 is None:\n",
    "        for k1, d1 in d.items():\n",
    "            d1_keys = list(d1.keys())\n",
    "            if all_k2 is None:\n",
    "                all_k2 = d1_keys\n",
    "            else:\n",
    "                if set(d1_keys) != set(all_k2):\n",
    "                    print('Warning:\\n', d1_keys, '\\n', all_k2)\n",
    "            # all_k2.update(list(d1.keys()))\n",
    "        if sort_k2_kwargs is not None:\n",
    "            all_k2.sort(**sort_k2_kwargs)\n",
    "    \n",
    "    print_str = '\\t'.join(['X' * head_col_w] + [f'{k2:<{col_w}s}' for k2 in all_k2]) + '\\n'\n",
    "    \n",
    "    for k1 in all_k1:\n",
    "        d1 = d[k1]\n",
    "        print_str += f'{k1:<{head_col_w}s}'\n",
    "        for k2 in all_k2:\n",
    "            v = d1[k2]\n",
    "            print_str += f'\\t{v:<{col_w}.{decm_w}f}'\n",
    "        print_str += '\\n'\n",
    "    \n",
    "    print(print_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USKG error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from play_pred()\n",
    "\n",
    "def pred_sql(mt, ex, padding=\"max_length\"):\n",
    "    text_in = ex['text_in']\n",
    "    struct_in = ex['struct_in']\n",
    "\n",
    "    txt = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "    \n",
    "    tokenized_txt = mt.tokenizer_uskg([txt], max_length=1024, padding=padding, truncation=True)\n",
    "    \n",
    "    device = mt.model.device\n",
    "    pred = mt.tokenizer_uskg.batch_decode(\n",
    "      mt.model.generate(\n",
    "        torch.tensor(tokenized_txt.data['input_ids'], dtype=int, device=device),\n",
    "        torch.tensor(tokenized_txt.data['attention_mask'], dtype=int, device=device),\n",
    "        num_beams=1, \n",
    "        max_length=256\n",
    "        ), \n",
    "      skip_special_tokens=True \n",
    "    )\n",
    "    return pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from evaluator.evaluate_one()\n",
    "\n",
    "def evaluate_sql(evaluator, db_name, gold, predicted):\n",
    "    schema = evaluator.schemas[db_name]\n",
    "    g_sql = sp_eval.get_sql(schema, gold)\n",
    "    hardness = evaluator.eval_hardness(g_sql)\n",
    "    # self.scores[hardness][\"count\"] += 1\n",
    "    # self.scores[\"all\"][\"count\"] += 1\n",
    "\n",
    "    parse_error = False\n",
    "    try:\n",
    "        p_sql = sp_eval.get_sql(schema, predicted)\n",
    "    except:\n",
    "        # If p_sql is not valid, then we will use an empty sql to evaluate with the correct sql\n",
    "        p_sql = {\n",
    "            \"except\": None,\n",
    "            \"from\": {\"conds\": [], \"table_units\": []},\n",
    "            \"groupBy\": [],\n",
    "            \"having\": [],\n",
    "            \"intersect\": None,\n",
    "            \"limit\": None,\n",
    "            \"orderBy\": [],\n",
    "            \"select\": [False, []],\n",
    "            \"union\": None,\n",
    "            \"where\": [],\n",
    "        }\n",
    "\n",
    "        # TODO fix\n",
    "        parse_error = True\n",
    "\n",
    "    # rebuild sql for value evaluation\n",
    "    kmap = evaluator.kmaps[db_name]\n",
    "    g_valid_col_units = sp_eval.build_valid_col_units(g_sql[\"from\"][\"table_units\"], schema)\n",
    "    g_sql = sp_eval.rebuild_sql_val(g_sql)\n",
    "    g_sql = sp_eval.rebuild_sql_col(g_valid_col_units, g_sql, kmap)\n",
    "    p_valid_col_units = sp_eval.build_valid_col_units(p_sql[\"from\"][\"table_units\"], schema)\n",
    "    p_sql = sp_eval.rebuild_sql_val(p_sql)\n",
    "    p_sql = sp_eval.rebuild_sql_col(p_valid_col_units, p_sql, kmap)\n",
    "    \n",
    "    exec_score = None\n",
    "    partial_scores = None\n",
    "    exact_score = None\n",
    "    if evaluator.etype in [\"all\", \"exec\"]:\n",
    "        try:\n",
    "            exec_score = sp_eval.eval_exec_match(\n",
    "                evaluator.db_paths[db_name], predicted, gold, p_sql, g_sql\n",
    "            )\n",
    "            exec_score = int(exec_score)\n",
    "        except:\n",
    "            exec_score = 0\n",
    "    if evaluator.etype in [\"all\", \"match\"]:\n",
    "        partial_scores = evaluator.eval_partial_match(p_sql, g_sql)\n",
    "        exact_score = evaluator.eval_exact_match(p_sql, g_sql, partial_scores)\n",
    "        # update_scores_match(self.scores, exact_score, hardness, partial_scores, PARTIAL_TYPES)\n",
    "\n",
    "    return {\n",
    "        \"predicted\": predicted,\n",
    "        \"gold\": gold,\n",
    "        \"predicted_parse_error\": parse_error,\n",
    "        \"hardness\": hardness,\n",
    "        \"exact\": exact_score,\n",
    "        \"partial\": partial_scores,\n",
    "        \"exec\": exec_score,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'\n",
    "\n",
    "def execute_sql(db, sql_str):\n",
    "    db_path = os.path.join(db_dir, db, f'{db}.sqlite')\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(sql_str)\n",
    "        res = cursor.fetchall()\n",
    "    except:\n",
    "        res = 'ERROR'\n",
    "    conn.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = processed_spider_dev[123]\n",
    "ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('car_1',\n",
       " 'What are the countries having at least one car maker? List name and id.',\n",
       " 'select t1.countryname, t1.countryid from countries as t1 join car_makers as t2 on t1.countryid = t2.country group by t1.countryid having count(*) >= 1;',\n",
       " 'select t1.countryname, t1.id from countries as t1 join car_makers as t2 on t1.countryid = t2.country group by t1.countryname having count(*) >= 1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pred_sql(mt_uskg, ex)\n",
    "ex['db_id'], ex['text_in'], ex['seq_out'], pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('car_1',\n",
       " 'What are the countries having at least one car maker? List name and id.',\n",
       " 'select t1.countryname, t1.countryid from countries as t1 join car_makers as t2 on t1.countryid = t2.country group by t1.countryid having count(*) >= 1;',\n",
       " 'select t1.countryname, t1.id from countries as t1 join car_makers as t2 on t1.countryid = t2.country group by t1.countryname having count(*) >= 1')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "ex['db_id'], ex['text_in'], ex['seq_out'], pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "txt = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "txt_toks = mt_uskg.tokenizer_uskg.tokenize(txt)\n",
    "len(txt_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"select count(*) from battle where id not in ( select lost_in_battle from ship where tonnage = '225' );\",\n",
       " [(7,)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_res = execute_sql(ex['db_id'], ex['seq_out'])\n",
    "ex['seq_out'], exec_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('select count(*) from battle where id not in ( select lost_in_battle from ship where tonnage > 225 )',\n",
       " [(3,)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_res = execute_sql(ex['db_id'], pred)\n",
    "pred, exec_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8,)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_pred = \"\"\"\n",
    "SELECT COUNT(DISTINCT battle.id) AS num_battles\n",
    "FROM battle\n",
    "LEFT JOIN ship ON battle.id = ship.lost_in_battle\n",
    "WHERE (ship.tonnage != '225' OR ship.tonnage IS NULL)\n",
    "\"\"\"\n",
    "\n",
    "execute_sql(ex['db_id'], chatgpt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_res = evaluate_sql(evaluator, db_name=spider_ex['db_id'], gold=spider_ex['seq_out'], predicted=pred)\n",
    "# eval_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a765918a08614fbc982989ab115dc3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = []\n",
    "eval_sql_results = []\n",
    "\n",
    "for ex_id, ex in enumerate(tqdm(processed_spider_dev)):\n",
    "    pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "    eval_res = evaluate_sql(evaluator, db_name=ex['db_id'], gold=ex['seq_out'], predicted=pred)\n",
    "    \n",
    "    all_preds.append(pred)\n",
    "    eval_sql_results.append(eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6692456479690522, 0.6808510638297872)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no padding; identical!\n",
    "avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "avg_exact, avg_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = '/home/yshao/Projects/rome/results/clean_predictions'\n",
    "os.makedirs(res_dir, exist_ok=True)\n",
    "\n",
    "pred_path = os.path.join(res_dir, 'predictions.txt')\n",
    "eval_path = os.path.join(res_dir, 'evals.jsonl')\n",
    "\n",
    "with open(pred_path, 'w') as f:\n",
    "    for p in all_preds:\n",
    "        f.write(p + '\\n')\n",
    "\n",
    "with open(eval_path, 'w') as f:\n",
    "    for e in eval_sql_results:\n",
    "        f.write(json.dumps(e, indent=None) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6692456479690522, 0.6808510638297872)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding to 1024 \n",
    "avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "avg_exact, avg_exec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual error cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(eval_sql_results):\n",
    "    if d['exact'] and d['exec']:\n",
    "        continue\n",
    "    err_msg = ('A' if not d['exact'] else '') + ('X' if not d['exec'] else '')\n",
    "    ex = processed_spider_dev[i]\n",
    "    print(f'ID = {i}: {err_msg}  ({ex[\"db_id\"]}) {ex[\"text_in\"]}')\n",
    "    print(f'Pred: {d[\"predicted\"]}')\n",
    "    print(f'Gold: {d[\"gold\"]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator.schemas['dog_kennels'].schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc by db_id \n",
    "eval_sql_results_by_db_id = defaultdict(list)\n",
    "\n",
    "for i, d in enumerate(eval_sql_results):\n",
    "    d['ex_id'] = i\n",
    "    ex = processed_spider_dev[i]\n",
    "    db_id = ex['db_id']\n",
    "    eval_sql_results_by_db_id[db_id].append(d)\n",
    "\n",
    "len(eval_sql_results_by_db_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concert_singer\t0.8889\t0.8889\n",
      "pets_1\t0.5714\t0.7381\n",
      "car_1\t0.3478\t0.3913\n",
      "flight_2\t0.7000\t0.7500\n",
      "employee_hire_evaluation\t0.9474\t0.9737\n",
      "cre_Doc_Template_Mgt\t0.8333\t0.9048\n",
      "course_teach\t0.8667\t0.9333\n",
      "museum_visit\t0.7222\t0.8333\n",
      "wta_1\t0.6774\t0.6129\n",
      "battle_death\t0.5000\t0.5000\n",
      "student_transcripts_tracking\t0.6667\t0.6795\n",
      "tvshow\t0.7258\t0.6613\n",
      "poker_player\t0.8750\t0.8750\n",
      "voter_1\t0.6000\t0.6667\n",
      "world_1\t0.5083\t0.4833\n",
      "orchestra\t0.8000\t0.8750\n",
      "network_1\t0.6250\t0.4643\n",
      "dog_kennels\t0.5854\t0.5976\n",
      "singer\t0.8667\t0.8667\n",
      "real_estate_properties\t0.5000\t0.5000\n"
     ]
    }
   ],
   "source": [
    "for db_id, results in eval_sql_results_by_db_id.items():\n",
    "    _avg_exact = np.mean([d['exact'] for d in results])\n",
    "    _avg_exec = np.mean([d['exec'] for d in results])\n",
    "    print(f'{db_id}\\t{_avg_exact:.4f}\\t{_avg_exec:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full SQL prediction with edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder attention (exp A1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_enc_self_attention_mask_for_section_pair(\n",
    "    ex,\n",
    "    q_sect,\n",
    "    k_sect,\n",
    "    seq_len=None,\n",
    "    mt=None,\n",
    "    prefix_len=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    For attention-related experiments: build encoder self-attention masks for a section pair\n",
    "\n",
    "    Args:\n",
    "    a_ex (Dict)\n",
    "    q_sect (str)\n",
    "    k_sect (str)\n",
    "    seq_len (int): sequence length\n",
    "    prefix_len (int): prefix length\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    enc_sentence = ex['enc_sentence']\n",
    "\n",
    "    text_range = ex['text_range']\n",
    "    struct_range = ex['struct_range']\n",
    "    text_st, text_ed = text_range\n",
    "    struct_st, struct_ed = struct_range\n",
    "    # text_tok_indices = list(range(*text_range))\n",
    "    # struct_tok_indices = list(range(*struct_range))\n",
    "    \n",
    "    token_ranges_dict = ex['struct_node_ranges_dict']\n",
    "\n",
    "    if seq_len is None:\n",
    "        # need to tokenize and decide seq_len\n",
    "        assert mt is not None\n",
    "        _tok_ids = mt.tokenizer.encode(enc_sentence, add_special_tokens=True)\n",
    "        seq_len = len(_tok_ids)\n",
    "\n",
    "    # seq_len should include EOS, while struct shouldn't \n",
    "    assert seq_len == struct_ed + 1, (seq_len, struct_ed)\n",
    "    \n",
    "    ## Config for each section\n",
    "    ## 'is_range': whether the section is a single range \n",
    "    ## 'pos': if is_range, a tuple for the range; otherwise, a list of indices \n",
    "    ## Note: not including \"self\" and \"context\" sect for now; they don't fit into this config format \n",
    "    section_configs = {\n",
    "        'text': {\n",
    "            'is_range': True,\n",
    "            'q_pos': (text_st, text_ed),\n",
    "            'k_pos': (text_st + prefix_len, text_ed + prefix_len),\n",
    "        },\n",
    "        'struct': {\n",
    "            'is_range': True,\n",
    "            'q_pos': (struct_st, struct_ed),\n",
    "            'k_pos': (struct_st + prefix_len, struct_ed + prefix_len),\n",
    "        },\n",
    "        'prefix': {\n",
    "            'is_range': True,\n",
    "            'q_pos': None,  # prefix does not have q \n",
    "            'k_pos': (0, prefix_len),\n",
    "        },\n",
    "        'eos': {\n",
    "            'is_range': True,\n",
    "            'q_pos': (seq_len - 1, seq_len),\n",
    "            'k_pos': (seq_len + prefix_len - 1, seq_len + prefix_len),\n",
    "        },\n",
    "        'all': {\n",
    "            'is_range': True,\n",
    "            'q_pos': (0, seq_len),\n",
    "            'k_pos': (0, seq_len + prefix_len),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # mix_mask: (batch, head, src_len, tgt_len)\n",
    "    mix_mask = torch.zeros(1, 1, seq_len, seq_len + prefix_len).bool()\n",
    "    \n",
    "    if q_sect == 'self':\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        q_config = section_configs[q_sect]\n",
    "        k_config = section_configs[k_sect]\n",
    "        \n",
    "        # For now, all config is range \n",
    "        assert q_config['is_range'] and k_config['is_range']\n",
    "        \n",
    "        q_st, q_ed = q_config['q_pos']\n",
    "        k_st, k_ed = k_config['k_pos']\n",
    "        \n",
    "        mix_mask[:, :, q_st : q_ed, k_st : k_ed] = True\n",
    "    \n",
    "    return mix_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def add_enc_attention_edit(mt, ex, mix_layers, section_pairs, attn_corrupt_type='weights'):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        mix_layers: List[int], the layers to edit\n",
    "        section_pairs: List[Tuple(str, str)]: corrupting attention from which to which\n",
    "            sections: \"text\", \"struct\", \"prefix\", \"eos\"; \"self\", \"context\"\n",
    "            (notice that \"self\" is per-node; \"context->context\" is invalid here)\n",
    "        attn_corrupt_type: (same as trace exp) weights / logits \n",
    "    \"\"\"\n",
    "    \n",
    "    ## Code to be executed when entering the context\n",
    "    \n",
    "    ex = copy.deepcopy(ex)\n",
    "    \n",
    "    text_in = ex['text_in']\n",
    "    struct_in = ex['struct_in']\n",
    "\n",
    "    enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "    enc_tokenized = mt.tokenizer(enc_sentence)\n",
    "    ex['enc_sentence'] = enc_sentence\n",
    "    ex['enc_tokenized'] = enc_tokenized\n",
    "    \n",
    "    parsed_struct_in = ctu.parse_struct_in(struct_in)\n",
    "    \n",
    "    token_ranges_dict = ctu.find_struct_name_ranges(mt.tokenizer, ex)\n",
    "    text_range = ex['text_range']\n",
    "    struct_range = ex['struct_range']\n",
    "    # token_ranges_dict = ex['struct_node_ranges_dict']\n",
    "\n",
    "    all_mix_masks = [build_enc_self_attention_mask_for_section_pair(\n",
    "            ex,\n",
    "            q_sect,\n",
    "            k_sect,\n",
    "            mt=mt) for q_sect, k_sect in section_pairs]\n",
    "    \n",
    "    mix_mask = torch.logical_or(*all_mix_masks) if len(all_mix_masks) > 1 else all_mix_masks[0]\n",
    "    \n",
    "    def _attn_w_fn(attn):\n",
    "        _mix_mask = mix_mask.to(device=attn.device)\n",
    "        _zero = torch.tensor(0, dtype=attn.dtype, device=attn.device)\n",
    "        attn = torch.where(_mix_mask, _zero, attn)     # no need to keep batch_idx=0 clean here\n",
    "        return attn\n",
    "\n",
    "    def _attn_lg_fn(attn):\n",
    "        _mix_mask = mix_mask.to(device=attn.device)\n",
    "        _neg = torch.tensor(-1e9, dtype=attn.dtype, device=attn.device)\n",
    "        attn = torch.where(_mix_mask, _neg, attn)\n",
    "        return attn\n",
    "\n",
    "#     def p_hook_fn(m, inp):\n",
    "#         if attn_corrupt_type == 'weights':\n",
    "#             m.ext_attention_weights_fn = _attn_w_fn\n",
    "#         elif attn_corrupt_type == 'logits':\n",
    "#             m.ext_attention_logits_fn = _attn_lg_fn\n",
    "#         else:\n",
    "#             raise ValueError(attn_corrupt_type)\n",
    "\n",
    "#     def f_hook_fn(m, inp, outp):\n",
    "#         m.ext_attention_weights_fn = None\n",
    "#         m.ext_attention_logits_fn = None\n",
    "\n",
    "#     all_hooks = []\n",
    "\n",
    "    edit_module_list = [nethook.get_module(mt.model, layer) for layer in mix_layers]\n",
    "    for m in edit_module_list:\n",
    "        if attn_corrupt_type == 'weights':\n",
    "            m.ext_attention_weights_fn = _attn_w_fn\n",
    "        elif attn_corrupt_type == 'logits':\n",
    "            m.ext_attention_logits_fn = _attn_lg_fn\n",
    "\n",
    "    try:\n",
    "        ## You can yield any object that will be bound to the variable after 'as' in 'with' statement\n",
    "        yield\n",
    "        \n",
    "    finally:\n",
    "        ## Code to be executed when exiting the context\n",
    "        for m in edit_module_list:\n",
    "            m.ext_attention_weights_fn = None\n",
    "            m.ext_attention_logits_fn = None\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_0_result_dir = '/home/yshao/Projects/rome/results/exp_A1_0_enc_attention_removal_eval'\n",
    "os.makedirs(a1_0_result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running for all configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Current exp: A1.0.1 (attn_corrupt_type=logits)\n",
    "\n",
    "# layer_k -> layer range \n",
    "layer_configs = {\n",
    "#     'low': range(12),\n",
    "    'mid': range(6, 18),\n",
    "    'high': range(12, 24),\n",
    "#     'all': range(24),\n",
    "}\n",
    "\n",
    "# sect_k -> section pairs\n",
    "sect_configs = {\n",
    "    's->t': [('struct', 'text')],\n",
    "    't->s': [('text', 'struct')],\n",
    "    't<->s': [('struct', 'text'), ('text', 'struct')],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06e7d344c274dce856d3295debf9599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = mid, Sect = s->t : Exact = 0.5019, Exec = 0.5184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ef2a5328d14bf2b09a742f100a79a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = mid, Sect = t->s : Exact = 0.6451, Exec = 0.6586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22cc3c194f64c719b648030b0a2fc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = mid, Sect = t<->s : Exact = 0.4294, Exec = 0.4468\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648bb186aada4fd395ac55e383dd832f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = high, Sect = s->t : Exact = 0.4072, Exec = 0.4362\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e620e30e5147909770407bf1367436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = high, Sect = t->s : Exact = 0.6151, Exec = 0.6412\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86941ea5f20d479daf69a7107915fa2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = high, Sect = t<->s : Exact = 0.3250, Exec = 0.3559\n"
     ]
    }
   ],
   "source": [
    "for layer_k, layer_range in layer_configs.items():\n",
    "    for sect_k, section_pairs in sect_configs.items():\n",
    "        mix_layers = [ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') for l in layer_range]\n",
    "\n",
    "        all_preds = []\n",
    "        eval_sql_results = []\n",
    "\n",
    "        for ex_id, ex in enumerate(tqdm(processed_spider_dev)):\n",
    "            with add_enc_attention_edit(mt=mt_uskg,\n",
    "                                    ex=ex,\n",
    "                                    mix_layers=mix_layers,\n",
    "                                    section_pairs=section_pairs,\n",
    "                                    attn_corrupt_type='logits'):\n",
    "                pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "\n",
    "            eval_res = evaluate_sql(evaluator, db_name=ex['db_id'], gold=ex['seq_out'], predicted=pred)\n",
    "\n",
    "            all_preds.append(pred)\n",
    "            eval_sql_results.append(eval_res)\n",
    "        \n",
    "        avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "        avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "        print(f'Layer = {layer_k}, Sect = {sect_k} : Exact = {avg_exact:.4f}, Exec = {avg_exec:.4f}')\n",
    "        \n",
    "        pred_path = os.path.join(a1_0_result_dir, f'exp=A1.0.1_dev_predictions-layer={layer_k}-sect={sect_k}.txt')\n",
    "        eval_path = os.path.join(a1_0_result_dir, f'exp=A1.0.1_dev_evals-layer={layer_k}-sect={sect_k}.jsonl')\n",
    "\n",
    "        with open(pred_path, 'w') as f:\n",
    "            for p in all_preds:\n",
    "                f.write(p + '\\n')\n",
    "\n",
    "        with open(eval_path, 'w') as f:\n",
    "            for e in eval_sql_results:\n",
    "                f.write(json.dumps(e, indent=None) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder cross attention (exp A1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dec_cross_attention_mask_for_section(\n",
    "    ex,\n",
    "    k_sect,\n",
    "    seq_len=None,\n",
    "    mt=None,\n",
    "    prefix_len=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    For attention-related experiments: build decoder cross-attention mask for an input section, block all-step X-att to this section \n",
    "    The q dimension is set to 1; in edit fn, it will be broadcasted to the correct size\n",
    "\n",
    "    Args:\n",
    "    a_ex (Dict)\n",
    "    k_sect (str)\n",
    "    seq_len (int): sequence length\n",
    "    prefix_len (int): prefix length\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    enc_sentence = ex['enc_sentence']\n",
    "\n",
    "    text_range = ex['text_range']\n",
    "    struct_range = ex['struct_range']\n",
    "    text_st, text_ed = text_range\n",
    "    struct_st, struct_ed = struct_range\n",
    "    # text_tok_indices = list(range(*text_range))\n",
    "    # struct_tok_indices = list(range(*struct_range))\n",
    "    \n",
    "    token_ranges_dict = ex['struct_node_ranges_dict']\n",
    "\n",
    "    if seq_len is None:\n",
    "        # need to tokenize and decide seq_len\n",
    "        assert mt is not None\n",
    "        _tok_ids = mt.tokenizer.encode(enc_sentence, add_special_tokens=True)\n",
    "        seq_len = len(_tok_ids)\n",
    "\n",
    "    # seq_len should include EOS, while struct shouldn't \n",
    "    assert seq_len == struct_ed + 1, (seq_len, struct_ed)\n",
    "    \n",
    "    ## Config for each section\n",
    "    ## 'is_range': whether the section is a single range \n",
    "    ## 'pos': if is_range, a tuple for the range; otherwise, a list of indices \n",
    "    ## Note: not including \"self\" and \"context\" sect for now; they don't fit into this config format \n",
    "    section_configs = {\n",
    "        'text': {\n",
    "            'is_range': True,\n",
    "            'k_pos': (text_st + prefix_len, text_ed + prefix_len),\n",
    "        },\n",
    "        'struct': {\n",
    "            'is_range': True,\n",
    "            'k_pos': (struct_st + prefix_len, struct_ed + prefix_len),\n",
    "        },\n",
    "        'prefix': {\n",
    "            'is_range': True,\n",
    "            'k_pos': (0, prefix_len),\n",
    "        },\n",
    "        'others': {\n",
    "            'is_range': False,\n",
    "            'k_pos': list(range(text_ed + prefix_len, struct_st + prefix_len)) + list(range(seq_len + prefix_len - 1, seq_len + prefix_len)),\n",
    "        },\n",
    "        'all': {\n",
    "            'is_range': True,\n",
    "            'k_pos': (0, seq_len + prefix_len),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # mix_mask: (batch, head, src_len, tgt_len)\n",
    "    mix_mask = torch.zeros(1, 1, 1, seq_len + prefix_len).bool()\n",
    "    \n",
    "    k_config = section_configs[k_sect]\n",
    "\n",
    "    if k_config['is_range']:\n",
    "        k_st, k_ed = k_config['k_pos']\n",
    "        mix_mask[:, :, :, k_st : k_ed] = True\n",
    "    else:\n",
    "        k_toks = k_config['k_pos']\n",
    "        mix_mask[:, :, :, k_toks] = True\n",
    "    \n",
    "    return mix_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def add_dec_cross_attention_edit(mt, ex, mix_layers, sections, attn_corrupt_type='weights'):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        mix_layers: List[int], the layers to edit\n",
    "        section: List[str]: corrupting attention from decoder to which sections\n",
    "            sections: \"text\", \"struct\", \"prefix\", \"others\"; \"self\", \"context\" (not implemented)\n",
    "            (notice that \"self\" is per-node; \"context->context\" is invalid here)\n",
    "        attn_corrupt_type: (same as trace exp) weights / logits \n",
    "    \"\"\"\n",
    "    \n",
    "    ## Code to be executed when entering the context\n",
    "    \n",
    "    ex = copy.deepcopy(ex)\n",
    "    \n",
    "    text_in = ex['text_in']\n",
    "    struct_in = ex['struct_in']\n",
    "\n",
    "    enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "    enc_tokenized = mt.tokenizer(enc_sentence)\n",
    "    ex['enc_sentence'] = enc_sentence\n",
    "    ex['enc_tokenized'] = enc_tokenized\n",
    "    \n",
    "    parsed_struct_in = ctu.parse_struct_in(struct_in)\n",
    "    \n",
    "    token_ranges_dict = ctu.find_struct_name_ranges(mt.tokenizer, ex)\n",
    "    text_range = ex['text_range']\n",
    "    struct_range = ex['struct_range']\n",
    "    # token_ranges_dict = ex['struct_node_ranges_dict']\n",
    "\n",
    "    all_mix_masks = [build_dec_cross_attention_mask_for_section(\n",
    "            ex,\n",
    "            k_sect,\n",
    "            mt=mt) for k_sect in sections]\n",
    "    \n",
    "    mix_mask = torch.logical_or(*all_mix_masks) if len(all_mix_masks) > 1 else all_mix_masks[0]\n",
    "    # print(mix_mask)\n",
    "    \n",
    "    def _attn_w_fn(attn):\n",
    "        _mix_mask = mix_mask.to(device=attn.device)\n",
    "        _zero = torch.tensor(0, dtype=attn.dtype, device=attn.device)\n",
    "        attn = torch.where(_mix_mask, _zero, attn)     # no need to keep batch_idx=0 clean here\n",
    "        return attn\n",
    "\n",
    "    def _attn_lg_fn(attn):\n",
    "        _mix_mask = mix_mask.to(device=attn.device)\n",
    "        _neg = torch.tensor(-1e9, dtype=attn.dtype, device=attn.device)\n",
    "        attn = torch.where(_mix_mask, _neg, attn)\n",
    "        return attn\n",
    "\n",
    "#     def p_hook_fn(m, inp):\n",
    "#         if attn_corrupt_type == 'weights':\n",
    "#             m.ext_attention_weights_fn = _attn_w_fn\n",
    "#         elif attn_corrupt_type == 'logits':\n",
    "#             m.ext_attention_logits_fn = _attn_lg_fn\n",
    "#         else:\n",
    "#             raise ValueError(attn_corrupt_type)\n",
    "\n",
    "#     def f_hook_fn(m, inp, outp):\n",
    "#         m.ext_attention_weights_fn = None\n",
    "#         m.ext_attention_logits_fn = None\n",
    "\n",
    "#     all_hooks = []\n",
    "\n",
    "    edit_module_list = [nethook.get_module(mt.model, layer) for layer in mix_layers]\n",
    "    for m in edit_module_list:\n",
    "        if attn_corrupt_type == 'weights':\n",
    "            m.ext_attention_weights_fn = _attn_w_fn\n",
    "        elif attn_corrupt_type == 'logits':\n",
    "            m.ext_attention_logits_fn = _attn_lg_fn\n",
    "\n",
    "    try:\n",
    "        ## You can yield any object that will be bound to the variable after 'as' in 'with' statement\n",
    "        yield\n",
    "        \n",
    "    finally:\n",
    "        ## Code to be executed when exiting the context\n",
    "        for m in edit_module_list:\n",
    "            m.ext_attention_weights_fn = None\n",
    "            m.ext_attention_logits_fn = None\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_1_result_dir = '/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval'\n",
    "os.makedirs(a1_1_result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running for all configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Current exp: A1.1.0 (attn_corrupt_type=weights); A1.1.1 (attn_corrupt_type=logits);\n",
    "\n",
    "# layer_k -> layer range \n",
    "layer_configs = {\n",
    "    'low': range(12),\n",
    "    'mid': range(6, 18),\n",
    "    'high': range(12, 24),\n",
    "    'all': range(24),\n",
    "}\n",
    "\n",
    "# sect_k -> section pairs\n",
    "sect_configs = {\n",
    "    'text': ['text'],\n",
    "    'struct': ['struct'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89feb73a54c4e07a69e21ad5d4e3c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = all, Sect = text : Exact = 0.0996, Exec = 0.1015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53d05757a73416dac734dcd7da012c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = all, Sect = struct : Exact = 0.0010, Exec = 0.0010\n"
     ]
    }
   ],
   "source": [
    "for layer_k, layer_range in layer_configs.items():\n",
    "    for sect_k, sections in sect_configs.items():\n",
    "        mix_layers = [ctu.layername_uskg(mt_uskg.model, 'decoder', l, 'cross_attn') for l in layer_range]\n",
    "\n",
    "        all_preds = []\n",
    "        eval_sql_results = []\n",
    "\n",
    "        for ex_id, ex in enumerate(tqdm(processed_spider_dev)):\n",
    "            with add_dec_cross_attention_edit(mt=mt_uskg,\n",
    "                                            ex=ex,\n",
    "                                            mix_layers=mix_layers,\n",
    "                                            sections=sections,\n",
    "                                            attn_corrupt_type='weights'):\n",
    "                pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "\n",
    "            eval_res = evaluate_sql(evaluator, db_name=ex['db_id'], gold=ex['seq_out'], predicted=pred)\n",
    "\n",
    "            all_preds.append(pred)\n",
    "            eval_sql_results.append(eval_res)\n",
    "        \n",
    "        avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "        avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "        print(f'Layer = {layer_k}, Sect = {sect_k} : Exact = {avg_exact:.4f}, Exec = {avg_exec:.4f}')\n",
    "        \n",
    "        pred_path = os.path.join(a1_1_result_dir, f'exp=A1.1.0_dev_predictions-layer={layer_k}-sect={sect_k}.txt')\n",
    "        eval_path = os.path.join(a1_1_result_dir, f'exp=A1.1.0_dev_evals-layer={layer_k}-sect={sect_k}.jsonl')\n",
    "\n",
    "        with open(pred_path, 'w') as f:\n",
    "            for p in all_preds:\n",
    "                f.write(p + '\\n')\n",
    "\n",
    "        with open(eval_path, 'w') as f:\n",
    "            for e in eval_sql_results:\n",
    "                f.write(json.dumps(e, indent=None) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76dd594921049c8b631408c9be40bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = low, Sect = text : Exact = 0.4400, Exec = 0.4700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74705ecef3e84208a668c740401677d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = low, Sect = struct : Exact = 0.2592, Exec = 0.2679\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa601990f4a448a847010e9766987f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = mid, Sect = text : Exact = 0.1818, Exec = 0.2002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbfec44615144dcabc6873de5c9d6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = mid, Sect = struct : Exact = 0.2147, Exec = 0.2128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef16df11e53b4b35b2ec04db73b489dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = high, Sect = text : Exact = 0.3994, Exec = 0.3627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a1b06d206e416ba7b54edd09f4a1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = high, Sect = struct : Exact = 0.1015, Exec = 0.1044\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ac3211848d40419a157ce71041f36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = all, Sect = text : Exact = 0.0706, Exec = 0.0812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00a29fe1ccf4f169326e40b971c54c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = all, Sect = struct : Exact = 0.0648, Exec = 0.0638\n"
     ]
    }
   ],
   "source": [
    "for layer_k, layer_range in layer_configs.items():\n",
    "    for sect_k, sections in sect_configs.items():\n",
    "        mix_layers = [ctu.layername_uskg(mt_uskg.model, 'decoder', l, 'cross_attn') for l in layer_range]\n",
    "\n",
    "        all_preds = []\n",
    "        eval_sql_results = []\n",
    "\n",
    "        for ex_id, ex in enumerate(tqdm(processed_spider_dev)):\n",
    "            with add_dec_cross_attention_edit(mt=mt_uskg,\n",
    "                                            ex=ex,\n",
    "                                            mix_layers=mix_layers,\n",
    "                                            sections=sections,\n",
    "                                            attn_corrupt_type='logits'):\n",
    "                pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "\n",
    "            eval_res = evaluate_sql(evaluator, db_name=ex['db_id'], gold=ex['seq_out'], predicted=pred)\n",
    "\n",
    "            all_preds.append(pred)\n",
    "            eval_sql_results.append(eval_res)\n",
    "        \n",
    "        avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "        avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "        print(f'Layer = {layer_k}, Sect = {sect_k} : Exact = {avg_exact:.4f}, Exec = {avg_exec:.4f}')\n",
    "        \n",
    "        pred_path = os.path.join(a1_1_result_dir, f'exp=A1.1.1_dev_predictions-layer={layer_k}-sect={sect_k}.txt')\n",
    "        eval_path = os.path.join(a1_1_result_dir, f'exp=A1.1.1_dev_evals-layer={layer_k}-sect={sect_k}.jsonl')\n",
    "\n",
    "        with open(pred_path, 'w') as f:\n",
    "            for p in all_preds:\n",
    "                f.write(p + '\\n')\n",
    "\n",
    "        with open(eval_path, 'w') as f:\n",
    "            for e in eval_sql_results:\n",
    "                f.write(json.dumps(e, indent=None) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder self attention (exp A1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def add_dec_self_attention_edit(mt, ex, mix_layers, attn_corrupt_type='weights'):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        mix_layers: List[int], the layers to edit. Different from other attentions, here is no \"sections\"\n",
    "            so no masks, we just corrupt all attention weights \n",
    "        attn_corrupt_type: (same as trace exp) weights / logits \n",
    "    \"\"\"\n",
    "    \n",
    "    ## Code to be executed when entering the context\n",
    "    \n",
    "    ex = copy.deepcopy(ex)\n",
    "    \n",
    "    text_in = ex['text_in']\n",
    "    struct_in = ex['struct_in']\n",
    "\n",
    "    enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "    enc_tokenized = mt.tokenizer(enc_sentence)\n",
    "    ex['enc_sentence'] = enc_sentence\n",
    "    ex['enc_tokenized'] = enc_tokenized\n",
    "    \n",
    "    parsed_struct_in = ctu.parse_struct_in(struct_in)\n",
    "    \n",
    "    token_ranges_dict = ctu.find_struct_name_ranges(mt.tokenizer, ex)\n",
    "    text_range = ex['text_range']\n",
    "    struct_range = ex['struct_range']\n",
    "    # token_ranges_dict = ex['struct_node_ranges_dict']\n",
    "\n",
    "    # all_mix_masks = [build_dec_cross_attention_mask_for_section(\n",
    "    #         ex,\n",
    "    #         k_sect,\n",
    "    #         mt=mt) for k_sect in sections]\n",
    "\n",
    "    # mix_mask = torch.logical_or(*all_mix_masks) if len(all_mix_masks) > 1 else all_mix_masks[0]\n",
    "    # print(mix_mask)\n",
    "    \n",
    "    def _attn_w_fn(attn):\n",
    "        _zero = torch.zeros_like(attn)\n",
    "        return _zero\n",
    "\n",
    "    def _attn_lg_fn(attn):\n",
    "        _neg = torch.full_like(attn, -1e9)\n",
    "        return _neg\n",
    "\n",
    "#     def p_hook_fn(m, inp):\n",
    "#         if attn_corrupt_type == 'weights':\n",
    "#             m.ext_attention_weights_fn = _attn_w_fn\n",
    "#         elif attn_corrupt_type == 'logits':\n",
    "#             m.ext_attention_logits_fn = _attn_lg_fn\n",
    "#         else:\n",
    "#             raise ValueError(attn_corrupt_type)\n",
    "\n",
    "#     def f_hook_fn(m, inp, outp):\n",
    "#         m.ext_attention_weights_fn = None\n",
    "#         m.ext_attention_logits_fn = None\n",
    "\n",
    "#     all_hooks = []\n",
    "\n",
    "    edit_module_list = [nethook.get_module(mt.model, layer) for layer in mix_layers]\n",
    "    for m in edit_module_list:\n",
    "        if attn_corrupt_type == 'weights':\n",
    "            m.ext_attention_weights_fn = _attn_w_fn\n",
    "        elif attn_corrupt_type == 'logits':\n",
    "            m.ext_attention_logits_fn = _attn_lg_fn\n",
    "\n",
    "    try:\n",
    "        ## You can yield any object that will be bound to the variable after 'as' in 'with' statement\n",
    "        yield\n",
    "        \n",
    "    finally:\n",
    "        ## Code to be executed when exiting the context\n",
    "        for m in edit_module_list:\n",
    "            m.ext_attention_weights_fn = None\n",
    "            m.ext_attention_logits_fn = None\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_2_result_dir = '/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval'\n",
    "os.makedirs(a1_2_result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running for all configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Current exp: A1.2.0 (attn_corrupt_type=weights); A1.2.1 (attn_corrupt_type=logits, not making much sense, TODO later)\n",
    "\n",
    "# layer_k -> layer range \n",
    "layer_configs = {\n",
    "    'low_3': range(3),\n",
    "    'mid_3': range(11, 14),\n",
    "    'high_3': range(21, 24),\n",
    "    'low': range(12),\n",
    "    'mid': range(6, 18),\n",
    "    'high': range(12, 24),\n",
    "    'all': range(24),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8d1631e22043ff857647174d1fb1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = low_3 : Exact = 0.5977, Exec = 0.6064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8d020e5ba0484eb16c0b00e48079fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = mid_3 : Exact = 0.6151, Exec = 0.6199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afc23d567ba4769b00acb599e012b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = high_3 : Exact = 0.6248, Exec = 0.6373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52592bf070684232a545b26379727520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = low : Exact = 0.0416, Exec = 0.0329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035d36b0893d486eb7c4dee3638fe114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = mid : Exact = 0.0696, Exec = 0.0841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39bed03df124c9aa056aa5ea16456e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = high : Exact = 0.2089, Exec = 0.2157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e766cd835c40e2bda6611a897a23bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = all : Exact = 0.0000, Exec = 0.0000\n"
     ]
    }
   ],
   "source": [
    "for layer_k, layer_range in layer_configs.items():\n",
    "    mix_layers = [ctu.layername_uskg(mt_uskg.model, 'decoder', l, 'self_attn') for l in layer_range]\n",
    "\n",
    "    all_preds = []\n",
    "    eval_sql_results = []\n",
    "\n",
    "    for ex_id, ex in enumerate(tqdm(processed_spider_dev)):\n",
    "        with add_dec_self_attention_edit(mt=mt_uskg,\n",
    "                                        ex=ex,\n",
    "                                        mix_layers=mix_layers,\n",
    "                                        attn_corrupt_type='weights'):\n",
    "            pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "\n",
    "        eval_res = evaluate_sql(evaluator, db_name=ex['db_id'], gold=ex['seq_out'], predicted=pred)\n",
    "\n",
    "        all_preds.append(pred)\n",
    "        eval_sql_results.append(eval_res)\n",
    "\n",
    "    avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "    avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "    print(f'Layer = {layer_k} : Exact = {avg_exact:.4f}, Exec = {avg_exec:.4f}')\n",
    "\n",
    "    pred_path = os.path.join(a1_2_result_dir, f'exp=A1.2.0_dev_predictions-layer={layer_k}.txt')\n",
    "    eval_path = os.path.join(a1_2_result_dir, f'exp=A1.2.0_dev_evals-layer={layer_k}.jsonl')\n",
    "\n",
    "    with open(pred_path, 'w') as f:\n",
    "        for p in all_preds:\n",
    "            f.write(p + '\\n')\n",
    "\n",
    "    with open(eval_path, 'w') as f:\n",
    "        for e in eval_sql_results:\n",
    "            f.write(json.dumps(e, indent=None) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_k = 'all'\n",
    "sect_k = 's->t'\n",
    "\n",
    "eval_path = f'/home/yshao/Projects/rome/results/exp_A1_0_enc_attention_removal_eval/exp=A1.0.0_dev_evals-layer={layer_k}-sect={sect_k}.jsonl'\n",
    "# eval_path = f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.0_dev_evals-layer={layer_k}-sect={sect_k}.jsonl'\n",
    "# eval_path = f'/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval/exp=A1.2.0_dev_evals-layer={layer_k}.jsonl'\n",
    "\n",
    "with open(eval_path, 'r') as f:\n",
    "    eval_results = [json.loads(l) for l in f]\n",
    "len(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = all, Sect = s->t : Exact = 0.5145, Exec = 0.5387\n"
     ]
    }
   ],
   "source": [
    "avg_exact = np.mean([d['exact'] for d in eval_results])\n",
    "avg_exec = np.mean([d['exec'] for d in eval_results])\n",
    "print(f'Layer = {layer_k}, Sect = {sect_k} : Exact = {avg_exact:.4f}, Exec = {avg_exec:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1034, 1034)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_k = 'high'\n",
    "sect_k = None\n",
    "\n",
    "# eval_path = f'/home/yshao/Projects/rome/results/exp_A1_0_enc_attention_removal_eval/exp=A1.0.0_dev_evals-layer={layer_k}-sect={sect_k}.jsonl'\n",
    "# eval_path = f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.0_dev_evals-layer={layer_k}-sect={sect_k}.jsonl'\n",
    "eval_path = f'/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval/exp=A1.2.0_dev_evals-layer={layer_k}.jsonl'\n",
    "\n",
    "clean_eval_path = os.path.join(f'/home/yshao/Projects/rome/results/clean_predictions/evals.jsonl')\n",
    "\n",
    "with open(eval_path, 'r') as f:\n",
    "    eval_sql_results = [json.loads(l) for l in f]\n",
    "\n",
    "with open(clean_eval_path, 'r') as f:\n",
    "    clean_sql_results = [json.loads(l) for l in f]\n",
    "    \n",
    "len(eval_sql_results), len(clean_sql_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrupted wrong, clean right \n",
    "\n",
    "_tally = 0\n",
    "\n",
    "for i, (e_d, c_d) in enumerate(zip(eval_sql_results, clean_sql_results)):\n",
    "    assert e_d['gold'] == c_d['gold'], (e_d, c_d)\n",
    "    \n",
    "    if e_d['exact'] and e_d['exec']:\n",
    "        # corrupted pred is right \n",
    "        continue\n",
    "    if not (c_d['exact'] and c_d['exec']):\n",
    "        # clean pred is also wrong \n",
    "        continue\n",
    "        \n",
    "    ## Extra filtering \n",
    "    if not c_d['hardness'] == 'easy':\n",
    "        continue\n",
    "        \n",
    "    err_msg = ('A' if not e_d['exact'] else '') + ('X' if not e_d['exec'] else '')\n",
    "    ex = processed_spider_dev[i]\n",
    "    _tally += 1\n",
    "    print(f'#{_tally} (ID = {i}): {err_msg}  ({ex[\"db_id\"]}) {ex[\"text_in\"]} {ex[\"struct_in\"]}')\n",
    "    print(f'E-Pred: {e_d[\"predicted\"]}')\n",
    "    print(f'C-Pred: {c_d[\"predicted\"]}')\n",
    "    print(f'Gold: {e_d[\"gold\"]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrupted right, clean wrong \n",
    "\n",
    "_tally = 0\n",
    "\n",
    "for i, (e_d, c_d) in enumerate(zip(eval_sql_results, clean_sql_results)):\n",
    "    assert e_d['gold'] == c_d['gold'], (e_d, c_d)\n",
    "    \n",
    "    if c_d['exact'] and c_d['exec']:\n",
    "        # clean pred is right \n",
    "        continue\n",
    "    if not (e_d['exact'] and e_d['exec']):\n",
    "        # corrupted pred is wrong \n",
    "        continue\n",
    "        \n",
    "    err_msg = ('A' if not c_d['exact'] else '') + ('X' if not c_d['exec'] else '')\n",
    "    ex = processed_spider_dev[i]\n",
    "    _tally += 1\n",
    "    print(f'#{_tally} (ID = {i}): {err_msg}  ({ex[\"db_id\"]}) {ex[\"text_in\"]} {ex[\"struct_in\"]}')\n",
    "    print(f'E-Pred: {e_d[\"predicted\"]}')\n",
    "    print(f'C-Pred: {c_d[\"predicted\"]}')\n",
    "    print(f'Gold: {e_d[\"gold\"]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator.schemas['dog_kennels'].schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc by db_id \n",
    "eval_sql_results_by_db_id = defaultdict(list)\n",
    "\n",
    "for i, d in enumerate(eval_sql_results):\n",
    "    d['ex_id'] = i\n",
    "    ex = processed_spider_dev[i]\n",
    "    db_id = ex['db_id']\n",
    "    eval_sql_results_by_db_id[db_id].append(d)\n",
    "\n",
    "len(eval_sql_results_by_db_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concert_singer\t0.8889\t0.8889\n",
      "pets_1\t0.5714\t0.7381\n",
      "car_1\t0.3478\t0.3913\n",
      "flight_2\t0.7000\t0.7500\n",
      "employee_hire_evaluation\t0.9474\t0.9737\n",
      "cre_Doc_Template_Mgt\t0.8333\t0.9048\n",
      "course_teach\t0.8667\t0.9333\n",
      "museum_visit\t0.7222\t0.8333\n",
      "wta_1\t0.6774\t0.6129\n",
      "battle_death\t0.5000\t0.5000\n",
      "student_transcripts_tracking\t0.6667\t0.6795\n",
      "tvshow\t0.7258\t0.6613\n",
      "poker_player\t0.8750\t0.8750\n",
      "voter_1\t0.6000\t0.6667\n",
      "world_1\t0.5083\t0.4833\n",
      "orchestra\t0.8000\t0.8750\n",
      "network_1\t0.6250\t0.4643\n",
      "dog_kennels\t0.5854\t0.5976\n",
      "singer\t0.8667\t0.8667\n",
      "real_estate_properties\t0.5000\t0.5000\n"
     ]
    }
   ],
   "source": [
    "for db_id, results in eval_sql_results_by_db_id.items():\n",
    "    _avg_exact = np.mean([d['exact'] for d in results])\n",
    "    _avg_exec = np.mean([d['exec'] for d in results])\n",
    "    print(f'{db_id}\\t{_avg_exact:.4f}\\t{_avg_exec:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quant. error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_k = 'high'\n",
    "# sect_k = None\n",
    "\n",
    "# eval_paths_dict = {\n",
    "#     'low': f'/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval/exp=A1.2.0_dev_evals-layer=low.jsonl',\n",
    "#     'mid': f'/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval/exp=A1.2.0_dev_evals-layer=mid.jsonl',\n",
    "#     'high': f'/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval/exp=A1.2.0_dev_evals-layer=high.jsonl',\n",
    "#     'clean': f'/home/yshao/Projects/rome/results/clean_predictions/evals.jsonl',\n",
    "# }\n",
    "\n",
    "eval_paths_dict = {\n",
    "    'all-text': f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.1_dev_evals-layer=all-sect=text.jsonl',\n",
    "    'all-struct': f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.1_dev_evals-layer=all-sect=struct.jsonl',\n",
    "    'clean': f'/home/yshao/Projects/rome/results/clean_predictions/evals.jsonl',\n",
    "}\n",
    "\n",
    "eval_results_dict = dict()\n",
    "for k, p in eval_paths_dict.items():\n",
    "    with open(p, 'r') as f:\n",
    "        eval_results_dict[k] = [json.loads(l) for l in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('all-text', 1034), ('all-struct', 1034), ('clean', 1034)]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, len(eval_results_dict[k])) for k in eval_results_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrupted wrong, clean right \n",
    "\n",
    "error_ids_dict = defaultdict(list)\n",
    "\n",
    "for i, c_d in enumerate(eval_results_dict['clean']):\n",
    "    if not (c_d['exact'] and c_d['exec']):\n",
    "        # clean pred is wrong \n",
    "        continue\n",
    "\n",
    "    ## Extra filtering \n",
    "    if not c_d['hardness'] == 'easy':\n",
    "        continue\n",
    "            \n",
    "    for k in eval_results_dict.keys():\n",
    "        if k == 'clean':\n",
    "            continue\n",
    "            \n",
    "        e_d = eval_results_dict[k][i]\n",
    "        assert e_d['gold'] == c_d['gold'], (e_d, c_d)\n",
    "\n",
    "        if e_d['exact'] and e_d['exec']:\n",
    "            # corrupted pred is right \n",
    "            continue\n",
    "        \n",
    "        error_ids_dict[k].append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('all-text', 178), ('all-struct', 173)]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, len(error_ids_dict[k])) for k in error_ids_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_wrong_ids = set.intersection(\n",
    "    set(error_ids_dict['all-text']),\n",
    "    set(error_ids_dict['all-struct']),\n",
    "#     set(error_ids_dict['high']),\n",
    ")\n",
    "all_wrong_ids = sorted(list(all_wrong_ids))\n",
    "len(all_wrong_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_N = 50\n",
    "\n",
    "observe_ids = [all_wrong_ids[int(i)] for i in np.linspace(0, len(all_wrong_ids) - 1, ob_N)]\n",
    "\n",
    "# observe_ids_path = f'/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval/exp=A1.2.0_dev-error_analysis-ob_ids.txt'\n",
    "# observe_ids_path = f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.0_dev-error_analysis-ob_ids.txt'\n",
    "observe_ids_path = f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.1_dev-error_analysis-ob_ids.txt'\n",
    "\n",
    "with open(observe_ids_path, 'w') as f:\n",
    "    for i in observe_ids:\n",
    "        f.write(f'{i}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe_ids_path = f'/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval/exp=A1.2.0_dev-error_analysis-ob_ids.txt'\n",
    "# observe_ids_path = f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.0_dev-error_analysis-ob_ids.txt'\n",
    "observe_ids_path = f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.1_dev-error_analysis-ob_ids.txt'\n",
    "\n",
    "with open(observe_ids_path, 'r') as f:\n",
    "    observe_ids = [int(l) for l in f]\n",
    "len(observe_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe_res_paths = {\n",
    "#     'low': f'/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval/exp=A1.2.0_dev-error_analysis-layer=low.jsonl',\n",
    "#     'mid': f'/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval/exp=A1.2.0_dev-error_analysis-layer=mid.jsonl',\n",
    "#     'high': f'/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval/exp=A1.2.0_dev-error_analysis-layer=high.jsonl',\n",
    "# }\n",
    "\n",
    "# observe_res_paths = {\n",
    "#     'all-text': f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.0_dev-error_analysis-layer=all-sect=text.txt',\n",
    "#     'all-struct': f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.0_dev-error_analysis-layer=all-sect=struct.txt',\n",
    "# }\n",
    "\n",
    "\n",
    "observe_res_paths = {\n",
    "    'all-text': f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.1_dev-error_analysis-layer=all-sect=text.txt',\n",
    "    'all-struct': f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.1_dev-error_analysis-layer=all-sect=struct.txt',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Human observation; if run and overwrite, back up the previous results!\n",
    "\n",
    "# for k, res_path in observe_res_paths.items():\n",
    "#     with open(res_path, 'w') as f:\n",
    "# #     if True:\n",
    "#         for idx in observe_ids:\n",
    "#             ex = processed_spider_dev[idx]\n",
    "#             c_d = eval_results_dict['clean'][idx]\n",
    "#             e_d = eval_results_dict[k][idx]\n",
    "            \n",
    "#             print(f'(ID = {idx}): ({ex[\"db_id\"]}) {ex[\"text_in\"]} {ex[\"struct_in\"]}')\n",
    "#             print(f'E-Pred: {e_d[\"predicted\"]}')\n",
    "#             print(f'Gold: {e_d[\"gold\"]}')\n",
    "#             print()\n",
    "            \n",
    "#             err_type = input('Error type:')\n",
    "#             dump_d = {\n",
    "#                 'ex_id': idx,\n",
    "#                 'hardness': c_d['hardness'],\n",
    "#                 'db_id': ex['db_id'],\n",
    "#                 'text_in': ex['text_in'],\n",
    "#                 'struct_in': ex['struct_in'],\n",
    "#                 'predicted': e_d['predicted'],\n",
    "#                 'gold': e_d['gold'],\n",
    "#                 'err_type': err_type,\n",
    "#             }\n",
    "            \n",
    "#             f.write(json.dumps(dump_d) + '\\n')\n",
    "            \n",
    "#             print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'S0': 'missing / wrong aggregator',\n",
    "    'S1': 'missing / wrong condition clause or ordering',\n",
    "    'S2': 'missing / wrong literal value',\n",
    "#     'S3': 'missing / wrong SELECT column',  # same as N1, put in N1 as it's node error \n",
    "    'J0': 'extra join, but still correct',\n",
    "    'J1': 'missing alias reference, may cause ambiguous-column error depending on the schema',\n",
    "    'N0': 'invalid (hallucinated) node name, either token or natural language phrases',\n",
    "    'N1': 'using \"*\" for an actual column',\n",
    "    'N2': 'valid but wrong node name (not including \"*\")'\n",
    "    'A0': 'low-level syntax - unpaired brackets / quotes',\n",
    "    'A1': 'low-level syntax - misspelled keyword',\n",
    "    'A2': 'low-level syntax - non-ending token',\n",
    "    'B0': 'clause-level syntax - missing / extra / misplaced / partial clauses (causing syntax error)',\n",
    "    'B2': 'clause-level syntax - alias error (t1 -> t1.col, t1 -> t1st, errors like this)',\n",
    "    'B3': 'clause-level syntax - missing / extra operator (causing syntax error)',\n",
    "    'C0': 'high-level error - natural language expression / values not quoted',\n",
    "    'C3': 'not really an error - has redundancy but is equivalent or also correct',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S0': 'missing / wrong aggregator',\n",
       " 'S1': 'missing / wrong condition clause or ordering',\n",
       " 'S2': 'missing / wrong literal value',\n",
       " 'J0': 'extra join, but still correct',\n",
       " 'J1': 'missing alias reference, may cause ambiguous-column error depending on the schema',\n",
       " 'N0': 'invalid (hallucinated) node name, either token or natural language phrases',\n",
       " 'N1': \"using '*' for an actual column\",\n",
       " 'N2': \"valid but wrong node name (not including '*')\",\n",
       " 'A0': 'low-level syntax - unpaired brackets / quotes',\n",
       " 'A1': 'low-level syntax - misspelled keyword',\n",
       " 'A2': 'low-level syntax - non-ending token',\n",
       " 'B0': 'clause-level syntax - missing / extra / misplaced / partial clauses (causing syntax error)',\n",
       " 'B2': 'clause-level syntax - alias error (t1 -> t1.col, t1 -> t1st, errors like this)',\n",
       " 'B3': 'clause-level syntax - missing / extra operator (causing syntax error)',\n",
       " 'C0': 'high-level error - natural language expression / values not quoted',\n",
       " 'C3': 'not really an error - has redundancy but is equivalent or also correct'}"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criteria_path = f'/home/yshao/Projects/rome/results/exp_A1_2_dec_self_attention_removal_eval/exp=A1.2.0_dev-error_analysis-criteria.json'\n",
    "criteria_path = f'/home/yshao/Projects/rome/results/exp_A1_1_dec_cross_attention_removal_eval/exp=A1.1.1_dev-error_analysis-criteria.json'\n",
    "\n",
    "with open(criteria_path, 'r') as f:\n",
    "    criteria_dict = json.load(f)\n",
    "criteria_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sect -> err_type -> cnt \n",
    "err_type_counters = defaultdict(Counter)\n",
    "err_htype_counters = defaultdict(Counter)   # high-level type (S/N/O(other))\n",
    "\n",
    "for sect_k, ob_path in observe_res_paths.items():\n",
    "    with open(ob_path, 'r') as f:\n",
    "        ob_results = [json.loads(l) for l in f]\n",
    "    for d in ob_results:\n",
    "        err_types = d['err_type'].split()\n",
    "        for _type in err_types:\n",
    "            err_type_counters[sect_k][_type] += 1\n",
    "        \n",
    "        htypes = list(set([_type[0] if (_type[0] in ('S', 'N')) else 'O'\n",
    "                           for _type in err_types]))   # 1st character\n",
    "        for _type in htypes:\n",
    "            err_htype_counters[sect_k][_type] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'all-text': Counter({'S': 46, 'N': 8, 'O': 2}),\n",
       "             'all-struct': Counter({'N': 47, 'O': 11})})"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_htype_counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXX\tS0    \tS1    \tS2    \tJ0    \tJ1    \tN0    \tN1    \tN2    \tA0    \tA1    \tA2    \tB0    \tB2    \tB3    \tC0    \tC3    \n",
      "all-text    \t31    \t21    \t1     \t0     \t1     \t0     \t6     \t2     \t0     \t0     \t0     \t0     \t0     \t0     \t0     \t1     \n",
      "all-struct  \t0     \t0     \t0     \t0     \t0     \t46    \t0     \t1     \t1     \t1     \t1     \t6     \t1     \t2     \t1     \t0     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_print_2D_dict(err_type_counters, all_k2=criteria_dict.keys(), decm_w=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'all-text': Counter({'S': 46, 'N': 8, 'O': 2}),\n",
       "             'all-struct': Counter({'N': 47, 'O': 11}),\n",
       "             'text': Counter(),\n",
       "             'struct': Counter()})"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_htype_counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting \n",
    "- from chatgpt, with modification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A1.2.0\n",
    "\n",
    "groups = ['low', 'mid', 'high']\n",
    "\n",
    "err_types = {\n",
    "    'A': \"Low-level syntax\",\n",
    "    'B': \"Clause-level syntax\",\n",
    "    'C': \"Semantic errors\",\n",
    "}\n",
    "values = [[err_htype_counters[group][err_type] for group in groups] for err_type in err_types.keys()]\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.25\n",
    "x = range(len(err_types))\n",
    "\n",
    "# Plot the bars for each group\n",
    "for i, (err_type, err_desc) in enumerate(err_types.items()):\n",
    "    ax.bar([pos + i * width for pos in x], values[i], width=width, label=err_desc)\n",
    "\n",
    "# Set labels and ticks\n",
    "ax.set_xticks([pos + width for pos in x])\n",
    "ax.set_xticklabels(groups)\n",
    "ax.set_ylim(top=50)\n",
    "ax.set_xlabel('Corrupting layer ranges')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Decoder self-attention corruption error types\\n')\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs('/home/yshao/Projects/rome/results/figs/exp-A1.2.0', exist_ok=True)\n",
    "# fig.savefig('/home/yshao/Projects/rome/results/figs/exp-A1.2.0/error_analysis-htypes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAwL0lEQVR4nO3dd3xV9f3H8dcnCYSEJUumgKIYUUQBUav+tCiKVXEgomKdiEKHFHDVhbaKVutAi4gTWgetVatUaOuugiJTwpA9ZAgyIiOMJJ/fH+dcvI0ZNyE3OcD7+XjcR878ns895+R+7jnne79fc3dERESiJqWqAxARESmKEpSIiESSEpSIiESSEpSIiESSEpSIiESSEpSIiETSXp+gzOw0M/smAnEsNbMzwmEzsxfNbKOZTa7q2BJhZuPN7KqqjqMqmVlLM9tiZqlVHYuI7EGCCj+Qc81ss5ltMrOJZnajme31Sa8CnAx0A1q4e5eyrmxmbmaHxo1XaBI2s6Fm9pf4ae5+truPrqht7A3iv1QAuPtyd6/l7vlVGVeyFD6vRKJuT5PJee5eG2gFPAjcCjy/x1FVEjNLS1LRrYCl7r41SeXvV4o6Tkk8dlWu8BVcWd/rvrxvZD/j7uV6AUuBMwpN6wIUAEeF4+nAI8By4FtgJJARt/z5wAzge2AR0D2c3gx4G9gALASuj1snA3gJ2AjMAW4Gvomb3wz4O7AOWAL8Om7eUOB14C/hNvsW8b5+Fpa7GVgJDImbd24Y7yZgInB04f0BXAdsB/KBLcC9RWyjCzApLGc18BRQPZz3CeDA1nD9q4DccL9uCV/NCL5c3Bbut/XAX4H6YRmtwzKuCvf9d8Ad4bzuwE5gV1jWzHD6R7H9EZZ9J7AMWAuMAeqWVnYx50kG8MewrBzg09g5APQAZof74SPgiEL781bgK2AHcGi43evC7X4CnBZ/7Aufl3HHe2x4PKcBHcJ5fw73aW64H26Je29pCZyHQ8N9PiYsezbQuYT9kAX8Jyzra+CSuHkvAU8D74bH/Ywi3n9aGfdXWqHtFz6vegPZBF8yY8tUC4/nsXH7oh+wiuA8jf9fKOn8q0HwP7Y+jPVLoHF5P2v02n9f5V+xiAQVTl8O9A+HHwv/wesDtYF3gGHhvC4EH1jdwpO9OZAVzvsEGBGe6McQJJuu4bwHgf+GZR4U/pN9E85LAaYCdwPVgUOAxcBZ4fyhBB/MF4TLZhQR/2rglHC4HtAxHD6W4MP6eCCV4AN6KZBeeH8AVwOflrDvOgEnhB86rYG5wMC4+Q4cGjd+Gj/+IL4J+BxoQfBF4Bng1XBe7MPlWYIE0YHgQ+uIuP3wl0LlfcQPCepagg/kQ4BawBvAnxMpu4j3+qew7ObhfvtJGG9bgg/LbgQfjLeE26wetz9nhMc4I267Y4Ca4bSi9kv8cYgd74vDbQwh+NJSrahzmB8nqJLOw6EEX0R+Fr6vYcDnxeyDmsAK4JrwmB9LkAjahfNfIvhfOIngvKxRxPsv0/4qJo7C59UtwNi48fOBWYX2xath/O3D9x/btyWdfzcQ/K9nhvumE1Cnqj/s9Nr7XuVfsfgE9TlwB2DhP1SbuHknAkvC4WeAx4pY/yCCq4/acdOGAS+Fw4sJr7TC8X78kKCOB5YXKu924MVweCjwSSnva3n4D1an0PSngd8VmvY1cGrh/UEpCaqIbQ4E3owbTyRBzQVOjxtvSvBhHEt6TvAMLDZ/MnBp3H4oKUG9DwyIm3d4omUXKjOF4AqlQxHz7gL+WmjZlcBpcfvz2rj5se0eUsp+iT8OQ4lLGuE24r+A7F620DbSKP08HAq8FzevHZBbzPHtDfy30LRngHvC4ZeAMUW8j/j3X6b9VUwchc+rZgRXf3XC8deBWwrti6y45f8APJ/A+Xcthe4w6KVXeV7JqNDQnOA2RiOCb1BTw0oUm4AJ4XQIPgAWFbF+M2CDu2+Om7YsLDc2f0WheTGtgGax7YXb/C3QOG6Z+HWL0pPgW/EyM/vYzE6MK3twobIPCuMplpn1CWuGbTGz8eG0tmY2zszWmNn3wANAw1LiKqwV8GZcLHMJPlDj3+uauOFtBFdDiWjG/+7XZQQfPGUtuyHB1UBxx3n3Nty9gODYNI9bpqhjVdrxK3b5cBvfUMoxi4uvpPMQfrwPahTz/KcVcHyhc6cP0KSoOIuZVt79VSx3XwV8BvQ0swOAs4GXS4hhGT/su5LOvz8D/wJeM7NVZvYHM6tWlthEoIKrmZvZcQT/MJ8S3MLIBY509wPCV113j32QrQDaFFHMKqC+mdWOm9aS4NsiBN+ADyo0L2YFwRXaAXGv2u7+s7hlvKT34O5fuvv5wIHAWwT31mNl31+o7Ex3f7WU8l72oGZYLXc/O5z8NDAPOMzd6xAkUSupmCKmrQDOLhRPDXdfWcSyiZQXbxXBB1BMSyCP4DliWXxHcBusuOO8extmZgTHNT7+ouKMn7aV4EtQrIxUfvgCFHNQ3PwUgltSq0ooPz6+ks7DslgBfFzoWNVy9/5xy5T2Xsu7v0ozGrgC6AVMKuL8Kfy/Ftt3xZ5/7r7L3e9193YEt3TPBa4sR2yyn6uQBGVmdczsXOA1gltHs8JveM8Cj5nZgeFyzc3srHC154FrzOx0M0sJ52W5+wqC2wPDzKyGmR1N8GA8Vi36r8DtZlbPzFoAv4oLZTKw2cxuNbMMM0s1s6PCxJnI+6geXvHUdfddBBUpCsLZzwI3mtnx4e+caprZOYU+wBJVOyx7i5llAf0Lzf+W4PlP/HgDM6sbN20kcL+ZtQpjb2Rm5ye4/W+B1iX8JOBV4DdmdrCZ1SK4whvr7nkJlg/s/pb/AvComTULj8eJZpZOcBzPCY9/NWAwwbOsiWXYxHyCq5ZzwjLuJHgeEq+TmV0UXtkMDLfxeTiv8H6Oj72087AsxgFtzeznZlYtfB1nZkeUoYyK2F9Fvd+3gI4Ez5TGFLHOXWaWaWZHEjxDGxtOL/b8M7Ofmln78AvD9wS3/gqKKFukRHuaoN4xs80E36buAB4lOIljbiV4kPt5eCvrPYLnGbj75HDZxwgeEH/MD98QLyO4B74KeJPgXv174bx7CW41LAH+TXA7gbDMfIJva8eE878DngPiP9hL83NgaRjvjQS3YnD3KcD1BDXuNobv6+oylBtvCHA5wf3/Z/nhnz5mKDA6vH1yibvPI0gai8NpzYAnCCqg/Ds8Bp8TPINLxN/Cv+vNbFoR818g2K+fEOzH7fzvF4GyGALMIqjJtQF4CEhx968Jvrk/SXCcziOoUbYz0YLdPQcYQHCMVxJcURX+vdg/CJ4BbSQ4theFXz4geKZ0Z7hPhxSxiZLOw4SFtwnPBC4Ny1pDsB8KJ9OSytjj/UWh8yosN5eg1uvBBJVhCvuY4Fx/H3jE3f8dTi/p/GtC8Dzre4Jbfx8T938qkihzL89dAZHoM7OhBJUCrqjqWKLMzO4G2sbvJzNrzQ81Hst05SxSUfSDPpH9mJnVJ7h1+fOqjkWkMDVLJLKfMrPrCW7Pj3f3T6o6HpHCdItPREQiSVdQIiISSUpQIiISSUpQIiISSUpQIiISSUpQIiISSUpQIiISSUpQIiISSUpQIiISSUpQIiISSUpQIiISSUpQIiISSUpQIiISSUpQIiISSUntD8rMlhL0GpsP5Ll757D/mbEEPZUuBS5x943JjENERPY+lXEF9VN3P8bdO4fjtwHvu/thBN1I31YJMYiIyF6mKm7xnQ+MDodHAxdUQQwiIhJxSe2w0MyWABsBB55x91FmtsndDwjnG7AxNl5o3X5AP4CaNWt2ysrKSlqcIvujqVOnfufujao6DpHiJPUZFHCyu680swOB/5jZvPiZ7u5mVmSGdPdRwCiAzp07+5QpU5Icqsj+xcyWVXUMIiVJ6i0+d18Z/l0LvAl0Ab41s6YA4d+1yYxBRET2TklLUGZW08xqx4aBM4Fs4G3gqnCxq4B/JCsGERHZeyXzFl9j4M3gMRNpwCvuPsHMvgT+ambXAcuAS5IYg4iI7KWSlqDcfTHQoYjp64HTk7VdESm/qVOnHpiWlvYccBT6Ib8kXwGQnZeX17dTp04/etyT7EoSIrIXSUtLe65JkyZHNGrUaGNKSkryqviKAAUFBbZu3bp2a9aseQ7oUXi+viGJSLyjGjVq9L2Sk1SGlJQUb9SoUQ7BFfuP51dyPCISbSlKTlKZwvOtyFykBCUiIpGkZ1AiUqzWt/2zU0WWt/TBc6aWtszy5cvTBgwY0HLmzJmZderUyW/YsOGuJ598ckV6erqfe+65hy1YsGB2RcaUiFdffbXufffd17ygoIC8vDy78cYbv7355pu/q+w4Jk6cmLFixYrqvXv3zgF4+eWX686ePTvjgQceWFPeMnv27Nn6888/r127du18gIyMjILp06fPK229yqAEJSKRUVBQQI8ePQ69/PLL148bN24xwKRJkzJWrVpV7eCDD95ZFTHt2LHDbrrpplaTJk2a26ZNm125ubk2f/786lURy5QpUzKnTJlSM5ag+vTpkwPk7Gm5v//977+55ppriu1VYteuXVSrVq3Y8UTXKyslKBGJjHHjxtVOS0vzW265ZV1s2oknnpgL8PXXX+9OCl9//XX1yy+//ODc3NwUgCeeeGJ5t27dto4bN672H//4x8YffvjhQoArr7yyZefOnbf++te/Xj9gwIDm//rXvw5ITU3100477ftRo0Z9s2rVqrRrrrmm1cqVK6sDPProo8vPPPPMrfExbdq0KSUvL88aN26cB5CRkeEdOnTYAVDc+oMGDWq2dOnS6suWLUtfvXp19WHDhq2YNGlSrQ8++KBO48aNd7333nsL09PTfciQIU0nTJhwwI4dO1I6d+685eWXX16WkpJCly5dDu/UqdOWTz/9tM7mzZtTR44cufS0007bOmzYsGbbt29PycrKqjV48ODVubm5KVOmTKk5ZsyY5StWrEi79tprWy1fvjwd4Kmnnlp2/PHH5/bo0eOQ1atXVy8oKLBbbrll1fXXX59Q90aDBg1qtnjx4vTly5enN2/efMdhhx22I378kUceWXnVVVe13rBhQ1qDBg3yxowZs/Swww7b2bNnz9bp6ekF2dnZmV26dNly4YUXbho8eHBLADNj4sSJ8+rVq1eQSAxKULL/GVq3kre3x19w9xtfffVVRocOHbaVtlyzZs3y/vvf/87PzMz0WbNmpV922WWHZGdnzy1u+TVr1qS+++679RYvXpydkpLCd999lwpwww03HDRo0KBvzzrrrC0LFiyoftZZZx22ePHi/7mF2Lhx4/xu3bptatmy5dEnnXTS9z/72c9y+vXrtyE1NbXE9ZctW5Y+ceLE+dOmTavRtWvXrNGjRy8aOXLkN926dWvz17/+te7Pf/7zTTfffPPaRx55ZDXABRdccPBrr71W9/LLL88ByMvLs1mzZs0dO3Zs3fvuu69Z9+7d599+++2rYgkJYPjw4Q1icd54440tTznllM133333ory8PHJyclLfeOONOk2aNNn10UcfLQRYv359alH7584772zx0EMPNQVo27Zt7ttvv70EYMGCBTW++OKLebVq1fJBgwY1ix/v2rXroX369Fn/q1/9av3jjz/eoH///ge99957iwBWr15dfdq0afPS0tLo2rXrocOHD1925plnbs3JyUnJzMxMKDmBEpSI7IV27txp1113Xas5c+ZkpKSksGzZsvSSlm/QoEF+enp6Qe/evVufe+65m2K3yD777LM6CxYsyIgtt2XLltScnJyUunXr/s+H6NixY5dNnjx57fjx42sPHz68yXvvvVfn73//+9Li1gc444wzctLT071Lly65+fn5dvHFF38PcOSRR+YuWbKkOsD48eNrP/roo022b9+esmnTprR27drlEt6y69Wr10aAn/zkJ1tvvvnmUm8pTpw4sfbrr7++BCAtLY0GDRrkd+zYMfeOO+44qH///s3PP//8nO7du28pat3ibvF17959U61atbyo8enTp9ccP378IoD+/ftvuPfee1vElrvooos2pqUF6eWEE07YMmTIkIMuueSSDZdddtnGNm3aJJygVItPRCKjffv2uTNnzswsbbn777+/8YEHHrhr7ty5c2bNmjVn165dKQDVqlXzgoIfPv927Nhh4XRmzJgx9+KLL944bty4A0477bTDANydadOmzZ03b96cefPmzVm7du1XdevWLTj55JMPy8rKate7d+9WsbK6dOmSe88996z94IMP5k+YMKFeSesDpKenO0BqaippaWmekhJ83KakpJCXl2fbtm2zwYMHt3rjjTcWzZ8/f84VV1zx3fbt23d/JteoUcMhSDb5+flWnv159NFH75g2bdqc9u3b5951113NhwwZ0rQs69esWbOgpPHi1KpVa/dyDzzwwJrnnntuWW5ubsopp5ySNX369BqJbl8JSkQi47zzztu8c+dOe+SRRxrGpn3xxRcZEyZMqBW/XE5OTmrTpk13paamMmLEiAb5+fkAtGnTZsfChQszcnNz7bvvvkv99NNP64TLp2zYsCG1d+/eOSNHjlwxb968TICTTz75+2HDhh0YK3fixIkZAJ9++umCefPmzRk7duyynJyclHHjxtWOj6dZs2Y7S1o/Edu2bUsBaNKkSV5OTk7KO++8U6+0derUqZO/ZcuWIj+3TzrppM0PP/xwI4C8vDzWr1+funTp0mq1a9cuGDBgwIZBgwatmTFjRqnJP1HHHnvs1ueee64ewDPPPFO/c+fORV6dzZ49O71Lly65999//5qjjz56a3Z2dsIJap+6xdf6tn9W2raWPnhOpW1LpKokUi28IqWkpPD2228vGjBgwEFPPPFEk/T0dG/RosWOJ598ckX8cgMHDlzbs2fPNq+99lqDrl275mRkZBQAHHroobvOO++8jVlZWUe2aNFix5FHHrkNYNOmTannnnvuobErqt/97ncrAEaNGrWib9++Ldu2bdsuPz/fjj/++M0/+clPlsdvq6CggIcffrjxL3/5y1Y1atQoyMzMLHj++eeXJLp+cRo2bJjfp0+fdUccccSRjRo1yuvQocPW0tY5++yzNz/yyCNNs7Ky2g0ePHh1/Lynn356+dVXX92qbdu2DVNSUnjqqaeW5eTkpN5+++0tUlJSSEtL8xEjRhTZB1j8MyiAGTNmFPs8L2bkyJHLr7zyytZPPPFEk1gliaKW+8Mf/nDgxIkT65iZH3744bkXX3xxwg9lk9qjbkVJtMNCJShJiCpJAGBmU929c/y0mTNnLu3QoUOl/75H9m8zZ85s2KFDh9aFp+sWn4iIRJISlIiIRJISlIiIRJISlIiIRJISlIiIRJISlIiIRNI+9TsoEalgQ+tWaHcbDM0p9XdVZtapb9++3z777LPfANx9992Nt2zZkvroo4+uSnQzmZmZx27btm16oss3b968fc2aNfNjrT2ccMIJm1966aUVpawmSaYEJSKRUr16dX/33XfrrV69ek3Tpk3zKmu7H3/88fyStlfeLify8vKItUsnZaO9JiKRkpqa6ldeeeW6Bx54oPGTTz65Mn7e119/Xb2oLh7mzZtX/dJLLz1k27ZtKd27d98Uv85dd93V+M0336y/c+dOO+ecczY99thjCV+JdenS5fCjjjpq2+TJk2v17Nlzw/jx4w+IH+/YseO222677aD8/Hw6dOiwbcyYMcsyMjK8efPm7Xv06LHh448/rjNw4MA1a9eurfbiiy82Sk1N9bZt226P9XUlJdMzKBGJnJtvvnntG2+8Ub9w9xD9+/dv2adPn/Xz58+f07t37/X9+/c/CGDAgAEt+/btu27+/PlzmjZtuiu2/BtvvFFn4cKFNb766qu5c+fOnTNjxozM8ePH1yq8PYBTTz21bVZWVrusrKx299577+729Xbu3GnZ2dlz77333m/jx2+99da1N9xww8Fjx45dNH/+/Dl5eXnE2sIDaNCgQd6cOXPm9uvXb+Pw4cObZGdnz5k/f/6cl156qcjmhuTHlKBEJHLq169f0KtXr/UPPvjggfHTp0+fXrNfv34bIOjiYerUqbUApk2bVuv666/fAHDDDTesjy0/YcKEOp988kmddu3atTvyyCPbLVq0qMa8efOKbKz0448/nh9rlfyee+5ZG5t+2WWXbYhfLjY+c+bMGi1atNhx9NFH7wC4+uqr13/66ae7G5W98sord3dfcfjhh+deeOGFB48YMaJ+tWrVot++XEQoQYlIJN1+++3fvvLKKw23bt2a0OdUSkrKjz743Z2BAweujiWe5cuXZ//mN78pU1uDtWvXLihpPJH1PvzwwwW/+MUv1k2bNi3z2GOPPWLXrl0lrSohJSgRiaTGjRvnn3feeRtfeeWV3V1vFNfFQ8eOHbc8++yz9QGeffbZ3b3Mnn322d//+c9/bhjrRHDJkiXVVq5cWSHP3jt06LB95cqV1bOzs9MBxowZ0+CUU07ZXHi5/Px8Fi1aVP28887b/Kc//Wll2KlhkT3byv9SJQkRKV4C1cKT6Y477lgzevTo3c91iuviYcSIEcsvvfTSQx5//PEm8ZUkLrroou9nz55d47jjjssCyMzMLHj55ZeXNG/e/Ee19U499dS2sWrmRxxxxLY333xzaUmxZWZm+siRI5f26tWrTaySxJAhQ9YVXi4vL88uv/zygzdv3pzq7ta3b9+1DRs2zC/fHtm/qLuNclJ3G3sxdbcBqLsNiQ51tyEiInsVJSgREYkkJSgREYkkJSgREYmkpCcoM0s1s+lmNi4cP9jMvjCzhWY21syqJzsGERHZ+1TGFdRNwNy48YeAx9z9UGAjcF0lxCAiInuZpP4OysxaAOcA9wODzMyArsDl4SKjgaHA08mMQ0TKp/3o9hXa3casq2aV+ruqRYsWVevXr1/LhQsXZhQUFHDGGWfkPP3009/UqFHDJ06cmLFixYrqvXv3zgEYNGhQs1q1auXfd99931ZknBINyb6Cehy4BYg1+dEA2OTusR/JfQM0L2pFM+tnZlPMbMq6dT/67ZuI7IMKCgq44IILDu3Ro8emZcuWZS9ZsiR769atKTfddFNzgClTpmT+85//rLAfsuXllb03j8LNFCXabJGaNyq7pF1Bmdm5wFp3n2pmp5V1fXcfBYyC4Ie6FRudiETRO++8Uzs9Pb3gpptuWg+QlpbGyJEjVxxyyCFHDxs2bNWwYcOabd++PSUrK6vW4MGDVwPMnTs3o0uXLoevWrWq+o033vjtnXfeuRZgxIgR9Z9++unGu3btso4dO24dM2bMsrS0NDIzM4/t06fPuk8++aTO8OHDl5911llbYtufPXt2+o033thyw4YNaTVq1Ch47rnnlh177LHbe/bs2To9Pb0gOzs7s0uXLls2btyYFj9+7bXXru/fv3+r3NzclFatWu145ZVXljZq1Ci/cHcdrVq12jls2LBmKSkpXrt27fwpU6Z8XTV7eu+QzFt8JwE9zOxnQA2gDvAEcICZpYVXUS2AlSWUISL7kVmzZmV06NBhW/y0+vXrFzRt2nTnggUL0m+//fZVU6ZMqTlmzJjlAIMGDcpYuHBhjYkTJ369adOm1COOOOKom2++ed3s2bPTX3/99fpTpkyZl56e7ldccUXLkSNHNvjlL3+5Pjc3N+X444/fGuuxN17fvn1bjRo1aln79u13fPDBBzX79+/f8vPPP58PsHr16urTpk2bl5aWRs+ePVvHj7dt27bdY489tvycc87ZMnDgwGa33nprsxdeeGEF/NA9B0Dbtm3b/fvf/55/8MEH7/ruu+/UHl8pkpag3P124HaA8ApqiLv3MbO/ARcDrwFXAf9IVgwisu8788wzN2VkZHhGRkZe/fr1d33zzTdpEyZMqJ2dnZ3ZoUOHIwC2b9+ecuCBB+YBpKamcvXVV28sXE5OTk7K9OnTa/Xq1atNbNrOnTstNnzRRRdtjO8ZNza+fv361M2bN6eec845WwCuv/769b169Toktlx8dx2dO3fe0qdPn9Y9e/bc2KdPnx/FIP+rKhqLvRV4zcx+D0wHnq+CGEQkgo466qjct956q178tA0bNqSsXr26ert27XZ88cUXmYXXSU9P3/0IIDU1lby8PHN369Wr1/o//elPP7pDU7169YKiumDPz8+ndu3aefPmzZtTVGy1atUqKGm8OPHdbrzyyivLP/jgg5pvv/123U6dOrWbOnXqnCZNmqjh2GJUyg913f0jdz83HF7s7l3c/VB37+XuOyojBhGJvh49emzevn17ylNPPdUAgkoMAwYMOKhXr17f1a5du6BOnTr5W7ZsKfVzq3v37t+PGzeuXqxrjW+//TZ1/vz5Jf7msn79+gUtWrTY+cILL9SDoMLGpEmTMkrbVoMGDfLr1KmTP2HChFoAzz//fIMTTzxxS1HLzp49O71r165bH3/88VX16tXLW7x4sX4HWgJ1tyEixUqkWnhFSklJ4a233lrYr1+/Vg8//HDTgoICunbtmjN8+PCVAGefffbmRx55pGlWVla7WCWJonTq1Gn7nXfeufL0009vW1BQQLVq1Xz48OHL27Ztu7Ok7b/66quLr7/++lYPPfRQ07y8PLvwwgs3nHjiibmlxf3iiy8u6d+/f6tf//rXKS1bttzx6quvLi1qud/85jctli5dmu7udvLJJ39/wgknlFr2/kzdbZSTutvYi6m7DUDdbUh0qLsNERHZqyhBiYhIJClBiUi8goKCAit9MZGKEZ5vRdaIVIISkXjZ69atq6skJZWhoKDA1q1bVxfILmq+avGJyG55eXl916xZ89yaNWuOQl9gJfkKgOy8vLy+Rc1UghKR3Tp16rQW6FHVcYiAviGJiEhEKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkKUGJiEgkJZSgzKx9WQs2sxpmNtnMZprZbDO7N5x+sJl9YWYLzWysmVUva9kiIrLvS/QKakSYbAaYWd0E19kBdHX3DsAxQHczOwF4CHjM3Q8FNgLXlTVoERHZ9yWUoNz9FKAPcBAw1cxeMbNupazj7r4lHK0WvhzoCrweTh8NXFCOuEVEZB+X8DMod18A3AncCpwKDDezeWZ2UXHrmFmqmc0A1gL/ARYBm9w9L1zkG6B5Mev2M7MpZjZl3bp1iYYpIiL7iESfQR1tZo8BcwmugM5z9yPC4ceKW8/d8939GKAF0AXISjQwdx/l7p3dvXOjRo0SXU1ERPYRaQku9yTwHPBbd8+NTXT3VWZ2Z2kru/smM/sQOBE4wMzSwquoFsDKcsQtIiL7uERv8Z0DvBJLTmaWYmaZAO7+56JWMLNGZnZAOJwBdCO4AvsQuDhc7CrgH+WOXkRE9lmJJqj3gIy48cxwWkmaAh+a2VfAl8B/3H0cwTOsQWa2EGgAPF+2kEVEZH+Q6C2+GnE18nD3LbErqOK4+1fAsUVMX0zwPEpERKRYiV5BbTWzjrERM+sE5JawvIiIyB5J9ApqIPA3M1sFGNAE6J2soERERBJKUO7+pZllAYeHk752913JC0tERPZ3iV5BARwHtA7X6WhmuPuYpEQlIiL7vYQSlJn9GWgDzADyw8kOKEGJiEhSJHoF1Rlo5+6ezGBERERiEq3Fl01QMUJERKRSJHoF1RCYY2aTCbrRAMDdeyQlKhER2e8lmqCGJjMIERGRwhKtZv6xmbUCDnP398JWJFKTG5qIiOzPEu1u43qCTgafCSc1B95KUkwiIiIJV5L4BXAS8D3s7rzwwGQFJSIikmiC2uHuO2MjZpZG8DsoERGRpEg0QX1sZr8FMsysG/A34J3khSUiIvu7RBPUbcA6YBZwA/AuUGpPuiIiIuWVaC2+AuDZ8CUiIpJ0ibbFt4Qinjm5+yEVHpGIiAhla4svpgbQC6hf8eGIiIgEEnoG5e7r414r3f1x4JzkhiYiIvuzRG/xdYwbTSG4oipLX1IiIiJlkmiS+WPccB6wFLikwqMREREJJVqL76fJDkRERCReorf4BpU0390frZhwREREAmWpxXcc8HY4fh4wGViQjKBEREQSTVAtgI7uvhnAzIYC/3T3K5IVmIiI7N8SbeqoMbAzbnxnOE1ERCQpEr2CGgNMNrM3w/ELgNFJiUhERITEa/Hdb2bjgVPCSde4+/TkhSUiIvu7RG/xAWQC37v7E8A3ZnZwkmISERFJuMv3e4BbgdvDSdWAvyQrKBERkUSvoC4EegBbAdx9FVA7WUGJiIgkmqB2ursTdrlhZjWTF5KIiEjiCeqvZvYMcICZXQ+8RymdF5rZQWb2oZnNMbPZZnZTOL2+mf3HzBaEf+vt2VsQEZF9UakJyswMGAu8DvwdOBy4292fLGXVPGCwu7cDTgB+YWbtCLqPf9/dDwPeD8dFRET+R6nVzN3dzexdd28P/CfRgt19NbA6HN5sZnOB5sD5wGnhYqOBjwgqYIiIiOyW6C2+aWZ2XHk3YmatgWOBL4DGYfICWEMxLVKYWT8zm2JmU9atW1feTYuIyF4q0QR1PPC5mS0ys6/MbJaZfZXIimZWi+DW4EB3/z5+XnzFi8LcfZS7d3b3zo0aNUowTBER2VeUeIvPzFq6+3LgrPIUbmbVCJLTy+7+Rjj5WzNr6u6rzawpsLY8ZYuIyL6ttCuotwDcfRnwqLsvi3+VtGJYueJ5YG6h/qLeBq4Kh68C/lGuyEVEZJ9WWiUJixs+pIxlnwT8HJhlZjPCab8FHiSotn4dsAx1HS8iIkUoLUF5McOlcvdP+d8EF+/0spQlIiL7n9ISVAcz+54g0WSEw4Tj7u51khqdiIjst0pMUO6eWlmBiIiIxCtLdxsiIiKVRglKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiSQlKREQiKa2qAxDZ17Uf3b5StzfrqlmVuj2RZEnaFZSZvWBma80sO25afTP7j5ktCP/WS9b2RURk75bMW3wvAd0LTbsNeN/dDwPeD8dFRER+JGkJyt0/ATYUmnw+MDocHg1ckKzti4jI3q2yK0k0dvfV4fAaoHFxC5pZPzObYmZT1q1bVznRiYhIZFRZLT53d8BLmD/K3Tu7e+dGjRpVYmQiIhIFlZ2gvjWzpgDh37WVvH0REdlLVHaCehu4Khy+CvhHJW9fRET2EsmsZv4qMAk43My+MbPrgAeBbma2ADgjHBcREfmRpP1Q190vK2bW6cnapoiI7DvU1JGIiESSEpSIiESS2uIrr6F1K3l7OZW7PRGRKqYrKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiSQlKBERiaS0qg5AEtN+dPtK3d6sq2ZV6vZERArTFZSIiESSEpSIiESSEpSIiESSEpSIiERSlSQoM+tuZl+b2UIzu60qYhARkWir9ARlZqnAn4CzgXbAZWbWrrLjEBGRaKuKK6guwEJ3X+zuO4HXgPOrIA4REYmwqvgdVHNgRdz4N8DxhRcys35Av3B0i5l9XQmxJczKv2pD4Luyr5Zd/i2Wg129B+9w37WvHbtWyYxDZE9F9oe67j4KGFXVcVQ0M5vi7p2rOg4pOx07kcpVFbf4VgIHxY23CKeJiIjsVhUJ6kvgMDM72MyqA5cCb1dBHCIiEmGVfovP3fPM7JfAv4BU4AV3n13ZcVShfe625X5Ex06kEpm7V3UMIiIiP6KWJEREJJKUoEREJJKUoCqQmR1gZgPKue4xZvazio5JEmNmA80sswLL+21FlSWyv1KCqlgHAOVKUMAxgBJU1RkIFJmgwua5ykoJSmQPKUFVrAeBNmY2w8weNrObzexLM/vKzO4FMLMLzex9CzQ1s/lm1hK4D+gdrtu7St/FPs7MaprZP81sppllm9k9QDPgQzP7MFxmi5n90cxmAiea2VIzaxjO62xmH4XDtczsRTObFR7nnmb2IJARHsuXq+htiuz1ItuSxF7qNuAodz/GzM4ELiZoe9CAt83s/9z9TTPrCfwC6A7c4+7LzexuoLO7/7LKot9/dAdWufs5AGZWF7gG+Km7x5oyqgl84e6Dw2WKK+suIMfd24fL1XP3v5vZL939mCS+B5F9nq6gkufM8DUdmAZkAYeF834F3A7scPdXqya8/dosoJuZPWRmp7h7ThHL5AN/T6CsMwha5wfA3TdWUIwi+z1dQSWPAcPc/Zki5rUACoDGZpbi7gWVG9r+zd3nm1lHgmd+vzez94tYbLu758eN5/HDF7oayY5RRHQFVdE2A7XD4X8B15pZLQAza25mB5pZGvACcBkwFxhUxLqSRGbWDNjm7n8BHgY6Uvr+Xwp0Cod7xk3/D8Ht2ljZ9cLBXWZWraJiFtkfKUFVIHdfD3xmZtlAN+AVYJKZzQJeJ/gA/C3wX3f/lCA59TWzI4APgXaqJFEp2gOTzWwGcA/we4JmjCbEKkkU4V7gCTObQnD7L+b3QL2wssVM4Kfh9FHAV6okIVJ+aupIREQiSVdQIiISSUpQIiISSUpQIiISSUpQIiISSUpQIiISSUpQlcDMmpjZa2a2yMymmtm7Zta2kmM4zcx+Ejd+o5ldWUFlf2RmnSuiLBGRGLUkkWQWNOL2JjDa3S8Np3UAGgPzE1g/zd3zihsvg9OALcBEAHcfWY4yqoSZpRZq1SF+Xnn3h4hEnK6gku+nwK74hODuM939v2GL5g+HP/KcFfuBbni1818zexuYU8R46/DHwITLDzGzoeHwR2b2RPiD32wz62JmrYEbgd+E008xs6FmNiRunYfMbHLYuvop4fRMM/urmc0xszfN7IvSrpTM7Gkzm2Jms+2HFty7mtlbcct0M7M3w+EzzWySmU0zs7/FtbyxNIxpGtCr0DZeMrORZvYF8IfwPU4ys+lmNtHMDg+Xu9rM3jCzCWa2wMz+EFfGdeF7nWxmz5rZU+H0Rmb2dwtaof/SzE4Kp58a7rsZ4XbU6odIkukKKvmOAqYWM+8ign6gOgANgS/N7JNwXkeCltGXmNlphcZbl7LNzLBF9f8DXnD3o8xsJLDF3R8BMLPTC62T5u5dLOg08R6CRlAHABvdvZ2ZHQXMSOD93uHuGyzoQ+l9MzuaoJWMEWbWyN3XEbQc/oIF3VfcCZzh7lvN7FaC1jXuC8ta7+4di9lOC+An7p5vZnWAU9w9z8zOAB7gh+aIjgGOBXYAX5vZkwQtQdzFD00cfQDMDJd/AnjM3T+1oBuUfwFHAEOAX7j7Z2ES3Z7AvhCRPaAEVbVOBl4Nb199a2YfA8cB3wOT3X1J3LKFx0vyKoC7f2JmdczsgATWeSP8OxVoHRffE2FZ2Wb2VQLlXGJm/QjOraZAO3f/ysz+DFxhZi8CJwJXEnR70Y6geSiA6sCkuLLGlrCdv8Xd9qsLjDazwwAH4tvAez/WWrmZzQFaEXwZ+NjdN4TT/wbEngmeQdDkVGz9OmFC+gx41IKmi95w928S2BcisgeUoJJvNkG/UGW1tYTx+Ja14cetaxduvyqR9qx2hH/zKed5YWYHE1xpHOfuG83spbjYXgTeIbjy+Ft4tWPAf9z9smKKLLwPipv3O+BDd78wvLr8KG7ejrjhRN5bCnCCuxe+QnrQzP5J0AL6Z2Z2lrvPK6UsEdkDegaVfB8A6eFVBQBmdnT4nOe/BL3opppZI+D/gMkJlPktcKCZNTCzdODcQvNjz7JOJuhML4fytZb+GXBJWFY7gkZWS1KHIHHkmFlj4OzYDHdfBawiuKX3Yjj5c+AkMzs03EZNK1/txrrAynD46gSW/xI41czqWdC6fHzr5P8m6K+LMKZjwr9t3H2Wuz8Urp9VjjhFpAyUoJLMg9Z4LwTOsKCa+WxgGLCGoHbfVwTPPz4AbnH3NQmUuYvgOc1kgu4eCn+T325m04GRwHXhtHeAC2OVJBIMfwTQKLw19nuCq8GiOveLxTWToIPGeQQtuX9WaJGXgRXuPjdcfh1BQnk1vH04ifJ98P8BGBa+51Kv/tx9JcFzqslhjEv54X39GuhsQfftcwgqlwAMtKDSyVfALmB8OeIUkTJQa+b7GDP7CBji7lMqoKxUoJq7bzezNsB7wOHuvrOc5T0FTHf35/c0tj1lZrXcfUt4BfUmQWWSN6s6LhH5gZ5BSUkygQ8t6HjPgAF7kJymEtz+G1yB8e2JoWGNvxoEt/XeqtpwRKQwXUGJiEgk6RmUiIhEkhKUiIhEkhKUiIhEkhKUiIhEkhKUiIhE0v8DwdQz7DG0UWYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A1.1.1\n",
    "\n",
    "groups = ['text', 'struct']\n",
    "\n",
    "err_types = {\n",
    "    'S': \"Clause-Semantics Errors\",\n",
    "    'N': \"Node Errors\",\n",
    "    'O': \"Other errors\",\n",
    "}\n",
    "values = [[err_htype_counters[f'all-{group}'][err_type] for group in groups] for err_type in err_types.keys()]\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.25\n",
    "x = range(len(groups))\n",
    "\n",
    "# Plot the bars for each group\n",
    "for i, (err_type, err_desc) in enumerate(err_types.items()):\n",
    "    ax.bar([pos + i * width for pos in x], values[i], width=width, label=err_desc)\n",
    "\n",
    "# Set labels and ticks\n",
    "ax.set_xticks([pos + width for pos in x])\n",
    "ax.set_xticklabels(groups)\n",
    "ax.set_ylim(top=50)\n",
    "ax.set_xlabel('Corrupting layer ranges')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Decoder self-attention corruption error types\\n')\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "# Show the plot\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/home/yshao/Projects/rome/results/figs/exp-A1.1.1', exist_ok=True)\n",
    "fig.savefig('/home/yshao/Projects/rome/results/figs/exp-A1.1.1/error_analysis-htypes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node relevance accuracy\n",
    "- (column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From final SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_eval_path = os.path.join(f'/home/yshao/Projects/rome/results/clean_predictions/evals.jsonl')\n",
    "\n",
    "with open(clean_eval_path, 'r') as f:\n",
    "    clean_sql_results = [json.loads(l) for l in f]\n",
    "\n",
    "len(clean_sql_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted': 'select count(*) from singer',\n",
       " 'gold': 'select count(*) from singer',\n",
       " 'predicted_parse_error': False,\n",
       " 'hardness': 'easy',\n",
       " 'exact': True,\n",
       " 'partial': {'select': {'acc': 1,\n",
       "   'rec': 1,\n",
       "   'f1': 1,\n",
       "   'label_total': 1,\n",
       "   'pred_total': 1},\n",
       "  'select(no AGG)': {'acc': 1,\n",
       "   'rec': 1,\n",
       "   'f1': 1,\n",
       "   'label_total': 1,\n",
       "   'pred_total': 1},\n",
       "  'where': {'acc': 1, 'rec': 1, 'f1': 1, 'label_total': 0, 'pred_total': 0},\n",
       "  'where(no OP)': {'acc': 1,\n",
       "   'rec': 1,\n",
       "   'f1': 1,\n",
       "   'label_total': 0,\n",
       "   'pred_total': 0},\n",
       "  'group(no Having)': {'acc': 1,\n",
       "   'rec': 1,\n",
       "   'f1': 1,\n",
       "   'label_total': 0,\n",
       "   'pred_total': 0},\n",
       "  'group': {'acc': 1, 'rec': 1, 'f1': 1, 'label_total': 0, 'pred_total': 0},\n",
       "  'order': {'acc': 1, 'rec': 1, 'f1': 1, 'label_total': 0, 'pred_total': 0},\n",
       "  'and/or': {'acc': 1, 'rec': 1, 'f1': 1, 'label_total': 1, 'pred_total': 1},\n",
       "  'IUEN': {'acc': 1, 'rec': 1, 'f1': 1, 'label_total': 0, 'pred_total': 0},\n",
       "  'keywords': {'acc': 1,\n",
       "   'rec': 1,\n",
       "   'f1': 1,\n",
       "   'label_total': 0,\n",
       "   'pred_total': 0}},\n",
       " 'exec': 1}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sql_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_spider_dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_all_cols = 0\n",
    "N_occ_cols = 0\n",
    "\n",
    "for i, (ex, res_d) in enumerate(zip(processed_spider_dev, clean_sql_results)):\n",
    "    ex = dict(ex)\n",
    "    ctu.add_basic_analysis_info(mt_uskg, ex)\n",
    "    \n",
    "    g_sql = ex['seq_out']\n",
    "    type2tok_ranges = ex['type2tok_ranges']\n",
    "    col_name_counter = ex['col_name_counter']\n",
    "    tab_name_counter = ex['tab_name_counter']\n",
    "    \n",
    "    node_name_counter = col_name_counter + tab_name_counter\n",
    "    \n",
    "    for col, cnt in col_name_counter.items():\n",
    "        if cnt == 1:\n",
    "#         if True:\n",
    "            N_all_cols += 1\n",
    "    \n",
    "    _occ_cols = set()\n",
    "    for s, e in type2tok_ranges['column']:\n",
    "        tok = g_sql[s: e]\n",
    "        if node_name_counter[tok] == 1:\n",
    "            _occ_cols.add(tok)\n",
    "    N_occ_cols += len(_occ_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16640, 1625)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross check with exp4.1-probing \n",
    "N_all_cols, N_occ_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_ids = []\n",
    "\n",
    "N_all_cols = 0\n",
    "N_occ_cols = 0\n",
    "N_pred_cols = 0\n",
    "\n",
    "N_corr_cols = 0\n",
    "N_corr_occ_cols = 0\n",
    "\n",
    "for i, (ex, res_d) in enumerate(zip(processed_spider_dev, clean_sql_results)):\n",
    "    ex = dict(ex)\n",
    "    ctu.add_basic_analysis_info(mt_uskg, ex)\n",
    "    \n",
    "    g_sql = ex['seq_out']\n",
    "    type2tok_ranges = ex['type2tok_ranges']\n",
    "    col_name_counter = ex['col_name_counter']\n",
    "    tab_name_counter = ex['tab_name_counter']\n",
    "    \n",
    "    node_name_counter = col_name_counter + tab_name_counter\n",
    "    \n",
    "    _all_cols = set()\n",
    "    for col, cnt in col_name_counter.items():\n",
    "        if cnt == 1:\n",
    "            _all_cols.add(col)\n",
    "    \n",
    "    _occ_cols = set()\n",
    "    for s, e in type2tok_ranges['column']:\n",
    "        tok = g_sql[s: e]\n",
    "        if node_name_counter[tok] == 1:\n",
    "            _occ_cols.add(tok)\n",
    "    _non_occ_cols = _all_cols - _occ_cols\n",
    "    \n",
    "    p_sql = res_d['predicted']\n",
    "    \n",
    "    try:\n",
    "        p_sql_tok_ranges = ctu.separate_punct_by_offset(p_sql)\n",
    "        p_sql_rg2type = ctu.categorize_tokens_offset(p_sql, p_sql_tok_ranges)\n",
    "    except ValueError as e:\n",
    "        if res_d['predicted_parse_error']:\n",
    "            invalid_ids.append(i)\n",
    "            continue\n",
    "        else:\n",
    "            raise e\n",
    "        \n",
    "    p_sql_type2rgs = defaultdict(list)\n",
    "    for _rg, _type in p_sql_rg2type.items():\n",
    "        p_sql_type2rgs[_type].append(_rg)\n",
    "    \n",
    "    _pred_cols = set()\n",
    "    for s, e in p_sql_type2rgs['column']:\n",
    "        tok = p_sql[s: e]\n",
    "        if node_name_counter[tok] == 1:\n",
    "            _pred_cols.add(tok)\n",
    "    _non_pred_cols = _all_cols - _pred_cols\n",
    "    \n",
    "    N_all_cols += len(_all_cols)\n",
    "    N_occ_cols += len(_occ_cols)\n",
    "    N_pred_cols += len(_pred_cols)\n",
    "    N_corr_cols += (len(_occ_cols & _pred_cols) + len(_non_occ_cols & _non_pred_cols))\n",
    "    N_corr_occ_cols += len(_occ_cols & _pred_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 700]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N_all_cols': 16620,\n",
       " 'N_occ_cols': 1620,\n",
       " 'N_pred_cols': 1564,\n",
       " 'N_corr_cols': 16358,\n",
       " 'N_corr_occ_cols': 1457}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'N_all_cols': N_all_cols,\n",
    "    'N_occ_cols': N_occ_cols,\n",
    "    'N_pred_cols': N_pred_cols,\n",
    "    'N_corr_cols': N_corr_cols,\n",
    "    'N_corr_occ_cols': N_corr_occ_cols,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc\t0.9842\n",
      "P\t0.9316\n",
      "R\t0.8994\n",
      "F1\t0.9152\n"
     ]
    }
   ],
   "source": [
    "Acc = N_corr_cols / N_all_cols\n",
    "P = N_corr_occ_cols / N_pred_cols\n",
    "R = N_corr_occ_cols / N_occ_cols\n",
    "F1 = (2 * P * R) / (P + R + 1e-9)\n",
    "\n",
    "res_dict = {\n",
    "    'Acc': Acc,\n",
    "    'P': P,\n",
    "    'R': R,\n",
    "    'F1': F1,\n",
    "}\n",
    "\n",
    "for k, v in res_dict.items():\n",
    "    print(f'{k}\\t{v:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     'all_cols': _all_cols,\n",
    "#     'occ_cols': _occ_cols,\n",
    "#     'non_occ_cols': _non_occ_cols,\n",
    "#     'pred_cols': _pred_cols,\n",
    "#     'non_pred_cols': _non_pred_cols,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heuristics: text exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_ids = []\n",
    "\n",
    "N_all_cols = 0\n",
    "N_occ_cols = 0\n",
    "N_pred_cols = 0\n",
    "\n",
    "N_corr_cols = 0\n",
    "N_corr_occ_cols = 0\n",
    "\n",
    "for i, (ex, res_d) in enumerate(zip(processed_spider_dev, clean_sql_results)):\n",
    "    ex = dict(ex)\n",
    "    ctu.add_basic_analysis_info(mt_uskg, ex)\n",
    "    \n",
    "    g_sql = ex['seq_out']\n",
    "    type2tok_ranges = ex['type2tok_ranges']\n",
    "    col_name_counter = ex['col_name_counter']\n",
    "    tab_name_counter = ex['tab_name_counter']\n",
    "    \n",
    "    node_name_counter = col_name_counter + tab_name_counter\n",
    "    \n",
    "    _all_cols = set()\n",
    "    for col, cnt in col_name_counter.items():\n",
    "        if cnt == 1:\n",
    "            _all_cols.add(col)\n",
    "    \n",
    "    _occ_cols = set()\n",
    "    for s, e in type2tok_ranges['column']:\n",
    "        tok = g_sql[s: e]\n",
    "        if node_name_counter[tok] == 1:\n",
    "            _occ_cols.add(tok)\n",
    "    _non_occ_cols = _all_cols - _occ_cols\n",
    "    \n",
    "    \n",
    "    col2table = ex['col2table']\n",
    "    _pred_cols = set()\n",
    "    for node in _all_cols:\n",
    "        node_table = col2table[node][0]\n",
    "        text_match = ctu.check_col_text_match(ex, node, node_table)\n",
    "        if text_match in ('exact', 'partial'):\n",
    "            _pred_cols.add(node)\n",
    "    \n",
    "    _non_pred_cols = _all_cols - _pred_cols\n",
    "    \n",
    "    N_all_cols += len(_all_cols)\n",
    "    N_occ_cols += len(_occ_cols)\n",
    "    N_pred_cols += len(_pred_cols)\n",
    "    N_corr_cols += (len(_occ_cols & _pred_cols) + len(_non_occ_cols & _non_pred_cols))\n",
    "    N_corr_occ_cols += len(_occ_cols & _pred_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N_all_cols': 16640,\n",
       " 'N_occ_cols': 1625,\n",
       " 'N_pred_cols': 2009,\n",
       " 'N_corr_cols': 15024,\n",
       " 'N_corr_occ_cols': 1009}"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'N_all_cols': N_all_cols,\n",
    "    'N_occ_cols': N_occ_cols,\n",
    "    'N_pred_cols': N_pred_cols,\n",
    "    'N_corr_cols': N_corr_cols,\n",
    "    'N_corr_occ_cols': N_corr_occ_cols,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc\t0.9029\n",
      "P\t0.5022\n",
      "R\t0.6209\n",
      "F1\t0.5553\n"
     ]
    }
   ],
   "source": [
    "Acc = N_corr_cols / N_all_cols\n",
    "P = N_corr_occ_cols / N_pred_cols\n",
    "R = N_corr_occ_cols / N_occ_cols\n",
    "F1 = (2 * P * R) / (P + R + 1e-9)\n",
    "\n",
    "res_dict = {\n",
    "    'Acc': Acc,\n",
    "    'P': P,\n",
    "    'R': R,\n",
    "    'F1': F1,\n",
    "}\n",
    "\n",
    "for k, v in res_dict.items():\n",
    "    print(f'{k}\\t{v:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add basic analysis info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_id = 111\n",
    "a_ex_id = 0\n",
    "\n",
    "ex = dict(processed_spider_dev[ex_id])\n",
    "ex['text_in'], \\\n",
    "ex['struct_in'], \\\n",
    "ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out'])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctu.add_basic_analysis_info(mt_uskg, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'enc_sentence', 'enc_tokenized', 'text_range', 'struct_range', 'parsed_struct_in', 'alias2table', 'col2table', 'col_name_counter', 'tab_name_counter', 'struct_node_ranges_dict', 'sql_tokens', 'sql_token_ranges', 'tok_ranges2type', 'type2tok_ranges'])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_analysis_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp test\n",
    "# ex['seq_out'] = 'select year from cars_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu.create_analysis_sample_dicts(\n",
    "                mt_uskg, ex,\n",
    "                subject_type='column',\n",
    "                remove_struct_duplicate_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list[a_ex_id].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list[a_ex_id]['alias2table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(d['dec_prompt'], d['expect'], d['node_name_ranges'], d['expect_input_ranges'], '------',\\\n",
    "  d['self_ranges'], d['context_ranges'],\\\n",
    "  d['category'], '------' * 2) for d in a_ex_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(a_ex_list[a_ex_id])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ctu.add_clean_prediction(mt_uskg, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parse_sql_alias2table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 'table_name', 't2': 'other_table', 't3': 'ttt'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sql = 'SELECT t2.aaa , t3.ccc FROM table_name as t1 JOIN other_table as t2 on table_name.a_a = other_table.b_a JOIN ttt as t3 on other_table.asth = ttt.asth'\n",
    "ctu.parse_sql_alias2table(_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['select t2.aaa, distinct(t3.ccc), count(*) from table_name as t1 join other_table as t2 on table_name.a_a = other_table.b_a join ttt as t3 on other_table.asth = ttt.asth where t2.col like',\n",
       " 'select t2.aaa, distinct(t3.ccc), count(*) from table_name as t1 join other_table as t2 on table_name.a_a = other_table.b_a join ttt as t3 on other_table.asth = ttt.asth where t2.col like %hey']"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sql = 'SELECT t2.aaa, DISTINCT(t3.ccc), COUNT(*) FROM table_name as t1 JOIN other_table as t2 on table_name.a_a = other_table.b_a JOIN ttt as t3 on other_table.asth = ttt.asth WHERE t2.col like %hey%'.lower()\n",
    "prompts = ctu.make_syntax_dec_prompt(_sql, '%', is_punct=True)\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "('.', ['select', 't1', '.', 'accelerate', 'from', 'cars_data', 'as', 't1', 'join', 'car_names', 'as', 't2', 'on', 't1', '.', 'id', '=', 't2', '.', 'makeid', 'where', 't2', '.', 'make', '=', \"'\", 'amc', 'hornet', 'sportabout', '(', 'sw', ')', \"'\", ';'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [875]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a_ex_list_syntax \u001b[38;5;241m=\u001b[39m \u001b[43mctu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_syntax_analysis_sample_dicts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmt_uskg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/rome/notebooks/experiments/causal_trace_uskg.py:2424\u001b[0m, in \u001b[0;36mcreate_syntax_analysis_sample_dicts\u001b[0;34m(mt, ex)\u001b[0m\n\u001b[1;32m   2422\u001b[0m _phrase \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_phrase_cache)\n\u001b[1;32m   2423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _phrase:\n\u001b[0;32m-> 2424\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m _phrase \u001b[38;5;129;01min\u001b[39;00m SQL_SYNTAX_PHRASES \u001b[38;5;241m+\u001b[39m SQL_SYNTAX_PUNCTS, (_phrase, sql_tokens)\n\u001b[1;32m   2425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _phrase \u001b[38;5;129;01min\u001b[39;00m SQL_SYNTAX_PHRASES:\n\u001b[1;32m   2426\u001b[0m         syntax_phrases\u001b[38;5;241m.\u001b[39madd(_phrase)\n",
      "\u001b[0;31mAssertionError\u001b[0m: ('.', ['select', 't1', '.', 'accelerate', 'from', 'cars_data', 'as', 't1', 'join', 'car_names', 'as', 't2', 'on', 't1', '.', 'id', '=', 't2', '.', 'makeid', 'where', 't2', '.', 'make', '=', \"'\", 'amc', 'hornet', 'sportabout', '(', 'sw', ')', \"'\", ';'])"
     ]
    }
   ],
   "source": [
    "a_ex_list_syntax = ctu.create_syntax_analysis_sample_dicts(\n",
    "                mt_uskg, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### context_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the name of the different car makers who produced a car in 1970?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'select year from cars_data',\n",
       " 'year')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex = dict(a_ex_list[0])\n",
    "a_ex['text_in'], a_ex['struct_in'], a_ex['seq_out'], a_ex['expect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['alias2table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "# For full context tokens, use [0, L] and [R, -1]\n",
    "# L: node left max end index ; R: node right min start index\n",
    "\n",
    "token_ranges_dict = a_ex['token_ranges_dict']\n",
    "_all_node_range_lists = list(token_ranges_dict['col_name_ranges'].values()) + list(token_ranges_dict['table_name_ranges'].values()) + list(token_ranges_dict['db_id_ranges'].values())\n",
    "_all_node_ranges = [rg\n",
    "                    for rg_list in _all_node_range_lists\n",
    "                    for rg in rg_list]\n",
    "_all_left_endpoint = [s for s, e in _all_node_ranges] + [struct_range[1]]\n",
    "_all_right_endpoint = [e for s, e in _all_node_ranges] + [struct_range[0]]\n",
    "# TODO: pull this part out to the shared function (e.g. create_analysis_sample_dicts)\n",
    "# TODO: test for columns on ends\n",
    "\n",
    "expect_input_ranges = a_ex['expect_input_ranges']    # list of ranges of node-of-interest (code allows dup)\n",
    "# tok_indices = [i for s, e in expect_input_ranges for i in range(s, e)]\n",
    "# expect_input_indices = [i for s, e in expect_input_ranges for i in range(s, e)]\n",
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "# node = a_ex['expect']\n",
    "\n",
    "context_range_endpoints = [struct_range[0]]\n",
    "self_range_endpoints = []       # This is different from `expect_input_ranges`: this includes boundary toks\n",
    "for tok_s, tok_e in expect_input_ranges:\n",
    "    _l = max([e for e in _all_right_endpoint if e <= tok_s])\n",
    "    _r = min([s for s in _all_left_endpoint if s >= tok_e])\n",
    "    context_range_endpoints.extend([_l, _r])\n",
    "    self_range_endpoints.extend([_l, _r])\n",
    "context_range_endpoints.append(struct_range[1])\n",
    "\n",
    "self_ranges = [(self_range_endpoints[i], self_range_endpoints[i+1])\n",
    "                for i in range(0, len(self_range_endpoints), 2)]\n",
    "self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "\n",
    "context_ranges = [(context_range_endpoints[i], context_range_endpoints[i+1])\n",
    "                    for i in range(0, len(context_range_endpoints), 2)]\n",
    "context_ranges = [(s, e) for s, e in context_ranges if e > s]\n",
    "context_tok_indices = corrupt_tok_indices = [i for s, e in context_ranges for i in range(s, e)]\n",
    "\n",
    "text_tok_indices = list(range(*text_range))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(137, 140)], [(24, 137)])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_ranges, context_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_tok_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", year\n"
     ]
    }
   ],
   "source": [
    "for s, e in self_ranges:\n",
    "    _piece = tokenizer.decode(a_ex['enc_tokenized']['input_ids'][s : e])\n",
    "    print(_piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| car_1 | continents : contid, continent | countries : countryid, countryname, continent | car_makers : id, maker, fullname, country | model_list : modelid, maker, model | car_names : makeid, model, make | cars_data : id, mpg, cylinders, edispl, horsepower, weight, accelerate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s, e in context_ranges:\n",
    "    _piece = tokenizer.decode(a_ex['enc_tokenized']['input_ids'][s : e])\n",
    "    print(_piece)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_uskg_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = dict(a_ex_list[a_ex_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the name of the different car makers who produced a car in 1970?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'select distinct t1.maker from car_makers as t1 join model_list as t2 on t1.id = t2.maker join car_names as t3 on t2.model = t3.model join cars_data as t4 on t3.',\n",
       " 'makeid')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_sentence, dec_prompt, expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 11,\n",
    "    [dec_prompt] * 11,\n",
    "    answer=expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = ctu.run_model_forward_uskg(mt_uskg.model, **inp, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, torch.Size([11, 16, 141, 151]))"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers, (bsz, n_heads, seq_len, seq_len + prev_len)\n",
    "len(_out.encoder_attentions), _out.encoder_attentions[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, torch.Size([11, 16, 2, 151]))"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers, (bsz, n_heads, prompt_len, seq_len + prev_len)\n",
    "len(_out.cross_attentions), _out.cross_attentions[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, torch.Size([11, 16, 2, 12]))"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers, (bsz, n_heads, prompt_len, prompt_len + prev_len)\n",
    "len(_out.decoder_attentions), _out.decoder_attentions[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'decoder_attention_mask'])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = dict(a_ex_list[a_ex_id])\n",
    "a_ex = ctu.add_clean_prediction(mt_uskg, a_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'Which city has the most frequent destination airport?; structed knowledge: | flight_2 | airlines : uid , airline , abbreviation , country | airports : city , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport',\n",
       " 'seq_out': 'select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.city order by count(*) desc limit 1',\n",
       " 'dec_prompt': 'select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.',\n",
       " 'expect': 'city',\n",
       " 'expect_type': 'column',\n",
       " 'db_id': 'flight_2',\n",
       " 'expect_input_ranges': [(45, 46)],\n",
       " 'expect_table': 'airports',\n",
       " 'answer': 'city',\n",
       " 'base_score': 0.9983423948287964,\n",
       " 'answers_t': [6726],\n",
       " 'correct_prediction': True,\n",
       " 'category': {'sql_hardness': 'extra',\n",
       "  'node_role': 'group by',\n",
       "  'text_match': 'exact'}}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ctu.make_basic_result_dict(a_ex)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']\n",
    "answer = result['answer']\n",
    "answers_t = result['answers_t']\n",
    "\n",
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 11,\n",
    "    [dec_prompt] * 11,\n",
    "    answer=expect)\n",
    "\n",
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "self_ranges = a_ex['self_ranges']\n",
    "context_ranges = a_ex['context_ranges']\n",
    "\n",
    "self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "context_tok_indices = corrupt_tok_indices = [i for s, e in context_ranges for i in range(s, e)]\n",
    "text_tok_indices = list(range(*text_range))\n",
    "struct_tok_indices = list(range(*struct_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6726], 'city', 0.8450507521629333)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_t, answer, _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8450507521629333"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_to_corrupt = [(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                for tnum in text_tok_indices]\n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=states_to_corrupt,\n",
    "#     tokens_to_mix=corrupt_tok_indices,\n",
    "#     tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9952, device='cuda:0')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pair of identical input to test correctness \n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_patch_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 12))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 23))\n",
    "                    for tnum in struct_tok_indices],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    tokens_to_mix_1st_pass=context_tok_indices,\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9952, device='cuda:0')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_patch_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 12))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 23))\n",
    "                    for tnum in struct_tok_indices],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_corrupt_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                    for tnum in context_tok_indices],\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253002524375916"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test corrupting attention \n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", l, \"self_attn\"))\n",
    "                    for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers)],\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n for n, w in mt_uskg.model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_probs = ctu.run_repatch_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "                    for tnum in self_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "                    for tnum in self_tok_indices],\n",
    "    answer_len=len(answers_t),\n",
    "    tokens_to_mix=corrupt_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32102])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.], device='cuda:0'),\n",
       "indices=tensor([7634], device='cuda:0'))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(vocab_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs[0, 7634]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2642e-25, 1.2223e-15, 7.3942e-18,  ..., 9.1578e-20, 2.6884e-39,\n",
       "         2.8131e-39]], device='cuda:0')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trace - partial edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uskg.models.prompt.modeling_t5 import T5Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_t5_config = copy.deepcopy(mt_uskg.model.config)\n",
    "_t5_config.d_model = 10\n",
    "_t5_config.d_kv = 4\n",
    "_t5_config.num_heads = 3\n",
    "_t5_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Attention(\n",
       "  (q): Linear(in_features=10, out_features=12, bias=False)\n",
       "  (k): Linear(in_features=10, out_features=12, bias=False)\n",
       "  (v): Linear(in_features=10, out_features=12, bias=False)\n",
       "  (o): Linear(in_features=12, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_attn_module = T5Attention(config=_t5_config)\n",
    "test_attn_module.eval()\n",
    "test_attn_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('q.weight', torch.Size([12, 10])),\n",
       " ('k.weight', torch.Size([12, 10])),\n",
       " ('v.weight', torch.Size([12, 10])),\n",
       " ('o.weight', torch.Size([10, 12]))]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v.size()) for k, v in test_attn_module.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'q', 'k', 'v', 'o']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k, v in test_attn_module.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 7, 10]),\n",
       " [('prev_key', torch.Size([1, 3, 2, 4])),\n",
       "  ('prev_value', torch.Size([1, 3, 2, 4])),\n",
       "  ('prev_key_padding_mask', torch.Size([1, 2]))])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_bs = 1\n",
    "_test_seqlen = 7\n",
    "_test_prevlen = 2\n",
    "\n",
    "_test_h = torch.randn(_test_bs, _test_seqlen, _t5_config.d_model)\n",
    "# _test_h[:, 0] = 999.0\n",
    "_test_prefix = {\n",
    "    'prev_key': torch.randn(_test_bs, _t5_config.num_heads, _test_prevlen, _t5_config.d_kv),\n",
    "    'prev_value': torch.randn(_test_bs, _t5_config.num_heads, _test_prevlen, _t5_config.d_kv),\n",
    "    'prev_key_padding_mask': torch.zeros(_test_bs, _test_prevlen).bool()\n",
    "}\n",
    "_test_h.size(), [(k, v.size()) for k, v in _test_prefix.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8561, -0.0552,  0.3845,  1.1441, -1.2765, -0.6869, -0.9646,\n",
       "          -1.0255, -2.3659, -1.7153],\n",
       "         [ 1.0685, -0.1617,  0.8310, -1.7257,  0.3674,  1.7559,  0.5763,\n",
       "          -0.9344,  0.9016,  0.7490],\n",
       "         [-1.1887, -1.0820, -0.5925,  0.7623, -0.6538, -0.0067,  0.5618,\n",
       "           1.3310,  1.2580, -0.6973],\n",
       "         [ 0.2807,  0.0763, -0.3539,  0.9494, -0.1557, -0.7645, -0.2103,\n",
       "          -1.0175, -0.3029, -0.0376],\n",
       "         [ 0.0984,  0.5610, -2.3323,  1.3421, -1.0381, -1.8568, -0.7754,\n",
       "          -1.6037,  0.2501, -1.4155],\n",
       "         [-1.4474, -0.4784,  0.0972, -0.3393,  1.2340,  0.7611, -0.4786,\n",
       "           0.0506, -0.1188,  2.7051],\n",
       "         [ 2.0642, -0.0186, -0.8283,  1.0852,  0.9819, -0.4044,  0.9831,\n",
       "          -0.2723,  0.2037,  1.6401]]])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev_key': tensor([[[[-2.2578,  0.2019,  0.3287,  0.3906],\n",
       "           [-1.2143, -0.7039, -1.0298,  0.1425]],\n",
       " \n",
       "          [[ 0.3967,  1.5168,  0.0967,  1.4454],\n",
       "           [ 0.1648,  0.2483,  1.5992,  1.2469]],\n",
       " \n",
       "          [[ 1.3875,  0.4460, -0.2676, -1.2290],\n",
       "           [ 2.0209,  1.1736,  0.8446,  0.8827]]]]),\n",
       " 'prev_value': tensor([[[[ 0.8351,  1.2052,  1.4187, -0.5358],\n",
       "           [-1.4274,  0.2792,  2.0149,  1.3695]],\n",
       " \n",
       "          [[-0.0379,  1.8999, -0.4236, -0.9176],\n",
       "           [ 1.5794,  1.1735, -0.2925,  2.2855]],\n",
       " \n",
       "          [[ 1.1935,  0.9343, -0.5582,  0.8163],\n",
       "           [-1.3765,  0.4046,  1.0941,  0.4058]]]]),\n",
       " 'prev_key_padding_mask': tensor([[False, False]])}"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_mask = torch.zeros(1, 1, 1, _test_seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = test_attn_module.forward(\n",
    "    _test_h,\n",
    "    mask=_test_mask,\n",
    "    prefix=_test_prefix,\n",
    "    output_attentions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3544, 0.3264, 0.2939, 0.3878, 0.4695, 0.2997, 0.1775],\n",
       "         [0.4028, 0.1655, 0.2949, 0.5148, 0.4162, 0.4189, 0.4683],\n",
       "         [0.5839, 0.4639, 0.1393, 0.4925, 0.6272, 0.1917, 0.4634]]])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out[3].sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_mask_attention(att, mix_mask):\n",
    "    # token 4,5,6 (in real_seq) not attending to 2 (in full_seq, i.e. 0 in real_seq)\n",
    "    # att: (bs, n_head, real_seq, full_seq)\n",
    "#     att[:, :, 4:, 2] = 0.0\n",
    "\n",
    "    _zero = torch.tensor(0, dtype=att.dtype)\n",
    "    att = torch.where(mix_mask, _zero, att)\n",
    "\n",
    "    print(att)\n",
    "    return att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ True, False,  True, False,  True, False,  True, False,  True],\n",
       "           [False, False, False, False, False, False, False, False, False],\n",
       "           [ True, False,  True, False,  True, False,  True, False,  True],\n",
       "           [False, False, False, False, False, False, False, False, False],\n",
       "           [ True, False,  True, False,  True, False,  True, False,  True],\n",
       "           [False, False, False, False, False, False, False, False, False],\n",
       "           [ True, False,  True, False,  True, False,  True, False,  True]]]]),\n",
       " tensor([[[[ True,  True, False, False, False,  True,  True,  True,  True],\n",
       "           [ True,  True, False, False, False,  True,  True,  True,  True],\n",
       "           [ True,  True, False, False, False,  True,  True,  True,  True],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False]]]]))"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_mask = torch.zeros(1, 1, _test_seqlen, _test_seqlen + _test_prevlen, dtype=bool)\n",
    "mix_mask[:, :, ::2, ::2] = 1\n",
    "\n",
    "mix_mask_2 = torch.zeros(1, 1, _test_seqlen, _test_seqlen + _test_prevlen, dtype=bool)\n",
    "mix_mask_2[:, :, :, :_test_prevlen] = 1\n",
    "mix_mask_2[:, :, 3:, _test_prevlen : _test_prevlen+3] = 1\n",
    "mix_mask_2[:, :, :3, _test_prevlen+3 :] = 1\n",
    "\n",
    "mix_mask, mix_mask_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_mask | mix_mask_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attn_module.ext_attention_weights_fn = lambda att : _test_mask_attention(att, mix_mask_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x7fc33d6065e0>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test_attn_module.ext_attention_weights_fn)\n",
    "print(test_attn_module.ext_attention_logits_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_out = test_attn_module.forward(\n",
    "    _test_h,\n",
    "    mask=_test_mask,\n",
    "    prefix=_test_prefix,\n",
    "    output_attentions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = dict(a_ex_list[a_ex_id])\n",
    "a_ex = ctu.add_clean_prediction(mt_uskg, a_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'What is the accelerate of the car make amc hornet sportabout (sw)?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'seq_out': \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\",\n",
       " 'dec_prompt': 'select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.',\n",
       " 'expect': 'make',\n",
       " 'expect_type': 'column',\n",
       " 'db_id': 'car_1',\n",
       " 'expect_input_ranges': [(121, 145)],\n",
       " 'expect_table': 'car_names',\n",
       " 'answer': 'make',\n",
       " 'base_score': 0.9998800754547119,\n",
       " 'answers_t': [19509],\n",
       " 'correct_prediction': True,\n",
       " 'category': {'sql_hardness': 'medium',\n",
       "  'node_role': 'where',\n",
       "  'text_match': 'exact'}}"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ctu.make_basic_result_dict(a_ex)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']\n",
    "answer = result['answer']\n",
    "answers_t = result['answers_t']\n",
    "\n",
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 2,\n",
    "    [dec_prompt] * 2,\n",
    "    answer=expect)\n",
    "\n",
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "self_ranges = a_ex['self_ranges']\n",
    "context_ranges = a_ex['context_ranges']\n",
    "\n",
    "self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "context_tok_indices = corrupt_tok_indices = [i for s, e in context_ranges for i in range(s, e)]\n",
    "text_tok_indices = list(range(*text_range))\n",
    "struct_tok_indices = list(range(*struct_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=context_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([19509], 'make', 0.9987825751304626)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_t, answer, _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score = ctu.trace_attention_manip_uskg_multi_token(\n",
    "# _probs = ctu.run_attention_manip_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     answer_len=len(answers_t),\n",
    "    answers_t=answers_t,\n",
    "#     states_to_patch=[],\n",
    "    layers_to_mix=[ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') for l in range(24)],\n",
    "    src_tokens_to_mix=text_tok_indices + struct_tok_indices, # src doesn't have prefix \n",
    "#     src_tokens_to_mix=[-1],\n",
    "    tgt_tokens_to_mix=list(range(10)) + [i + 10 for i in text_tok_indices + struct_tok_indices],  # tgt has prefix \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.6447], device='cuda:0'),\n",
       "indices=tensor([4350], device='cuda:0'))"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_probs.max(dim=-1)\n",
    "# _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name'"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.decode([4350])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctu.layername_uskg(mt_uskg.model, 'encoder', 0, 'self_attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit - attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder mask (toy example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex['text_range'] = (0, 3)\n",
    "ex['struct_range'] = (5, 10)\n",
    "ex['enc_sentence'] = \"what is? empty empty Table column column Table column\"\n",
    "ex['struct_node_ranges_dict'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'is',\n",
       " '?',\n",
       " 'empty',\n",
       " 'empty',\n",
       " 'Table',\n",
       " 'column',\n",
       " 'column',\n",
       " 'Table',\n",
       " 'column']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer_uskg.tokenize(ex['enc_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'text_range', 'struct_range', 'enc_sentence', 'struct_node_ranges_dict'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 3), (5, 10))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['text_range'], ex['struct_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_mask = build_enc_self_attention_mask_for_section_pair(\n",
    "    ex,\n",
    "    q_sect='text',\n",
    "    k_sect='text',\n",
    "    seq_len=None,\n",
    "    mt=mt_uskg,\n",
    "    prefix_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]])\n"
     ]
    }
   ],
   "source": [
    "print(mix_mask.to(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_mask = build_dec_cross_attention_mask_for_section(\n",
    "    ex,\n",
    "    k_sect='others',\n",
    "    seq_len=None,\n",
    "    mt=mt_uskg,\n",
    "    prefix_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1]]]])\n"
     ]
    }
   ],
   "source": [
    "print(mix_mask.to(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['text_in'], \\\n",
    "ex['struct_in'], \\\n",
    "ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select t1.accelerate from cars_data as t1 join car_names as t2 on t1.make = t2.makeid where t2.make = \"amc hornet sportabout\"'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select t1.name from car as t1 join t2 on t1.car = t2.caravan (select t2.caravan from car as t1 join t2 on t1.car = t2.caravan where t1.year = _2010'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_layers = [ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') for l in range(24)]\n",
    "section_pairs = [('all', 'all')]\n",
    "\n",
    "with add_enc_attention_edit(mt=mt_uskg,\n",
    "                        ex=ex,\n",
    "                        mix_layers=mix_layers,\n",
    "                        section_pairs=section_pairs,\n",
    "                        attn_corrupt_type='weights'):\n",
    "\n",
    "    pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select t1.accelerate from cars_data as t1 join car_names as t2 on t1.make = t2.makeid where t2.make = \"amc hornet sportabout\" (sw)'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_layers = [ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') for l in range(6, 18)]\n",
    "section_pairs = [('struct', 'text')]\n",
    "\n",
    "with add_enc_attention_edit(mt=mt_uskg,\n",
    "                        ex=ex,\n",
    "                        mix_layers=mix_layers,\n",
    "                        section_pairs=section_pairs,\n",
    "                        attn_corrupt_type='weights'):\n",
    "\n",
    "    pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False, False, False, False, False, False, False, False,\n",
      "           False, False, False]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cars_data: accelerated = 0-60 seconds, t1.speed = 0-60 seconds, t1.year = 00 and t1.year = 00'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_layers = [ctu.layername_uskg(mt_uskg.model, 'decoder', l, 'cross_attn') for l in range(24)]\n",
    "sections = ['prefix']\n",
    "\n",
    "with add_dec_cross_attention_edit(mt=mt_uskg,\n",
    "                        ex=ex,\n",
    "                        mix_layers=mix_layers,\n",
    "                        sections=sections,\n",
    "                        attn_corrupt_type='weights'):\n",
    "\n",
    "    pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select t1.accelerate from cars_data as t1 join car_names as t2 on t1.makeid = t2.makeid where t2.make = \"ammc hornet sportabout\"'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_layers = [ctu.layername_uskg(mt_uskg.model, 'decoder', l, 'self_attn') for l in range(23, 24)]\n",
    "\n",
    "with add_dec_self_attention_edit(mt=mt_uskg,\n",
    "                                ex=ex,\n",
    "                                mix_layers=mix_layers,\n",
    "                                attn_corrupt_type='weights'):\n",
    "\n",
    "    pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select t1.accelerate from cars_data as t1 join car_names as t2 on t1.make = t2.makeid where t2.make = \"amc hornet sportabout\"'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'select t1.accelerate from cars_data as t1 join car_names as t2 on t1.make = t2.makeid where t2.make = \"amc hornet sportabout\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_in = ex['text_in']\n",
    "# struct_in = ex['struct_in']\n",
    "\n",
    "# enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "# enc_tokenized = mt_uskg.tokenizer(enc_sentence)\n",
    "# ex['enc_sentence'] = enc_sentence\n",
    "# ex['enc_tokenized'] = enc_tokenized\n",
    "\n",
    "# parsed_struct_in = ctu.parse_struct_in(struct_in)\n",
    "\n",
    "# token_ranges_dict = ctu.find_struct_name_ranges(mt_uskg.tokenizer, ex)\n",
    "# text_range = ex['text_range']\n",
    "# struct_range = ex['struct_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = mt_uskg.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['mar', 'y', ':', 'has', '', 'a', 'little', 'lamb', 'b', 'b'],\n",
       " ['mar', 'y', ':', 'has', '', 'a', 'little', 'lamb', 'b', 'b'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"mary: has a little  lambbb\"\n",
    "s_ = \"mary: has a little lambbb\"\n",
    "tokenizer.tokenize(s), tokenizer.tokenize(s_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3157, 63, 10, 65, 3, 9, 385, 17871, 115, 115, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tokenizer(s)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'mar'),\n",
       " (1, 'y'),\n",
       " (2, ':'),\n",
       " (3, 'has'),\n",
       " (4, ''),\n",
       " (5, 'a'),\n",
       " (6, 'little'),\n",
       " (7, 'lamb'),\n",
       " (8, 'b'),\n",
       " (9, 'b'),\n",
       " (10, '</s>')]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(t.tokens()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenSpan(start=7, end=10)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_to_tokens(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lambbb'"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.decode_sentences(tokenizer, t['input_ids'][7:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"(a(a)a)\".rindex(\")\"), \"(a(a)a)\".index(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = \"\"\"| concert_singer | singer : singer_id , name ( First Last ) , country ( France , Germany , United States ) , \\\n",
    "song_name , song_release_year , age , is_male\"\"\"\n",
    "\n",
    "tokenizer.tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test struct_in parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "_struct_in = \"\"\"| concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , \\\n",
    "average | singer : singer_id , name ( First Last ) , country ( France , Germany , United States ) , \\\n",
    "song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , \\\n",
    "stadium_id , year ( 2008 , 2012 , 2022 ) | singer_in_concert : concert_id , singer_id\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((3, 'stadium'),\n",
       "  [[(5, 'stadium_id'), []],\n",
       "   [(7, 'location'), []],\n",
       "   [(9, 'name'), []],\n",
       "   [(11, 'capacity'), []],\n",
       "   [(13, 'highest'), []],\n",
       "   [(15, 'lowest'), []],\n",
       "   [(17, 'average'), []]]),\n",
       " ((19, 'singer'),\n",
       "  [[(21, 'singer_id'), []],\n",
       "   [(23, 'name'), [(25, 'First Last')]],\n",
       "   [(29, 'country'), [(31, 'France'), (33, 'Germany'), (35, 'United States')]],\n",
       "   [(39, 'song_name'), []],\n",
       "   [(41, 'song_release_year'), []],\n",
       "   [(43, 'age'), []],\n",
       "   [(45, 'is_male'), []]]),\n",
       " ((47, 'concert'),\n",
       "  [[(49, 'concert_id'), []],\n",
       "   [(51, 'concert_name'), []],\n",
       "   [(53, 'theme'), []],\n",
       "   [(55, 'stadium_id'), []],\n",
       "   [(57, 'year'), [(59, '2008'), (61, '2012'), (63, '2022')]]]),\n",
       " ((66, 'singer_in_concert'),\n",
       "  [[(68, 'concert_id'), []], [(70, 'singer_id'), []]])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.parse_struct_in(_struct_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "_text_in = text_in\n",
    "\n",
    "enc_sentence = f\"{_text_in}; structed knowledge: {_struct_in}\"\n",
    "enc_tokenized = mt_uskg.tokenizer(enc_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ranges_dict = ctu.find_struct_name_ranges(mt_uskg.tokenizer, enc_tokenized['input_ids'], _struct_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_ranges_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d_key, d in token_ranges_dict.items():\n",
    "    for name, ranges in d.items():\n",
    "        for s, e in ranges:\n",
    "            recs_name = ctu.decode_sentences(mt_uskg.tokenizer, enc_tokenized['input_ids'][s:e])\n",
    "            print(f'{d_key}\\t{name}\\t{recs_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False,  True]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cond = torch.eye(2).to(dtype=bool).view(1, 1, 4)\n",
    "_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 1.],\n",
       "         [1., 0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0., 1.],\n",
       "         [1., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ones = torch.ones(2, 2, 4)\n",
    "_zeros = torch.zeros(2, 2, 4)\n",
    "\n",
    "torch.where(_cond, _ones, _zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from play_pred()\n",
    "\n",
    "def pred_sql_with_edit(mt, ex, f_hook_fn=None, p_hook_fn=None):\n",
    "    text_in = ex['text_in']\n",
    "    struct_in = ex['struct_in']\n",
    "\n",
    "    txt = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "    \n",
    "    tokenized_txt = mt.tokenizer_uskg([txt], max_length=1024, padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    device = mt.model.device\n",
    "    \n",
    "    all_hooks = []\n",
    "    if f_hook_fn is not None:\n",
    "        f_hook = mt.model.register_forward_hook(f_hook_fn)\n",
    "        all_hooks.append(f_hook)\n",
    "    if p_hook_fn is not None:\n",
    "        p_hook = mt.model.register_forward_pre_hook(p_hook_fn)\n",
    "        all_hooks.append(p_hook)\n",
    "    \n",
    "    pred = mt.tokenizer_uskg.batch_decode(\n",
    "      mt.model.generate(\n",
    "        torch.tensor(tokenized_txt.data['input_ids'], dtype=int, device=device),\n",
    "        torch.tensor(tokenized_txt.data['attention_mask'], dtype=int, device=device),\n",
    "        num_beams=1, \n",
    "        max_length=256\n",
    "        ), \n",
    "      skip_special_tokens=True \n",
    "    )\n",
    "    \n",
    "    for hook in all_hooks:\n",
    "        hook.remove()\n",
    "    \n",
    "    return pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused implementation \n",
    "\n",
    "def build_enc_self_attention_global_mask(\n",
    "    ex,\n",
    "    seq_len=None,\n",
    "    mt=None,\n",
    "    prefix_len=10,\n",
    "    use_self_node=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    BBB\n",
    "    For attention-related experiments: build encoder self-attention masks across sections\n",
    "    (\"global\" means it is not specific to certain node, i.e. \"self\" means each node itself)\n",
    "\n",
    "    Args:\n",
    "    a_ex (Dict)\n",
    "    seq_len (int): sequence length\n",
    "    prefix_len (int): prefix length\n",
    "    use_self_node (bool): whether to include \"self\" and \"context\" related sections\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    enc_sentence = ex['enc_sentence']\n",
    "\n",
    "    text_range = ex['text_range']\n",
    "    struct_range = ex['struct_range']\n",
    "    text_st, text_ed = text_range\n",
    "    struct_st, struct_ed = struct_range\n",
    "    # text_tok_indices = list(range(*text_range))\n",
    "    # struct_tok_indices = list(range(*struct_range))\n",
    "    \n",
    "    token_ranges_dict = ex['struct_node_ranges_dict']\n",
    "\n",
    "#     if use_self_node:\n",
    "#         expect_input_ranges = a_ex['expect_input_ranges']\n",
    "#         tok_indices = [i for s, e in expect_input_ranges for i in range(s, e)]\n",
    "\n",
    "#         self_ranges = a_ex['self_ranges']\n",
    "#         struct_context_ranges = a_ex['context_ranges']\n",
    "\n",
    "#         self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "#         struct_context_tok_indices = [i for s, e in struct_context_ranges for i in range(s, e)]\n",
    "\n",
    "#         self_tok_indices_tgt_side = [i + prefix_len for i in self_tok_indices]\n",
    "#         struct_context_tok_indices_tgt_side = [i + prefix_len for i in struct_context_tok_indices]\n",
    "\n",
    "    if seq_len is None:\n",
    "        # need to tokenize and decide seq_len\n",
    "        # TODO: untested!\n",
    "        assert mt is not None\n",
    "        _tok_ids = mt.tokenizer.encode(enc_sentence, add_special_tokens=True)\n",
    "        seq_len = len(_tok_ids)\n",
    "\n",
    "    att_mix_mask_dict = dict()\n",
    "    # key: (q_sect, k_sect)\n",
    "    # mix_mask: (batch, head, src_len, tgt_len)\n",
    "    \n",
    "    t2s_mask = torch.zeros(1, 1, seq_len, seq_len + prefix_len).bool()\n",
    "    t2s_mask[:, :, text_st : text_ed, struct_st + prefix_len : struct_ed + prefix_len] = True\n",
    "    att_mix_mask_dict[('text', 'struct')] = t2s_mask\n",
    "\n",
    "    s2t_mask = torch.zeros_like(t2s_mask).bool()\n",
    "    s2t_mask[:, :, struct_st : struct_ed, text_st + prefix_len : text_ed + prefix_len] = True\n",
    "    att_mix_mask_dict[('struct', 'text')] = s2t_mask\n",
    "\n",
    "#     att_mix_mask_dict['t<->s'] = t2s_mask | s2t_mask\n",
    "\n",
    "    t2p_mask = torch.zeros_like(t2s_mask).bool()\n",
    "    t2p_mask[:, :, text_st : text_ed, :prefix_len] = True\n",
    "    att_mix_mask_dict[('text', 'prefix')] = t2p_mask\n",
    "\n",
    "    s2p_mask = torch.zeros_like(t2s_mask).bool()\n",
    "    s2p_mask[:, :, struct_st : struct_ed, :prefix_len] = True\n",
    "    att_mix_mask_dict[('struct', 'prefix')] = s2p_mask\n",
    "\n",
    "#     att_mix_mask_dict['ts->p'] = t2p_mask | s2p_mask\n",
    "\n",
    "    # ADDED: section self-attention\n",
    "    t2t_mask = torch.zeros_like(t2s_mask).bool()\n",
    "    t2t_mask[:, :, text_st : text_ed, text_st + prefix_len : text_ed + prefix_len] = True\n",
    "    att_mix_mask_dict[('text', 'text')] = t2t_mask\n",
    "\n",
    "    s2s_mask = torch.zeros_like(t2s_mask).bool()\n",
    "    s2s_mask[:, :, struct_st : struct_ed, struct_st + prefix_len : struct_ed + prefix_len] = True\n",
    "    att_mix_mask_dict[('struct', 'struct')] = s2s_mask\n",
    "\n",
    "    if use_self_node:\n",
    "        # TODO: self->self, self->context \n",
    "        # iterate through node ranges \n",
    "        NotImplemented\n",
    "        \n",
    "        \n",
    "#         # ADDED: regarding struct context\n",
    "#         # Notice that it's ok to have 1 list in indexing, but not ok to have 2\n",
    "#         # If there are 2 lists, it will become a \"gather()\" which treats the 2 lists in a zipped way\n",
    "#         s2c_mask = torch.zeros_like(t2s_mask).bool()\n",
    "#         s2c_mask[:, :, struct_st : struct_ed, struct_context_tok_indices_tgt_side] = True\n",
    "#         att_mix_mask_dict['s->c'] = s2c_mask\n",
    "\n",
    "#         c2p_mask = torch.zeros_like(t2s_mask).bool()\n",
    "#         c2p_mask[:, :, struct_context_tok_indices, :prefix_len] = True\n",
    "#         att_mix_mask_dict['c->p'] = c2p_mask\n",
    "\n",
    "#         # c2t: skipped, as already see even s2t is not so effective\n",
    "\n",
    "#         c2s_mask = torch.zeros_like(t2s_mask).bool()\n",
    "#         c2s_mask[:, :, struct_context_tok_indices, struct_st + prefix_len : struct_ed + prefix_len] = True\n",
    "#         att_mix_mask_dict['c->s'] = c2s_mask\n",
    "\n",
    "#         c2c_mask = c2s_mask.clone()\n",
    "#         c2c_mask[:, :, :, self_tok_indices_tgt_side] = False\n",
    "#         assert c2c_mask.sum().item() == len(struct_context_tok_indices) ** 2, \\\n",
    "#             (c2c_mask.sum().item(), len(struct_context_tok_indices) ** 2)\n",
    "#         att_mix_mask_dict['c->c'] = c2c_mask\n",
    "\n",
    "    att_mix_mask_dict[('all', 'all')] = torch.ones_like(t2s_mask).bool()\n",
    "\n",
    "    return att_mix_mask_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old hook-based implementation of exp A1.0 \n",
    "\n",
    "# def add_attention_edit_hook(mt, ex, mix_layers, section_pairs, attn_corrupt_type='weights'):\n",
    "#     \"\"\" \n",
    "#     Args:\n",
    "#         mix_layers: List[int], the layers to edit\n",
    "#         section_pairs: List[Tuple(str, str)]: corrupting attention from which to which\n",
    "#             sections: \"text\", \"struct\", \"prefix\", \"eos\"; \"self\", \"context\"\n",
    "#             (notice that \"self\" is per-node; \"context->context\" is invalid here)\n",
    "#         attn_corrupt_type: (same as trace exp) weights / logits \n",
    "#     \"\"\"\n",
    "    \n",
    "#     ex = copy.deepcopy(ex)\n",
    "    \n",
    "#     text_in = ex['text_in']\n",
    "#     struct_in = ex['struct_in']\n",
    "\n",
    "#     enc_sentence = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "#     enc_tokenized = mt.tokenizer(enc_sentence)\n",
    "#     ex['enc_sentence'] = enc_sentence\n",
    "#     ex['enc_tokenized'] = enc_tokenized\n",
    "    \n",
    "#     parsed_struct_in = ctu.parse_struct_in(struct_in)\n",
    "    \n",
    "#     token_ranges_dict = ctu.find_struct_name_ranges(mt.tokenizer, ex)\n",
    "#     text_range = ex['text_range']\n",
    "#     struct_range = ex['struct_range']\n",
    "#     # token_ranges_dict = ex['struct_node_ranges_dict']\n",
    "\n",
    "#     all_mix_masks = [build_enc_self_attention_mask_for_section_pair(\n",
    "#             ex,\n",
    "#             q_sect,\n",
    "#             k_sect,\n",
    "#             mt=mt) for q_sect, k_sect in section_pairs]\n",
    "    \n",
    "#     mix_mask = torch.logical_or(*all_mix_masks) if len(all_mix_masks) > 1 else all_mix_masks[0]\n",
    "    \n",
    "#     def _attn_w_fn(attn):\n",
    "#         _mix_mask = mix_mask.to(device=attn.device)\n",
    "#         _zero = torch.tensor(0, dtype=attn.dtype, device=attn.device)\n",
    "#         attn = torch.where(_mix_mask, _zero, attn)     # no need to keep batch_idx=0 clean here\n",
    "#         return attn\n",
    "\n",
    "#     def _attn_lg_fn(attn):\n",
    "#         _mix_mask = mix_mask.to(device=attn.device)\n",
    "#         _neg = torch.tensor(-1e9, dtype=attn.dtype, device=attn.device)\n",
    "#         attn = torch.where(_mix_mask, _neg, attn)\n",
    "#         return attn\n",
    "\n",
    "#     def p_hook_fn(m, inp):\n",
    "#         if attn_corrupt_type == 'weights':\n",
    "#             m.ext_attention_weights_fn = _attn_w_fn\n",
    "#         elif attn_corrupt_type == 'logits':\n",
    "#             m.ext_attention_logits_fn = _attn_lg_fn\n",
    "#         else:\n",
    "#             raise ValueError(attn_corrupt_type)\n",
    "\n",
    "#     def f_hook_fn(m, inp, outp):\n",
    "#         m.ext_attention_weights_fn = None\n",
    "#         m.ext_attention_logits_fn = None\n",
    "\n",
    "#     all_hooks = []\n",
    "    \n",
    "#     for layer in mix_layers:\n",
    "#         m = nethook.get_module(mt.model, layer)\n",
    "#         # print(m)\n",
    "#         p_hook = m.register_forward_pre_hook(p_hook_fn)\n",
    "#         f_hook = m.register_forward_hook(f_hook_fn)\n",
    "#         all_hooks.extend([p_hook, f_hook])\n",
    "\n",
    "#     return all_hooks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old test for exp A1.0 hook-implementation \n",
    "\n",
    "# mix_layers = [ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') for l in range(24)]\n",
    "# section_pairs = [('all', 'all')]\n",
    "\n",
    "# all_hooks = add_attention_edit_hook(\n",
    "#     mt=mt_uskg,\n",
    "#     ex=ex,\n",
    "#     mix_layers=mix_layers,\n",
    "#     section_pairs=section_pairs,\n",
    "#     attn_corrupt_type='weights')\n",
    "\n",
    "# pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "\n",
    "# for hook in all_hooks:\n",
    "#     hook.remove()\n",
    "\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer = all; Sect = t<->s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mix_layers = [ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') for l in range(24)]\n",
    "section_pairs = [('struct', 'text'), ('text', 'struct')]\n",
    "\n",
    "all_preds = []\n",
    "eval_sql_results = []\n",
    "\n",
    "for ex_id, ex in enumerate(tqdm(processed_spider_dev[::111])):\n",
    "    with add_enc_attention_edit(mt=mt_uskg,\n",
    "                            ex=ex,\n",
    "                            mix_layers=mix_layers,\n",
    "                            section_pairs=section_pairs,\n",
    "                            attn_corrupt_type='weights'):\n",
    "        pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "    \n",
    "    eval_res = evaluate_sql(evaluator, db_name=ex['db_id'], gold=ex['seq_out'], predicted=pred)\n",
    "    \n",
    "    all_preds.append(pred)\n",
    "    eval_sql_results.append(eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "avg_exact, avg_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = os.path.join(a1_0_result_dir, 'predictions-layer=all-sect=t<->s.txt')\n",
    "eval_path = os.path.join(a1_0_result_dir, 'evals-layer=all-sect=t<->s.jsonl')\n",
    "\n",
    "with open(pred_path, 'w') as f:\n",
    "    for p in all_preds:\n",
    "        f.write(p + '\\n')\n",
    "\n",
    "with open(eval_path, 'w') as f:\n",
    "    for e in eval_sql_results:\n",
    "        f.write(json.dumps(e, indent=None) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer = all; Sect = t->s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mix_layers = [ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') for l in range(24)]\n",
    "section_pairs = [('text', 'struct')]\n",
    "\n",
    "all_preds = []\n",
    "eval_sql_results = []\n",
    "\n",
    "for ex_id, ex in enumerate(tqdm(processed_spider_dev[::111])):\n",
    "    with add_enc_attention_edit(mt=mt_uskg,\n",
    "                            ex=ex,\n",
    "                            mix_layers=mix_layers,\n",
    "                            section_pairs=section_pairs,\n",
    "                            attn_corrupt_type='weights'):\n",
    "        pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "    \n",
    "    eval_res = evaluate_sql(evaluator, db_name=ex['db_id'], gold=ex['seq_out'], predicted=pred)\n",
    "        \n",
    "    all_preds.append(pred)\n",
    "    eval_sql_results.append(eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.4)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "avg_exact, avg_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = os.path.join(a1_0_result_dir, 'predictions-layer=all-sect=t->s.txt')\n",
    "eval_path = os.path.join(a1_0_result_dir, 'evals-layer=all-sect=t->s.jsonl')\n",
    "\n",
    "with open(pred_path, 'w') as f:\n",
    "    for p in all_preds:\n",
    "        f.write(p + '\\n')\n",
    "\n",
    "with open(eval_path, 'w') as f:\n",
    "    for e in eval_sql_results:\n",
    "        f.write(json.dumps(e, indent=None) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer = all; Sect = s->t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mix_layers = [ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') for l in range(24)]\n",
    "section_pairs = [('struct', 'text')]\n",
    "\n",
    "all_preds = []\n",
    "eval_sql_results = []\n",
    "\n",
    "for ex_id, ex in enumerate(tqdm(processed_spider_dev[::111])):\n",
    "    with add_enc_attention_edit(mt=mt_uskg,\n",
    "                            ex=ex,\n",
    "                            mix_layers=mix_layers,\n",
    "                            section_pairs=section_pairs,\n",
    "                            attn_corrupt_type='weights'):\n",
    "        pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "    \n",
    "    eval_res = evaluate_sql(evaluator, db_name=ex['db_id'], gold=ex['seq_out'], predicted=pred)\n",
    "        \n",
    "    all_preds.append(pred)\n",
    "    eval_sql_results.append(eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "avg_exact, avg_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = os.path.join(a1_0_result_dir, 'predictions-layer=all-sect=s->t.txt')\n",
    "eval_path = os.path.join(a1_0_result_dir, 'evals-layer=all-sect=s->t.jsonl')\n",
    "\n",
    "with open(pred_path, 'w') as f:\n",
    "    for p in all_preds:\n",
    "        f.write(p + '\\n')\n",
    "\n",
    "with open(eval_path, 'w') as f:\n",
    "    for e in eval_sql_results:\n",
    "        f.write(json.dumps(e, indent=None) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer = low; Sect = s->t\n",
    "- Using \"s->t\" since it's shown ineffective (though better than t->s) and give the potential of isolated (non-contextualized) struct embedding in applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mix_layers = [ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') for l in range(12)]\n",
    "section_pairs = [('struct', 'text')]\n",
    "\n",
    "all_preds = []\n",
    "eval_sql_results = []\n",
    "\n",
    "for ex_id, ex in enumerate(tqdm(processed_spider_dev[::111])):\n",
    "    with add_enc_attention_edit(mt=mt_uskg,\n",
    "                            ex=ex,\n",
    "                            mix_layers=mix_layers,\n",
    "                            section_pairs=section_pairs,\n",
    "                            attn_corrupt_type='weights'):\n",
    "        pred = pred_sql(mt_uskg, ex, padding=False)\n",
    "    \n",
    "    eval_res = evaluate_sql(evaluator, db_name=ex['db_id'], gold=ex['seq_out'], predicted=pred)\n",
    "            \n",
    "    all_preds.append(pred)\n",
    "    eval_sql_results.append(eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.5)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "avg_exact, avg_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = os.path.join(a1_0_result_dir, 'predictions-layer=low-sect=s->t.txt')\n",
    "eval_path = os.path.join(a1_0_result_dir, 'evals-layer=low-sect=s->t.jsonl')\n",
    "\n",
    "with open(pred_path, 'w') as f:\n",
    "    for p in all_preds:\n",
    "        f.write(p + '\\n')\n",
    "\n",
    "with open(eval_path, 'w') as f:\n",
    "    for e in eval_sql_results:\n",
    "        f.write(json.dumps(e, indent=None) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "706px",
    "left": "38px",
    "top": "171px",
    "width": "259px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

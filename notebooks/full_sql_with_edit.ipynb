{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/causal_trace.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Tracing\n",
    "\n",
    "A demonstration of the double-intervention causal tracing method.\n",
    "\n",
    "The strategy used by causal tracing is to understand important\n",
    "states within a transfomer by doing two interventions simultaneously:\n",
    "\n",
    "1. Corrupt a subset of the input.  In our paper, we corrupt the subject tokens\n",
    "   to frustrate the ability of the transformer to accurately complete factual\n",
    "   prompts about the subject.\n",
    "2. Restore a subset of the internal hidden states.  In our paper, we scan\n",
    "   hidden states at all layers and all tokens, searching for individual states\n",
    "   that carry the necessary information for the transformer to recover its\n",
    "   capability to complete the factual prompt.\n",
    "\n",
    "The traces of decisive states can be shown on a heatmap.  This notebook\n",
    "demonstrates the code for conducting causal traces and creating these heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `experiments.causal_trace` module contains a set of functions for running causal traces.\n",
    "\n",
    "In this notebook, we reproduce, demonstrate and discuss the interesting functions.\n",
    "\n",
    "We begin by importing several utility functions that deal with tokens and transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import defaultdict, Counter\n",
    "from util import nethook\n",
    "from util.globals import DATA_DIR\n",
    "from experiments.causal_trace import (\n",
    "    ModelAndTokenizer,\n",
    "    layername,\n",
    "    guess_subject,\n",
    "    plot_trace_heatmap,\n",
    ")\n",
    "from experiments.causal_trace import (\n",
    "    make_inputs,\n",
    "    decode_tokens,\n",
    "    find_token_range,\n",
    "    predict_token,\n",
    "    predict_from_input,\n",
    "    collect_embedding_std,\n",
    ")\n",
    "from dsets import KnownsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f35ae2abc10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "# from uskg.models.unified.prefixtuning import Model\n",
    "from uskg.models.unified import finetune, prefixtuning\n",
    "from uskg.utils.configue import Configure\n",
    "from uskg.utils.training_arguments import WrappedSeq2SeqTrainingArguments\n",
    "from uskg.seq2seq_construction import spider as s2s_spider\n",
    "from uskg.third_party.spider.preprocess.get_tables import dump_db_json_schema\n",
    "from uskg.third_party.spider import evaluation as sp_eval\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# import stanza\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "\n",
    "from experiments import causal_trace_uskg as ctu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tokenizer_uskg: hkunlp/from_all_T5_large_prefix_spider_with_cell_value2\n",
      "Using tokenizer_fast: t5-large\n",
      "prefix-tuning sequence length is 10.\n"
     ]
    }
   ],
   "source": [
    "mt_uskg = ctu.ModelAndTokenizer_USKG('t5-large-prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('constructor', 'seq2seq_construction.spider'),\n",
       " ('schema_serialization_with_db_content', True),\n",
       " ('target_with_db_id', False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mt_uskg.task_args.seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.model.pretrain_model.encoder.embed_tokens is mt_uskg.model.pretrain_model.shared, \\\n",
    "mt_uskg.model.pretrain_model.decoder.embed_tokens is mt_uskg.model.pretrain_model.shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.model.preseqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [k for k,v in mt_uskg.model.named_parameters()]\n",
    "# [k for k,v in mt_uskg.model.named_modules()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spider dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_train_path = '/home/yshao/Projects/SDR-analysis/data/spider/train+ratsql_graph.json'\n",
    "spider_dev_path = '/home/yshao/Projects/SDR-analysis/data/spider/dev+ratsql_graph.json'\n",
    "spider_db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev = ctu.load_raw_dataset(\n",
    "    data_filepath = spider_dev_path,\n",
    "    db_path=spider_db_dir,\n",
    "#     schema_cache=SCHEMA_CACHE\n",
    ")\n",
    "len(raw_spider_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_spider_dev[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.task_args.dataset.use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_spider_dev = s2s_spider.DevDataset(\n",
    "    args=mt_uskg.task_args,\n",
    "    raw_datasets=raw_spider_dev,\n",
    "    cache_root='../cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What are the names of all European countries with at least 3 manufacturers?',\n",
       " '| car_1 | continents : contid , continent ( europe ) | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.countryname from countries as t1 join continents as t2 on t1.continent = t2.contid join car_makers as t3 on t1.countryid = t3.country where t2.continent = 'europe' group by t1.countryname having count(*) >= 3;\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = 130\n",
    "processed_spider_dev[_id]['text_in'], \\\n",
    "processed_spider_dev[_id]['struct_in'], \\\n",
    "processed_spider_dev[_id]['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_enc_sentence = f\"{processed_spider_dev[_id]['text_in']}; structed knowledge: {processed_spider_dev[_id]['struct_in']}\"\n",
    "_toks = mt_uskg.tokenizer.tokenize(_enc_sentence)\n",
    "len(_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # _occ_punct = set()\n",
    "\n",
    "# for _id in range(len(processed_spider_dev)):\n",
    "#     ex = processed_spider_dev[_id]\n",
    "# #     _occ_punct.update(set(string.punctuation) & set(ex['seq_out']))\n",
    "#     if '_(' in ex['struct_in']:\n",
    "#         print(_id, ex['question'])\n",
    "#         print(ex['struct_in'])\n",
    "#         print(ex['seq_out'])\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Train set\n",
    "\n",
    "# raw_spider_train = ctu.load_raw_dataset(\n",
    "#     data_filepath = spider_train_path,\n",
    "#     db_path=spider_db_dir,\n",
    "# )\n",
    "# processed_spider_train = s2s_spider.TrainDataset(\n",
    "#     args=mt_uskg.task_args,\n",
    "#     raw_datasets=raw_spider_train,\n",
    "#     cache_root='../cache')\n",
    "# len(processed_spider_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_spider_train[5441]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "- merged in create_analysis_sample_dicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = '/home/yshao/Projects/language/language/xsp/data/spider/tables.json'\n",
    "db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmaps = sp_eval.build_foreign_key_map_from_json(table_path)\n",
    "evaluator = sp_eval.Evaluator(db_dir=db_dir, kmaps=kmaps, etype='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctu.evaluate_hardness.evaluator = evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0, 0, 'hard')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "_sql_str = 'select t1.birth_date from people as t1 join poker_player as t2 on t1.people_id = t2.people_id order by t2.earnings asc limit 1'\n",
    "db_name = 'poker_player'\n",
    "schema = evaluator.schemas[db_name]\n",
    "_sql = sp_eval.get_sql(schema, _sql_str)\n",
    "sp_eval.count_component1(_sql), sp_eval.count_component2(_sql), sp_eval.count_others(_sql), \\\n",
    "evaluator.eval_hardness(_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USKG error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from play_pred()\n",
    "\n",
    "def pred_sql(mt, ex):\n",
    "    text_in = ex['text_in']\n",
    "    struct_in = ex['struct_in']\n",
    "\n",
    "    txt = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "    \n",
    "    tokenized_txt = mt.tokenizer_uskg([txt], max_length=1024, padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    device = mt.model.device\n",
    "    pred = mt.tokenizer_uskg.batch_decode(\n",
    "      mt.model.generate(\n",
    "        torch.tensor(tokenized_txt.data['input_ids'], dtype=int, device=device),\n",
    "        torch.tensor(tokenized_txt.data['attention_mask'], dtype=int, device=device),\n",
    "        num_beams=1, \n",
    "        max_length=256\n",
    "        ), \n",
    "      skip_special_tokens=True \n",
    "    )\n",
    "    return pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from evaluator.evaluate_one()\n",
    "\n",
    "def evaluate_sql(evaluator, db_name, gold, predicted):\n",
    "    schema = evaluator.schemas[db_name]\n",
    "    g_sql = sp_eval.get_sql(schema, gold)\n",
    "    hardness = evaluator.eval_hardness(g_sql)\n",
    "    # self.scores[hardness][\"count\"] += 1\n",
    "    # self.scores[\"all\"][\"count\"] += 1\n",
    "\n",
    "    parse_error = False\n",
    "    try:\n",
    "        p_sql = sp_eval.get_sql(schema, predicted)\n",
    "    except:\n",
    "        # If p_sql is not valid, then we will use an empty sql to evaluate with the correct sql\n",
    "        p_sql = {\n",
    "            \"except\": None,\n",
    "            \"from\": {\"conds\": [], \"table_units\": []},\n",
    "            \"groupBy\": [],\n",
    "            \"having\": [],\n",
    "            \"intersect\": None,\n",
    "            \"limit\": None,\n",
    "            \"orderBy\": [],\n",
    "            \"select\": [False, []],\n",
    "            \"union\": None,\n",
    "            \"where\": [],\n",
    "        }\n",
    "\n",
    "        # TODO fix\n",
    "        parse_error = True\n",
    "\n",
    "    # rebuild sql for value evaluation\n",
    "    kmap = evaluator.kmaps[db_name]\n",
    "    g_valid_col_units = sp_eval.build_valid_col_units(g_sql[\"from\"][\"table_units\"], schema)\n",
    "    g_sql = sp_eval.rebuild_sql_val(g_sql)\n",
    "    g_sql = sp_eval.rebuild_sql_col(g_valid_col_units, g_sql, kmap)\n",
    "    p_valid_col_units = sp_eval.build_valid_col_units(p_sql[\"from\"][\"table_units\"], schema)\n",
    "    p_sql = sp_eval.rebuild_sql_val(p_sql)\n",
    "    p_sql = sp_eval.rebuild_sql_col(p_valid_col_units, p_sql, kmap)\n",
    "    \n",
    "    exec_score = None\n",
    "    partial_scores = None\n",
    "    exact_score = None\n",
    "    if evaluator.etype in [\"all\", \"exec\"]:\n",
    "        exec_score = sp_eval.eval_exec_match(\n",
    "            evaluator.db_paths[db_name], predicted, gold, p_sql, g_sql\n",
    "        )\n",
    "        exec_score = int(exec_score)\n",
    "    if evaluator.etype in [\"all\", \"match\"]:\n",
    "        partial_scores = evaluator.eval_partial_match(p_sql, g_sql)\n",
    "        exact_score = evaluator.eval_exact_match(p_sql, g_sql, partial_scores)\n",
    "        # update_scores_match(self.scores, exact_score, hardness, partial_scores, PARTIAL_TYPES)\n",
    "\n",
    "    return {\n",
    "        \"predicted\": predicted,\n",
    "        \"gold\": gold,\n",
    "        \"predicted_parse_error\": parse_error,\n",
    "        \"hardness\": hardness,\n",
    "        \"exact\": exact_score,\n",
    "        \"partial\": partial_scores,\n",
    "        \"exec\": exec_score,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = '/home/yshao/Projects/language/language/xsp/data/spider/database'\n",
    "\n",
    "def execute_sql(db, sql_str):\n",
    "    db_path = os.path.join(db_dir, db, f'{db}.sqlite')\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(sql_str)\n",
    "        res = cursor.fetchall()\n",
    "    except:\n",
    "        res = 'ERROR'\n",
    "    conn.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = processed_spider_dev[503]\n",
    "ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('battle_death',\n",
       " \"How many battles did not lose any ship with tonnage '225'?\",\n",
       " \"select count(*) from battle where id not in ( select lost_in_battle from ship where tonnage = '225' );\",\n",
       " 'select count(*) from battle where id not in ( select lost_in_battle from ship where tonnage > 225 )')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pred_sql(mt_uskg, ex)\n",
    "ex['db_id'], ex['text_in'], ex['seq_out'], pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_in = ex['text_in']\n",
    "struct_in = ex['struct_in']\n",
    "txt = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "txt_toks = mt_uskg.tokenizer_uskg.tokenize(txt)\n",
    "len(txt_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"select count(*) from battle where id not in ( select lost_in_battle from ship where tonnage = '225' );\",\n",
       " [(7,)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_res = execute_sql(ex['db_id'], ex['seq_out'])\n",
    "ex['seq_out'], exec_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('select count(*) from battle where id not in ( select lost_in_battle from ship where tonnage > 225 )',\n",
       " [(3,)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_res = execute_sql(ex['db_id'], pred)\n",
    "pred, exec_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8,)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_pred = \"\"\"\n",
    "SELECT COUNT(DISTINCT battle.id) AS num_battles\n",
    "FROM battle\n",
    "LEFT JOIN ship ON battle.id = ship.lost_in_battle\n",
    "WHERE (ship.tonnage != '225' OR ship.tonnage IS NULL)\n",
    "\"\"\"\n",
    "\n",
    "execute_sql(ex['db_id'], chatgpt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spider_ex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_res \u001b[38;5;241m=\u001b[39m evaluate_sql(evaluator, db_name\u001b[38;5;241m=\u001b[39m\u001b[43mspider_ex\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdb_id\u001b[39m\u001b[38;5;124m'\u001b[39m], gold\u001b[38;5;241m=\u001b[39mspider_ex[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_out\u001b[39m\u001b[38;5;124m'\u001b[39m], predicted\u001b[38;5;241m=\u001b[39mpred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spider_ex' is not defined"
     ]
    }
   ],
   "source": [
    "# eval_res = evaluate_sql(evaluator, db_name=spider_ex['db_id'], gold=spider_ex['seq_out'], predicted=pred)\n",
    "# eval_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab76cae127742adbc790384e85093b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: rerun with tokenizer_uskg decoding (?)\n",
    "\n",
    "eval_sql_results = []\n",
    "\n",
    "for ex_id, ex in enumerate(tqdm(processed_spider_dev)):\n",
    "    pred = pred_sql(mt_uskg, ex)\n",
    "    eval_res = evaluate_sql(evaluator, db_name=ex['db_id'], gold=ex['seq_out'], predicted=pred)\n",
    "    eval_sql_results.append(eval_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6692456479690522, 0.6808510638297872)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_exact = np.mean([d['exact'] for d in eval_sql_results])\n",
    "avg_exec = np.mean([d['exec'] for d in eval_sql_results])\n",
    "avg_exact, avg_exec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual error cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(eval_sql_results):\n",
    "    if d['exact'] and d['exec']:\n",
    "        continue\n",
    "    err_msg = ('A' if not d['exact'] else '') + ('X' if not d['exec'] else '')\n",
    "    ex = processed_spider_dev[i]\n",
    "    print(f'ID = {i}: {err_msg}  ({ex[\"db_id\"]}) {ex[\"text_in\"]}')\n",
    "    print(f'Pred: {d[\"predicted\"]}')\n",
    "    print(f'Gold: {d[\"gold\"]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator.schemas['dog_kennels'].schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc by db_id \n",
    "eval_sql_results_by_db_id = defaultdict(list)\n",
    "\n",
    "for i, d in enumerate(eval_sql_results):\n",
    "    d['ex_id'] = i\n",
    "    ex = processed_spider_dev[i]\n",
    "    db_id = ex['db_id']\n",
    "    eval_sql_results_by_db_id[db_id].append(d)\n",
    "\n",
    "len(eval_sql_results_by_db_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concert_singer\t0.8889\t0.8889\n",
      "pets_1\t0.5714\t0.7381\n",
      "car_1\t0.3478\t0.3913\n",
      "flight_2\t0.7000\t0.7500\n",
      "employee_hire_evaluation\t0.9474\t0.9737\n",
      "cre_Doc_Template_Mgt\t0.8333\t0.9048\n",
      "course_teach\t0.8667\t0.9333\n",
      "museum_visit\t0.7222\t0.8333\n",
      "wta_1\t0.6774\t0.6129\n",
      "battle_death\t0.5000\t0.5000\n",
      "student_transcripts_tracking\t0.6667\t0.6795\n",
      "tvshow\t0.7258\t0.6613\n",
      "poker_player\t0.8750\t0.8750\n",
      "voter_1\t0.6000\t0.6667\n",
      "world_1\t0.5083\t0.4833\n",
      "orchestra\t0.8000\t0.8750\n",
      "network_1\t0.6250\t0.4643\n",
      "dog_kennels\t0.5854\t0.5976\n",
      "singer\t0.8667\t0.8667\n",
      "real_estate_properties\t0.5000\t0.5000\n"
     ]
    }
   ],
   "source": [
    "for db_id, results in eval_sql_results_by_db_id.items():\n",
    "    _avg_exact = np.mean([d['exact'] for d in results])\n",
    "    _avg_exec = np.mean([d['exec'] for d in results])\n",
    "    print(f'{db_id}\\t{_avg_exact:.4f}\\t{_avg_exec:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full SQL prediction with edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from play_pred()\n",
    "\n",
    "def pred_sql(mt, ex):\n",
    "    text_in = ex['text_in']\n",
    "    struct_in = ex['struct_in']\n",
    "\n",
    "    txt = f\"{text_in}; structed knowledge: {struct_in}\"\n",
    "    \n",
    "    tokenized_txt = mt.tokenizer_uskg([txt], max_length=1024, padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    device = mt.model.device\n",
    "    pred = mt.tokenizer_uskg.batch_decode(\n",
    "      mt.model.generate(\n",
    "        torch.tensor(tokenized_txt.data['input_ids'], dtype=int, device=device),\n",
    "        torch.tensor(tokenized_txt.data['attention_mask'], dtype=int, device=device),\n",
    "        num_beams=1, \n",
    "        max_length=256\n",
    "        ), \n",
    "      skip_special_tokens=True \n",
    "    )\n",
    "    return pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_analysis_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the accelerate of the car make amc hornet sportabout (sw)?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\")"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_id = 111\n",
    "a_ex_id = 0\n",
    "\n",
    "ex = processed_spider_dev[ex_id]\n",
    "ex['text_in'], \\\n",
    "ex['struct_in'], \\\n",
    "ex['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp test\n",
    "# ex['seq_out'] = 'select year from cars_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex_list = ctu.create_analysis_sample_dicts(\n",
    "                mt_uskg, ex,\n",
    "                subject_type='column',\n",
    "                remove_struct_duplicate_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'question', 'db_id', 'db_path', 'db_table_names', 'db_column_names', 'db_column_types', 'db_primary_keys', 'db_foreign_keys', 'rat_sql_graph', 'serialized_schema', 'struct_in', 'text_in', 'seq_out', 'enc_sentence', 'enc_tokenized', 'text_range', 'struct_range', 'struct_node_ranges_dict', 'dec_prompt', 'expect', 'expect_type', 'remove_struct_duplicate_nodes', 'parsed_struct_in', 'col2table', 'token_ranges_dict', 'node_name_ranges', 'expect_input_ranges', 'alias2table', 'self_ranges', 'context_ranges', 'category'])"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[a_ex_id].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 'cars_data', 't2': 'car_names'}"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex_list[a_ex_id]['alias2table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(d['dec_prompt'], d['expect'], d['node_name_ranges'], d['expect_input_ranges'], '------',\\\n",
    "  d['self_ranges'], d['context_ranges'],\\\n",
    "  d['category'], '------' * 2) for d in a_ex_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(a_ex_list[a_ex_id])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ctu.add_clean_prediction(mt_uskg, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parse_sql_alias2table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 'table_name', 't2': 'other_table', 't3': 'ttt'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sql = 'SELECT t2.aaa , t3.ccc FROM table_name as t1 JOIN other_table as t2 on table_name.a_a = other_table.b_a JOIN ttt as t3 on other_table.asth = ttt.asth'\n",
    "ctu.parse_sql_alias2table(_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['select t2.aaa, distinct(t3.ccc), count(*) from table_name as t1 join other_table as t2 on table_name.a_a = other_table.b_a join ttt as t3 on other_table.asth = ttt.asth where t2.col like',\n",
       " 'select t2.aaa, distinct(t3.ccc), count(*) from table_name as t1 join other_table as t2 on table_name.a_a = other_table.b_a join ttt as t3 on other_table.asth = ttt.asth where t2.col like %hey']"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sql = 'SELECT t2.aaa, DISTINCT(t3.ccc), COUNT(*) FROM table_name as t1 JOIN other_table as t2 on table_name.a_a = other_table.b_a JOIN ttt as t3 on other_table.asth = ttt.asth WHERE t2.col like %hey%'.lower()\n",
    "prompts = ctu.make_syntax_dec_prompt(_sql, '%', is_punct=True)\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "('.', ['select', 't1', '.', 'accelerate', 'from', 'cars_data', 'as', 't1', 'join', 'car_names', 'as', 't2', 'on', 't1', '.', 'id', '=', 't2', '.', 'makeid', 'where', 't2', '.', 'make', '=', \"'\", 'amc', 'hornet', 'sportabout', '(', 'sw', ')', \"'\", ';'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [875]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a_ex_list_syntax \u001b[38;5;241m=\u001b[39m \u001b[43mctu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_syntax_analysis_sample_dicts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmt_uskg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/rome/notebooks/experiments/causal_trace_uskg.py:2424\u001b[0m, in \u001b[0;36mcreate_syntax_analysis_sample_dicts\u001b[0;34m(mt, ex)\u001b[0m\n\u001b[1;32m   2422\u001b[0m _phrase \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_phrase_cache)\n\u001b[1;32m   2423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _phrase:\n\u001b[0;32m-> 2424\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m _phrase \u001b[38;5;129;01min\u001b[39;00m SQL_SYNTAX_PHRASES \u001b[38;5;241m+\u001b[39m SQL_SYNTAX_PUNCTS, (_phrase, sql_tokens)\n\u001b[1;32m   2425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _phrase \u001b[38;5;129;01min\u001b[39;00m SQL_SYNTAX_PHRASES:\n\u001b[1;32m   2426\u001b[0m         syntax_phrases\u001b[38;5;241m.\u001b[39madd(_phrase)\n",
      "\u001b[0;31mAssertionError\u001b[0m: ('.', ['select', 't1', '.', 'accelerate', 'from', 'cars_data', 'as', 't1', 'join', 'car_names', 'as', 't2', 'on', 't1', '.', 'id', '=', 't2', '.', 'makeid', 'where', 't2', '.', 'make', '=', \"'\", 'amc', 'hornet', 'sportabout', '(', 'sw', ')', \"'\", ';'])"
     ]
    }
   ],
   "source": [
    "a_ex_list_syntax = ctu.create_syntax_analysis_sample_dicts(\n",
    "                mt_uskg, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### context_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the name of the different car makers who produced a car in 1970?',\n",
       " '| car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'select year from cars_data',\n",
       " 'year')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex = dict(a_ex_list[0])\n",
    "a_ex['text_in'], a_ex['struct_in'], a_ex['seq_out'], a_ex['expect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ex['alias2table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "# For full context tokens, use [0, L] and [R, -1]\n",
    "# L: node left max end index ; R: node right min start index\n",
    "\n",
    "token_ranges_dict = a_ex['token_ranges_dict']\n",
    "_all_node_range_lists = list(token_ranges_dict['col_name_ranges'].values()) + list(token_ranges_dict['table_name_ranges'].values()) + list(token_ranges_dict['db_id_ranges'].values())\n",
    "_all_node_ranges = [rg\n",
    "                    for rg_list in _all_node_range_lists\n",
    "                    for rg in rg_list]\n",
    "_all_left_endpoint = [s for s, e in _all_node_ranges] + [struct_range[1]]\n",
    "_all_right_endpoint = [e for s, e in _all_node_ranges] + [struct_range[0]]\n",
    "# TODO: pull this part out to the shared function (e.g. create_analysis_sample_dicts)\n",
    "# TODO: test for columns on ends\n",
    "\n",
    "expect_input_ranges = a_ex['expect_input_ranges']    # list of ranges of node-of-interest (code allows dup)\n",
    "# tok_indices = [i for s, e in expect_input_ranges for i in range(s, e)]\n",
    "# expect_input_indices = [i for s, e in expect_input_ranges for i in range(s, e)]\n",
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "# node = a_ex['expect']\n",
    "\n",
    "context_range_endpoints = [struct_range[0]]\n",
    "self_range_endpoints = []       # This is different from `expect_input_ranges`: this includes boundary toks\n",
    "for tok_s, tok_e in expect_input_ranges:\n",
    "    _l = max([e for e in _all_right_endpoint if e <= tok_s])\n",
    "    _r = min([s for s in _all_left_endpoint if s >= tok_e])\n",
    "    context_range_endpoints.extend([_l, _r])\n",
    "    self_range_endpoints.extend([_l, _r])\n",
    "context_range_endpoints.append(struct_range[1])\n",
    "\n",
    "self_ranges = [(self_range_endpoints[i], self_range_endpoints[i+1])\n",
    "                for i in range(0, len(self_range_endpoints), 2)]\n",
    "self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "\n",
    "context_ranges = [(context_range_endpoints[i], context_range_endpoints[i+1])\n",
    "                    for i in range(0, len(context_range_endpoints), 2)]\n",
    "context_ranges = [(s, e) for s, e in context_ranges if e > s]\n",
    "context_tok_indices = corrupt_tok_indices = [i for s, e in context_ranges for i in range(s, e)]\n",
    "\n",
    "text_tok_indices = list(range(*text_range))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(137, 140)], [(24, 137)])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_ranges, context_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_tok_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", year\n"
     ]
    }
   ],
   "source": [
    "for s, e in self_ranges:\n",
    "    _piece = tokenizer.decode(a_ex['enc_tokenized']['input_ids'][s : e])\n",
    "    print(_piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| car_1 | continents : contid, continent | countries : countryid, countryname, continent | car_makers : id, maker, fullname, country | model_list : modelid, maker, model | car_names : makeid, model, make | cars_data : id, mpg, cylinders, edispl, horsepower, weight, accelerate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s, e in context_ranges:\n",
    "    _piece = tokenizer.decode(a_ex['enc_tokenized']['input_ids'][s : e])\n",
    "    print(_piece)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_uskg_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = dict(a_ex_list[a_ex_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the name of the different car makers who produced a car in 1970?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker , fullname , country | model_list : modelid , maker , model | car_names : makeid , model , make | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'select distinct t1.maker from car_makers as t1 join model_list as t2 on t1.id = t2.maker join car_names as t3 on t2.model = t3.model join cars_data as t4 on t3.',\n",
       " 'makeid')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_sentence, dec_prompt, expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 11,\n",
    "    [dec_prompt] * 11,\n",
    "    answer=expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = ctu.run_model_forward_uskg(mt_uskg.model, **inp, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, torch.Size([11, 16, 141, 151]))"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers, (bsz, n_heads, seq_len, seq_len + prev_len)\n",
    "len(_out.encoder_attentions), _out.encoder_attentions[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, torch.Size([11, 16, 2, 151]))"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers, (bsz, n_heads, prompt_len, seq_len + prev_len)\n",
    "len(_out.cross_attentions), _out.cross_attentions[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, torch.Size([11, 16, 2, 12]))"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layers, (bsz, n_heads, prompt_len, prompt_len + prev_len)\n",
    "len(_out.decoder_attentions), _out.decoder_attentions[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'decoder_attention_mask'])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = dict(a_ex_list[a_ex_id])\n",
    "a_ex = ctu.add_clean_prediction(mt_uskg, a_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'Which city has the most frequent destination airport?; structed knowledge: | flight_2 | airlines : uid , airline , abbreviation , country | airports : city , airportcode , airportname , country , countryabbrev | flights : airline , flightno , sourceairport , destairport',\n",
       " 'seq_out': 'select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.city order by count(*) desc limit 1',\n",
       " 'dec_prompt': 'select t1.city from airports as t1 join flights as t2 on t1.airportcode = t2.destairport group by t1.',\n",
       " 'expect': 'city',\n",
       " 'expect_type': 'column',\n",
       " 'db_id': 'flight_2',\n",
       " 'expect_input_ranges': [(45, 46)],\n",
       " 'expect_table': 'airports',\n",
       " 'answer': 'city',\n",
       " 'base_score': 0.9983423948287964,\n",
       " 'answers_t': [6726],\n",
       " 'correct_prediction': True,\n",
       " 'category': {'sql_hardness': 'extra',\n",
       "  'node_role': 'group by',\n",
       "  'text_match': 'exact'}}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ctu.make_basic_result_dict(a_ex)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']\n",
    "answer = result['answer']\n",
    "answers_t = result['answers_t']\n",
    "\n",
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 11,\n",
    "    [dec_prompt] * 11,\n",
    "    answer=expect)\n",
    "\n",
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "self_ranges = a_ex['self_ranges']\n",
    "context_ranges = a_ex['context_ranges']\n",
    "\n",
    "self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "context_tok_indices = corrupt_tok_indices = [i for s, e in context_ranges for i in range(s, e)]\n",
    "text_tok_indices = list(range(*text_range))\n",
    "struct_tok_indices = list(range(*struct_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6726], 'city', 0.8450507521629333)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_t, answer, _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8450507521629333"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_to_corrupt = [(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                for tnum in text_tok_indices]\n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=states_to_corrupt,\n",
    "#     tokens_to_mix=corrupt_tok_indices,\n",
    "#     tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9952, device='cuda:0')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pair of identical input to test correctness \n",
    "\n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_patch_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 12))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 23))\n",
    "                    for tnum in struct_tok_indices],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=text_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    tokens_to_mix_1st_pass=context_tok_indices,\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9952, device='cuda:0')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_patch_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 12))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', 23))\n",
    "                    for tnum in struct_tok_indices],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                    for tnum in text_tok_indices],\n",
    "    states_to_corrupt_1st_pass=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", 0, \"embed\"))\n",
    "                    for tnum in context_tok_indices],\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253002524375916"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test corrupting attention \n",
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "#                     for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    states_to_corrupt=[(tnum, ctu.layername_uskg(mt_uskg.model, \"encoder\", l, \"self_attn\"))\n",
    "                    for tnum in text_tok_indices for l in range(mt_uskg.num_enc_layers)],\n",
    "    replace=True,\n",
    ").item()\n",
    "\n",
    "_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n for n, w in mt_uskg.model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_probs = ctu.run_repatch_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', l))\n",
    "                    for tnum in self_tok_indices for l in range(mt_uskg.num_enc_layers - 1)],\n",
    "    states_to_unpatch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "                    for tnum in self_tok_indices],\n",
    "    answer_len=len(answers_t),\n",
    "    tokens_to_mix=corrupt_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32102])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.], device='cuda:0'),\n",
       "indices=tensor([7634], device='cuda:0'))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(vocab_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs[0, 7634]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2642e-25, 1.2223e-15, 7.3942e-18,  ..., 9.1578e-20, 2.6884e-39,\n",
       "         2.8131e-39]], device='cuda:0')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trace - partial edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uskg.models.prompt.modeling_t5 import T5Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_t5_config = copy.deepcopy(mt_uskg.model.config)\n",
    "_t5_config.d_model = 10\n",
    "_t5_config.d_kv = 4\n",
    "_t5_config.num_heads = 3\n",
    "_t5_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Attention(\n",
       "  (q): Linear(in_features=10, out_features=12, bias=False)\n",
       "  (k): Linear(in_features=10, out_features=12, bias=False)\n",
       "  (v): Linear(in_features=10, out_features=12, bias=False)\n",
       "  (o): Linear(in_features=12, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_attn_module = T5Attention(config=_t5_config)\n",
    "test_attn_module.eval()\n",
    "test_attn_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('q.weight', torch.Size([12, 10])),\n",
       " ('k.weight', torch.Size([12, 10])),\n",
       " ('v.weight', torch.Size([12, 10])),\n",
       " ('o.weight', torch.Size([10, 12]))]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v.size()) for k, v in test_attn_module.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'q', 'k', 'v', 'o']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k, v in test_attn_module.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 7, 10]),\n",
       " [('prev_key', torch.Size([1, 3, 2, 4])),\n",
       "  ('prev_value', torch.Size([1, 3, 2, 4])),\n",
       "  ('prev_key_padding_mask', torch.Size([1, 2]))])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_bs = 1\n",
    "_test_seqlen = 7\n",
    "_test_prevlen = 2\n",
    "\n",
    "_test_h = torch.randn(_test_bs, _test_seqlen, _t5_config.d_model)\n",
    "# _test_h[:, 0] = 999.0\n",
    "_test_prefix = {\n",
    "    'prev_key': torch.randn(_test_bs, _t5_config.num_heads, _test_prevlen, _t5_config.d_kv),\n",
    "    'prev_value': torch.randn(_test_bs, _t5_config.num_heads, _test_prevlen, _t5_config.d_kv),\n",
    "    'prev_key_padding_mask': torch.zeros(_test_bs, _test_prevlen).bool()\n",
    "}\n",
    "_test_h.size(), [(k, v.size()) for k, v in _test_prefix.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8561, -0.0552,  0.3845,  1.1441, -1.2765, -0.6869, -0.9646,\n",
       "          -1.0255, -2.3659, -1.7153],\n",
       "         [ 1.0685, -0.1617,  0.8310, -1.7257,  0.3674,  1.7559,  0.5763,\n",
       "          -0.9344,  0.9016,  0.7490],\n",
       "         [-1.1887, -1.0820, -0.5925,  0.7623, -0.6538, -0.0067,  0.5618,\n",
       "           1.3310,  1.2580, -0.6973],\n",
       "         [ 0.2807,  0.0763, -0.3539,  0.9494, -0.1557, -0.7645, -0.2103,\n",
       "          -1.0175, -0.3029, -0.0376],\n",
       "         [ 0.0984,  0.5610, -2.3323,  1.3421, -1.0381, -1.8568, -0.7754,\n",
       "          -1.6037,  0.2501, -1.4155],\n",
       "         [-1.4474, -0.4784,  0.0972, -0.3393,  1.2340,  0.7611, -0.4786,\n",
       "           0.0506, -0.1188,  2.7051],\n",
       "         [ 2.0642, -0.0186, -0.8283,  1.0852,  0.9819, -0.4044,  0.9831,\n",
       "          -0.2723,  0.2037,  1.6401]]])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev_key': tensor([[[[-2.2578,  0.2019,  0.3287,  0.3906],\n",
       "           [-1.2143, -0.7039, -1.0298,  0.1425]],\n",
       " \n",
       "          [[ 0.3967,  1.5168,  0.0967,  1.4454],\n",
       "           [ 0.1648,  0.2483,  1.5992,  1.2469]],\n",
       " \n",
       "          [[ 1.3875,  0.4460, -0.2676, -1.2290],\n",
       "           [ 2.0209,  1.1736,  0.8446,  0.8827]]]]),\n",
       " 'prev_value': tensor([[[[ 0.8351,  1.2052,  1.4187, -0.5358],\n",
       "           [-1.4274,  0.2792,  2.0149,  1.3695]],\n",
       " \n",
       "          [[-0.0379,  1.8999, -0.4236, -0.9176],\n",
       "           [ 1.5794,  1.1735, -0.2925,  2.2855]],\n",
       " \n",
       "          [[ 1.1935,  0.9343, -0.5582,  0.8163],\n",
       "           [-1.3765,  0.4046,  1.0941,  0.4058]]]]),\n",
       " 'prev_key_padding_mask': tensor([[False, False]])}"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_mask = torch.zeros(1, 1, 1, _test_seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = test_attn_module.forward(\n",
    "    _test_h,\n",
    "    mask=_test_mask,\n",
    "    prefix=_test_prefix,\n",
    "    output_attentions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3544, 0.3264, 0.2939, 0.3878, 0.4695, 0.2997, 0.1775],\n",
       "         [0.4028, 0.1655, 0.2949, 0.5148, 0.4162, 0.4189, 0.4683],\n",
       "         [0.5839, 0.4639, 0.1393, 0.4925, 0.6272, 0.1917, 0.4634]]])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_out[3].sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_mask_attention(att, mix_mask):\n",
    "    # token 4,5,6 (in real_seq) not attending to 2 (in full_seq, i.e. 0 in real_seq)\n",
    "    # att: (bs, n_head, real_seq, full_seq)\n",
    "#     att[:, :, 4:, 2] = 0.0\n",
    "\n",
    "    _zero = torch.tensor(0, dtype=att.dtype)\n",
    "    att = torch.where(mix_mask, _zero, att)\n",
    "\n",
    "    print(att)\n",
    "    return att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ True, False,  True, False,  True, False,  True, False,  True],\n",
       "           [False, False, False, False, False, False, False, False, False],\n",
       "           [ True, False,  True, False,  True, False,  True, False,  True],\n",
       "           [False, False, False, False, False, False, False, False, False],\n",
       "           [ True, False,  True, False,  True, False,  True, False,  True],\n",
       "           [False, False, False, False, False, False, False, False, False],\n",
       "           [ True, False,  True, False,  True, False,  True, False,  True]]]]),\n",
       " tensor([[[[ True,  True, False, False, False,  True,  True,  True,  True],\n",
       "           [ True,  True, False, False, False,  True,  True,  True,  True],\n",
       "           [ True,  True, False, False, False,  True,  True,  True,  True],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False],\n",
       "           [ True,  True,  True,  True,  True, False, False, False, False]]]]))"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_mask = torch.zeros(1, 1, _test_seqlen, _test_seqlen + _test_prevlen, dtype=bool)\n",
    "mix_mask[:, :, ::2, ::2] = 1\n",
    "\n",
    "mix_mask_2 = torch.zeros(1, 1, _test_seqlen, _test_seqlen + _test_prevlen, dtype=bool)\n",
    "mix_mask_2[:, :, :, :_test_prevlen] = 1\n",
    "mix_mask_2[:, :, 3:, _test_prevlen : _test_prevlen+3] = 1\n",
    "mix_mask_2[:, :, :3, _test_prevlen+3 :] = 1\n",
    "\n",
    "mix_mask, mix_mask_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_mask | mix_mask_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attn_module.ext_attention_weights_fn = lambda att : _test_mask_attention(att, mix_mask_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x7fc33d6065e0>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test_attn_module.ext_attention_weights_fn)\n",
    "print(test_attn_module.ext_attention_logits_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_out = test_attn_module.forward(\n",
    "    _test_h,\n",
    "    mask=_test_mask,\n",
    "    prefix=_test_prefix,\n",
    "    output_attentions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ex = dict(a_ex_list[a_ex_id])\n",
    "a_ex = ctu.add_clean_prediction(mt_uskg, a_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_sentence': 'What is the accelerate of the car make amc hornet sportabout (sw)?; structed knowledge: | car_1 | continents : contid , continent | countries : countryid , countryname , continent | car_makers : id , maker ( amc ) , fullname , country | model_list : modelid , maker , model ( amc ) | car_names : makeid , model ( amc ) , make ( amc hornet , amc hornet sportabout (sw) ) | cars_data : id , mpg , cylinders , edispl , horsepower , weight , accelerate , year',\n",
       " 'seq_out': \"select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.make = 'amc hornet sportabout (sw)';\",\n",
       " 'dec_prompt': 'select t1.accelerate from cars_data as t1 join car_names as t2 on t1.id = t2.makeid where t2.',\n",
       " 'expect': 'make',\n",
       " 'expect_type': 'column',\n",
       " 'db_id': 'car_1',\n",
       " 'expect_input_ranges': [(121, 145)],\n",
       " 'expect_table': 'car_names',\n",
       " 'answer': 'make',\n",
       " 'base_score': 0.9998800754547119,\n",
       " 'answers_t': [19509],\n",
       " 'correct_prediction': True,\n",
       " 'category': {'sql_hardness': 'medium',\n",
       "  'node_role': 'where',\n",
       "  'text_match': 'exact'}}"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ctu.make_basic_result_dict(a_ex)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sentence = a_ex['enc_sentence']\n",
    "dec_prompt = a_ex['dec_prompt']\n",
    "expect = a_ex['expect']\n",
    "answer = result['answer']\n",
    "answers_t = result['answers_t']\n",
    "\n",
    "inp = ctu.make_inputs_t5(\n",
    "    mt_uskg.tokenizer,\n",
    "    [enc_sentence] * 2,\n",
    "    [dec_prompt] * 2,\n",
    "    answer=expect)\n",
    "\n",
    "text_range = a_ex['text_range']\n",
    "struct_range = a_ex['struct_range']\n",
    "\n",
    "self_ranges = a_ex['self_ranges']\n",
    "context_ranges = a_ex['context_ranges']\n",
    "\n",
    "self_tok_indices = [i for s, e in self_ranges for i in range(s, e)]\n",
    "context_tok_indices = corrupt_tok_indices = [i for s, e in context_ranges for i in range(s, e)]\n",
    "text_tok_indices = list(range(*text_range))\n",
    "struct_tok_indices = list(range(*struct_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score = ctu.trace_with_repatch_uskg(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     states_to_patch=[(tnum, ctu.layername_uskg(mt_uskg.model, 'encoder', mt_uskg.num_enc_layers - 1))\n",
    "#                     for tnum in range(*struct_range)],\n",
    "    states_to_patch=[],\n",
    "    states_to_unpatch=[],\n",
    "    answers_t=answers_t,\n",
    "    tokens_to_mix=context_tok_indices,\n",
    "    tokens_to_mix_individual_indices=True,\n",
    "    replace=True,\n",
    ").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([19509], 'make', 0.9987825751304626)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_t, answer, _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "_score = ctu.trace_attention_manip_uskg_multi_token(\n",
    "# _probs = ctu.run_attention_manip_uskg_multi_token(\n",
    "    model=mt_uskg.model,\n",
    "    inp=inp,\n",
    "#     answer_len=len(answers_t),\n",
    "    answers_t=answers_t,\n",
    "#     states_to_patch=[],\n",
    "    layers_to_mix=[ctu.layername_uskg(mt_uskg.model, 'encoder', l, 'self_attn') for l in range(24)],\n",
    "    src_tokens_to_mix=text_tok_indices + struct_tok_indices, # src doesn't have prefix \n",
    "#     src_tokens_to_mix=[-1],\n",
    "    tgt_tokens_to_mix=list(range(10)) + [i + 10 for i in text_tok_indices + struct_tok_indices],  # tgt has prefix \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.6447], device='cuda:0'),\n",
       "indices=tensor([4350], device='cuda:0'))"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_probs.max(dim=-1)\n",
    "# _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name'"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_uskg.tokenizer.decode([4350])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctu.layername_uskg(mt_uskg.model, 'encoder', 0, 'self_attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nested_json_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[0.4967141530112327, -0.13826430117118466],\n",
       "   [0.6476885381006925, 1.5230298564080254]],\n",
       "  [[-0.23415337472333597, -0.23413695694918055],\n",
       "   [1.5792128155073915, 0.7674347291529088]]],\n",
       " [[[-0.4694743859349521, 0.5425600435859647],\n",
       "   [-0.46341769281246226, -0.46572975357025687]],\n",
       "  [[0.24196227156603412, -1.913280244657798],\n",
       "   [-1.7249178325130328, -0.5622875292409727]]]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(2,2,2,2).tolist()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctu.nested_list_processing(a, func=lambda x: np.format_float_positional(x, precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [[[[0.4967141530112327, -0.13826430117118466],\n",
       "    [0.6476885381006925, 1.5230298564080254]],\n",
       "   [[-0.23415337472333597, -0.23413695694918055],\n",
       "    [1.5792128155073915, 0.7674347291529088]]],\n",
       "  [[[-0.4694743859349521, 0.5425600435859647],\n",
       "    [-0.46341769281246226, -0.46572975357025687]],\n",
       "   [[0.24196227156603412, -1.913280244657798],\n",
       "    [-1.7249178325130328, -0.5622875292409727]]]],\n",
       " 'a_list': {'a0': [[[0.4967141530112327, -0.13826430117118466],\n",
       "    [0.6476885381006925, 1.5230298564080254]],\n",
       "   [[-0.23415337472333597, -0.23413695694918055],\n",
       "    [1.5792128155073915, 0.7674347291529088]]],\n",
       "  'a1_list': {'a10': [[-0.4694743859349521, 0.5425600435859647],\n",
       "    [-0.46341769281246226, -0.46572975357025687]],\n",
       "   'a11': [[0.24196227156603412, -1.913280244657798],\n",
       "    [-1.7249178325130328, -0.5622875292409727]]}}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {\n",
    "    'a': a,\n",
    "    'a_list': {\n",
    "        'a0': a[0],\n",
    "        'a1_list': {\n",
    "            'a10': a[1][0],\n",
    "            'a11': a[1][1],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [[[['0.5', '-0.14'], ['0.65', '1.52']],\n",
       "   [['-0.23', '-0.23'], ['1.58', '0.77']]],\n",
       "  [[['-0.47', '0.54'], ['-0.46', '-0.47']],\n",
       "   [['0.24', '-1.91'], ['-1.72', '-0.56']]]],\n",
       " 'a_list': {'a0': [[['0.5', '-0.14'], ['0.65', '1.52']],\n",
       "   [['-0.23', '-0.23'], ['1.58', '0.77']]],\n",
       "  'a1_list': {'a10': [['-0.47', '0.54'], ['-0.46', '-0.47']],\n",
       "   'a11': [['0.24', '-1.91'], ['-1.72', '-0.56']]}}}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.nested_json_processing(b, func=lambda x: np.format_float_positional(x, precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = mt_uskg.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁mar', 'y', ':', '▁has', '▁', 'a', '▁little', '▁lamb', 'b', 'b'],\n",
       " ['▁mar', 'y', ':', '▁has', '▁', 'a', '▁little', '▁lamb', 'b', 'b'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"mary: has a little  lambbb\"\n",
    "s_ = \"mary: has a little lambbb\"\n",
    "tokenizer.tokenize(s), tokenizer.tokenize(s_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3157, 63, 10, 65, 3, 9, 385, 17871, 115, 115, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tokenizer(s)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '▁mar'),\n",
       " (1, 'y'),\n",
       " (2, ':'),\n",
       " (3, '▁has'),\n",
       " (4, '▁'),\n",
       " (5, 'a'),\n",
       " (6, '▁little'),\n",
       " (7, '▁lamb'),\n",
       " (8, 'b'),\n",
       " (9, 'b'),\n",
       " (10, '</s>')]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(t.tokens()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenSpan(start=7, end=10)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_to_tokens(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lambbb'"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.decode_sentences(tokenizer, t['input_ids'][7:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"(a(a)a)\".rindex(\")\"), \"(a(a)a)\".index(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = \"\"\"| concert_singer | singer : singer_id , name ( First Last ) , country ( France , Germany , United States ) , \\\n",
    "song_name , song_release_year , age , is_male\"\"\"\n",
    "\n",
    "tokenizer.tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test struct_in parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "_struct_in = \"\"\"| concert_singer | stadium : stadium_id , location , name , capacity , highest , lowest , \\\n",
    "average | singer : singer_id , name ( First Last ) , country ( France , Germany , United States ) , \\\n",
    "song_name , song_release_year , age , is_male | concert : concert_id , concert_name , theme , \\\n",
    "stadium_id , year ( 2008 , 2012 , 2022 ) | singer_in_concert : concert_id , singer_id\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((3, 'stadium'),\n",
       "  [[(5, 'stadium_id'), []],\n",
       "   [(7, 'location'), []],\n",
       "   [(9, 'name'), []],\n",
       "   [(11, 'capacity'), []],\n",
       "   [(13, 'highest'), []],\n",
       "   [(15, 'lowest'), []],\n",
       "   [(17, 'average'), []]]),\n",
       " ((19, 'singer'),\n",
       "  [[(21, 'singer_id'), []],\n",
       "   [(23, 'name'), [(25, 'First Last')]],\n",
       "   [(29, 'country'), [(31, 'France'), (33, 'Germany'), (35, 'United States')]],\n",
       "   [(39, 'song_name'), []],\n",
       "   [(41, 'song_release_year'), []],\n",
       "   [(43, 'age'), []],\n",
       "   [(45, 'is_male'), []]]),\n",
       " ((47, 'concert'),\n",
       "  [[(49, 'concert_id'), []],\n",
       "   [(51, 'concert_name'), []],\n",
       "   [(53, 'theme'), []],\n",
       "   [(55, 'stadium_id'), []],\n",
       "   [(57, 'year'), [(59, '2008'), (61, '2012'), (63, '2022')]]]),\n",
       " ((66, 'singer_in_concert'),\n",
       "  [[(68, 'concert_id'), []], [(70, 'singer_id'), []]])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctu.parse_struct_in(_struct_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "_text_in = text_in\n",
    "\n",
    "enc_sentence = f\"{_text_in}; structed knowledge: {_struct_in}\"\n",
    "enc_tokenized = mt_uskg.tokenizer(enc_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ranges_dict = ctu.find_struct_name_ranges(mt_uskg.tokenizer, enc_tokenized['input_ids'], _struct_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_ranges_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d_key, d in token_ranges_dict.items():\n",
    "    for name, ranges in d.items():\n",
    "        for s, e in ranges:\n",
    "            recs_name = ctu.decode_sentences(mt_uskg.tokenizer, enc_tokenized['input_ids'][s:e])\n",
    "            print(f'{d_key}\\t{name}\\t{recs_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "706px",
    "left": "38px",
    "top": "171px",
    "width": "259px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
